<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Like</title>
  
  <subtitle>哈哈哈</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://liketea.xyz/"/>
  <updated>2021-08-28T13:22:48.985Z</updated>
  <id>http://liketea.xyz/</id>
  
  <author>
    <name>Like</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Spark 指南：Spark SQL（二）—— 结构化操作</title>
    <link href="http://liketea.xyz/Spark/Spark/Spark%20%E6%8C%87%E5%8D%97%EF%BC%9ASpark%20SQL%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%20%E7%BB%93%E6%9E%84%E5%8C%96%E6%93%8D%E4%BD%9C/"/>
    <id>http://liketea.xyz/Spark/Spark/Spark 指南：Spark SQL（二）—— 结构化操作/</id>
    <published>2021-08-05T06:16:46.000Z</published>
    <updated>2021-08-28T13:22:48.985Z</updated>
    
    <content type="html"><![CDATA[<p>从定义上讲，DataFrame 由一系列行和列组成，行的类型为 Row，列可以表示成每个单独行的计算表达式。Schema 定义了每个列的名称和类型，Partition 定义了整个集群中 DataFrame 的物理分布。</p><h2 id="Schema"><a href="#Schema" class="headerlink" title="Schema"></a>Schema</h2><p>Schema 定义了 DataFrame 的列名和类型，我们可以让数据源定义 Schema（schema-on-read），也可以自己明确地进行定义。对于临时分析，schema-on-read 通常效果很好，但是这也可能导致精度问题，例如在读取文件时将 Long 型错误地设置为整型，在生产环境中手动定义 Schema 通常是更好的选择，尤其是在使用 CSV 和 JSON 等无类型数据源时。</p><p>Schema 是一种 structType，由很多 StructFields 组成，每个 StructField 具有名称、类型和布尔值标识（用于指示该列是否可以为 null），最后用户可以选择指定与该列关联的元数据，元数据是一种存储有关此列的信息的方式（Spark 在其机器学习库中使用此信息）。如果数据中的类型与 Schema 不匹配，Spark 将引发错误。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> schema = <span class="type">StructType</span>(</span><br><span class="line">    <span class="type">Array</span>(</span><br><span class="line">        <span class="type">StructField</span>(<span class="string">&quot;name&quot;</span>, <span class="type">StringType</span>, <span class="literal">true</span>),</span><br><span class="line">        <span class="type">StructField</span>(<span class="string">&quot;age&quot;</span>, <span class="type">IntegerType</span>, <span class="literal">false</span>)</span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line"><span class="keyword">val</span> data = spark.sparkContext.parallelize(<span class="type">Seq</span>(</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;like&quot;</span>, <span class="number">18</span>),</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;arya&quot;</span>, <span class="number">24</span>)</span><br><span class="line">))</span><br><span class="line"><span class="keyword">val</span> df = spark.createDataFrame(data, schema)</span><br><span class="line">df.show()</span><br><span class="line">+----+---+</span><br><span class="line">|name|age|</span><br><span class="line">+----+---+</span><br><span class="line">|like| <span class="number">18</span>|</span><br><span class="line">|arya| <span class="number">24</span>|</span><br><span class="line">+----+---+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打印 DataFrame 的 Schema</span></span><br><span class="line">df.printSchema</span><br><span class="line">root</span><br><span class="line"> |-- name: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- age: integer (nullable = <span class="literal">false</span>)</span><br></pre></td></tr></table></figure></div><h2 id="Columns-and-Expressions"><a href="#Columns-and-Expressions" class="headerlink" title="Columns and Expressions"></a>Columns and Expressions</h2><p><strong>列只是表达式</strong>（<code>Columns are just Expressions</code>）：列以及列上的转换与经过解析的表达式拥有相同的逻辑计划。这是极为重要的一点，这意味着你可以将表达式编写为 DataFrame 代码或 SQL 表达式，并获得完全相同的性能特性。</p><h3 id="Columns"><a href="#Columns" class="headerlink" title="Columns"></a>Columns</h3><p>对 Spark 而言，Columns 是一种逻辑构造，仅表示通过表达式在每条记录上所计算出来的值。这意味着要有一个列的实际值，我们就需要有一个行，要有一个行，我们就需要有一个 DataFrame，你不能在 DataFrame 上下文之外操作单个列，你必须在 DataFrame 中使用 Spark 转换来修改列的内容。</p><p>在 DataFrame 中引用列的方式有很多，以下几种语法形式是等价的：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">df.columns</span><br><span class="line"><span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(name, dob, gender, salary)</span><br><span class="line"></span><br><span class="line">df.select(<span class="symbol">&#x27;dob</span>, $<span class="string">&quot;dob&quot;</span>, df(<span class="string">&quot;dob&quot;</span>), col(<span class="string">&quot;dob&quot;</span>), df.col(<span class="string">&quot;dob&quot;</span>), expr(<span class="string">&quot;dob&quot;</span>)).show()</span><br><span class="line">+-----+-----+-----+-----+-----+</span><br><span class="line">|  dob|  dob|  dob|  dob|  dob|</span><br><span class="line">+-----+-----+-----+-----+-----+</span><br><span class="line">|<span class="number">36636</span>|<span class="number">36636</span>|<span class="number">36636</span>|<span class="number">36636</span>|<span class="number">36636</span>|</span><br><span class="line">|<span class="number">40288</span>|<span class="number">40288</span>|<span class="number">40288</span>|<span class="number">40288</span>|<span class="number">40288</span>|</span><br><span class="line">|<span class="number">42114</span>|<span class="number">42114</span>|<span class="number">42114</span>|<span class="number">42114</span>|<span class="number">42114</span>|</span><br><span class="line">|<span class="number">39192</span>|<span class="number">39192</span>|<span class="number">39192</span>|<span class="number">39192</span>|<span class="number">39192</span>|</span><br><span class="line">+-----+-----+-----+-----+-----+</span><br></pre></td></tr></table></figure></div><h3 id="Expressions"><a href="#Expressions" class="headerlink" title="Expressions"></a>Expressions</h3><p>Expressions 是对 DataFrame 记录中一个或多个值的一组转换，可以将其视为一个函数，该函数将一个或多个列名作为输入，进行解析，然后可能应用更多表达式为数据集中每个记录创建单个值（可以是诸如 Map 或 Array 之类的复杂类型）。在最简单的情况下，通过 <code>expr()</code> 函数创建的表达式仅仅是  DataFrame 列引用，<code>expr(&quot;col_name&quot;)</code> 等价于 <code>col(&quot;col_name&quot;)</code>。</p><p>列提供了表达式功能的子集，如果使用 <code>col()</code> 并想在该列上执行转换，则必须在该列引用上执行那些转换，使用表达式时， expr 函数实际上可以解析字符串中的转换和列引用，例如：<code>expr(&quot;col_name - 5&quot;)</code> 等价于 <code>col(&quot;col_name&quot;) - 5</code>，甚至等价于 <code>expr(&quot;col_name&quot;) - 5</code>。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.expr</span><br><span class="line">(((col(<span class="string">&quot;col_name&quot;</span>) + <span class="number">5</span>) * <span class="number">200</span>) - <span class="number">6</span>) &lt; col(<span class="string">&quot;other_col&quot;</span>)</span><br><span class="line">expr(<span class="string">&quot;(((col_name + 5) * 200) - 6) &lt; other_col&quot;</span>)</span><br></pre></td></tr></table></figure></div><h2 id="Records-and-Rows"><a href="#Records-and-Rows" class="headerlink" title="Records and Rows"></a>Records and Rows</h2><p>DataFrame 中的每一行都是一条记录，Spark 将此记录表示为 Row 类型的对象，Spark 使用列表达式操纵 Row 对象，以产生可用的值。Row 对象在内部表示为字节数组，但是字节数组接口从未显示给用户，因为我们仅使用列表达式来操作它们。</p><p>可以通过手动实例化具有每个列中的值的 Row 对象来创建行，但是务必注意只有 DataFrame 有 Schema，Row 本身没有模式。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></span><br><span class="line"><span class="keyword">val</span> myRow = <span class="type">Row</span>(<span class="string">&quot;hello&quot;</span>, <span class="literal">null</span>, <span class="number">1</span>, <span class="literal">false</span>)</span><br></pre></td></tr></table></figure></div><p>访问行中的数据很容易，只需要指定位置或列名：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df.collect().foreach(row=&gt;&#123;</span><br><span class="line">    <span class="keyword">val</span> name = row(<span class="number">0</span>).asInstanceOf[<span class="type">String</span>]</span><br><span class="line">    <span class="keyword">val</span> age = row.getAs[<span class="type">Integer</span>](<span class="string">&quot;age&quot;</span>)</span><br><span class="line">    println(<span class="string">s&quot;name:<span class="subst">$name</span> age:<span class="subst">$age</span>&quot;</span>)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></div><h2 id="DataFrame-转换"><a href="#DataFrame-转换" class="headerlink" title="DataFrame 转换"></a>DataFrame 转换</h2><p>DataFrame 转换不会改变原有的 DataFrame，而是生成一个新的 DataFrame。很多 DataFrame 转换/函数被包含在 <code>org.apache.spark.sql.functions</code> 模块，使用前推荐先导入相关模块：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></span><br></pre></td></tr></table></figure></div><p>本文主要用到的示例数据：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = <span class="type">Seq</span>(</span><br><span class="line">      <span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;James &quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;Smith&quot;</span>),<span class="string">&quot;36636&quot;</span>,<span class="string">&quot;M&quot;</span>,<span class="string">&quot;3000&quot;</span>),</span><br><span class="line">      <span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;Michael &quot;</span>,<span class="string">&quot;Rose&quot;</span>,<span class="string">&quot;&quot;</span>),<span class="string">&quot;40288&quot;</span>,<span class="string">&quot;M&quot;</span>,<span class="string">&quot;4000&quot;</span>),</span><br><span class="line">      <span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;Robert &quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;Williams&quot;</span>),<span class="string">&quot;42114&quot;</span>,<span class="string">&quot;M&quot;</span>,<span class="string">&quot;4000&quot;</span>),</span><br><span class="line">      <span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;Maria &quot;</span>,<span class="string">&quot;Anne&quot;</span>,<span class="string">&quot;Jones&quot;</span>),<span class="string">&quot;39192&quot;</span>,<span class="string">&quot;F&quot;</span>,<span class="string">&quot;4000&quot;</span>),</span><br><span class="line">      <span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;Jen&quot;</span>,<span class="string">&quot;Mary&quot;</span>,<span class="string">&quot;Brown&quot;</span>),<span class="string">&quot;&quot;</span>,<span class="string">&quot;F&quot;</span>,<span class="string">&quot;-1&quot;</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> schema = <span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">      .add(<span class="string">&quot;name&quot;</span>,<span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">          .add(<span class="string">&quot;firstname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">          .add(<span class="string">&quot;middlename&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">          .add(<span class="string">&quot;lastname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      )  </span><br><span class="line">      .add(<span class="string">&quot;dob&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      .add(<span class="string">&quot;gender&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      .add(<span class="string">&quot;salary&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df = spark.createDataFrame(spark.sparkContext.parallelize(data),schema)</span><br><span class="line">df.show()</span><br><span class="line">df.printSchema</span><br></pre></td></tr></table></figure></div><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|                name|  dob|gender|salary|</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|   [James , , Smith]|36636|     M|  3000|</span><br><span class="line">|  [Michael , Rose, ]|40288|     M|  4000|</span><br><span class="line">|[Robert , , Willi...|42114|     M|  4000|</span><br><span class="line">|[Maria , Anne, Jo...|39192|     F|  4000|</span><br><span class="line">|  [Jen, Mary, Brown]|     |     F|    -1|</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- name: struct (nullable = true)</span><br><span class="line"> |    |-- firstname: string (nullable = true)</span><br><span class="line"> |    |-- middlename: string (nullable = true)</span><br><span class="line"> |    |-- lastname: string (nullable = true)</span><br><span class="line"> |-- dob: string (nullable = true)</span><br><span class="line"> |-- gender: string (nullable = true)</span><br><span class="line"> |-- salary: string (nullable = true)</span><br></pre></td></tr></table></figure></div><h3 id="列操作"><a href="#列操作" class="headerlink" title="列操作"></a>列操作</h3><h4 id="select-——-筛选列"><a href="#select-——-筛选列" class="headerlink" title="select —— 筛选列"></a>select —— 筛选列</h4><ul><li><p>功能：<code>select()</code> 用于筛选/操作列；</p></li><li><p>语法：有两种语法形式，但是两种形式不能混用；</p></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 传入列名字符串</span></span><br><span class="line">select(col : scala.<span class="type">Predef</span>.<span class="type">String</span>, cols : scala.<span class="type">Predef</span>.<span class="type">String</span>*) : org.apache.spark.sql.<span class="type">DataFrame</span></span><br><span class="line"><span class="comment">// 传入多个列对象</span></span><br><span class="line">select(cols : org.apache.spark.sql.<span class="type">Column</span>*) : org.apache.spark.sql.<span class="type">DataFrame</span></span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 可以是列名字符串、*代表所有列、a.b 代表 struct 中的子域、不可用 as</span></span><br><span class="line">df.select(<span class="string">&quot;name.firstname&quot;</span>, <span class="string">&quot;dob&quot;</span>, <span class="string">&quot;*&quot;</span>).show()</span><br><span class="line">+---------+-----+--------------------+-----+------+------+</span><br><span class="line">|firstname|  dob|                name|  dob|gender|salary|</span><br><span class="line">+---------+-----+--------------------+-----+------+------+</span><br><span class="line">|   <span class="type">James</span> |<span class="number">36636</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|</span><br><span class="line">| <span class="type">Michael</span> |<span class="number">40288</span>|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|</span><br><span class="line">|  <span class="type">Robert</span> |<span class="number">42114</span>|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|</span><br><span class="line">|   <span class="type">Maria</span> |<span class="number">39192</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|</span><br><span class="line">|      <span class="type">Jen</span>|     |  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|</span><br><span class="line">+---------+-----+--------------------+-----+------+------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 列对象有多种表示方法：$&quot;col_name&quot;、col(&quot;col_name&quot;)、df(&quot;col_name&quot;)</span></span><br><span class="line"><span class="comment">// 列可以通过.as(col_name) 起别名</span></span><br><span class="line"><span class="comment">// 列可以通过.cast() 改变列的类型</span></span><br><span class="line"><span class="comment">// 列字面量用 lit(c) 表示</span></span><br><span class="line">df.select($<span class="string">&quot;name.firstname&quot;</span>.cast(<span class="string">&quot;String&quot;</span>), col(<span class="string">&quot;dob&quot;</span>).as(<span class="string">&quot;f_dob&quot;</span>), df(<span class="string">&quot;*&quot;</span>), lit(<span class="number">1</span>).as(<span class="string">&quot;new_col&quot;</span>)).show()</span><br><span class="line">+---------+-----+--------------------+-----+------+------+-------+</span><br><span class="line">|firstname|f_dob|                name|  dob|gender|salary|new_col|</span><br><span class="line">+---------+-----+--------------------+-----+------+------+-------+</span><br><span class="line">|   <span class="type">James</span> |<span class="number">36636</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|      <span class="number">1</span>|</span><br><span class="line">| <span class="type">Michael</span> |<span class="number">40288</span>|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|      <span class="number">1</span>|</span><br><span class="line">|  <span class="type">Robert</span> |<span class="number">42114</span>|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|      <span class="number">1</span>|</span><br><span class="line">|   <span class="type">Maria</span> |<span class="number">39192</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|      <span class="number">1</span>|</span><br><span class="line">|      <span class="type">Jen</span>|     |  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|      <span class="number">1</span>|</span><br><span class="line">+---------+-----+--------------------+-----+------+------+-------+</span><br></pre></td></tr></table></figure></div><h4 id="selectExpr-——-通过-SQL-语句筛选列"><a href="#selectExpr-——-通过-SQL-语句筛选列" class="headerlink" title="selectExpr —— 通过 SQL 语句筛选列"></a>selectExpr —— 通过 SQL 语句筛选列</h4><ul><li>功能：selectExpr 和 select 作用相同，只是 selectExpr 更加简洁、灵活、强大；</li><li>语法：可以通过构造任意有效的非聚合 SQL 语句来生成列（如果使用了聚合函数，则只能应用于整个 DataFrame）；这释放了 Spark 的真正力量，我们可以将 selectExpr 视为构建复杂表达式以生成新的 DataFrame 的简单方法；如果列名中包含了保留字或关键字，例如空格或破折号，可以通过反引号（`）字符引用列名；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">selectExpr(exprs : scala.<span class="type">Predef</span>.<span class="type">String</span>*) : org.apache.spark.sql.<span class="type">DataFrame</span></span><br><span class="line">select(cols : org.apache.spark.sql.<span class="type">Column</span>*, expr())</span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">df.selectExpr(<span class="string">&quot;name.firstname&quot;</span>, <span class="string">&quot;dob as f_dob&quot;</span>, <span class="string">&quot;*&quot;</span>, <span class="string">&quot;dob + salary as new_col&quot;</span>).show()</span><br><span class="line">df.select(col(<span class="string">&quot;name.firstname&quot;</span>), expr(<span class="string">&quot;dob as f_dob&quot;</span>), df(<span class="string">&quot;*&quot;</span>), expr(<span class="string">&quot;dob + salary as new_col&quot;</span>), lit(<span class="number">1</span>).as(<span class="string">&quot;f_one&quot;</span>)).show()</span><br><span class="line"></span><br><span class="line">+---------+-----+--------------------+-----+------+------+-------+-----+</span><br><span class="line">|firstname|f_dob|                name|  dob|gender|salary|new_col|f_one|</span><br><span class="line">+---------+-----+--------------------+-----+------+------+-------+-----+</span><br><span class="line">|   <span class="type">James</span> |<span class="number">36636</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|<span class="number">39636.0</span>|    <span class="number">1</span>|</span><br><span class="line">| <span class="type">Michael</span> |<span class="number">40288</span>|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|<span class="number">44288.0</span>|    <span class="number">1</span>|</span><br><span class="line">|  <span class="type">Robert</span> |<span class="number">42114</span>|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|<span class="number">46114.0</span>|    <span class="number">1</span>|</span><br><span class="line">|   <span class="type">Maria</span> |<span class="number">39192</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|<span class="number">43192.0</span>|    <span class="number">1</span>|</span><br><span class="line">|      <span class="type">Jen</span>|     |  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|   <span class="literal">null</span>|    <span class="number">1</span>|</span><br><span class="line">+---------+-----+--------------------+-----+------+------+-------+-----+</span><br><span class="line"></span><br><span class="line">df.selectExpr(<span class="string">&quot;max(salary) as max_salary&quot;</span>, <span class="string">&quot;avg(salary) as `avg salary`&quot;</span>).show()</span><br><span class="line">+----------+----------+</span><br><span class="line">|max_salary|avg salary|</span><br><span class="line">+----------+----------+</span><br><span class="line">|      <span class="number">4000</span>|    <span class="number">2999.8</span>|</span><br><span class="line">+----------+----------+</span><br></pre></td></tr></table></figure></div><p>selectExpr 的灵活用法使其可以替代大部分的列操作算子，但是考虑到代码的简洁性，对于一些具体的操作，往往会有更简单直接的算子。事实上，DataFrame 操作使用最多的算子是 <code>withColumn</code>，<code>withColumn</code> 算子将单列处理逻辑封装到独立的子句中，更具可读性，也方便了代码维护。</p><h4 id="withColumn-——-添加或更新列"><a href="#withColumn-——-添加或更新列" class="headerlink" title="withColumn —— 添加或更新列"></a>withColumn —— 添加或更新列</h4><ul><li>功能：<code>withColumn()</code> 可以用来添加新列、改变已有列的值、改变列的类型；        </li><li>语法：withColumn 有两个参数，列名和将为 DataFrame 各行创建值的表达式；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">withColumn(colName: <span class="type">String</span>, col: <span class="type">Column</span>): <span class="type">DataFrame</span></span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 添加新的列</span></span><br><span class="line">df.withColumn(<span class="string">&quot;CopiedColumn&quot;</span>,col(<span class="string">&quot;salary&quot;</span>)* <span class="number">-1</span>)</span><br><span class="line"><span class="comment">// 改变列类型</span></span><br><span class="line">df.withColumn(<span class="string">&quot;salary&quot;</span>,col(<span class="string">&quot;salary&quot;</span>).cast(<span class="string">&quot;Integer&quot;</span>))</span><br><span class="line"><span class="comment">// 改变已有列的值</span></span><br><span class="line">df.withColumn(<span class="string">&quot;salary&quot;</span>,col(<span class="string">&quot;salary&quot;</span>)*<span class="number">100</span>)</span><br></pre></td></tr></table></figure></div><h4 id="withColumnRenamed-——-重命名列"><a href="#withColumnRenamed-——-重命名列" class="headerlink" title="withColumnRenamed —— 重命名列"></a>withColumnRenamed —— 重命名列</h4><ul><li>功能：withColumnRenamed 用于重命名列；</li><li>语法：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">withColumnRenamed(existingName: <span class="type">String</span>, newName: <span class="type">String</span>): <span class="type">DataFrame</span></span><br></pre></td></tr></table></figure></div><ul><li>示例：有多种方式可以用于重命名单个列、多个列、所有列、嵌套列</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 重命名单个列，withColumnRenamed(x, y) 将 y 列重名为 x</span></span><br><span class="line">df.withColumnRenamed(<span class="string">&quot;dob&quot;</span>,<span class="string">&quot;DateOfBirth&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 重命名嵌套列，col(&quot;name&quot;).cast(schema2) 将嵌套列重命名为 schema2 中定义的列名</span></span><br><span class="line"><span class="keyword">val</span> schema2 = <span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">    .add(<span class="string">&quot;fname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">    .add(<span class="string">&quot;middlename&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">    .add(<span class="string">&quot;lname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">df.select(col(<span class="string">&quot;name&quot;</span>).cast(schema2), col(<span class="string">&quot;dob&quot;</span>), col(<span class="string">&quot;gender&quot;</span>), col(<span class="string">&quot;salary&quot;</span>)).printSchema</span><br><span class="line">root</span><br><span class="line"> |-- name: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- fname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- middlename: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- lname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- dob: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- gender: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: string (nullable = <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 重命名嵌套列，col(&quot;x.y&quot;).as(&quot;z&quot;) 可以将 x 中的 y 抽离出来作为单独的列</span></span><br><span class="line"><span class="keyword">val</span> df4 = df.select(col(<span class="string">&quot;name.firstname&quot;</span>).as(<span class="string">&quot;fname&quot;</span>),</span><br><span class="line">  col(<span class="string">&quot;name.middlename&quot;</span>).as(<span class="string">&quot;mname&quot;</span>),</span><br><span class="line">  col(<span class="string">&quot;name.lastname&quot;</span>).as(<span class="string">&quot;lname&quot;</span>),</span><br><span class="line">  col(<span class="string">&quot;dob&quot;</span>),col(<span class="string">&quot;gender&quot;</span>),col(<span class="string">&quot;salary&quot;</span>))</span><br><span class="line">df4.show()</span><br><span class="line">+--------+-----+--------+-----+------+------+</span><br><span class="line">|   fname|mname|   lname|  dob|gender|salary|</span><br><span class="line">+--------+-----+--------+-----+------+------+</span><br><span class="line">|  <span class="type">James</span> |     |   <span class="type">Smith</span>|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|</span><br><span class="line">|<span class="type">Michael</span> | <span class="type">Rose</span>|        |<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|</span><br><span class="line">| <span class="type">Robert</span> |     |<span class="type">Williams</span>|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|</span><br><span class="line">|  <span class="type">Maria</span> | <span class="type">Anne</span>|   <span class="type">Jones</span>|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|</span><br><span class="line">|     <span class="type">Jen</span>| <span class="type">Mary</span>|   <span class="type">Brown</span>|     |     <span class="type">F</span>|    <span class="number">-1</span>|</span><br><span class="line">+--------+-----+--------+-----+------+------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 重命名多列，col() 函数</span></span><br><span class="line"><span class="keyword">val</span> old_columns = <span class="type">Seq</span>(<span class="string">&quot;dob&quot;</span>,<span class="string">&quot;gender&quot;</span>,<span class="string">&quot;salary&quot;</span>,<span class="string">&quot;fname&quot;</span>,<span class="string">&quot;mname&quot;</span>,<span class="string">&quot;lname&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> new_columns = <span class="type">Seq</span>(<span class="string">&quot;DateOfBirth&quot;</span>,<span class="string">&quot;Sex&quot;</span>,<span class="string">&quot;salary&quot;</span>,<span class="string">&quot;firstName&quot;</span>,<span class="string">&quot;middleName&quot;</span>,<span class="string">&quot;lastName&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> columnsList = old_columns.zip(new_columns).map(f=&gt;&#123;col(f._1).as(f._2)&#125;)</span><br><span class="line"><span class="keyword">val</span> df5 = df4.select(columnsList:_*)</span><br><span class="line">df5.show()</span><br><span class="line">+-----------+---+------+---------+----------+--------+</span><br><span class="line">|<span class="type">DateOfBirth</span>|<span class="type">Sex</span>|salary|firstName|middleName|lastName|</span><br><span class="line">+-----------+---+------+---------+----------+--------+</span><br><span class="line">|      <span class="number">36636</span>|  <span class="type">M</span>|  <span class="number">3000</span>|   <span class="type">James</span> |          |   <span class="type">Smith</span>|</span><br><span class="line">|      <span class="number">40288</span>|  <span class="type">M</span>|  <span class="number">4000</span>| <span class="type">Michael</span> |      <span class="type">Rose</span>|        |</span><br><span class="line">|      <span class="number">42114</span>|  <span class="type">M</span>|  <span class="number">4000</span>|  <span class="type">Robert</span> |          |<span class="type">Williams</span>|</span><br><span class="line">|      <span class="number">39192</span>|  <span class="type">F</span>|  <span class="number">4000</span>|   <span class="type">Maria</span> |      <span class="type">Anne</span>|   <span class="type">Jones</span>|</span><br><span class="line">|           |  <span class="type">F</span>|    <span class="number">-1</span>|      <span class="type">Jen</span>|      <span class="type">Mary</span>|   <span class="type">Brown</span>|</span><br><span class="line">+-----------+---+------+---------+----------+--------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 重命名所有列，toDF() 方法</span></span><br><span class="line"><span class="keyword">val</span> newColumns = <span class="type">Seq</span>(<span class="string">&quot;newCol1&quot;</span>,<span class="string">&quot;newCol2&quot;</span>,<span class="string">&quot;newCol3&quot;</span>,<span class="string">&quot;newCol4&quot;</span>)</span><br><span class="line">df.toDF(newColumns:_*).show()</span><br><span class="line">+--------------------+-------+-------+-------+</span><br><span class="line">|             newCol1|newCol2|newCol3|newCol4|</span><br><span class="line">+--------------------+-------+-------+-------+</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|  <span class="number">36636</span>|      <span class="type">M</span>|   <span class="number">3000</span>|</span><br><span class="line">|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|  <span class="number">40288</span>|      <span class="type">M</span>|   <span class="number">4000</span>|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|  <span class="number">42114</span>|      <span class="type">M</span>|   <span class="number">4000</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|  <span class="number">39192</span>|      <span class="type">F</span>|   <span class="number">4000</span>|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|       |      <span class="type">F</span>|     <span class="number">-1</span>|</span><br><span class="line">+--------------------+-------+-------+-------+</span><br></pre></td></tr></table></figure></div><h4 id="drop-——-删除列"><a href="#drop-——-删除列" class="headerlink" title="drop —— 删除列"></a>drop —— 删除列</h4><ul><li>功能：drop() 用于删除 DataFrame 中单个或多个列，如果指定列不存在则忽略，在两个表进行 join 时通常可以利用这一点来保证两个表除了关联键之外不存在同名字段。</li><li>语法：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// drop 有三种不同的形式：</span></span><br><span class="line"><span class="number">1</span>) drop(colName : scala.<span class="type">Predef</span>.<span class="type">String</span>) : org.apache.spark.sql.<span class="type">DataFrame</span></span><br><span class="line"><span class="number">2</span>) drop(colNames : scala.<span class="type">Predef</span>.<span class="type">String</span>*) : org.apache.spark.sql.<span class="type">DataFrame</span></span><br><span class="line"><span class="number">3</span>) drop(col : org.apache.spark.sql.<span class="type">Column</span>) : org.apache.spark.sql.<span class="type">DataFrame</span></span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> df = spark.range(<span class="number">3</span>)</span><br><span class="line">    .withColumn(<span class="string">&quot;today_str&quot;</span>,lit(<span class="string">&quot;2020-11-04&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;today&quot;</span>, current_date())</span><br><span class="line">    .withColumn(<span class="string">&quot;now&quot;</span>, current_timestamp())</span><br><span class="line">    .orderBy(rand())</span><br><span class="line">df.show(<span class="literal">false</span>)</span><br><span class="line">+---+----------+----------+-----------------------+</span><br><span class="line">|id |today_str |today     |now                    |</span><br><span class="line">+---+----------+----------+-----------------------+</span><br><span class="line">|<span class="number">0</span>  |<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span> <span class="number">20</span>:<span class="number">57</span>:<span class="number">06.515</span>|</span><br><span class="line">|<span class="number">1</span>  |<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span> <span class="number">20</span>:<span class="number">57</span>:<span class="number">06.515</span>|</span><br><span class="line">|<span class="number">2</span>  |<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span> <span class="number">20</span>:<span class="number">57</span>:<span class="number">06.515</span>|</span><br><span class="line">+---+----------+----------+-----------------------+</span><br><span class="line"><span class="comment">// 删除单列</span></span><br><span class="line">df.drop(<span class="string">&quot;today_str&quot;</span>).show()</span><br><span class="line">+---+----------+--------------------+</span><br><span class="line">| id|     today|                 now|</span><br><span class="line">+---+----------+--------------------+</span><br><span class="line">|  <span class="number">0</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span> <span class="number">22</span>:<span class="number">19</span>:...|</span><br><span class="line">|  <span class="number">1</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span> <span class="number">22</span>:<span class="number">19</span>:...|</span><br><span class="line">|  <span class="number">2</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span> <span class="number">22</span>:<span class="number">19</span>:...|</span><br><span class="line">+---+----------+--------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 删除多列</span></span><br><span class="line">df.drop(<span class="string">&quot;today_str&quot;</span>, <span class="string">&quot;today&quot;</span>).show()</span><br><span class="line">+---+--------------------+</span><br><span class="line">| id|                 now|</span><br><span class="line">+---+--------------------+</span><br><span class="line">|  <span class="number">0</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span> <span class="number">22</span>:<span class="number">19</span>:...|</span><br><span class="line">|  <span class="number">1</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span> <span class="number">22</span>:<span class="number">19</span>:...|</span><br><span class="line">|  <span class="number">2</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span> <span class="number">22</span>:<span class="number">19</span>:...|</span><br><span class="line">+---+--------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 删除不存在的列</span></span><br><span class="line">df.drop(<span class="string">&quot;xxx&quot;</span>).show()</span><br><span class="line">+---+----------+----------+--------------------+</span><br><span class="line">| id| today_str|     today|                 now|</span><br><span class="line">+---+----------+----------+--------------------+</span><br><span class="line">|  <span class="number">0</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span> <span class="number">22</span>:<span class="number">19</span>:...|</span><br><span class="line">|  <span class="number">1</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span> <span class="number">22</span>:<span class="number">19</span>:...|</span><br><span class="line">|  <span class="number">2</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-04</span> <span class="number">22</span>:<span class="number">19</span>:...|</span><br><span class="line">+---+----------+----------+--------------------+</span><br></pre></td></tr></table></figure></div><h3 id="行操作"><a href="#行操作" class="headerlink" title="行操作"></a>行操作</h3><h4 id="where-filter-——-筛选行"><a href="#where-filter-——-筛选行" class="headerlink" title="where | filter —— 筛选行"></a>where | filter —— 筛选行</h4><ul><li>功能：where 和 filter 是完全等价的，用于按照指定条件筛选 DataFrame 中满足条件的行；</li><li>语法：传入一个布尔表达式，过滤掉 false 所对应的行；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 有四种形式</span></span><br><span class="line"><span class="number">1</span>) filter(condition: <span class="type">Column</span>): <span class="type">Dataset</span>[<span class="type">T</span>]</span><br><span class="line"><span class="number">2</span>) filter(conditionExpr: <span class="type">String</span>): <span class="type">Dataset</span>[<span class="type">T</span>]</span><br><span class="line"><span class="number">3</span>) filter(func: <span class="type">T</span> =&gt; <span class="type">Boolean</span>): <span class="type">Dataset</span>[<span class="type">T</span>]</span><br><span class="line"><span class="number">4</span>) filter(func: <span class="type">FilterFunction</span>[<span class="type">T</span>]): <span class="type">Dataset</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">df.show()</span><br><span class="line">+--------------------+------------------+-----+------+</span><br><span class="line">|                name|         languages|state|gender|</span><br><span class="line">+--------------------+------------------+-----+------+</span><br><span class="line">|    [<span class="type">James</span>, , <span class="type">Smith</span>]|[<span class="type">Java</span>, <span class="type">Scala</span>, <span class="type">C</span>++]|   <span class="type">OH</span>|     <span class="type">M</span>|</span><br><span class="line">|      [<span class="type">Anna</span>, <span class="type">Rose</span>, ]|[<span class="type">Spark</span>, <span class="type">Java</span>, <span class="type">C</span>++]|   <span class="type">NY</span>|     <span class="type">F</span>|</span><br><span class="line">| [<span class="type">Julia</span>, , <span class="type">Williams</span>]|      [<span class="type">CSharp</span>, <span class="type">VB</span>]|   <span class="type">OH</span>|     <span class="type">F</span>|</span><br><span class="line">|[<span class="type">Maria</span>, <span class="type">Anne</span>, <span class="type">Jones</span>]|      [<span class="type">CSharp</span>, <span class="type">VB</span>]|   <span class="type">NY</span>|     <span class="type">M</span>|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|      [<span class="type">CSharp</span>, <span class="type">VB</span>]|   <span class="type">NY</span>|     <span class="type">M</span>|</span><br><span class="line">|[<span class="type">Mike</span>, <span class="type">Mary</span>, <span class="type">Will</span>...|      [<span class="type">Python</span>, <span class="type">VB</span>]|   <span class="type">OH</span>|     <span class="type">M</span>|</span><br><span class="line">+--------------------+------------------+-----+------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// Column 形式表达式</span></span><br><span class="line">df.filter(df(<span class="string">&quot;state&quot;</span>) === <span class="string">&quot;OH&quot;</span> &amp;&amp; df(<span class="string">&quot;gender&quot;</span>) === <span class="string">&quot;M&quot;</span>)</span><br><span class="line"><span class="comment">// String 形式表达式 == 和 = 等价</span></span><br><span class="line">df.filter(<span class="string">&quot;gender == &#x27;M&#x27;&quot;</span>)</span><br><span class="line">df.filter(<span class="string">&quot;gender = &#x27;M&#x27;&quot;</span>)</span><br><span class="line"><span class="comment">// Filtering on an Array column</span></span><br><span class="line">df.filter(array_contains(df(<span class="string">&quot;languages&quot;</span>),<span class="string">&quot;Java&quot;</span>))</span><br><span class="line"><span class="comment">// Filtering on Nested Struct columns</span></span><br><span class="line">df.filter(df(<span class="string">&quot;name.lastname&quot;</span>) === <span class="string">&quot;Williams&quot;</span>)</span><br></pre></td></tr></table></figure></div><h4 id="distinct-——-行去重"><a href="#distinct-——-行去重" class="headerlink" title="distinct —— 行去重"></a>distinct —— 行去重</h4><ul><li>功能：<code>distinct()</code> 方法可以移除 DataFrame 中重复的行，<code>dropDuplicates()</code> 方法用于移除 DataFrame 中在某几个字段上重复的行（默认保留重复行中的第一行）。</li><li>语法：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">distinct(): <span class="type">Dataset</span>[<span class="type">T</span>] = dropDuplicates()</span><br><span class="line">dropDuplicates(colNames: <span class="type">Seq</span>[<span class="type">String</span>]): <span class="type">Dataset</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">df.show()</span><br><span class="line">+-------------+----------+------+</span><br><span class="line">|employee_name|department|salary|</span><br><span class="line">+-------------+----------+------+</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|</span><br><span class="line">|      <span class="type">Michael</span>|     <span class="type">Sales</span>|  <span class="number">4600</span>|</span><br><span class="line">|       <span class="type">Robert</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|</span><br><span class="line">|        <span class="type">Maria</span>|   <span class="type">Finance</span>|  <span class="number">3000</span>|</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|</span><br><span class="line">|        <span class="type">Scott</span>|   <span class="type">Finance</span>|  <span class="number">3300</span>|</span><br><span class="line">|          <span class="type">Jen</span>|   <span class="type">Finance</span>|  <span class="number">3900</span>|</span><br><span class="line">|         <span class="type">Jeff</span>| <span class="type">Marketing</span>|  <span class="number">3000</span>|</span><br><span class="line">|        <span class="type">Kumar</span>| <span class="type">Marketing</span>|  <span class="number">2000</span>|</span><br><span class="line">|         <span class="type">Saif</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|</span><br><span class="line">+-------------+----------+------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// Distinct all columns</span></span><br><span class="line"><span class="keyword">val</span> distinctDF = df.distinct()</span><br><span class="line">println(<span class="string">&quot;Distinct count: &quot;</span>+distinctDF.count())</span><br><span class="line">distinctDF.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line"><span class="type">Distinct</span> count: <span class="number">9</span></span><br><span class="line">+-------------+----------+------+</span><br><span class="line">|employee_name|department|salary|</span><br><span class="line">+-------------+----------+------+</span><br><span class="line">|<span class="type">James</span>        |<span class="type">Sales</span>     |<span class="number">3000</span>  |</span><br><span class="line">|<span class="type">Michael</span>      |<span class="type">Sales</span>     |<span class="number">4600</span>  |</span><br><span class="line">|<span class="type">Maria</span>        |<span class="type">Finance</span>   |<span class="number">3000</span>  |</span><br><span class="line">|<span class="type">Robert</span>       |<span class="type">Sales</span>     |<span class="number">4100</span>  |</span><br><span class="line">|<span class="type">Saif</span>         |<span class="type">Sales</span>     |<span class="number">4100</span>  |</span><br><span class="line">|<span class="type">Scott</span>        |<span class="type">Finance</span>   |<span class="number">3300</span>  |</span><br><span class="line">|<span class="type">Jeff</span>         |<span class="type">Marketing</span> |<span class="number">3000</span>  |</span><br><span class="line">|<span class="type">Jen</span>          |<span class="type">Finance</span>   |<span class="number">3900</span>  |</span><br><span class="line">|<span class="type">Kumar</span>        |<span class="type">Marketing</span> |<span class="number">2000</span>  |</span><br><span class="line">+-------------+----------+------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// Distinct using dropDuplicates</span></span><br><span class="line"><span class="keyword">val</span> dropDisDF = df.dropDuplicates(<span class="string">&quot;department&quot;</span>,<span class="string">&quot;salary&quot;</span>)</span><br><span class="line">println(<span class="string">&quot;Distinct count of department &amp; salary : &quot;</span>+dropDisDF.count())</span><br><span class="line">dropDisDF.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line"><span class="type">Distinct</span> count of department &amp; salary : <span class="number">8</span></span><br><span class="line">+-------------+----------+------+</span><br><span class="line">|employee_name|department|salary|</span><br><span class="line">+-------------+----------+------+</span><br><span class="line">|<span class="type">Jen</span>          |<span class="type">Finance</span>   |<span class="number">3900</span>  |</span><br><span class="line">|<span class="type">Maria</span>        |<span class="type">Finance</span>   |<span class="number">3000</span>  |</span><br><span class="line">|<span class="type">Scott</span>        |<span class="type">Finance</span>   |<span class="number">3300</span>  |</span><br><span class="line">|<span class="type">Michael</span>      |<span class="type">Sales</span>     |<span class="number">4600</span>  |</span><br><span class="line">|<span class="type">Kumar</span>        |<span class="type">Marketing</span> |<span class="number">2000</span>  |</span><br><span class="line">|<span class="type">Robert</span>       |<span class="type">Sales</span>     |<span class="number">4100</span>  |</span><br><span class="line">|<span class="type">James</span>        |<span class="type">Sales</span>     |<span class="number">3000</span>  |</span><br><span class="line">|<span class="type">Jeff</span>         |<span class="type">Marketing</span> |<span class="number">3000</span>  |</span><br><span class="line">+-------------+----------+------+</span><br></pre></td></tr></table></figure></div><h4 id="groupBy-——-行分组"><a href="#groupBy-——-行分组" class="headerlink" title="groupBy —— 行分组"></a>groupBy —— 行分组</h4><ul><li>功能：和 SQL 中的 group by 语句类似，<code>groupBy()</code> 函数用于将 <code>DataFrame/Dataset</code> 按照指定字段分组，返回一个 <code>RelationalGroupedDataset</code> 对象</li><li><p>语法：<code>RelationalGroupedDataset</code> 对象包含以下几种聚合方法：</p><ul><li>count()/max()/min()/mean()/avg()/sum(): 返回每个分组的行数/最大/最小/平均值/和；</li><li>agg(): 可以同时计算多个聚合；</li><li>pivot(): 用于行转列；</li></ul></li><li><p>示例：</p></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"><span class="keyword">val</span> simpleData = <span class="type">Seq</span>((<span class="string">&quot;James&quot;</span>,<span class="string">&quot;Sales&quot;</span>,<span class="string">&quot;NY&quot;</span>,<span class="number">90000</span>,<span class="number">34</span>,<span class="number">10000</span>),</span><br><span class="line">    (<span class="string">&quot;Michael&quot;</span>,<span class="string">&quot;Sales&quot;</span>,<span class="string">&quot;NY&quot;</span>,<span class="number">86000</span>,<span class="number">56</span>,<span class="number">20000</span>),</span><br><span class="line">    (<span class="string">&quot;Robert&quot;</span>,<span class="string">&quot;Sales&quot;</span>,<span class="string">&quot;CA&quot;</span>,<span class="number">81000</span>,<span class="number">30</span>,<span class="number">23000</span>),</span><br><span class="line">    (<span class="string">&quot;Maria&quot;</span>,<span class="string">&quot;Finance&quot;</span>,<span class="string">&quot;CA&quot;</span>,<span class="number">90000</span>,<span class="number">24</span>,<span class="number">23000</span>),</span><br><span class="line">    (<span class="string">&quot;Raman&quot;</span>,<span class="string">&quot;Finance&quot;</span>,<span class="string">&quot;CA&quot;</span>,<span class="number">99000</span>,<span class="number">40</span>,<span class="number">24000</span>),</span><br><span class="line">    (<span class="string">&quot;Scott&quot;</span>,<span class="string">&quot;Finance&quot;</span>,<span class="string">&quot;NY&quot;</span>,<span class="number">83000</span>,<span class="number">36</span>,<span class="number">19000</span>),</span><br><span class="line">    (<span class="string">&quot;Jen&quot;</span>,<span class="string">&quot;Finance&quot;</span>,<span class="string">&quot;NY&quot;</span>,<span class="number">79000</span>,<span class="number">53</span>,<span class="number">15000</span>),</span><br><span class="line">    (<span class="string">&quot;Jeff&quot;</span>,<span class="string">&quot;Marketing&quot;</span>,<span class="string">&quot;CA&quot;</span>,<span class="number">80000</span>,<span class="number">25</span>,<span class="number">18000</span>),</span><br><span class="line">    (<span class="string">&quot;Kumar&quot;</span>,<span class="string">&quot;Marketing&quot;</span>,<span class="string">&quot;NY&quot;</span>,<span class="number">91000</span>,<span class="number">50</span>,<span class="number">21000</span>)</span><br><span class="line">  )</span><br><span class="line"><span class="keyword">val</span> df = simpleData.toDF(<span class="string">&quot;employee_name&quot;</span>,<span class="string">&quot;department&quot;</span>,<span class="string">&quot;state&quot;</span>,<span class="string">&quot;salary&quot;</span>,<span class="string">&quot;age&quot;</span>,<span class="string">&quot;bonus&quot;</span>)</span><br><span class="line">df.show()</span><br><span class="line"></span><br><span class="line">+-------------+----------+-----+------+---+-----+</span><br><span class="line">|employee_name|department|state|salary|age|bonus|</span><br><span class="line">+-------------+----------+-----+------+---+-----+</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|   <span class="type">NY</span>| <span class="number">90000</span>| <span class="number">34</span>|<span class="number">10000</span>|</span><br><span class="line">|      <span class="type">Michael</span>|     <span class="type">Sales</span>|   <span class="type">NY</span>| <span class="number">86000</span>| <span class="number">56</span>|<span class="number">20000</span>|</span><br><span class="line">|       <span class="type">Robert</span>|     <span class="type">Sales</span>|   <span class="type">CA</span>| <span class="number">81000</span>| <span class="number">30</span>|<span class="number">23000</span>|</span><br><span class="line">|        <span class="type">Maria</span>|   <span class="type">Finance</span>|   <span class="type">CA</span>| <span class="number">90000</span>| <span class="number">24</span>|<span class="number">23000</span>|</span><br><span class="line">|        <span class="type">Raman</span>|   <span class="type">Finance</span>|   <span class="type">CA</span>| <span class="number">99000</span>| <span class="number">40</span>|<span class="number">24000</span>|</span><br><span class="line">|        <span class="type">Scott</span>|   <span class="type">Finance</span>|   <span class="type">NY</span>| <span class="number">83000</span>| <span class="number">36</span>|<span class="number">19000</span>|</span><br><span class="line">|          <span class="type">Jen</span>|   <span class="type">Finance</span>|   <span class="type">NY</span>| <span class="number">79000</span>| <span class="number">53</span>|<span class="number">15000</span>|</span><br><span class="line">|         <span class="type">Jeff</span>| <span class="type">Marketing</span>|   <span class="type">CA</span>| <span class="number">80000</span>| <span class="number">25</span>|<span class="number">18000</span>|</span><br><span class="line">|        <span class="type">Kumar</span>| <span class="type">Marketing</span>|   <span class="type">NY</span>| <span class="number">91000</span>| <span class="number">50</span>|<span class="number">21000</span>|</span><br><span class="line">+-------------+----------+-----+------+---+-----+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算每个分组的行数</span></span><br><span class="line">df.groupBy(<span class="string">&quot;department&quot;</span>).count().show()</span><br><span class="line">+----------+-----+</span><br><span class="line">|department|count|</span><br><span class="line">+----------+-----+</span><br><span class="line">|     <span class="type">Sales</span>|    <span class="number">3</span>|</span><br><span class="line">|   <span class="type">Finance</span>|    <span class="number">4</span>|</span><br><span class="line">| <span class="type">Marketing</span>|    <span class="number">2</span>|</span><br><span class="line">+----------+-----+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在某个列上聚合</span></span><br><span class="line">df.groupBy(<span class="string">&quot;department&quot;</span>).sum(<span class="string">&quot;salary&quot;</span>).show(<span class="literal">false</span>)</span><br><span class="line">+----------+-----------+</span><br><span class="line">|department|sum(salary)|</span><br><span class="line">+----------+-----------+</span><br><span class="line">|<span class="type">Sales</span>     |<span class="number">257000</span>     |</span><br><span class="line">|<span class="type">Finance</span>   |<span class="number">351000</span>     |</span><br><span class="line">|<span class="type">Marketing</span> |<span class="number">171000</span>     |</span><br><span class="line">+----------+-----------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 同时在多列应用相同的聚合函数</span></span><br><span class="line">df.groupBy(<span class="string">&quot;department&quot;</span>,<span class="string">&quot;state&quot;</span>)</span><br><span class="line">    .sum(<span class="string">&quot;salary&quot;</span>,<span class="string">&quot;bonus&quot;</span>)</span><br><span class="line">    .show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+----------+-----+-----------+----------+</span><br><span class="line">|department|state|sum(salary)|sum(bonus)|</span><br><span class="line">+----------+-----+-----------+----------+</span><br><span class="line">|<span class="type">Finance</span>   |<span class="type">NY</span>   |<span class="number">162000</span>     |<span class="number">34000</span>     |</span><br><span class="line">|<span class="type">Marketing</span> |<span class="type">NY</span>   |<span class="number">91000</span>      |<span class="number">21000</span>     |</span><br><span class="line">|<span class="type">Sales</span>     |<span class="type">CA</span>   |<span class="number">81000</span>      |<span class="number">23000</span>     |</span><br><span class="line">|<span class="type">Marketing</span> |<span class="type">CA</span>   |<span class="number">80000</span>      |<span class="number">18000</span>     |</span><br><span class="line">|<span class="type">Finance</span>   |<span class="type">CA</span>   |<span class="number">189000</span>     |<span class="number">47000</span>     |</span><br><span class="line">|<span class="type">Sales</span>     |<span class="type">NY</span>   |<span class="number">176000</span>     |<span class="number">30000</span>     |</span><br><span class="line">+----------+-----+-----------+----------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// agg() 可以同时在多个列上应用不同聚合函数，并为每个聚合结果起别名</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line">df.groupBy(<span class="string">&quot;department&quot;</span>)</span><br><span class="line">    .agg(</span><br><span class="line">      sum(<span class="string">&quot;salary&quot;</span>).as(<span class="string">&quot;sum_salary&quot;</span>),</span><br><span class="line">      avg(<span class="string">&quot;salary&quot;</span>).as(<span class="string">&quot;avg_salary&quot;</span>),</span><br><span class="line">      sum(<span class="string">&quot;bonus&quot;</span>).as(<span class="string">&quot;sum_bonus&quot;</span>),</span><br><span class="line">      max(<span class="string">&quot;bonus&quot;</span>).as(<span class="string">&quot;max_bonus&quot;</span>))</span><br><span class="line">    .show(<span class="literal">false</span>)</span><br><span class="line">+----------+----------+-----------------+---------+---------+</span><br><span class="line">|department|sum_salary|avg_salary       |sum_bonus|max_bonus|</span><br><span class="line">+----------+----------+-----------------+---------+---------+</span><br><span class="line">|<span class="type">Sales</span>     |<span class="number">257000</span>    |<span class="number">85666.66666666667</span>|<span class="number">53000</span>    |<span class="number">23000</span>    |</span><br><span class="line">|<span class="type">Finance</span>   |<span class="number">351000</span>    |<span class="number">87750.0</span>          |<span class="number">81000</span>    |<span class="number">24000</span>    |</span><br><span class="line">|<span class="type">Marketing</span> |<span class="number">171000</span>    |<span class="number">85500.0</span>          |<span class="number">39000</span>    |<span class="number">21000</span>    |</span><br><span class="line">+----------+----------+-----------------+---------+---------+</span><br></pre></td></tr></table></figure></div><h4 id="sort-——-行排序"><a href="#sort-——-行排序" class="headerlink" title="sort —— 行排序"></a>sort —— 行排序</h4><ul><li>功能：在 Spark 中，可以使用 sort() 或 orderBy() 方法来根据某几个字段的值对 DataFrame/Dataset 进行排序。</li><li>语法：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// sort</span></span><br><span class="line">sort(sortCol : scala.<span class="type">Predef</span>.<span class="type">String</span>, sortCols : scala.<span class="type">Predef</span>.<span class="type">String</span>*) : <span class="type">Dataset</span>[<span class="type">T</span>]</span><br><span class="line">sort(sortExprs : org.apache.spark.sql.<span class="type">Column</span>*) : <span class="type">Dataset</span>[<span class="type">T</span>]</span><br><span class="line"><span class="comment">// orderBy</span></span><br><span class="line">orderBy(sortCol : scala.<span class="type">Predef</span>.<span class="type">String</span>, sortCols : scala.<span class="type">Predef</span>.<span class="type">String</span>*) : <span class="type">Dataset</span>[<span class="type">T</span>]</span><br><span class="line">orderBy(sortExprs : org.apache.spark.sql.<span class="type">Column</span>*) : <span class="type">Dataset</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">df.sort(<span class="string">&quot;department&quot;</span>,<span class="string">&quot;state&quot;</span>).show(<span class="literal">false</span>)</span><br><span class="line">df.sort(col(<span class="string">&quot;department&quot;</span>),col(<span class="string">&quot;state&quot;</span>)).show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">df.orderBy(<span class="string">&quot;department&quot;</span>,<span class="string">&quot;state&quot;</span>).show(<span class="literal">false</span>)</span><br><span class="line">df.orderBy(col(<span class="string">&quot;department&quot;</span>),col(<span class="string">&quot;state&quot;</span>)).show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 默认即为升序 asc</span></span><br><span class="line">df.sort(col(<span class="string">&quot;department&quot;</span>).asc,col(<span class="string">&quot;state&quot;</span>).desc).show(<span class="literal">false</span>)</span><br><span class="line">df.orderBy(col(<span class="string">&quot;department&quot;</span>).asc,col(<span class="string">&quot;state&quot;</span>).desc).show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Spark SQL 函数提供了 asc desc asc_nulls_first asc_nulls_last 函数</span></span><br><span class="line">df.select($<span class="string">&quot;employee_name&quot;</span>,asc(<span class="string">&quot;department&quot;</span>),desc(<span class="string">&quot;state&quot;</span>),$<span class="string">&quot;salary&quot;</span>,$<span class="string">&quot;age&quot;</span>,$<span class="string">&quot;bonus&quot;</span>).show(<span class="literal">false</span>)</span><br><span class="line">df.createOrReplaceTempView(<span class="string">&quot;EMP&quot;</span>)</span><br><span class="line">spark.sql(<span class="string">&quot; select employee_name,asc(&#x27;department&#x27;),desc(&#x27;state&#x27;),salary,age,bonus from EMP&quot;</span>).show(<span class="literal">false</span>)</span><br></pre></td></tr></table></figure></div><h4 id="map-——-映射"><a href="#map-——-映射" class="headerlink" title="map —— 映射"></a>map —— 映射</h4><ul><li>功能：map() 和 mapPartitions() 转换将函数应用于 DataFrame/Dataset 的每个元素/记录/行，并返回新的 DataFrame/Dataset，需要注意的是这两个转换都返回 Dataset[U] 而不是 DataFrame（在Spark 2.0中，DataFrame = Dataset [Row]）。</li><li>语法: Spark 提供了 2 个映射转换签名，一个以 scala.function1 作为参数，另一个以 Spark MapFunction 作为签名，注意到这两个函数都返回 Dataset [U]，但不返回DataFrame，即Dataset [Row]。如果希望将 DataFrame 作为输出，则需要使用 toDF() 函数将 Dataset 转换为 DataFrame。</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>) map[<span class="type">U</span>](func : scala.<span class="type">Function1</span>[<span class="type">T</span>, <span class="type">U</span>])(<span class="keyword">implicit</span> evidence$<span class="number">6</span> : org.apache.spark.sql.<span class="type">Encoder</span>[<span class="type">U</span>]) </span><br><span class="line">        : org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">U</span>]</span><br><span class="line"><span class="number">2</span>) map[<span class="type">U</span>](func : org.apache.spark.api.java.function.<span class="type">MapFunction</span>[<span class="type">T</span>, <span class="type">U</span>], encoder : org.apache.spark.sql.<span class="type">Encoder</span>[<span class="type">U</span>]) </span><br><span class="line">        : org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">U</span>]</span><br></pre></td></tr></table></figure></div><ul><li>示例:</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 示例数据</span></span><br><span class="line"><span class="keyword">val</span> structureData = <span class="type">Seq</span>(</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;James&quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;Smith&quot;</span>,<span class="string">&quot;36636&quot;</span>,<span class="string">&quot;NewYork&quot;</span>,<span class="number">3100</span>),</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;Michael&quot;</span>,<span class="string">&quot;Rose&quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;40288&quot;</span>,<span class="string">&quot;California&quot;</span>,<span class="number">4300</span>),</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;Robert&quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;Williams&quot;</span>,<span class="string">&quot;42114&quot;</span>,<span class="string">&quot;Florida&quot;</span>,<span class="number">1400</span>),</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;Maria&quot;</span>,<span class="string">&quot;Anne&quot;</span>,<span class="string">&quot;Jones&quot;</span>,<span class="string">&quot;39192&quot;</span>,<span class="string">&quot;Florida&quot;</span>,<span class="number">5500</span>),</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;Jen&quot;</span>,<span class="string">&quot;Mary&quot;</span>,<span class="string">&quot;Brown&quot;</span>,<span class="string">&quot;34561&quot;</span>,<span class="string">&quot;NewYork&quot;</span>,<span class="number">3000</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> structureSchema = <span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">    .add(<span class="string">&quot;firstname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">    .add(<span class="string">&quot;middlename&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">    .add(<span class="string">&quot;lastname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">    .add(<span class="string">&quot;id&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">    .add(<span class="string">&quot;location&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">    .add(<span class="string">&quot;salary&quot;</span>,<span class="type">IntegerType</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df2 = spark.createDataFrame(</span><br><span class="line">    spark.sparkContext.parallelize(structureData),structureSchema)</span><br><span class="line">df2.printSchema()</span><br><span class="line">df2.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- firstname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- middlename: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- lastname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- id: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- location: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">+---------+----------+--------+-----+----------+------+</span><br><span class="line">|firstname|middlename|lastname|id   |location  |salary|</span><br><span class="line">+---------+----------+--------+-----+----------+------+</span><br><span class="line">|<span class="type">James</span>    |          |<span class="type">Smith</span>   |<span class="number">36636</span>|<span class="type">NewYork</span>   |<span class="number">3100</span>  |</span><br><span class="line">|<span class="type">Michael</span>  |<span class="type">Rose</span>      |        |<span class="number">40288</span>|<span class="type">California</span>|<span class="number">4300</span>  |</span><br><span class="line">|<span class="type">Robert</span>   |          |<span class="type">Williams</span>|<span class="number">42114</span>|<span class="type">Florida</span>   |<span class="number">1400</span>  |</span><br><span class="line">|<span class="type">Maria</span>    |<span class="type">Anne</span>      |<span class="type">Jones</span>   |<span class="number">39192</span>|<span class="type">Florida</span>   |<span class="number">5500</span>  |</span><br><span class="line">|<span class="type">Jen</span>      |<span class="type">Mary</span>      |<span class="type">Brown</span>   |<span class="number">34561</span>|<span class="type">NewYork</span>   |<span class="number">3000</span>  |</span><br><span class="line">+---------+----------+--------+-----+----------+------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 为了通过实例解释 map() 和 mapPartitions()，我们再创建一个 Util 类，这个类具有一个 combine() 方法，该方法接收三个字符串参数，通过逗号合并三个参数并输出。</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Util</span> <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">combine</span></span>(fname:<span class="type">String</span>,mname:<span class="type">String</span>,lname:<span class="type">String</span>):<span class="type">String</span> = &#123;</span><br><span class="line">    fname+<span class="string">&quot;,&quot;</span>+mname+<span class="string">&quot;,&quot;</span>+lname</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// map 是在 worker 节点上执行的，而我们在 map 函数内部创建了 Util 实例，初始化将发生在 DataFrame 中的每一行，当您进行了大量复杂的初始化时，这会导致性能问题</span></span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"><span class="keyword">val</span> df3 = df2.map(row=&gt;&#123;</span><br><span class="line">    <span class="keyword">val</span> util = <span class="keyword">new</span> <span class="type">Util</span>()</span><br><span class="line">    <span class="keyword">val</span> fullName = util.combine(row.getString(<span class="number">0</span>),row.getString(<span class="number">1</span>),row.getString(<span class="number">2</span>))</span><br><span class="line">    (fullName, row.getString(<span class="number">3</span>),row.getInt(<span class="number">5</span>))</span><br><span class="line">&#125;)</span><br><span class="line"><span class="keyword">val</span> df3Map =  df3.toDF(<span class="string">&quot;fullName&quot;</span>,<span class="string">&quot;id&quot;</span>,<span class="string">&quot;salary&quot;</span>)</span><br><span class="line"></span><br><span class="line">df3Map.printSchema()</span><br><span class="line">df3Map.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- fullName: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- id: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: integer (nullable = <span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+----------------+-----+------+</span><br><span class="line">|fullName        |id   |salary|</span><br><span class="line">+----------------+-----+------+</span><br><span class="line">|<span class="type">James</span>,,<span class="type">Smith</span>    |<span class="number">36636</span>|<span class="number">3100</span>  |</span><br><span class="line">|<span class="type">Michael</span>,<span class="type">Rose</span>,   |<span class="number">40288</span>|<span class="number">4300</span>  |</span><br><span class="line">|<span class="type">Robert</span>,,<span class="type">Williams</span>|<span class="number">42114</span>|<span class="number">1400</span>  |</span><br><span class="line">|<span class="type">Maria</span>,<span class="type">Anne</span>,<span class="type">Jones</span>|<span class="number">39192</span>|<span class="number">5500</span>  |</span><br><span class="line">|<span class="type">Jen</span>,<span class="type">Mary</span>,<span class="type">Brown</span>  |<span class="number">34561</span>|<span class="number">3000</span>  |</span><br><span class="line">+----------------+-----+------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// mapPartitions() 提供了一种功能，可以对每个分区进行一次初始化（例如，数据库连接），而不是对每个行进行一次初始化，这有助于提提高效率，下面代码将得到和上例相同的结果</span></span><br><span class="line"><span class="keyword">val</span> df4 = df2.mapPartitions(iterator =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> util = <span class="keyword">new</span> <span class="type">Util</span>()</span><br><span class="line">    <span class="keyword">val</span> res = iterator.map(row=&gt;&#123;</span><br><span class="line">        <span class="keyword">val</span> fullName = util.combine(row.getString(<span class="number">0</span>),row.getString(<span class="number">1</span>),row.getString(<span class="number">2</span>))</span><br><span class="line">        (fullName, row.getString(<span class="number">3</span>),row.getInt(<span class="number">5</span>))</span><br><span class="line">    &#125;)</span><br><span class="line">    res</span><br><span class="line">&#125;)</span><br><span class="line"><span class="keyword">val</span> df4part = df4.toDF(<span class="string">&quot;fullName&quot;</span>,<span class="string">&quot;id&quot;</span>,<span class="string">&quot;salary&quot;</span>)</span><br><span class="line">df4part.printSchema()</span><br><span class="line">df4part.show(<span class="literal">false</span>)</span><br></pre></td></tr></table></figure></div><h4 id="foreach-——-遍历"><a href="#foreach-——-遍历" class="headerlink" title="foreach —— 遍历"></a>foreach —— 遍历</h4><ul><li><p>功能：foreach() 方法用于在 RDD/DataFrame/Dataset 的每个元素上应用函数，主要用于操作累积器共享变量，也可以用于将 RDD/DataFrame 结果写入数据库，生产消息到 kafka topic 等。foreachPartition() 方法用于在 RDD/DataFrame/Dataset 的每个分区上应用函数，主要用于在每个分区进行复杂的初始化操作（比如连接数据库），也可以用于操作累加器变量。foreach() 和 foreachPartition() 方法都是不会返回值的 action。</p></li><li><p>语法:</p></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">foreachPartition(f : scala.<span class="type">Function1</span>[scala.<span class="type">Iterator</span>[<span class="type">T</span>], scala.<span class="type">Unit</span>]) : scala.<span class="type">Unit</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div><ul><li>示例:</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// foreach 操作累加器</span></span><br><span class="line"><span class="keyword">val</span> longAcc = spark.sparkContext.longAccumulator(<span class="string">&quot;SumAccumulator&quot;</span>)</span><br><span class="line">df.foreach(f=&gt; &#123;</span><br><span class="line">    longAcc.add(f.getInt(<span class="number">1</span>))</span><br><span class="line">  &#125;)</span><br><span class="line">println(<span class="string">&quot;Accumulator value:&quot;</span>+longAcc.value)</span><br><span class="line"></span><br><span class="line"><span class="comment">// foreachPartition 写入数据</span></span><br><span class="line"><span class="keyword">val</span> df = spark.createDataFrame(data).toDF(<span class="string">&quot;Product&quot;</span>,<span class="string">&quot;Amount&quot;</span>,<span class="string">&quot;Country&quot;</span>)</span><br><span class="line">df.foreachPartition(partition =&gt; &#123;</span><br><span class="line">    <span class="comment">//Initialize database connection or kafka</span></span><br><span class="line">    partition.foreach(fun=&gt;&#123;</span><br><span class="line">      <span class="comment">//apply the function to insert the database </span></span><br><span class="line">      <span class="comment">// or produce kafka topic</span></span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="comment">//If you have batch inserts, do here.</span></span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// rdd foreach 和 DataFrame foreach 是等价的 action</span></span><br><span class="line"><span class="keyword">val</span> rdd2 = spark.sparkContext.parallelize(<span class="type">Seq</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>))</span><br><span class="line"><span class="keyword">val</span> longAcc2 = spark.sparkContext.longAccumulator(<span class="string">&quot;SumAccumulator2&quot;</span>)</span><br><span class="line">  rdd.foreach(f=&gt; &#123;</span><br><span class="line">    longAcc2.add(f)</span><br><span class="line">  &#125;)</span><br><span class="line">println(<span class="string">&quot;Accumulator value:&quot;</span>+longAcc2.value)</span><br></pre></td></tr></table></figure></div><h4 id="sample-——-随机抽样"><a href="#sample-——-随机抽样" class="headerlink" title="sample —— 随机抽样"></a>sample —— 随机抽样</h4><ul><li>功能：从 DataFrame 中抽取一些随机记录；</li><li>语法：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// withReplacement: 是否是有放回抽样; fraction: 抽样比例; seed: 抽样算法初始值</span></span><br><span class="line">sample(fraction: <span class="type">Double</span>)</span><br><span class="line">sample(fraction: <span class="type">Double</span>, seed: <span class="type">Long</span>)</span><br><span class="line">sample(withReplacement: <span class="type">Boolean</span>, fraction: <span class="type">Double</span>)</span><br><span class="line">sample(withReplacement: <span class="type">Boolean</span>, fraction: <span class="type">Double</span>, seed: <span class="type">Long</span>)</span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">df.sample(<span class="number">0.2</span>).show()</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|                name|  dob|gender|salary|</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line"></span><br><span class="line">df.sample(<span class="number">0.5</span>, <span class="number">1000</span>L).show()</span><br><span class="line">+------------------+-----+------+------+</span><br><span class="line">|              name|  dob|gender|salary|</span><br><span class="line">+------------------+-----+------+------+</span><br><span class="line">| [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|</span><br><span class="line">|[<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|</span><br><span class="line">+------------------+-----+------+------+</span><br><span class="line"></span><br><span class="line">df.sample(<span class="literal">true</span>, <span class="number">0.5</span>, <span class="number">1000</span>L).show()</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|                name|  dob|gender|salary|</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|</span><br><span class="line">+--------------------+-----+------+------+</span><br></pre></td></tr></table></figure></div><h4 id="split-——-随机分割"><a href="#split-——-随机分割" class="headerlink" title="split —— 随机分割"></a>split —— 随机分割</h4><ul><li>功能：将原始 DataFrame 随机拆分，这通常与机器学习算法一起使用以创建训练、验证和测试集；</li><li>语法：返回 Array(DataFrame)；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">randomSplit(weights: <span class="type">Array</span>[<span class="type">Double</span>])</span><br><span class="line">randomSplit(weights: <span class="type">Array</span>[<span class="type">Double</span>], seed: <span class="type">Long</span>)</span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dfs = df.randomSplit(<span class="type">Array</span>(<span class="number">0.8</span>, <span class="number">0.2</span>))</span><br><span class="line">dfs(<span class="number">0</span>).show()</span><br><span class="line">dfs(<span class="number">1</span>).show()</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|                name|  dob|gender|salary|</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|</span><br><span class="line">|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line"></span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|                name|  dob|gender|salary|</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|</span><br><span class="line">+--------------------+-----+------+------+</span><br></pre></td></tr></table></figure></div><h4 id="limit-——-限制"><a href="#limit-——-限制" class="headerlink" title="limit —— 限制"></a>limit —— 限制</h4><ul><li>功能：限制从 DataFrame 中提取的内容，当你需要一个空的 DataFrame 但又想保留 Schema 信息时可以通过 <code>df.limit(0)</code> 来实现；</li><li>语法：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.limit(n)</span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">df.orderBy(<span class="string">&quot;dob&quot;</span>).limit(<span class="number">3</span>).show()</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|                name|  dob|gender|salary|</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line"></span><br><span class="line">df.limit(<span class="number">0</span>).show()</span><br><span class="line">+----+---+------+------+</span><br><span class="line">|name|dob|gender|salary|</span><br><span class="line">+----+---+------+------+</span><br><span class="line">+----+---+------+------+</span><br></pre></td></tr></table></figure></div><h4 id="first-last-——-首行或末行"><a href="#first-last-——-首行或末行" class="headerlink" title="first | last —— 首行或末行"></a>first | last —— 首行或末行</h4><ul><li><p>功能：获取某列第一行/最后一行的值</p></li><li><p>语法：</p></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">first(e: <span class="type">Column</span>, ignoreNulls: <span class="type">Boolean</span>)</span><br><span class="line">first(columnName: <span class="type">String</span>, ignoreNulls: <span class="type">Boolean</span>)</span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df.select(first(<span class="string">&quot;name&quot;</span>), first(<span class="string">&quot;dob&quot;</span>), last(<span class="string">&quot;gender&quot;</span>), last(<span class="string">&quot;salary&quot;</span>)).show()</span><br><span class="line">+------------------+-----------------+-------------------+-------------------+</span><br><span class="line">|first(name, <span class="literal">false</span>)|first(dob, <span class="literal">false</span>)|last(gender, <span class="literal">false</span>)|last(salary, <span class="literal">false</span>)|</span><br><span class="line">+------------------+-----------------+-------------------+-------------------+</span><br><span class="line">| [<span class="type">James</span> , , <span class="type">Smith</span>]|            <span class="number">36636</span>|                  <span class="type">F</span>|                 <span class="number">-1</span>|</span><br><span class="line">+------------------+-----------------+-------------------+-------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure></div><h3 id="表操作"><a href="#表操作" class="headerlink" title="表操作"></a>表操作</h3><h4 id="union-——-合并"><a href="#union-——-合并" class="headerlink" title="union —— 合并"></a>union —— 合并</h4><ul><li>功能：在 Spark 中 union() 和 unionAll() 作用相同，用于合并两个 schema 相同（不会校验schema，只会校验字段数是否相同）的 DataFrame，但是都不会对结果进行去重，如果需要去重，可以通过去重算子对结果去重。</li><li>语法：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.union(df2)</span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 没有什么好展示的</span></span><br><span class="line"><span class="keyword">val</span> df5 = df.union(df2).distinct()</span><br></pre></td></tr></table></figure></div><h4 id="join-——-连接"><a href="#join-——-连接" class="headerlink" title="join —— 连接"></a>join —— 连接</h4><ul><li>功能：Spark SQL 支持传统 SQL 中可用的所有基本联接操作（这里不再赘述），尽管 Spark 核心联接在设计时不小心会产生巨大的性能问题，因为它涉及到跨网络的数据 shuffe，另一方面，Spark SQL 连接在默认情况下具有更多的优化（多亏了 DataFrames &amp; Dataset），但是在使用时仍然会有一些性能问题需要考虑；</li><li>语法: 三要素为连接表、连接谓词、连接类型；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>) join(right: <span class="type">Dataset</span>[_]): <span class="type">DataFrame</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用 usingColumn：join 结果中只会保留左表的 usingColumn，以及左右表其他列</span></span><br><span class="line"><span class="number">2</span>) join(right: <span class="type">Dataset</span>[_], usingColumn: <span class="type">String</span>): <span class="type">DataFrame</span></span><br><span class="line"><span class="number">3</span>) join(right: <span class="type">Dataset</span>[_], usingColumns: <span class="type">Seq</span>[<span class="type">String</span>]): <span class="type">DataFrame</span></span><br><span class="line"><span class="number">4</span>) join(right: <span class="type">Dataset</span>[_], usingColumns: <span class="type">Seq</span>[<span class="type">String</span>], joinType: <span class="type">String</span>): <span class="type">DataFrame</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用 joinExprs：joinExprs 返回一个布尔型 Column，join 结果会包含两个表的所有列</span></span><br><span class="line"><span class="number">5</span>) join(right: <span class="type">Dataset</span>[_], joinExprs: <span class="type">Column</span>): <span class="type">DataFrame</span></span><br><span class="line"><span class="number">6</span>) join(right: <span class="type">Dataset</span>[_], joinExprs: <span class="type">Column</span>, joinType: <span class="type">String</span>): <span class="type">DataFrame</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 笛卡尔积：将左表中的每一行与右表中的每一行进行连接</span></span><br><span class="line"><span class="number">7</span>) crossJoin(right: <span class="type">Dataset</span>[_])</span><br></pre></td></tr></table></figure></div><ul><li>join 类型: 对于上面语句 4 和语句 5，你可以使用 JoinType 或 Join String 中的一种，如果要使用 JoinType，应该先导入 <code>import org.apache.spark.sql.catalyst.plans._</code>，以下示例将采用上面语句 6 的形式</li></ul><div class="table-container"><table><thead><tr><th>JoinType</th><th>Join String</th><th>Equivalent SQL Join</th></tr></thead><tbody><tr><td>Inner.sql</td><td>inner</td><td>INNER JOIN</td></tr><tr><td>FullOuter.sql</td><td>outer, full, fullouter, full_outer</td><td>FULL OUTER JOIN</td></tr><tr><td>LeftOuter.sql</td><td>left, leftouter, left_outer</td><td>LEFT JOIN</td></tr><tr><td>RightOuter.sql</td><td>right, rightouter, right_outer</td><td>RIGHT JOIN</td></tr><tr><td>Cross.sql</td><td>cross</td><td>-</td></tr><tr><td>LeftAnti.sql</td><td>anti, leftanti, left_anti</td><td>-</td></tr><tr><td>LeftSemi.sql</td><td>semi, leftsemi, left_semi</td><td>-</td></tr></tbody></table></div><ul><li>示例数据:</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> emp = <span class="type">Seq</span>((<span class="number">1</span>,<span class="string">&quot;Smith&quot;</span>,<span class="number">-1</span>,<span class="string">&quot;2018&quot;</span>,<span class="string">&quot;10&quot;</span>,<span class="string">&quot;M&quot;</span>,<span class="number">3000</span>),</span><br><span class="line">    (<span class="number">2</span>,<span class="string">&quot;Rose&quot;</span>,<span class="number">1</span>,<span class="string">&quot;2010&quot;</span>,<span class="string">&quot;20&quot;</span>,<span class="string">&quot;M&quot;</span>,<span class="number">4000</span>),</span><br><span class="line">    (<span class="number">3</span>,<span class="string">&quot;Williams&quot;</span>,<span class="number">1</span>,<span class="string">&quot;2010&quot;</span>,<span class="string">&quot;10&quot;</span>,<span class="string">&quot;M&quot;</span>,<span class="number">1000</span>),</span><br><span class="line">    (<span class="number">4</span>,<span class="string">&quot;Jones&quot;</span>,<span class="number">2</span>,<span class="string">&quot;2005&quot;</span>,<span class="string">&quot;10&quot;</span>,<span class="string">&quot;F&quot;</span>,<span class="number">2000</span>),</span><br><span class="line">    (<span class="number">5</span>,<span class="string">&quot;Brown&quot;</span>,<span class="number">2</span>,<span class="string">&quot;2010&quot;</span>,<span class="string">&quot;40&quot;</span>,<span class="string">&quot;&quot;</span>,<span class="number">-1</span>),</span><br><span class="line">      (<span class="number">6</span>,<span class="string">&quot;Brown&quot;</span>,<span class="number">2</span>,<span class="string">&quot;2010&quot;</span>,<span class="string">&quot;50&quot;</span>,<span class="string">&quot;&quot;</span>,<span class="number">-1</span>)</span><br><span class="line">  )</span><br><span class="line"><span class="keyword">val</span> empColumns = <span class="type">Seq</span>(<span class="string">&quot;emp_id&quot;</span>,<span class="string">&quot;name&quot;</span>,<span class="string">&quot;superior_emp_id&quot;</span>,<span class="string">&quot;year_joined&quot;</span>,</span><br><span class="line">   <span class="string">&quot;emp_dept_id&quot;</span>,<span class="string">&quot;gender&quot;</span>,<span class="string">&quot;salary&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> spark.sqlContext.implicits._</span><br><span class="line"><span class="keyword">val</span> empDF = emp.toDF(empColumns:_*)</span><br><span class="line">empDF.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+</span><br><span class="line">|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+</span><br><span class="line">|<span class="number">1</span>     |<span class="type">Smith</span>   |<span class="number">-1</span>             |<span class="number">2018</span>       |<span class="number">10</span>         |<span class="type">M</span>     |<span class="number">3000</span>  |</span><br><span class="line">|<span class="number">2</span>     |<span class="type">Rose</span>    |<span class="number">1</span>              |<span class="number">2010</span>       |<span class="number">20</span>         |<span class="type">M</span>     |<span class="number">4000</span>  |</span><br><span class="line">|<span class="number">3</span>     |<span class="type">Williams</span>|<span class="number">1</span>              |<span class="number">2010</span>       |<span class="number">10</span>         |<span class="type">M</span>     |<span class="number">1000</span>  |</span><br><span class="line">|<span class="number">4</span>     |<span class="type">Jones</span>   |<span class="number">2</span>              |<span class="number">2005</span>       |<span class="number">10</span>         |<span class="type">F</span>     |<span class="number">2000</span>  |</span><br><span class="line">|<span class="number">5</span>     |<span class="type">Brown</span>   |<span class="number">2</span>              |<span class="number">2010</span>       |<span class="number">40</span>         |      |<span class="number">-1</span>    |</span><br><span class="line">|<span class="number">6</span>     |<span class="type">Brown</span>   |<span class="number">2</span>              |<span class="number">2010</span>       |<span class="number">50</span>         |      |<span class="number">-1</span>    |</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> dept = <span class="type">Seq</span>((<span class="string">&quot;Finance&quot;</span>,<span class="number">10</span>),</span><br><span class="line">(<span class="string">&quot;Marketing&quot;</span>,<span class="number">20</span>),</span><br><span class="line">(<span class="string">&quot;Sales&quot;</span>,<span class="number">30</span>),</span><br><span class="line">(<span class="string">&quot;IT&quot;</span>,<span class="number">40</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> deptColumns = <span class="type">Seq</span>(<span class="string">&quot;dept_name&quot;</span>,<span class="string">&quot;dept_id&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> deptDF = dept.toDF(deptColumns:_*)</span><br><span class="line">deptDF.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+---------+-------+</span><br><span class="line">|dept_name|dept_id|</span><br><span class="line">+---------+-------+</span><br><span class="line">|<span class="type">Finance</span>  |<span class="number">10</span>     |</span><br><span class="line">|<span class="type">Marketing</span>|<span class="number">20</span>     |</span><br><span class="line">|<span class="type">Sales</span>    |<span class="number">30</span>     |</span><br><span class="line">|<span class="type">IT</span>       |<span class="number">40</span>     |</span><br><span class="line">+---------+-------+</span><br></pre></td></tr></table></figure></div><h5 id="Inner-Join"><a href="#Inner-Join" class="headerlink" title="Inner Join"></a>Inner Join</h5><p>Inner Join 内连接，只返回匹配成功的行。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">empDF.join(deptDF,empDF(<span class="string">&quot;emp_dept_id&quot;</span>) ===  deptDF(<span class="string">&quot;dept_id&quot;</span>),<span class="string">&quot;inner&quot;</span>).show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|<span class="number">1</span>     |<span class="type">Smith</span>   |<span class="number">-1</span>             |<span class="number">2018</span>       |<span class="number">10</span>         |<span class="type">M</span>     |<span class="number">3000</span>  |<span class="type">Finance</span>  |<span class="number">10</span>     |</span><br><span class="line">|<span class="number">2</span>     |<span class="type">Rose</span>    |<span class="number">1</span>              |<span class="number">2010</span>       |<span class="number">20</span>         |<span class="type">M</span>     |<span class="number">4000</span>  |<span class="type">Marketing</span>|<span class="number">20</span>     |</span><br><span class="line">|<span class="number">3</span>     |<span class="type">Williams</span>|<span class="number">1</span>              |<span class="number">2010</span>       |<span class="number">10</span>         |<span class="type">M</span>     |<span class="number">1000</span>  |<span class="type">Finance</span>  |<span class="number">10</span>     |</span><br><span class="line">|<span class="number">4</span>     |<span class="type">Jones</span>   |<span class="number">2</span>              |<span class="number">2005</span>       |<span class="number">10</span>         |<span class="type">F</span>     |<span class="number">2000</span>  |<span class="type">Finance</span>  |<span class="number">10</span>     |</span><br><span class="line">|<span class="number">5</span>     |<span class="type">Brown</span>   |<span class="number">2</span>              |<span class="number">2010</span>       |<span class="number">40</span>         |      |<span class="number">-1</span>    |<span class="type">IT</span>       |<span class="number">40</span>     |</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br></pre></td></tr></table></figure></div><h5 id="Full-Join"><a href="#Full-Join" class="headerlink" title="Full Join"></a>Full Join</h5><p>Outer/Full,/Fullouter Join 全外连接，匹配成功的 + 左表有右表没有 + 右表有左表没有</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">empDF.join(deptDF,empDF(<span class="string">&quot;emp_dept_id&quot;</span>) ===  deptDF(<span class="string">&quot;dept_id&quot;</span>),<span class="string">&quot;outer&quot;</span>).show(<span class="literal">false</span>)</span><br><span class="line">empDF.join(deptDF,empDF(<span class="string">&quot;emp_dept_id&quot;</span>) ===  deptDF(<span class="string">&quot;dept_id&quot;</span>),<span class="string">&quot;full&quot;</span>).show(<span class="literal">false</span>)</span><br><span class="line">empDF.join(deptDF,empDF(<span class="string">&quot;emp_dept_id&quot;</span>) ===  deptDF(<span class="string">&quot;dept_id&quot;</span>),<span class="string">&quot;fullouter&quot;</span>).show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|<span class="number">2</span>     |<span class="type">Rose</span>    |<span class="number">1</span>              |<span class="number">2010</span>       |<span class="number">20</span>         |<span class="type">M</span>     |<span class="number">4000</span>  |<span class="type">Marketing</span>|<span class="number">20</span>     |</span><br><span class="line">|<span class="number">5</span>     |<span class="type">Brown</span>   |<span class="number">2</span>              |<span class="number">2010</span>       |<span class="number">40</span>         |      |<span class="number">-1</span>    |<span class="type">IT</span>       |<span class="number">40</span>     |</span><br><span class="line">|<span class="number">1</span>     |<span class="type">Smith</span>   |<span class="number">-1</span>             |<span class="number">2018</span>       |<span class="number">10</span>         |<span class="type">M</span>     |<span class="number">3000</span>  |<span class="type">Finance</span>  |<span class="number">10</span>     |</span><br><span class="line">|<span class="number">3</span>     |<span class="type">Williams</span>|<span class="number">1</span>              |<span class="number">2010</span>       |<span class="number">10</span>         |<span class="type">M</span>     |<span class="number">1000</span>  |<span class="type">Finance</span>  |<span class="number">10</span>     |</span><br><span class="line">|<span class="number">4</span>     |<span class="type">Jones</span>   |<span class="number">2</span>              |<span class="number">2005</span>       |<span class="number">10</span>         |<span class="type">F</span>     |<span class="number">2000</span>  |<span class="type">Finance</span>  |<span class="number">10</span>     |</span><br><span class="line">|<span class="number">6</span>     |<span class="type">Brown</span>   |<span class="number">2</span>              |<span class="number">2010</span>       |<span class="number">50</span>         |      |<span class="number">-1</span>    |<span class="literal">null</span>     |<span class="literal">null</span>   |</span><br><span class="line">|<span class="literal">null</span>  |<span class="literal">null</span>    |<span class="literal">null</span>           |<span class="literal">null</span>       |<span class="literal">null</span>       |<span class="literal">null</span>  |<span class="literal">null</span>  |<span class="type">Sales</span>    |<span class="number">30</span>     |</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line"></span><br></pre></td></tr></table></figure></div><h5 id="Left-Join"><a href="#Left-Join" class="headerlink" title="Left Join"></a>Left Join</h5><p>Left/Leftouter Join 左连接，匹配成功的 + 左表有右表没有的</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">empDF.join(deptDF,empDF(<span class="string">&quot;emp_dept_id&quot;</span>) ===  deptDF(<span class="string">&quot;dept_id&quot;</span>),<span class="string">&quot;left&quot;</span>).show(<span class="literal">false</span>)</span><br><span class="line">empDF.join(deptDF,empDF(<span class="string">&quot;emp_dept_id&quot;</span>) ===  deptDF(<span class="string">&quot;dept_id&quot;</span>),<span class="string">&quot;leftouter&quot;</span>).show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|<span class="number">1</span>     |<span class="type">Smith</span>   |<span class="number">-1</span>             |<span class="number">2018</span>       |<span class="number">10</span>         |<span class="type">M</span>     |<span class="number">3000</span>  |<span class="type">Finance</span>  |<span class="number">10</span>     |</span><br><span class="line">|<span class="number">2</span>     |<span class="type">Rose</span>    |<span class="number">1</span>              |<span class="number">2010</span>       |<span class="number">20</span>         |<span class="type">M</span>     |<span class="number">4000</span>  |<span class="type">Marketing</span>|<span class="number">20</span>     |</span><br><span class="line">|<span class="number">3</span>     |<span class="type">Williams</span>|<span class="number">1</span>              |<span class="number">2010</span>       |<span class="number">10</span>         |<span class="type">M</span>     |<span class="number">1000</span>  |<span class="type">Finance</span>  |<span class="number">10</span>     |</span><br><span class="line">|<span class="number">4</span>     |<span class="type">Jones</span>   |<span class="number">2</span>              |<span class="number">2005</span>       |<span class="number">10</span>         |<span class="type">F</span>     |<span class="number">2000</span>  |<span class="type">Finance</span>  |<span class="number">10</span>     |</span><br><span class="line">|<span class="number">5</span>     |<span class="type">Brown</span>   |<span class="number">2</span>              |<span class="number">2010</span>       |<span class="number">40</span>         |      |<span class="number">-1</span>    |<span class="type">IT</span>       |<span class="number">40</span>     |</span><br><span class="line">|<span class="number">6</span>     |<span class="type">Brown</span>   |<span class="number">2</span>              |<span class="number">2010</span>       |<span class="number">50</span>         |      |<span class="number">-1</span>    |<span class="literal">null</span>     |<span class="literal">null</span>   |</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line"></span><br></pre></td></tr></table></figure></div><h5 id="Right-Join"><a href="#Right-Join" class="headerlink" title="Right Join"></a>Right Join</h5><p>Right/Rightouter Join 右连接，匹配成功的 + 右表有左表没有的</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">empDF.join(deptDF,empDF(<span class="string">&quot;emp_dept_id&quot;</span>) ===  deptDF(<span class="string">&quot;dept_id&quot;</span>),<span class="string">&quot;right&quot;</span>).show(<span class="literal">false</span>)</span><br><span class="line">empDF.join(deptDF,empDF(<span class="string">&quot;emp_dept_id&quot;</span>) ===  deptDF(<span class="string">&quot;dept_id&quot;</span>),<span class="string">&quot;rightouter&quot;</span>).show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|<span class="number">4</span>     |<span class="type">Jones</span>   |<span class="number">2</span>              |<span class="number">2005</span>       |<span class="number">10</span>         |<span class="type">F</span>     |<span class="number">2000</span>  |<span class="type">Finance</span>  |<span class="number">10</span>     |</span><br><span class="line">|<span class="number">3</span>     |<span class="type">Williams</span>|<span class="number">1</span>              |<span class="number">2010</span>       |<span class="number">10</span>         |<span class="type">M</span>     |<span class="number">1000</span>  |<span class="type">Finance</span>  |<span class="number">10</span>     |</span><br><span class="line">|<span class="number">1</span>     |<span class="type">Smith</span>   |<span class="number">-1</span>             |<span class="number">2018</span>       |<span class="number">10</span>         |<span class="type">M</span>     |<span class="number">3000</span>  |<span class="type">Finance</span>  |<span class="number">10</span>     |</span><br><span class="line">|<span class="number">2</span>     |<span class="type">Rose</span>    |<span class="number">1</span>              |<span class="number">2010</span>       |<span class="number">20</span>         |<span class="type">M</span>     |<span class="number">4000</span>  |<span class="type">Marketing</span>|<span class="number">20</span>     |</span><br><span class="line">|<span class="literal">null</span>  |<span class="literal">null</span>    |<span class="literal">null</span>           |<span class="literal">null</span>       |<span class="literal">null</span>       |<span class="literal">null</span>  |<span class="literal">null</span>  |<span class="type">Sales</span>    |<span class="number">30</span>     |</span><br><span class="line">|<span class="number">5</span>     |<span class="type">Brown</span>   |<span class="number">2</span>              |<span class="number">2010</span>       |<span class="number">40</span>         |      |<span class="number">-1</span>    |<span class="type">IT</span>       |<span class="number">40</span>     |</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br></pre></td></tr></table></figure></div><h5 id="Left-Semi-Join"><a href="#Left-Semi-Join" class="headerlink" title="Left Semi Join"></a>Left Semi Join</h5><p>Left Semi Join 左半连接，匹配成功的，只保留左表字段。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">empDF.join(deptDF,empDF(<span class="string">&quot;emp_dept_id&quot;</span>) ===  deptDF(<span class="string">&quot;dept_id&quot;</span>),<span class="string">&quot;leftsemi&quot;</span>).show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+</span><br><span class="line">|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+</span><br><span class="line">|<span class="number">1</span>     |<span class="type">Smith</span>   |<span class="number">-1</span>             |<span class="number">2018</span>       |<span class="number">10</span>         |<span class="type">M</span>     |<span class="number">3000</span>  |</span><br><span class="line">|<span class="number">2</span>     |<span class="type">Rose</span>    |<span class="number">1</span>              |<span class="number">2010</span>       |<span class="number">20</span>         |<span class="type">M</span>     |<span class="number">4000</span>  |</span><br><span class="line">|<span class="number">3</span>     |<span class="type">Williams</span>|<span class="number">1</span>              |<span class="number">2010</span>       |<span class="number">10</span>         |<span class="type">M</span>     |<span class="number">1000</span>  |</span><br><span class="line">|<span class="number">4</span>     |<span class="type">Jones</span>   |<span class="number">2</span>              |<span class="number">2005</span>       |<span class="number">10</span>         |<span class="type">F</span>     |<span class="number">2000</span>  |</span><br><span class="line">|<span class="number">5</span>     |<span class="type">Brown</span>   |<span class="number">2</span>              |<span class="number">2010</span>       |<span class="number">40</span>         |      |<span class="number">-1</span>    |</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+</span><br></pre></td></tr></table></figure></div><h5 id="Left-Anti-Join"><a href="#Left-Anti-Join" class="headerlink" title="Left Anti Join"></a>Left Anti Join</h5><p>Left Anti Join 反左半连接，没有匹配成功的，只返回左表字段</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">empDF.join(deptDF,empDF(<span class="string">&quot;emp_dept_id&quot;</span>) ===  deptDF(<span class="string">&quot;dept_id&quot;</span>),<span class="string">&quot;leftanti&quot;</span>).show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+------+-----+---------------+-----------+-----------+------+------+</span><br><span class="line">|emp_id|name |superior_emp_id|year_joined|emp_dept_id|gender|salary|</span><br><span class="line">+------+-----+---------------+-----------+-----------+------+------+</span><br><span class="line">|<span class="number">6</span>     |<span class="type">Brown</span>|<span class="number">2</span>              |<span class="number">2010</span>       |<span class="number">50</span>         |      |<span class="number">-1</span>    |</span><br><span class="line">+------+-----+---------------+-----------+-----------+------+------+</span><br><span class="line"></span><br></pre></td></tr></table></figure></div><h5 id="Self-Join"><a href="#Self-Join" class="headerlink" title="Self Join"></a>Self Join</h5><p>虽然没有自连接类型，但是可以使用以上任意一种 join 类型与自己关联，但是要通过别名的方式。为DataFrame 起别名 <code>&quot;a&quot;</code> 后，原有字段名 <code>&quot;col&quot;</code> 就变成 <code>&quot;a.col&quot;</code>，可以通过 <code>&quot;a.*&quot;</code> 把原有的列“释放”出来。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">empDF.as(<span class="string">&quot;emp1&quot;</span>).join(empDF.as(<span class="string">&quot;emp2&quot;</span>), col(<span class="string">&quot;emp1.superior_emp_id&quot;</span>) === col(<span class="string">&quot;emp2.emp_id&quot;</span>),<span class="string">&quot;inner&quot;</span>)</span><br><span class="line">    .select(col(<span class="string">&quot;emp1.emp_id&quot;</span>),col(<span class="string">&quot;emp1.name&quot;</span>),</span><br><span class="line">      col(<span class="string">&quot;emp2.emp_id&quot;</span>).as(<span class="string">&quot;superior_emp_id&quot;</span>),</span><br><span class="line">      col(<span class="string">&quot;emp2.name&quot;</span>).as(<span class="string">&quot;superior_emp_name&quot;</span>)</span><br><span class="line">    )</span><br><span class="line">    .show(<span class="literal">false</span>)</span><br><span class="line">  </span><br><span class="line">+------+--------+---------------+-----------------+</span><br><span class="line">|emp_id|name    |superior_emp_id|superior_emp_name|</span><br><span class="line">+------+--------+---------------+-----------------+</span><br><span class="line">|<span class="number">2</span>     |<span class="type">Rose</span>    |<span class="number">1</span>              |<span class="type">Smith</span>            |</span><br><span class="line">|<span class="number">3</span>     |<span class="type">Williams</span>|<span class="number">1</span>              |<span class="type">Smith</span>            |</span><br><span class="line">|<span class="number">4</span>     |<span class="type">Jones</span>   |<span class="number">2</span>              |<span class="type">Rose</span>             |</span><br><span class="line">|<span class="number">5</span>     |<span class="type">Brown</span>   |<span class="number">2</span>              |<span class="type">Rose</span>             |</span><br><span class="line">|<span class="number">6</span>     |<span class="type">Brown</span>   |<span class="number">2</span>              |<span class="type">Rose</span>             |</span><br><span class="line">+------+--------+---------------+-----------------+</span><br></pre></td></tr></table></figure></div><h5 id="Cross-Join"><a href="#Cross-Join" class="headerlink" title="Cross Join"></a>Cross Join</h5><p>Cross Join（笛卡尔连接、交叉连接）会将左侧 DataFrame 中的每一行与右侧 DataFrame 中的每一行进行连接，这将导致结果 DataFrame 中的行数发生绝对爆炸，仅在绝对必要时才应使用笛卡尔积，它们很危险！！！我们分几种场景来讨论和 Cross Join 相关的一些问题：</p><ul><li><code>join</code> 算子中如果指定了连接谓词，那么，即使将参数 <code>joinType</code> 设置为 “cross”，实际执行的仍然是 <code>inner join</code></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">empDF.join(deptDF, empDF(<span class="string">&quot;emp_dept_id&quot;</span>) === deptDF(<span class="string">&quot;dept_id&quot;</span>), <span class="string">&quot;cross&quot;</span>).show()</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|     <span class="number">1</span>|   <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">2</span>|    <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">3</span>|<span class="type">Williams</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">1000</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">4</span>|   <span class="type">Jones</span>|              <span class="number">2</span>|       <span class="number">2005</span>|         <span class="number">10</span>|     <span class="type">F</span>|  <span class="number">2000</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">5</span>|   <span class="type">Brown</span>|              <span class="number">2</span>|       <span class="number">2010</span>|         <span class="number">40</span>|      |    <span class="number">-1</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br></pre></td></tr></table></figure></div><ul><li><code>join</code> 算子中，如果将连接谓词设置为恒等式，可以实现笛卡尔积（<code>joinType</code>需同时设置为 “cross”）</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">empDF.join(deptDF, lit(<span class="number">1</span>) === lit(<span class="number">1</span>), <span class="string">&quot;cross&quot;</span>).show()</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|     <span class="number">1</span>|   <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">1</span>|   <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">1</span>|   <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|    <span class="type">Sales</span>|     <span class="number">30</span>|</span><br><span class="line">|     <span class="number">1</span>|   <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">|     <span class="number">2</span>|    <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">2</span>|    <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">2</span>|    <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|    <span class="type">Sales</span>|     <span class="number">30</span>|</span><br><span class="line">|     <span class="number">2</span>|    <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">|     <span class="number">3</span>|<span class="type">Williams</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">1000</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">3</span>|<span class="type">Williams</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">1000</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">3</span>|<span class="type">Williams</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">1000</span>|    <span class="type">Sales</span>|     <span class="number">30</span>|</span><br><span class="line">|     <span class="number">3</span>|<span class="type">Williams</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">1000</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">|     <span class="number">4</span>|   <span class="type">Jones</span>|              <span class="number">2</span>|       <span class="number">2005</span>|         <span class="number">10</span>|     <span class="type">F</span>|  <span class="number">2000</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">4</span>|   <span class="type">Jones</span>|              <span class="number">2</span>|       <span class="number">2005</span>|         <span class="number">10</span>|     <span class="type">F</span>|  <span class="number">2000</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">4</span>|   <span class="type">Jones</span>|              <span class="number">2</span>|       <span class="number">2005</span>|         <span class="number">10</span>|     <span class="type">F</span>|  <span class="number">2000</span>|    <span class="type">Sales</span>|     <span class="number">30</span>|</span><br><span class="line">|     <span class="number">4</span>|   <span class="type">Jones</span>|              <span class="number">2</span>|       <span class="number">2005</span>|         <span class="number">10</span>|     <span class="type">F</span>|  <span class="number">2000</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">|     <span class="number">5</span>|   <span class="type">Brown</span>|              <span class="number">2</span>|       <span class="number">2010</span>|         <span class="number">40</span>|      |    <span class="number">-1</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">5</span>|   <span class="type">Brown</span>|              <span class="number">2</span>|       <span class="number">2010</span>|         <span class="number">40</span>|      |    <span class="number">-1</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">5</span>|   <span class="type">Brown</span>|              <span class="number">2</span>|       <span class="number">2010</span>|         <span class="number">40</span>|      |    <span class="number">-1</span>|    <span class="type">Sales</span>|     <span class="number">30</span>|</span><br><span class="line">|     <span class="number">5</span>|   <span class="type">Brown</span>|              <span class="number">2</span>|       <span class="number">2010</span>|         <span class="number">40</span>|      |    <span class="number">-1</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br></pre></td></tr></table></figure></div><ul><li><code>join</code> 算子中，如果省略了连接谓词，则会报 <code>AnalysisException</code> 错误，一种解决办法是设置 <code>spark.conf.set(&quot;spark.sql.crossJoin.enabled&quot;,true)</code>，以允许笛卡尔积而不会发出警告或 Spark 不会尝试为您执行另一种连接</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">empDF.join(deptDF).show()</span><br><span class="line">org.apache.spark.sql.<span class="type">AnalysisException</span>: <span class="type">Detected</span> <span class="keyword">implicit</span> cartesian product <span class="keyword">for</span> <span class="type">INNER</span> join between logical plans</span><br><span class="line"><span class="type">LocalRelation</span> [emp_id#<span class="number">940</span>, name#<span class="number">941</span>, superior_emp_id#<span class="number">942</span>, year_joined#<span class="number">943</span>, emp_dept_id#<span class="number">944</span>, gender#<span class="number">945</span>, salary#<span class="number">946</span>]</span><br><span class="line">and</span><br><span class="line"><span class="type">LocalRelation</span> [dept_name#<span class="number">981</span>, dept_id#<span class="number">982</span>]</span><br><span class="line"><span class="type">Join</span> condition is missing or trivial.</span><br><span class="line"><span class="type">Either</span>: use the <span class="type">CROSS</span> <span class="type">JOIN</span> syntax to allow cartesian products between these</span><br><span class="line">relations, or: enable <span class="keyword">implicit</span> cartesian products by setting the configuration</span><br><span class="line">variable spark.sql.crossJoin.enabled=<span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">spark.conf.set(<span class="string">&quot;spark.sql.crossJoin.enabled&quot;</span>,<span class="literal">true</span>)</span><br><span class="line">empDF.join(deptDF).show()</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|     <span class="number">1</span>|   <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">1</span>|   <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">1</span>|   <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|    <span class="type">Sales</span>|     <span class="number">30</span>|</span><br><span class="line">|     <span class="number">1</span>|   <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">|     <span class="number">2</span>|    <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">2</span>|    <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">2</span>|    <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|    <span class="type">Sales</span>|     <span class="number">30</span>|</span><br><span class="line">|     <span class="number">2</span>|    <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">|     <span class="number">3</span>|<span class="type">Williams</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">1000</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">3</span>|<span class="type">Williams</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">1000</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">3</span>|<span class="type">Williams</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">1000</span>|    <span class="type">Sales</span>|     <span class="number">30</span>|</span><br><span class="line">|     <span class="number">3</span>|<span class="type">Williams</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">1000</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">|     <span class="number">4</span>|   <span class="type">Jones</span>|              <span class="number">2</span>|       <span class="number">2005</span>|         <span class="number">10</span>|     <span class="type">F</span>|  <span class="number">2000</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">4</span>|   <span class="type">Jones</span>|              <span class="number">2</span>|       <span class="number">2005</span>|         <span class="number">10</span>|     <span class="type">F</span>|  <span class="number">2000</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">4</span>|   <span class="type">Jones</span>|              <span class="number">2</span>|       <span class="number">2005</span>|         <span class="number">10</span>|     <span class="type">F</span>|  <span class="number">2000</span>|    <span class="type">Sales</span>|     <span class="number">30</span>|</span><br><span class="line">|     <span class="number">4</span>|   <span class="type">Jones</span>|              <span class="number">2</span>|       <span class="number">2005</span>|         <span class="number">10</span>|     <span class="type">F</span>|  <span class="number">2000</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">|     <span class="number">5</span>|   <span class="type">Brown</span>|              <span class="number">2</span>|       <span class="number">2010</span>|         <span class="number">40</span>|      |    <span class="number">-1</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">5</span>|   <span class="type">Brown</span>|              <span class="number">2</span>|       <span class="number">2010</span>|         <span class="number">40</span>|      |    <span class="number">-1</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">5</span>|   <span class="type">Brown</span>|              <span class="number">2</span>|       <span class="number">2010</span>|         <span class="number">40</span>|      |    <span class="number">-1</span>|    <span class="type">Sales</span>|     <span class="number">30</span>|</span><br><span class="line">|     <span class="number">5</span>|   <span class="type">Brown</span>|              <span class="number">2</span>|       <span class="number">2010</span>|         <span class="number">40</span>|      |    <span class="number">-1</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">only showing top <span class="number">20</span> rows</span><br></pre></td></tr></table></figure></div><ul><li>以上方式虽然可以实现 cross Join，但并不推荐使用，从 <code>spark-sql_2.11</code> 2.1.0 之后的版本专门提供了 <code>crossJoin</code> 算子来实现笛卡尔积，使用 <code>crossJoin</code> 不用修改配置</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">empDF.crossJoin(deptDF).show()</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br><span class="line">|     <span class="number">1</span>|   <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">1</span>|   <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">1</span>|   <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|    <span class="type">Sales</span>|     <span class="number">30</span>|</span><br><span class="line">|     <span class="number">1</span>|   <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">|     <span class="number">2</span>|    <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">2</span>|    <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">2</span>|    <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|    <span class="type">Sales</span>|     <span class="number">30</span>|</span><br><span class="line">|     <span class="number">2</span>|    <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">|     <span class="number">3</span>|<span class="type">Williams</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">1000</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">3</span>|<span class="type">Williams</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">1000</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">3</span>|<span class="type">Williams</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">1000</span>|    <span class="type">Sales</span>|     <span class="number">30</span>|</span><br><span class="line">|     <span class="number">3</span>|<span class="type">Williams</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">1000</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">|     <span class="number">4</span>|   <span class="type">Jones</span>|              <span class="number">2</span>|       <span class="number">2005</span>|         <span class="number">10</span>|     <span class="type">F</span>|  <span class="number">2000</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">4</span>|   <span class="type">Jones</span>|              <span class="number">2</span>|       <span class="number">2005</span>|         <span class="number">10</span>|     <span class="type">F</span>|  <span class="number">2000</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">4</span>|   <span class="type">Jones</span>|              <span class="number">2</span>|       <span class="number">2005</span>|         <span class="number">10</span>|     <span class="type">F</span>|  <span class="number">2000</span>|    <span class="type">Sales</span>|     <span class="number">30</span>|</span><br><span class="line">|     <span class="number">4</span>|   <span class="type">Jones</span>|              <span class="number">2</span>|       <span class="number">2005</span>|         <span class="number">10</span>|     <span class="type">F</span>|  <span class="number">2000</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">|     <span class="number">5</span>|   <span class="type">Brown</span>|              <span class="number">2</span>|       <span class="number">2010</span>|         <span class="number">40</span>|      |    <span class="number">-1</span>|  <span class="type">Finance</span>|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">5</span>|   <span class="type">Brown</span>|              <span class="number">2</span>|       <span class="number">2010</span>|         <span class="number">40</span>|      |    <span class="number">-1</span>|<span class="type">Marketing</span>|     <span class="number">20</span>|</span><br><span class="line">|     <span class="number">5</span>|   <span class="type">Brown</span>|              <span class="number">2</span>|       <span class="number">2010</span>|         <span class="number">40</span>|      |    <span class="number">-1</span>|    <span class="type">Sales</span>|     <span class="number">30</span>|</span><br><span class="line">|     <span class="number">5</span>|   <span class="type">Brown</span>|              <span class="number">2</span>|       <span class="number">2010</span>|         <span class="number">40</span>|      |    <span class="number">-1</span>|       <span class="type">IT</span>|     <span class="number">40</span>|</span><br><span class="line">+------+--------+---------------+-----------+-----------+------+------+---------+-------+</span><br></pre></td></tr></table></figure></div><h5 id="同源-DataFrame-JOIN-陷阱"><a href="#同源-DataFrame-JOIN-陷阱" class="headerlink" title="同源 DataFrame JOIN 陷阱"></a>同源 DataFrame JOIN 陷阱</h5><p>当同源 DataFrame（衍生于同一个 DataFrame ）之间进行 Join 时，可能会导致一些意想不到的错误。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> x = empDF.groupBy(<span class="string">&quot;superior_emp_id&quot;</span>).agg(count(<span class="string">&quot;*&quot;</span>).as(<span class="string">&quot;f_cnt&quot;</span>))</span><br><span class="line">x.show()</span><br><span class="line">+---------------+-----+</span><br><span class="line">|superior_emp_id|f_cnt|</span><br><span class="line">+---------------+-----+</span><br><span class="line">|             <span class="number">-1</span>|    <span class="number">1</span>|</span><br><span class="line">|              <span class="number">1</span>|    <span class="number">2</span>|</span><br><span class="line">|              <span class="number">2</span>|    <span class="number">3</span>|</span><br><span class="line">+---------------+-----+</span><br><span class="line"></span><br><span class="line"><span class="comment">// join 后的结果不应该为空</span></span><br><span class="line">empDF.join(x, empDF(<span class="string">&quot;emp_id&quot;</span>) === x(<span class="string">&quot;superior_emp_id&quot;</span>)).show()</span><br><span class="line">+------+----+---------------+-----------+-----------+------+------+---------------+-----+</span><br><span class="line">|emp_id|name|superior_emp_id|year_joined|emp_dept_id|gender|salary|superior_emp_id|f_cnt|</span><br><span class="line">+------+----+---------------+-----------+-----------+------+------+---------------+-----+</span><br><span class="line">+------+----+---------------+-----------+-----------+------+------+---------------+-----+</span><br></pre></td></tr></table></figure></div><p>有多种方式可以解决这个问题：</p><ul><li>使用 SQL 表达式</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">empDF.createOrReplaceTempView(<span class="string">&quot;empDF&quot;</span>)</span><br><span class="line">x.createOrReplaceTempView(<span class="string">&quot;x&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> sql = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">select * </span></span><br><span class="line"><span class="string">from empDF join x </span></span><br><span class="line"><span class="string">on empDF.emp_id = x.superior_emp_id</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">spark.sql(sql).show()</span><br><span class="line">+------+---------+---------------+-----------+-------+------+------+---------------+-----+</span><br><span class="line">|emp_id|dept_name|superior_emp_id|year_joined|dept_id|gender|salary|superior_emp_id|f_cnt|</span><br><span class="line">+------+---------+---------------+-----------+-------+------+------+---------------+-----+</span><br><span class="line">|     <span class="number">1</span>|    <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|     <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|              <span class="number">1</span>|    <span class="number">2</span>|</span><br><span class="line">|     <span class="number">2</span>|     <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|     <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|              <span class="number">2</span>|    <span class="number">3</span>|</span><br><span class="line">+------+---------+---------------+-----------+-------+------+------+---------------+-----+</span><br></pre></td></tr></table></figure></div><ul><li>为 DataFrame 起别名</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">empDF.as(<span class="string">&quot;a&quot;</span>).join(x.as(<span class="string">&quot;b&quot;</span>), col(<span class="string">&quot;a.emp_id&quot;</span>) === col(<span class="string">&quot;b.superior_emp_id&quot;</span>)).show()</span><br><span class="line">+------+---------+---------------+-----------+-------+------+------+---------------+-----+</span><br><span class="line">|emp_id|dept_name|superior_emp_id|year_joined|dept_id|gender|salary|superior_emp_id|f_cnt|</span><br><span class="line">+------+---------+---------------+-----------+-------+------+------+---------------+-----+</span><br><span class="line">|     <span class="number">1</span>|    <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|     <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|              <span class="number">1</span>|    <span class="number">2</span>|</span><br><span class="line">|     <span class="number">2</span>|     <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|     <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|              <span class="number">2</span>|    <span class="number">3</span>|</span><br><span class="line">+------+---------+---------------+-----------+-------+------+------+---------------+-----+</span><br></pre></td></tr></table></figure></div><ul><li><code>withColumn</code> 重命名列</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> x = empDF.groupBy(<span class="string">&quot;superior_emp_id&quot;</span>).agg(count(<span class="string">&quot;*&quot;</span>).as(<span class="string">&quot;f_cnt&quot;</span>))</span><br><span class="line">    .withColumnRenamed(<span class="string">&quot;superior_emp_id&quot;</span>, <span class="string">&quot;superior_emp_id&quot;</span>)</span><br><span class="line">empDF.join(x, empDF(<span class="string">&quot;emp_id&quot;</span>) === x(<span class="string">&quot;superior_emp_id&quot;</span>)).show()</span><br><span class="line">+------+---------+---------------+-----------+-------+------+------+---------------+-----+</span><br><span class="line">|emp_id|dept_name|superior_emp_id|year_joined|dept_id|gender|salary|superior_emp_id|f_cnt|</span><br><span class="line">+------+---------+---------------+-----------+-------+------+------+---------------+-----+</span><br><span class="line">|     <span class="number">1</span>|    <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|     <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|              <span class="number">1</span>|    <span class="number">2</span>|</span><br><span class="line">|     <span class="number">2</span>|     <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|     <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|              <span class="number">2</span>|    <span class="number">3</span>|</span><br><span class="line">+------+---------+---------------+-----------+-------+------+------+---------------+-----+</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> x = empDF.groupBy(<span class="string">&quot;superior_emp_id&quot;</span>).agg(count(<span class="string">&quot;*&quot;</span>).as(<span class="string">&quot;f_cnt&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;superior_emp_id&quot;</span>, col(<span class="string">&quot;superior_emp_id&quot;</span>))</span><br><span class="line">empDF.join(x, empDF(<span class="string">&quot;emp_id&quot;</span>) === x(<span class="string">&quot;superior_emp_id&quot;</span>)).show()</span><br><span class="line">+------+-----+---------------+-----------+-----------+------+------+---------------+-----+</span><br><span class="line">|emp_id| name|superior_emp_id|year_joined|emp_dept_id|gender|salary|superior_emp_id|f_cnt|</span><br><span class="line">+------+-----+---------------+-----------+-----------+------+------+---------------+-----+</span><br><span class="line">|     <span class="number">1</span>|<span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|              <span class="number">1</span>|    <span class="number">2</span>|</span><br><span class="line">|     <span class="number">2</span>| <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|              <span class="number">2</span>|    <span class="number">3</span>|</span><br><span class="line">+------+-----+---------------+-----------+-----------+------+------+---------------+-----+</span><br></pre></td></tr></table></figure></div><ul><li><code>toDF</code> 重新定义其中一个 DataFrame 的 Schema：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = x.toDF(x.columns:_*)</span><br><span class="line">empDF.join(x, empDF(<span class="string">&quot;emp_id&quot;</span>) === x(<span class="string">&quot;superior_emp_id&quot;</span>)).show()</span><br><span class="line">+------+-----+---------------+-----------+-----------+------+------+---------------+-----+</span><br><span class="line">|emp_id| name|superior_emp_id|year_joined|emp_dept_id|gender|salary|superior_emp_id|f_cnt|</span><br><span class="line">+------+-----+---------------+-----------+-----------+------+------+---------------+-----+</span><br><span class="line">|     <span class="number">1</span>|<span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|         <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|              <span class="number">1</span>|    <span class="number">2</span>|</span><br><span class="line">|     <span class="number">2</span>| <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|         <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|              <span class="number">2</span>|    <span class="number">3</span>|</span><br></pre></td></tr></table></figure></div><h5 id="usingColumn-陷阱"><a href="#usingColumn-陷阱" class="headerlink" title="usingColumn 陷阱"></a>usingColumn 陷阱</h5><p><code>usingColumn</code> 语法得到的结果 DataFrame 中会自动去除被 join DataFrame 的关联键，只保留主调 DataFrame 中的关联键，所以不能通过 <code>select</code> 或 <code>expr</code> 选择被调 DataFrame 中的关联键，但是却可以在 <code>filter</code> 中引用被调 DataFrame 中的关联键：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> x = deptDF.limit(<span class="number">2</span>).select(<span class="string">&quot;dept_id&quot;</span>).toDF(<span class="string">&quot;dept_id&quot;</span>)</span><br><span class="line">x.show()</span><br><span class="line">+-------+</span><br><span class="line">|dept_id|</span><br><span class="line">+-------+</span><br><span class="line">|     <span class="number">10</span>|</span><br><span class="line">|     <span class="number">20</span>|</span><br><span class="line">+-------+</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> res = deptDF.join(x, <span class="type">Seq</span>(<span class="string">&quot;dept_id&quot;</span>), <span class="string">&quot;left&quot;</span>)</span><br><span class="line">res.show()</span><br><span class="line">res.printSchema</span><br><span class="line">+-------+---------+</span><br><span class="line">|dept_id|dept_name|</span><br><span class="line">+-------+---------+</span><br><span class="line">|     <span class="number">10</span>|  <span class="type">Finance</span>|</span><br><span class="line">|     <span class="number">20</span>|<span class="type">Marketing</span>|</span><br><span class="line">|     <span class="number">30</span>|    <span class="type">Sales</span>|</span><br><span class="line">|     <span class="number">40</span>|       <span class="type">IT</span>|</span><br><span class="line">+-------+---------+</span><br><span class="line"></span><br><span class="line">res.filter(x(<span class="string">&quot;dept_id&quot;</span>).isNull).show()</span><br><span class="line">+-------+---------+</span><br><span class="line">|dept_id|dept_name|</span><br><span class="line">+-------+---------+</span><br><span class="line">|     <span class="number">30</span>|    <span class="type">Sales</span>|</span><br><span class="line">|     <span class="number">40</span>|       <span class="type">IT</span>|</span><br><span class="line">+-------+---------+</span><br><span class="line"></span><br><span class="line">res.select(expr(<span class="string">&quot;x.dept_id&quot;</span>)).show()</span><br><span class="line">org.apache.spark.sql.<span class="type">AnalysisException</span>: cannot resolve &#x27;`x.dept_id`&#x27; given input columns: [dept_id, dept_name]; line <span class="number">1</span> pos <span class="number">0</span>;</span><br><span class="line"><span class="symbol">&#x27;Project</span> [<span class="symbol">&#x27;x</span>.dept_id]</span><br><span class="line">+- <span class="type">Project</span> [dept_id#<span class="number">456</span>, dept_name#<span class="number">455</span>]</span><br><span class="line">   +- <span class="type">Join</span> <span class="type">LeftOuter</span>, (dept_id#<span class="number">456</span> = dept_id#<span class="number">497</span>)</span><br><span class="line"></span><br><span class="line">res.select(x(<span class="string">&quot;dept_id&quot;</span>)).show()</span><br><span class="line">org.apache.spark.sql.<span class="type">AnalysisException</span>: <span class="type">Cannot</span> resolve column name <span class="string">&quot;dept_id&quot;</span> among (superior_emp_id, f_cnt);</span><br><span class="line">  at org.apache.spark.sql.<span class="type">Dataset</span>$$anonfun$resolve$<span class="number">1.</span>apply(<span class="type">Dataset</span>.scala:<span class="number">223</span>)</span><br><span class="line">  at org.apache.spark.sql.<span class="type">Dataset</span>$$anonfun$resolve$<span class="number">1.</span>apply(<span class="type">Dataset</span>.scala:<span class="number">223</span>)</span><br></pre></td></tr></table></figure></div><h5 id="处理-join-中的同名字段"><a href="#处理-join-中的同名字段" class="headerlink" title="处理 join 中的同名字段"></a>处理 join 中的同名字段</h5><p>如果参与 join 的两个 DataFrame 之间存在相同名称的字段，很容易在后续的转换操作中出现 <code>Reference is ambiguous</code> 的错误，整体上有两种解决思路：</p><ol><li>如果需要的字段少：那就 select 你所需要的字段就行了；</li><li>如果需要的字段多：那就 drop 不需要的字段；</li></ol><p>在 join 前中后又可以有不同的处理方式：</p><ol><li>join 前：修改/删除其中一方 DataFrame 的同名字段名；</li><li>join 中：如果同名字段是 join 的关联键，使用 <code>usingColumn</code> 语法，join 后只会保留左表关联字段；</li><li>join 后：<ol><li>要么通过 <code>select(Expr)</code> 明确指定需要的表字段；</li><li>要么通过 <code>drop</code> 删除不需要的表字段；</li><li>要么通过 <code>withColumn</code> 添加新的字段，此时 <code>withColumn</code> 如果用于修改已有同名字段的内容，将会同时修改所有同名字段，修改后的结果仍会保留同名字段；  </li></ol></li></ol><p>示例：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 示例数据</span></span><br><span class="line"><span class="keyword">val</span> emp = <span class="type">Seq</span>((<span class="number">1</span>,<span class="string">&quot;Smith&quot;</span>,<span class="number">-1</span>,<span class="string">&quot;2018&quot;</span>,<span class="string">&quot;10&quot;</span>,<span class="string">&quot;M&quot;</span>,<span class="number">3000</span>),</span><br><span class="line">    (<span class="number">2</span>,<span class="string">&quot;Rose&quot;</span>,<span class="number">1</span>,<span class="string">&quot;2010&quot;</span>,<span class="string">&quot;20&quot;</span>,<span class="string">&quot;M&quot;</span>,<span class="number">4000</span>),</span><br><span class="line">    (<span class="number">3</span>,<span class="string">&quot;Williams&quot;</span>,<span class="number">1</span>,<span class="string">&quot;2010&quot;</span>,<span class="string">&quot;10&quot;</span>,<span class="string">&quot;M&quot;</span>,<span class="number">1000</span>),</span><br><span class="line">    (<span class="number">4</span>,<span class="string">&quot;Jones&quot;</span>,<span class="number">2</span>,<span class="string">&quot;2005&quot;</span>,<span class="string">&quot;10&quot;</span>,<span class="string">&quot;F&quot;</span>,<span class="number">2000</span>),</span><br><span class="line">    (<span class="number">5</span>,<span class="string">&quot;Brown&quot;</span>,<span class="number">2</span>,<span class="string">&quot;2010&quot;</span>,<span class="string">&quot;40&quot;</span>,<span class="string">&quot;&quot;</span>,<span class="number">-1</span>),</span><br><span class="line">      (<span class="number">6</span>,<span class="string">&quot;Brown&quot;</span>,<span class="number">2</span>,<span class="string">&quot;2010&quot;</span>,<span class="string">&quot;50&quot;</span>,<span class="string">&quot;&quot;</span>,<span class="number">-1</span>)</span><br><span class="line">  )</span><br><span class="line"><span class="keyword">val</span> empColumns = <span class="type">Seq</span>(<span class="string">&quot;emp_id&quot;</span>,<span class="string">&quot;dept_name&quot;</span>,<span class="string">&quot;superior_emp_id&quot;</span>,<span class="string">&quot;year_joined&quot;</span>,</span><br><span class="line">   <span class="string">&quot;dept_id&quot;</span>,<span class="string">&quot;gender&quot;</span>,<span class="string">&quot;salary&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> spark.sqlContext.implicits._</span><br><span class="line"><span class="keyword">val</span> empDF = emp.toDF(empColumns:_*)</span><br><span class="line">empDF.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+------+---------+---------------+-----------+-------+------+------+</span><br><span class="line">|emp_id|dept_name|superior_emp_id|year_joined|dept_id|gender|salary|</span><br><span class="line">+------+---------+---------------+-----------+-------+------+------+</span><br><span class="line">|<span class="number">1</span>     |<span class="type">Smith</span>    |<span class="number">-1</span>             |<span class="number">2018</span>       |<span class="number">10</span>     |<span class="type">M</span>     |<span class="number">3000</span>  |</span><br><span class="line">|<span class="number">2</span>     |<span class="type">Rose</span>     |<span class="number">1</span>              |<span class="number">2010</span>       |<span class="number">20</span>     |<span class="type">M</span>     |<span class="number">4000</span>  |</span><br><span class="line">|<span class="number">3</span>     |<span class="type">Williams</span> |<span class="number">1</span>              |<span class="number">2010</span>       |<span class="number">10</span>     |<span class="type">M</span>     |<span class="number">1000</span>  |</span><br><span class="line">|<span class="number">4</span>     |<span class="type">Jones</span>    |<span class="number">2</span>              |<span class="number">2005</span>       |<span class="number">10</span>     |<span class="type">F</span>     |<span class="number">2000</span>  |</span><br><span class="line">|<span class="number">5</span>     |<span class="type">Brown</span>    |<span class="number">2</span>              |<span class="number">2010</span>       |<span class="number">40</span>     |      |<span class="number">-1</span>    |</span><br><span class="line">|<span class="number">6</span>     |<span class="type">Brown</span>    |<span class="number">2</span>              |<span class="number">2010</span>       |<span class="number">50</span>     |      |<span class="number">-1</span>    |</span><br><span class="line">+------+---------+---------------+-----------+-------+------+------+</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> dept = <span class="type">Seq</span>((<span class="string">&quot;Finance&quot;</span>,<span class="number">10</span>),</span><br><span class="line">(<span class="string">&quot;Marketing&quot;</span>,<span class="number">20</span>),</span><br><span class="line">(<span class="string">&quot;Sales&quot;</span>,<span class="number">30</span>),</span><br><span class="line">(<span class="string">&quot;IT&quot;</span>,<span class="number">40</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> deptColumns = <span class="type">Seq</span>(<span class="string">&quot;dept_name&quot;</span>,<span class="string">&quot;dept_id&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> deptDF = dept.toDF(deptColumns:_*)</span><br><span class="line">deptDF.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+---------+-------+</span><br><span class="line">|dept_name|dept_id|</span><br><span class="line">+---------+-------+</span><br><span class="line">|<span class="type">Finance</span>  |<span class="number">10</span>     |</span><br><span class="line">|<span class="type">Marketing</span>|<span class="number">20</span>     |</span><br><span class="line">|<span class="type">Sales</span>    |<span class="number">30</span>     |</span><br><span class="line">|<span class="type">IT</span>       |<span class="number">40</span>     |</span><br><span class="line">+---------+-------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// usingColumn 会去掉右侧 DataFrame 的关联键，这里使用 deptDF(&quot;*&quot;) 会报无法找到 dept_id 的错误</span></span><br><span class="line">res.select(deptDF(<span class="string">&quot;*&quot;</span>)).show()</span><br><span class="line">org.apache.spark.sql.<span class="type">AnalysisException</span>: <span class="type">Resolved</span> attribute(s) dept_id#<span class="number">477</span> missing from emp_id#<span class="number">435</span>,salary#<span class="number">441</span>,year_joined#<span class="number">438</span>,gender#<span class="number">440</span>,dept_name#<span class="number">436</span>,dept_id#<span class="number">439</span>,dept_name#<span class="number">476</span>,superior_emp_id#<span class="number">437</span> in operator !<span class="type">Project</span> [dept_name#<span class="number">476</span>, dept_id#<span class="number">477</span>]. <span class="type">Attribute</span>(s) <span class="keyword">with</span> the same name appear in the operation: dept_id. <span class="type">Please</span> check <span class="keyword">if</span> the right attribute(s) are used.;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 选择 empDF 中所有字段，以及 deptDF 中的 dept_name 字段</span></span><br><span class="line">res.select(empDF(<span class="string">&quot;*&quot;</span>), deptDF(<span class="string">&quot;dept_name&quot;</span>)).show()</span><br><span class="line">+------+---------+---------------+-----------+-------+------+------+---------+</span><br><span class="line">|emp_id|dept_name|superior_emp_id|year_joined|dept_id|gender|salary|dept_name|</span><br><span class="line">+------+---------+---------------+-----------+-------+------+------+---------+</span><br><span class="line">|     <span class="number">1</span>|    <span class="type">Smith</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|     <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">3000</span>|  <span class="type">Finance</span>|</span><br><span class="line">|     <span class="number">2</span>|     <span class="type">Rose</span>|              <span class="number">1</span>|       <span class="number">2010</span>|     <span class="number">20</span>|     <span class="type">M</span>|  <span class="number">4000</span>|<span class="type">Marketing</span>|</span><br><span class="line">|     <span class="number">3</span>| <span class="type">Williams</span>|              <span class="number">1</span>|       <span class="number">2010</span>|     <span class="number">10</span>|     <span class="type">M</span>|  <span class="number">1000</span>|  <span class="type">Finance</span>|</span><br><span class="line">|     <span class="number">4</span>|    <span class="type">Jones</span>|              <span class="number">2</span>|       <span class="number">2005</span>|     <span class="number">10</span>|     <span class="type">F</span>|  <span class="number">2000</span>|  <span class="type">Finance</span>|</span><br><span class="line">|     <span class="number">5</span>|    <span class="type">Brown</span>|              <span class="number">2</span>|       <span class="number">2010</span>|     <span class="number">40</span>|      |    <span class="number">-1</span>|       <span class="type">IT</span>|</span><br><span class="line">+------+---------+---------------+-----------+-------+------+------+---------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 上面结果包含了同名字段 dept_name，如果直接引用字段名则会报 ambiguous 错误</span></span><br><span class="line">res.select(empDF(<span class="string">&quot;*&quot;</span>), deptDF(<span class="string">&quot;dept_name&quot;</span>)).select(<span class="string">&quot;dept_name&quot;</span>).show()</span><br><span class="line">org.apache.spark.sql.<span class="type">AnalysisException</span>: <span class="type">Reference</span> <span class="symbol">&#x27;dept_nam</span>e&#x27; is ambiguous, could be: dept_name, dept_name.;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 想通过先删除左表的 dept_name 再选择左表中所有字段，但 empDF(&quot;*&quot;) 仍然会包含已经删掉的字段</span></span><br><span class="line">res.drop(empDF(<span class="string">&quot;dept_name&quot;</span>)).select(empDF(<span class="string">&quot;*&quot;</span>), deptDF(<span class="string">&quot;dept_name&quot;</span>)).show()</span><br><span class="line">org.apache.spark.sql.<span class="type">AnalysisException</span>: <span class="type">Resolved</span> attribute(s) dept_name#<span class="number">436</span> missing from</span><br><span class="line"></span><br><span class="line"><span class="comment">// 其实只要先 select 再 drop 就可以了，但是这种方法有很大局限，一个是当用列对象参数时， drop(column) 只能删除一列，而且这一列还必须已存在，当用列名时，drop 又会把所有同名的列删除掉</span></span><br><span class="line">res.select(empDF(<span class="string">&quot;*&quot;</span>), deptDF(<span class="string">&quot;dept_name&quot;</span>)).drop(empDF(<span class="string">&quot;dept_name&quot;</span>))</span><br><span class="line">.select(<span class="string">&quot;dept_name&quot;</span>)</span><br><span class="line">.show()</span><br><span class="line">+---------+</span><br><span class="line">|dept_name|</span><br><span class="line">+---------+</span><br><span class="line">|  <span class="type">Finance</span>|</span><br><span class="line">|<span class="type">Marketing</span>|</span><br><span class="line">|  <span class="type">Finance</span>|</span><br><span class="line">|  <span class="type">Finance</span>|</span><br><span class="line">|       <span class="type">IT</span>|</span><br><span class="line">+---------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 值得说明的是 withColumn 并不会消除同名字段的分歧，只会同时改变同名字段的值</span></span><br><span class="line">res.withColumn(<span class="string">&quot;dept_name&quot;</span>, lit(<span class="number">1</span>)).show()</span><br><span class="line">+-------+------+---------+---------------+-----------+------+------+---------+</span><br><span class="line">|dept_id|emp_id|dept_name|superior_emp_id|year_joined|gender|salary|dept_name|</span><br><span class="line">+-------+------+---------+---------------+-----------+------+------+---------+</span><br><span class="line">|     <span class="number">10</span>|     <span class="number">1</span>|        <span class="number">1</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|     <span class="type">M</span>|  <span class="number">3000</span>|        <span class="number">1</span>|</span><br><span class="line">|     <span class="number">20</span>|     <span class="number">2</span>|        <span class="number">1</span>|              <span class="number">1</span>|       <span class="number">2010</span>|     <span class="type">M</span>|  <span class="number">4000</span>|        <span class="number">1</span>|</span><br><span class="line">|     <span class="number">10</span>|     <span class="number">3</span>|        <span class="number">1</span>|              <span class="number">1</span>|       <span class="number">2010</span>|     <span class="type">M</span>|  <span class="number">1000</span>|        <span class="number">1</span>|</span><br><span class="line">|     <span class="number">10</span>|     <span class="number">4</span>|        <span class="number">1</span>|              <span class="number">2</span>|       <span class="number">2005</span>|     <span class="type">F</span>|  <span class="number">2000</span>|        <span class="number">1</span>|</span><br><span class="line">|     <span class="number">40</span>|     <span class="number">5</span>|        <span class="number">1</span>|              <span class="number">2</span>|       <span class="number">2010</span>|      |    <span class="number">-1</span>|        <span class="number">1</span>|</span><br><span class="line">+-------+------+---------+---------------+-----------+------+------+---------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 综上，比较好的做法是在join前 drop 掉最后不需要的列（如果需要对其 select(&quot;*&quot;)的话）</span></span><br><span class="line"><span class="keyword">val</span> res = empDF.drop(<span class="string">&quot;dept_name&quot;</span>).as(<span class="string">&quot;a&quot;</span>).join(deptDF.as(<span class="string">&quot;b&quot;</span>), <span class="type">Seq</span>(<span class="string">&quot;dept_id&quot;</span>))</span><br><span class="line">res.show()</span><br><span class="line">+-------+------+---------------+-----------+------+------+---------+</span><br><span class="line">|dept_id|emp_id|superior_emp_id|year_joined|gender|salary|dept_name|</span><br><span class="line">+-------+------+---------------+-----------+------+------+---------+</span><br><span class="line">|     <span class="number">10</span>|     <span class="number">1</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|     <span class="type">M</span>|  <span class="number">3000</span>|  <span class="type">Finance</span>|</span><br><span class="line">|     <span class="number">20</span>|     <span class="number">2</span>|              <span class="number">1</span>|       <span class="number">2010</span>|     <span class="type">M</span>|  <span class="number">4000</span>|<span class="type">Marketing</span>|</span><br><span class="line">|     <span class="number">10</span>|     <span class="number">3</span>|              <span class="number">1</span>|       <span class="number">2010</span>|     <span class="type">M</span>|  <span class="number">1000</span>|  <span class="type">Finance</span>|</span><br><span class="line">|     <span class="number">10</span>|     <span class="number">4</span>|              <span class="number">2</span>|       <span class="number">2005</span>|     <span class="type">F</span>|  <span class="number">2000</span>|  <span class="type">Finance</span>|</span><br><span class="line">|     <span class="number">40</span>|     <span class="number">5</span>|              <span class="number">2</span>|       <span class="number">2010</span>|      |    <span class="number">-1</span>|       <span class="type">IT</span>|</span><br><span class="line">+-------+------+---------------+-----------+------+------+---------+</span><br><span class="line"></span><br><span class="line">res.select(<span class="string">&quot;a.*&quot;</span>, <span class="string">&quot;b.dept_name&quot;</span>).show()</span><br><span class="line">+-------+------+---------------+-----------+------+------+---------+</span><br><span class="line">|dept_id|emp_id|superior_emp_id|year_joined|gender|salary|dept_name|</span><br><span class="line">+-------+------+---------------+-----------+------+------+---------+</span><br><span class="line">|     <span class="number">10</span>|     <span class="number">1</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|     <span class="type">M</span>|  <span class="number">3000</span>|  <span class="type">Finance</span>|</span><br><span class="line">|     <span class="number">20</span>|     <span class="number">2</span>|              <span class="number">1</span>|       <span class="number">2010</span>|     <span class="type">M</span>|  <span class="number">4000</span>|<span class="type">Marketing</span>|</span><br><span class="line">|     <span class="number">10</span>|     <span class="number">3</span>|              <span class="number">1</span>|       <span class="number">2010</span>|     <span class="type">M</span>|  <span class="number">1000</span>|  <span class="type">Finance</span>|</span><br><span class="line">|     <span class="number">10</span>|     <span class="number">4</span>|              <span class="number">2</span>|       <span class="number">2005</span>|     <span class="type">F</span>|  <span class="number">2000</span>|  <span class="type">Finance</span>|</span><br><span class="line">|     <span class="number">40</span>|     <span class="number">5</span>|              <span class="number">2</span>|       <span class="number">2010</span>|      |    <span class="number">-1</span>|       <span class="type">IT</span>|</span><br><span class="line">+-------+------+---------------+-----------+------+------+---------+</span><br><span class="line"></span><br><span class="line">res.selectExpr(<span class="string">&quot;a.*&quot;</span>, <span class="string">&quot;b.dept_name as f_new_name&quot;</span>).show()</span><br><span class="line">+-------+------+---------------+-----------+------+------+----------+</span><br><span class="line">|dept_id|emp_id|superior_emp_id|year_joined|gender|salary|f_new_name|</span><br><span class="line">+-------+------+---------------+-----------+------+------+----------+</span><br><span class="line">|     <span class="number">10</span>|     <span class="number">1</span>|             <span class="number">-1</span>|       <span class="number">2018</span>|     <span class="type">M</span>|  <span class="number">3000</span>|   <span class="type">Finance</span>|</span><br><span class="line">|     <span class="number">20</span>|     <span class="number">2</span>|              <span class="number">1</span>|       <span class="number">2010</span>|     <span class="type">M</span>|  <span class="number">4000</span>| <span class="type">Marketing</span>|</span><br><span class="line">|     <span class="number">10</span>|     <span class="number">3</span>|              <span class="number">1</span>|       <span class="number">2010</span>|     <span class="type">M</span>|  <span class="number">1000</span>|   <span class="type">Finance</span>|</span><br><span class="line">|     <span class="number">10</span>|     <span class="number">4</span>|              <span class="number">2</span>|       <span class="number">2005</span>|     <span class="type">F</span>|  <span class="number">2000</span>|   <span class="type">Finance</span>|</span><br><span class="line">|     <span class="number">40</span>|     <span class="number">5</span>|              <span class="number">2</span>|       <span class="number">2010</span>|      |    <span class="number">-1</span>|        <span class="type">IT</span>|</span><br><span class="line">+-------+------+---------------+-----------+------+------+----------+</span><br></pre></td></tr></table></figure></div><h5 id="join-最佳实践"><a href="#join-最佳实践" class="headerlink" title="join 最佳实践"></a>join 最佳实践</h5><p>DataFrame API 的 JOIN 操作有诸多需要注意的地方，除了正确使用 JOIN 类型和 JOIN 语法外，经常引起困惑的地方在于如何从 JOIN 结果中选择我们需要的字段，对此，我们总结了一些最佳实践：</p><ol><li>当 DataFrame 不方便通过一个变量来引用时，可以在 JOIN 语句中为 DataFrame 起别名：<ol><li>可以通过 <code>&quot;表别名.字段名&quot;</code> 来引用对应字段；</li><li>如果不存在同名字段，也可以省略掉表别名，直接用 <code>&quot;字段名&quot;</code> 来应用对应字段；</li></ol></li><li>当 JOIN 的两个 DataFrame 中包含同名字段时：<ol><li>可以在 JOIN 前删除/重命名无用的同名字段；</li><li>如果同名字段作为关联字段，<code>usingColumn</code> 语法将只会保留左表关联字段；</li><li>可以在 JOIN 后 <code>select(Expr)</code> 需要的字段，<code>drop</code> 不需要的字段，<code>withColumn</code> 添加新的字段；</li></ol></li><li>同源 DataFrame 之间 JOIN，在 JOIN 前通过 <code>toDF()</code> 转化其中一个 DataFrame；</li></ol><p>看过上面的示例，你可能会觉得 DataFrame 的 JOIN 太不方便了，还不如直接写 SQL 表达式呢！事实上，DataFrame API 更加紧凑，更便于编写结构化代码，能够帮助我们完成大部分的语法检查，如果要在 DataFrame 中穿插 SQL 表达式，就使用 expr() 或 selectExpr() 函数吧！</p><h4 id="repartition-——-重分区"><a href="#repartition-——-重分区" class="headerlink" title="repartition —— 重分区"></a>repartition —— 重分区</h4><ul><li>功能：repartition 会导致数据的完全随机洗牌（shuffle），这意味着通常仅应在将来的分区数大于当前的分区数时或在按一组列进行分区时重新分区；如果经常要按照某个列进行过滤，则值得按该列重新分区；</li><li>语法：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指定所需的分区数</span></span><br><span class="line">repartition(numPartitions: <span class="type">Int</span>)</span><br><span class="line"><span class="comment">// 指定按照某列进行分区</span></span><br><span class="line">repartition(partitionExprs: <span class="type">Column</span>*)</span><br><span class="line">repartition(numPartitions: <span class="type">Int</span>, partitionExprs: <span class="type">Column</span>*)</span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.repartition(3)</span><br><span class="line">df.repartition(col(&quot;dob&quot;))</span><br><span class="line">df.repartition(5, col(&quot;dob&quot;))</span><br></pre></td></tr></table></figure></div><h4 id="coalesce-——-分区合并"><a href="#coalesce-——-分区合并" class="headerlink" title="coalesce —— 分区合并"></a>coalesce —— 分区合并</h4><ul><li>功能：coalesce 不会引起 full shuffle，并尝试合并分区（将来的分区数小于当前的分区数）；</li><li>语法：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">coalesce(numPartitions: <span class="type">Int</span>)</span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.repartition(<span class="number">5</span>, col(<span class="string">&quot;dob&quot;</span>)).coalesce(<span class="number">2</span>)</span><br></pre></td></tr></table></figure></div><h4 id="cache-persist-——-缓存"><a href="#cache-persist-——-缓存" class="headerlink" title="cache | persist —— 缓存"></a>cache | persist —— 缓存</h4><ul><li><p>功能：虽然 Spark 提供的计算速度是传统 Map Reduce 作业的 100 倍，但是如果您没有将作业设计为重用重复计算，那么当您处理数十亿或数万亿数据时，性能会下降。使用 cache() 和 persist() 方法，每个节点将其分区的数据存储在内存/磁盘中，并在该数据集的其他操作中重用它们，真正缓存是在第一次被相关 action 调用后才缓存。Spark 在节点上的持久数据是容错的，这意味着如果数据集的任何分区丢失，它将使用创建它的原始转换自动重新计算。Spark 会自动监视您进行的每个 persist（）和cache（）调用，并检查每个节点上的使用情况，如果不再使用或通过 least-recently-used (LRU) 算法，删除持久化数据，也可以使用 unpersist（）方法手动删除。unpersist（）将数据集标记为非持久性，并立即从内存和磁盘中删除它的所有块。</p></li><li><p>语法:</p></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// StorageLevel </span></span><br><span class="line"><span class="number">1</span>) persist() : <span class="type">Dataset</span>.<span class="keyword">this</span>.<span class="keyword">type</span></span><br><span class="line"><span class="number">2</span>) persist(newLevel : org.apache.spark.storage.<span class="type">StorageLevel</span>) : <span class="type">Dataset</span>.<span class="keyword">this</span>.<span class="keyword">type</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// cache() 调用的也是 persist()，df.cache() 的默认存储级别为 MEMORY_AND_DISK，而RDD.chache() 的默认存储级别为 MEMORY_ONLY</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cache</span></span>(): <span class="keyword">this</span>.<span class="keyword">type</span> = persist()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 手动取消持久化</span></span><br><span class="line">unpersist() : <span class="type">Dataset</span>.<span class="keyword">this</span>.<span class="keyword">type</span></span><br><span class="line">unpersist(blocking : scala.<span class="type">Boolean</span>) : <span class="type">Dataset</span>.<span class="keyword">this</span>.<span class="keyword">type</span></span><br></pre></td></tr></table></figure></div><ul><li>示例:</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// cache</span></span><br><span class="line"><span class="keyword">val</span> df = spark.read.options(<span class="type">Map</span>(<span class="string">&quot;inferSchema&quot;</span>-&gt;<span class="string">&quot;true&quot;</span>,<span class="string">&quot;delimiter&quot;</span>-&gt;<span class="string">&quot;,&quot;</span>,<span class="string">&quot;header&quot;</span>-&gt;<span class="string">&quot;true&quot;</span>)).csv(<span class="string">&quot;src/main/resources/zipcodes.csv&quot;</span>)</span><br><span class="line">  </span><br><span class="line"><span class="keyword">val</span> df2 = df.where(col(<span class="string">&quot;State&quot;</span>) === <span class="string">&quot;PR&quot;</span>).cache()</span><br><span class="line">df2.show(<span class="literal">false</span>)</span><br><span class="line">println(df2.count())</span><br><span class="line"><span class="keyword">val</span> df3 = df2.where(col(<span class="string">&quot;Zipcode&quot;</span>) === <span class="number">704</span>)</span><br><span class="line">println(df2.count())</span><br><span class="line"></span><br><span class="line"><span class="comment">// persist</span></span><br><span class="line"><span class="keyword">val</span> dfPersist = df.persist(<span class="type">StorageLevel</span>.<span class="type">MEMORY_ONLY</span>)</span><br><span class="line">dfPersist.show(<span class="literal">false</span>)</span><br><span class="line"><span class="comment">// unpersist</span></span><br><span class="line"><span class="keyword">val</span> dfPersist = dfPersist.unpersist()</span><br></pre></td></tr></table></figure></div><ul><li>StorageLevel 有以下几个级别：</li></ul><div class="table-container"><table><thead><tr><th>级别</th><th>使用空间</th><th>CPU时间</th><th>是否内存</th><th>是否磁盘</th><th>备注</th></tr></thead><tbody><tr><td>MEMORY_ONLY</td><td>高</td><td>低</td><td>是</td><td>否</td><td>-</td></tr><tr><td>MEMORY_ONLY_2</td><td>高</td><td>低</td><td>是</td><td>否</td><td>数据存2份</td></tr><tr><td>MEMORY_ONLY_SER_2</td><td>低</td><td>高</td><td>是</td><td>否</td><td>数据序列化，数据存2份</td></tr><tr><td>MEMORY_AND_DISK</td><td>高</td><td>中等</td><td>部分</td><td>部分</td><td>内存放不下，则溢写到磁盘</td></tr><tr><td>MEMORY_AND_DISK_2</td><td>高</td><td>中等</td><td>部分</td><td>部分</td><td>数据存2份</td></tr><tr><td>MEMORY_AND_DISK_SER</td><td>低</td><td>高</td><td>部分</td><td>部分</td><td>-</td></tr><tr><td>MEMORY_AND_DISK_SER_2</td><td>低</td><td>高</td><td>部分</td><td>部分</td><td>数据存2份</td></tr><tr><td>DISK_ONLY</td><td>低</td><td>高</td><td>否</td><td>是</td><td></td></tr><tr><td>DISK_ONLY_2</td><td>低</td><td>高</td><td>否</td><td>是</td><td>数据存2份</td></tr><tr><td>NONE</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>OFF_HEAP</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr></tbody></table></div><h4 id="collect-——-收集到-driver"><a href="#collect-——-收集到-driver" class="headerlink" title="collect —— 收集到 driver"></a>collect —— 收集到 driver</h4><ul><li><p>功能：collect() 和 collectAsList() 用于将 RDD/DataFrame/Dataset 中所有的数据拉取到 Driver 节点，然后你可以在 driver 节点使用 scala 进行进一步处理，通常用于较小的数据集，如果数据集过大可能会导致内存不足，很容易使 driver 节点崩溃并时区应用程序的状态，这也很昂贵，因为是逐条处理，而不是并行计算。</p></li><li><p>语法：</p></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">collect() : scala.<span class="type">Array</span>[<span class="type">T</span>]</span><br><span class="line">collectAsList() : java.util.<span class="type">List</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">df.show()</span><br><span class="line">+---------------------+-----+------+------+</span><br><span class="line">|name                 |id   |gender|salary|</span><br><span class="line">+---------------------+-----+------+------+</span><br><span class="line">|[<span class="type">James</span> , , <span class="type">Smith</span>]    |<span class="number">36636</span>|<span class="type">M</span>     |<span class="number">3000</span>  |</span><br><span class="line">|[<span class="type">Michael</span> , <span class="type">Rose</span>, ]   |<span class="number">40288</span>|<span class="type">M</span>     |<span class="number">4000</span>  |</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Williams</span>]|<span class="number">42114</span>|<span class="type">M</span>     |<span class="number">4000</span>  |</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jones</span>]|<span class="number">39192</span>|<span class="type">F</span>     |<span class="number">4000</span>  |</span><br><span class="line">|[<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]   |     |<span class="type">F</span>     |<span class="number">-1</span>    |</span><br><span class="line">+---------------------+-----+------+------+</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> colList = df.collectAsList()</span><br><span class="line"><span class="keyword">val</span> colData = df.collect()</span><br><span class="line">colData.foreach(row =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> salary = row.getInt(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">val</span> fullName:<span class="type">Row</span> = row.getStruct(<span class="number">0</span>) </span><br><span class="line">    <span class="keyword">val</span> firstName = fullName.getString(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">val</span> middleName = fullName.get(<span class="number">1</span>).toString</span><br><span class="line">    <span class="keyword">val</span> lastName = fullName.getAs[<span class="type">String</span>](<span class="string">&quot;lastname&quot;</span>)</span><br><span class="line">    println(firstName+<span class="string">&quot;,&quot;</span>+middleName+<span class="string">&quot;,&quot;</span>+lastName+<span class="string">&quot;,&quot;</span>+salary)</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line"><span class="type">James</span> ,,<span class="type">Smith</span>,<span class="number">3000</span></span><br><span class="line"><span class="type">Michael</span> ,<span class="type">Rose</span>,,<span class="number">4000</span></span><br><span class="line"><span class="type">Robert</span> ,,<span class="type">Williams</span>,<span class="number">4000</span></span><br><span class="line"><span class="type">Maria</span> ,<span class="type">Anne</span>,<span class="type">Jones</span>,<span class="number">4000</span></span><br><span class="line"><span class="type">Jen</span>,<span class="type">Mary</span>,<span class="type">Brown</span>,<span class="number">-1</span></span><br></pre></td></tr></table></figure></div><h3 id="其他操作"><a href="#其他操作" class="headerlink" title="其他操作"></a>其他操作</h3><h4 id="when-——-条件判断"><a href="#when-——-条件判断" class="headerlink" title="when —— 条件判断"></a>when —— 条件判断</h4><ul><li>功能：<code>when otherwise</code> 类似于 SQL 中的 case when 语句；</li><li>语法：可以由多个 when 表达式（不满足前一个 when 条件则继续匹配下一个 when 条件），也可以不带 otherwise 表达式（不满足 when 条件则返回 null）；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">when(condition: <span class="type">Column</span>, value: <span class="type">Any</span>): <span class="type">Column</span></span><br><span class="line">otherwise(value: <span class="type">Any</span>): <span class="type">Column</span></span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">df.withColumn(<span class="string">&quot;new_gender&quot;</span>, when(col(<span class="string">&quot;gender&quot;</span>) === <span class="string">&quot;M&quot;</span>, <span class="string">&quot;Male&quot;</span>)).show()</span><br><span class="line">+--------------------+-----+------+------+----------+</span><br><span class="line">|                name|  dob|gender|salary|new_gender|</span><br><span class="line">+--------------------+-----+------+------+----------+</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|      <span class="type">Male</span>|</span><br><span class="line">|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|      <span class="type">Male</span>|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|      <span class="type">Male</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|      <span class="literal">null</span>|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|      <span class="literal">null</span>|</span><br><span class="line">+--------------------+-----+------+------+----------+</span><br><span class="line"></span><br><span class="line">df.withColumn(<span class="string">&quot;new_gender&quot;</span>, when(col(<span class="string">&quot;gender&quot;</span>) === <span class="string">&quot;M&quot;</span>, <span class="string">&quot;Male&quot;</span>).otherwise(<span class="string">&quot;Unknown&quot;</span>)).show()</span><br><span class="line">+--------------------+-----+------+------+----------+</span><br><span class="line">|                name|  dob|gender|salary|new_gender|</span><br><span class="line">+--------------------+-----+------+------+----------+</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|      <span class="type">Male</span>|</span><br><span class="line">|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|      <span class="type">Male</span>|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|      <span class="type">Male</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|   <span class="type">Unknown</span>|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|   <span class="type">Unknown</span>|</span><br><span class="line">+--------------------+-----+------+------+----------+</span><br><span class="line">df.withColumn(<span class="string">&quot;new_gender&quot;</span>, </span><br><span class="line">       when(col(<span class="string">&quot;gender&quot;</span>) === <span class="string">&quot;M&quot;</span>, <span class="string">&quot;Male&quot;</span>)</span><br><span class="line">      .when(col(<span class="string">&quot;gender&quot;</span>) === <span class="string">&quot;F&quot;</span>, <span class="string">&quot;Female&quot;</span>)</span><br><span class="line">      .otherwise(<span class="string">&quot;Unknown&quot;</span>))</span><br><span class="line">+--------------------+-----+------+------+----------+</span><br><span class="line">|                name|  dob|gender|salary|new_gender|</span><br><span class="line">+--------------------+-----+------+------+----------+</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|      <span class="type">Male</span>|</span><br><span class="line">|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|      <span class="type">Male</span>|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|      <span class="type">Male</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|    <span class="type">Female</span>|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|    <span class="type">Female</span>|</span><br><span class="line">+--------------------+-----+------+------+----------+</span><br></pre></td></tr></table></figure></div><h4 id="flatten-——-列拆多列"><a href="#flatten-——-列拆多列" class="headerlink" title="flatten —— 列拆多列"></a>flatten —— 列拆多列</h4><ul><li><p>功能：在 Spark SQL 中，扁平化 DataFrame 的嵌套结构列对于一级嵌套很简单，而对于多级嵌套和存在数百个列的情况下则很复杂。</p></li><li><p>扁平化嵌套 struct: 如果哦列数有限，可以通过引用列名似乎很容易解决，但是请想象一下，如果您有100多个列并在一个select中引用所有列，那么会很麻烦。可以通过创建一个递归函数 flattenStructSchema（）轻松地将数百个嵌套级别列展平。</p></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> structureData = <span class="type">Seq</span>(</span><br><span class="line">    <span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;James &quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;Smith&quot;</span>),<span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;CA&quot;</span>,<span class="string">&quot;Los Angles&quot;</span>),<span class="type">Row</span>(<span class="string">&quot;CA&quot;</span>,<span class="string">&quot;Sandiago&quot;</span>))),</span><br><span class="line">    <span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;Michael &quot;</span>,<span class="string">&quot;Rose&quot;</span>,<span class="string">&quot;&quot;</span>),<span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;NY&quot;</span>,<span class="string">&quot;New York&quot;</span>),<span class="type">Row</span>(<span class="string">&quot;NJ&quot;</span>,<span class="string">&quot;Newark&quot;</span>))),</span><br><span class="line">    <span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;Robert &quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;Williams&quot;</span>),<span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;DE&quot;</span>,<span class="string">&quot;Newark&quot;</span>),<span class="type">Row</span>(<span class="string">&quot;CA&quot;</span>,<span class="string">&quot;Las Vegas&quot;</span>))),</span><br><span class="line">    <span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;Maria &quot;</span>,<span class="string">&quot;Anne&quot;</span>,<span class="string">&quot;Jones&quot;</span>),<span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;PA&quot;</span>,<span class="string">&quot;Harrisburg&quot;</span>),<span class="type">Row</span>(<span class="string">&quot;CA&quot;</span>,<span class="string">&quot;Sandiago&quot;</span>))),</span><br><span class="line">    <span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;Jen&quot;</span>,<span class="string">&quot;Mary&quot;</span>,<span class="string">&quot;Brown&quot;</span>),<span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;CA&quot;</span>,<span class="string">&quot;Los Angles&quot;</span>),<span class="type">Row</span>(<span class="string">&quot;NJ&quot;</span>,<span class="string">&quot;Newark&quot;</span>)))</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> structureSchema = <span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">    .add(<span class="string">&quot;name&quot;</span>,<span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">      .add(<span class="string">&quot;firstname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      .add(<span class="string">&quot;middlename&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      .add(<span class="string">&quot;lastname&quot;</span>,<span class="type">StringType</span>))</span><br><span class="line">    .add(<span class="string">&quot;address&quot;</span>,<span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">      .add(<span class="string">&quot;current&quot;</span>,<span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">        .add(<span class="string">&quot;state&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">        .add(<span class="string">&quot;city&quot;</span>,<span class="type">StringType</span>))</span><br><span class="line">      .add(<span class="string">&quot;previous&quot;</span>,<span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">        .add(<span class="string">&quot;state&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">        .add(<span class="string">&quot;city&quot;</span>,<span class="type">StringType</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df = spark.createDataFrame(</span><br><span class="line">    spark.sparkContext.parallelize(structureData),structureSchema)</span><br><span class="line">df.printSchema()</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- name: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- firstname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- middlename: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- lastname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- address: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- current: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |    |-- state: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |    |-- city: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- previous: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |    |-- state: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |    |-- city: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> </span><br><span class="line">df.show(<span class="literal">false</span>)</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">|name                 |address                           |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">|[<span class="type">James</span> , , <span class="type">Smith</span>]    |[[<span class="type">CA</span>, <span class="type">Los</span> <span class="type">Angles</span>], [<span class="type">CA</span>, <span class="type">Sandiago</span>]]|</span><br><span class="line">|[<span class="type">Michael</span> , <span class="type">Rose</span>, ]   |[[<span class="type">NY</span>, <span class="type">New</span> <span class="type">York</span>], [<span class="type">NJ</span>, <span class="type">Newark</span>]]    |</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Williams</span>]|[[<span class="type">DE</span>, <span class="type">Newark</span>], [<span class="type">CA</span>, <span class="type">Las</span> <span class="type">Vegas</span>]]   |</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jones</span>]|[[<span class="type">PA</span>, <span class="type">Harrisburg</span>], [<span class="type">CA</span>, <span class="type">Sandiago</span>]]|</span><br><span class="line">|[<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]   |[[<span class="type">CA</span>, <span class="type">Los</span> <span class="type">Angles</span>], [<span class="type">NJ</span>, <span class="type">Newark</span>]]  |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 可以通过使用点符号（parentColumn.childColumn）来引用嵌套结构列，一种将嵌套结构打平的简单方法如下:</span></span><br><span class="line"><span class="keyword">val</span> df2 = df.select(col(<span class="string">&quot;name.*&quot;</span>),</span><br><span class="line">    col(<span class="string">&quot;address.current.*&quot;</span>),</span><br><span class="line">    col(<span class="string">&quot;address.previous.*&quot;</span>))</span><br><span class="line"><span class="keyword">val</span> df2Flatten = df2.toDF(<span class="string">&quot;fname&quot;</span>,<span class="string">&quot;mename&quot;</span>,<span class="string">&quot;lname&quot;</span>,<span class="string">&quot;currAddState&quot;</span>,</span><br><span class="line">    <span class="string">&quot;currAddCity&quot;</span>,<span class="string">&quot;prevAddState&quot;</span>,<span class="string">&quot;prevAddCity&quot;</span>)</span><br><span class="line">df2Flatten.printSchema()</span><br><span class="line">df2Flatten.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- name_firstname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- name_middlename: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- name_lastname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- address_current_state: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- address_current_city: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- address_previous_state: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- address_previous_city: string (nullable = <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">+--------+------+--------+------------+-----------+------------+-----------+</span><br><span class="line">|fname   |mename|lname   |currAddState|currAddCity|prevAddState|prevAddCity|</span><br><span class="line">+--------+------+--------+------------+-----------+------------+-----------+</span><br><span class="line">|<span class="type">James</span>   |      |<span class="type">Smith</span>   |<span class="type">CA</span>          |<span class="type">Los</span> <span class="type">Angles</span> |<span class="type">CA</span>          |<span class="type">Sandiago</span>   |</span><br><span class="line">|<span class="type">Michael</span> |<span class="type">Rose</span>  |        |<span class="type">NY</span>          |<span class="type">New</span> <span class="type">York</span>   |<span class="type">NJ</span>          |<span class="type">Newark</span>     |</span><br><span class="line">|<span class="type">Robert</span>  |      |<span class="type">Williams</span>|<span class="type">DE</span>          |<span class="type">Newark</span>     |<span class="type">CA</span>          |<span class="type">Las</span> <span class="type">Vegas</span>  |</span><br><span class="line">|<span class="type">Maria</span>   |<span class="type">Anne</span>  |<span class="type">Jones</span>   |<span class="type">PA</span>          |<span class="type">Harrisburg</span> |<span class="type">CA</span>          |<span class="type">Sandiago</span>   |</span><br><span class="line">|<span class="type">Jen</span>     |<span class="type">Mary</span>  |<span class="type">Brown</span>   |<span class="type">CA</span>          |<span class="type">Los</span> <span class="type">Angles</span> |<span class="type">NJ</span>          |<span class="type">Newark</span>     |</span><br><span class="line">+--------+------+--------+------------+-----------+------------+-----------+</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flattenStructSchema</span></span>(schema: <span class="type">StructType</span>, prefix: <span class="type">String</span> = <span class="literal">null</span>) : <span class="type">Array</span>[<span class="type">Column</span>] = &#123;</span><br><span class="line">    schema.fields.flatMap(f =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> columnName = <span class="keyword">if</span> (prefix == <span class="literal">null</span>) f.name <span class="keyword">else</span> (prefix + <span class="string">&quot;.&quot;</span> + f.name)</span><br><span class="line"></span><br><span class="line">      f.dataType <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> st: <span class="type">StructType</span> =&gt; flattenStructSchema(st, columnName)</span><br><span class="line">        <span class="keyword">case</span> _ =&gt; <span class="type">Array</span>(col(columnName).as(columnName.replace(<span class="string">&quot;.&quot;</span>,<span class="string">&quot;_&quot;</span>)))</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line"><span class="keyword">val</span> df3 = df.select(flattenStructSchema(df.schema):_*)</span><br><span class="line">df3.printSchema()</span><br><span class="line">df3.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+--------------+---------------+-------------+---------------------+--------------------+----------------------+---------------------+</span><br><span class="line">|name.firstname|name.middlename|name.lastname|address.current.state|address.current.city|address.previous.state|address.previous.city|</span><br><span class="line">+--------------+---------------+-------------+---------------------+--------------------+----------------------+---------------------+</span><br><span class="line">|<span class="type">James</span>         |               |<span class="type">Smith</span>        |<span class="type">CA</span>                   |<span class="type">Los</span> <span class="type">Angles</span>          |<span class="type">CA</span>                    |<span class="type">Sandiago</span>             |</span><br><span class="line">|<span class="type">Michael</span>       |<span class="type">Rose</span>           |             |<span class="type">NY</span>                   |<span class="type">New</span> <span class="type">York</span>            |<span class="type">NJ</span>                    |<span class="type">Newark</span>               |</span><br><span class="line">|<span class="type">Robert</span>        |               |<span class="type">Williams</span>     |<span class="type">DE</span>                   |<span class="type">Newark</span>              |<span class="type">CA</span>                    |<span class="type">Las</span> <span class="type">Vegas</span>            |</span><br><span class="line">|<span class="type">Maria</span>         |<span class="type">Anne</span>           |<span class="type">Jones</span>        |<span class="type">PA</span>                   |<span class="type">Harrisburg</span>          |<span class="type">CA</span>                    |<span class="type">Sandiago</span>             |</span><br><span class="line">|<span class="type">Jen</span>           |<span class="type">Mary</span>           |<span class="type">Brown</span>        |<span class="type">CA</span>                   |<span class="type">Los</span> <span class="type">Angles</span>          |<span class="type">NJ</span>                    |<span class="type">Newark</span>               |</span><br><span class="line">+--------------+---------------+-------------+---------------------+--------------------+----------------------+---------------------+</span><br></pre></td></tr></table></figure></div><ul><li>扁平化嵌套 Array: 上个示例展示了如何打平嵌套 Row，对于嵌套 Array 则可以通过 flatten() 方法除去嵌套数组第一层嵌套。</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> arrayArrayData = <span class="type">Seq</span>(</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;James&quot;</span>,<span class="type">List</span>(<span class="type">List</span>(<span class="string">&quot;Java&quot;</span>,<span class="string">&quot;Scala&quot;</span>,<span class="string">&quot;C++&quot;</span>),<span class="type">List</span>(<span class="string">&quot;Spark&quot;</span>,<span class="string">&quot;Java&quot;</span>))),</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;Michael&quot;</span>,<span class="type">List</span>(<span class="type">List</span>(<span class="string">&quot;Spark&quot;</span>,<span class="string">&quot;Java&quot;</span>,<span class="string">&quot;C++&quot;</span>),<span class="type">List</span>(<span class="string">&quot;Spark&quot;</span>,<span class="string">&quot;Java&quot;</span>))),</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;Robert&quot;</span>,<span class="type">List</span>(<span class="type">List</span>(<span class="string">&quot;CSharp&quot;</span>,<span class="string">&quot;VB&quot;</span>),<span class="type">List</span>(<span class="string">&quot;Spark&quot;</span>,<span class="string">&quot;Python&quot;</span>)))</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> arrayArraySchema = <span class="keyword">new</span> <span class="type">StructType</span>().add(<span class="string">&quot;name&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">    .add(<span class="string">&quot;subjects&quot;</span>,<span class="type">ArrayType</span>(<span class="type">ArrayType</span>(<span class="type">StringType</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df = spark.createDataFrame(</span><br><span class="line">     spark.sparkContext.parallelize(arrayArrayData),arrayArraySchema)</span><br><span class="line">df.printSchema()</span><br><span class="line">df.show()</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- name: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- subjects: array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- element: array (containsNull = <span class="literal">true</span>)</span><br><span class="line"> |    |    |-- element: string (containsNull = <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">+-------+-----------------------------------+</span><br><span class="line">|name   |subjects                           |</span><br><span class="line">+-------+-----------------------------------+</span><br><span class="line">|<span class="type">James</span>  |[[<span class="type">Java</span>, <span class="type">Scala</span>, <span class="type">C</span>++], [<span class="type">Spark</span>, <span class="type">Java</span>]]|</span><br><span class="line">|<span class="type">Michael</span>|[[<span class="type">Spark</span>, <span class="type">Java</span>, <span class="type">C</span>++], [<span class="type">Spark</span>, <span class="type">Java</span>]]|</span><br><span class="line">|<span class="type">Robert</span> |[[<span class="type">CSharp</span>, <span class="type">VB</span>], [<span class="type">Spark</span>, <span class="type">Python</span>]]    |</span><br><span class="line">+-------+-----------------------------------+</span><br><span class="line"></span><br><span class="line">df.select($<span class="string">&quot;name&quot;</span>,flatten($<span class="string">&quot;subjects&quot;</span>)).show(<span class="literal">false</span>)</span><br><span class="line">+-------+-------------------------------+</span><br><span class="line">|name   |flatten(subjects)              |</span><br><span class="line">+-------+-------------------------------+</span><br><span class="line">|<span class="type">James</span>  |[<span class="type">Java</span>, <span class="type">Scala</span>, <span class="type">C</span>++, <span class="type">Spark</span>, <span class="type">Java</span>]|</span><br><span class="line">|<span class="type">Michael</span>|[<span class="type">Spark</span>, <span class="type">Java</span>, <span class="type">C</span>++, <span class="type">Spark</span>, <span class="type">Java</span>]|</span><br><span class="line">|<span class="type">Robert</span> |[<span class="type">CSharp</span>, <span class="type">VB</span>, <span class="type">Spark</span>, <span class="type">Python</span>]    |</span><br><span class="line">+-------+-------------------------------+</span><br></pre></td></tr></table></figure></div><h4 id="explode-——-行拆多行"><a href="#explode-——-行拆多行" class="headerlink" title="explode —— 行拆多行"></a>explode —— 行拆多行</h4><ul><li>功能：在处理 JSON，Parquet，Avro 和 XML 等结构化文件时，我们通常需要从数组、列表和字典等集合中获取数据。在这种情况下，explode 函数（explode，explorer_outer，posexplode，posexplode_outer）对于将集合列转换为行以便有效地在 Spark 中进行处理很有用。</li><li><p>语法：</p></li><li><p>示例：</p></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 示例数据</span></span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> arrayData = <span class="type">Seq</span>(</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;James&quot;</span>,<span class="type">List</span>(<span class="string">&quot;Java&quot;</span>,<span class="string">&quot;Scala&quot;</span>),<span class="type">Map</span>(<span class="string">&quot;hair&quot;</span>-&gt;<span class="string">&quot;black&quot;</span>,<span class="string">&quot;eye&quot;</span>-&gt;<span class="string">&quot;brown&quot;</span>)),</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;Michael&quot;</span>,<span class="type">List</span>(<span class="string">&quot;Spark&quot;</span>,<span class="string">&quot;Java&quot;</span>,<span class="literal">null</span>),<span class="type">Map</span>(<span class="string">&quot;hair&quot;</span>-&gt;<span class="string">&quot;brown&quot;</span>,<span class="string">&quot;eye&quot;</span>-&gt;<span class="literal">null</span>)),</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;Robert&quot;</span>,<span class="type">List</span>(<span class="string">&quot;CSharp&quot;</span>,<span class="string">&quot;&quot;</span>),<span class="type">Map</span>(<span class="string">&quot;hair&quot;</span>-&gt;<span class="string">&quot;red&quot;</span>,<span class="string">&quot;eye&quot;</span>-&gt;<span class="string">&quot;&quot;</span>)),</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;Washington&quot;</span>,<span class="literal">null</span>,<span class="literal">null</span>),</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;Jefferson&quot;</span>,<span class="type">List</span>(),<span class="type">Map</span>())</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> arraySchema = <span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">    .add(<span class="string">&quot;name&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">    .add(<span class="string">&quot;knownLanguages&quot;</span>, <span class="type">ArrayType</span>(<span class="type">StringType</span>))</span><br><span class="line">    .add(<span class="string">&quot;properties&quot;</span>, <span class="type">MapType</span>(<span class="type">StringType</span>,<span class="type">StringType</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df = spark.createDataFrame(spark.sparkContext.parallelize(arrayData),arraySchema)</span><br><span class="line">df.printSchema()</span><br><span class="line">df.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- name: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- knownLanguages: array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- element: string (containsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- properties: map (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- key: string</span><br><span class="line"> |    |-- value: string (valueContainsNull = <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">+----------+--------------+-----------------------------+</span><br><span class="line">|name      |knownLanguages|properties                   |</span><br><span class="line">+----------+--------------+-----------------------------+</span><br><span class="line">|<span class="type">James</span>     |[<span class="type">Java</span>, <span class="type">Scala</span>] |[hair -&gt; black, eye -&gt; brown]|</span><br><span class="line">|<span class="type">Michael</span>   |[<span class="type">Spark</span>, <span class="type">Java</span>,]|[hair -&gt; brown, eye -&gt;]      |</span><br><span class="line">|<span class="type">Robert</span>    |[<span class="type">CSharp</span>, ]    |[hair -&gt; red, eye -&gt; ]       |</span><br><span class="line">|<span class="type">Washington</span>|<span class="literal">null</span>          |<span class="literal">null</span>                         |</span><br><span class="line">|<span class="type">Jefferson</span> |[]            |[]                           |</span><br><span class="line">+----------+--------------+-----------------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将数组爆炸成行，爆炸后的列名默认为 &quot;col&quot;，如果数组为 null 或空则会被跳过，值为null则会返回 null</span></span><br><span class="line">df.select($<span class="string">&quot;name&quot;</span>,explode($<span class="string">&quot;knownLanguages&quot;</span>)).show(<span class="literal">false</span>)</span><br><span class="line">+-------+------+</span><br><span class="line">|name   |col   |</span><br><span class="line">+-------+------+</span><br><span class="line">|<span class="type">James</span>  |<span class="type">Java</span>  |</span><br><span class="line">|<span class="type">James</span>  |<span class="type">Scala</span> |</span><br><span class="line">|<span class="type">Michael</span>|<span class="type">Spark</span> |</span><br><span class="line">|<span class="type">Michael</span>|<span class="type">Java</span>  |</span><br><span class="line">|<span class="type">Michael</span>|<span class="literal">null</span>  |</span><br><span class="line">|<span class="type">Robert</span> |<span class="type">CSharp</span>|</span><br><span class="line">|<span class="type">Robert</span> |      |</span><br><span class="line">+-------+------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将字典爆炸成行，爆炸后键列默认列名为 &quot;key&quot;，值列默认为 &quot;value&quot;</span></span><br><span class="line">df.select($<span class="string">&quot;name&quot;</span>,explode($<span class="string">&quot;properties&quot;</span>)).show(<span class="literal">false</span>)</span><br><span class="line">+-------+----+-----+</span><br><span class="line">|name   |key |value|</span><br><span class="line">+-------+----+-----+</span><br><span class="line">|<span class="type">James</span>  |hair|black|</span><br><span class="line">|<span class="type">James</span>  |eye |brown|</span><br><span class="line">|<span class="type">Michael</span>|hair|brown|</span><br><span class="line">|<span class="type">Michael</span>|eye |<span class="literal">null</span> |</span><br><span class="line">|<span class="type">Robert</span> |hair|red  |</span><br><span class="line">|<span class="type">Robert</span> |eye |     |</span><br><span class="line">+-------+----+-----+</span><br><span class="line"></span><br><span class="line"><span class="comment">// explode_outer 遇到 null 或空的数组、字典将返回 null</span></span><br><span class="line">df.select($<span class="string">&quot;name&quot;</span>,explode_outer($<span class="string">&quot;knownLanguages&quot;</span>)).show(<span class="literal">false</span>)</span><br><span class="line">+----------+------+</span><br><span class="line">|name      |col   |</span><br><span class="line">+----------+------+</span><br><span class="line">|<span class="type">James</span>     |<span class="type">Java</span>  |</span><br><span class="line">|<span class="type">James</span>     |<span class="type">Scala</span> |</span><br><span class="line">|<span class="type">Michael</span>   |<span class="type">Spark</span> |</span><br><span class="line">|<span class="type">Michael</span>   |<span class="type">Java</span>  |</span><br><span class="line">|<span class="type">Michael</span>   |<span class="literal">null</span>  |</span><br><span class="line">|<span class="type">Robert</span>    |<span class="type">CSharp</span>|</span><br><span class="line">|<span class="type">Robert</span>    |      |</span><br><span class="line">|<span class="type">Washington</span>|<span class="literal">null</span>  |</span><br><span class="line">|<span class="type">Jeferson</span>  |<span class="literal">null</span>  |</span><br><span class="line">+----------+------+</span><br><span class="line"></span><br><span class="line">df.select($<span class="string">&quot;name&quot;</span>,explode_outer($<span class="string">&quot;properties&quot;</span>)).show(<span class="literal">false</span>)</span><br><span class="line">+----------+----+-----+</span><br><span class="line">|name      |key |value|</span><br><span class="line">+----------+----+-----+</span><br><span class="line">|<span class="type">James</span>     |hair|black|</span><br><span class="line">|<span class="type">James</span>     |eye |brown|</span><br><span class="line">|<span class="type">Michael</span>   |hair|brown|</span><br><span class="line">|<span class="type">Michael</span>   |eye |<span class="literal">null</span> |</span><br><span class="line">|<span class="type">Robert</span>    |hair|red  |</span><br><span class="line">|<span class="type">Robert</span>    |eye |     |</span><br><span class="line">|<span class="type">Washington</span>|<span class="literal">null</span>|<span class="literal">null</span> |</span><br><span class="line">|<span class="type">Jeferson</span>  |<span class="literal">null</span>|<span class="literal">null</span> |</span><br><span class="line">+----------+----+-----+</span><br><span class="line"></span><br><span class="line"><span class="comment">// posexplode 会在 explode 基础上添加位置列 &quot;pos&quot;</span></span><br><span class="line">df.select($<span class="string">&quot;name&quot;</span>,posexplode($<span class="string">&quot;knownLanguages&quot;</span>)).show(<span class="literal">false</span>)</span><br><span class="line">+-------+---+------+</span><br><span class="line">|name   |pos|col   |</span><br><span class="line">+-------+---+------+</span><br><span class="line">|<span class="type">James</span>  |<span class="number">0</span>  |<span class="type">Java</span>  |</span><br><span class="line">|<span class="type">James</span>  |<span class="number">1</span>  |<span class="type">Scala</span> |</span><br><span class="line">|<span class="type">Michael</span>|<span class="number">0</span>  |<span class="type">Spark</span> |</span><br><span class="line">|<span class="type">Michael</span>|<span class="number">1</span>  |<span class="type">Java</span>  |</span><br><span class="line">|<span class="type">Michael</span>|<span class="number">2</span>  |<span class="literal">null</span>  |</span><br><span class="line">|<span class="type">Robert</span> |<span class="number">0</span>  |<span class="type">CSharp</span>|</span><br><span class="line">|<span class="type">Robert</span> |<span class="number">1</span>  |      |</span><br><span class="line">+-------+---+------+</span><br><span class="line"></span><br><span class="line">df.select($<span class="string">&quot;name&quot;</span>,posexplode($<span class="string">&quot;properties&quot;</span>)).show(<span class="literal">false</span>)</span><br><span class="line">+-------+---+----+-----+</span><br><span class="line">|name   |pos|key |value|</span><br><span class="line">+-------+---+----+-----+</span><br><span class="line">|<span class="type">James</span>  |<span class="number">0</span>  |hair|black|</span><br><span class="line">|<span class="type">James</span>  |<span class="number">1</span>  |eye |brown|</span><br><span class="line">|<span class="type">Michael</span>|<span class="number">0</span>  |hair|brown|</span><br><span class="line">|<span class="type">Michael</span>|<span class="number">1</span>  |eye |<span class="literal">null</span> |</span><br><span class="line">|<span class="type">Robert</span> |<span class="number">0</span>  |hair|red  |</span><br><span class="line">|<span class="type">Robert</span> |<span class="number">1</span>  |eye |     |</span><br><span class="line">+-------+---+----+-----+</span><br><span class="line"></span><br><span class="line"><span class="comment">// posexplode_outer 会在 explode_outer 的基础上添加位置列 &quot;pos&quot;</span></span><br><span class="line">df.select($<span class="string">&quot;name&quot;</span>,posexplode_outer($<span class="string">&quot;knownLanguages&quot;</span>)).show(<span class="literal">false</span>)</span><br><span class="line">+----------+----+------+</span><br><span class="line">|name      |pos |col   |</span><br><span class="line">+----------+----+------+</span><br><span class="line">|<span class="type">James</span>     |<span class="number">0</span>   |<span class="type">Java</span>  |</span><br><span class="line">|<span class="type">James</span>     |<span class="number">1</span>   |<span class="type">Scala</span> |</span><br><span class="line">|<span class="type">Michael</span>   |<span class="number">0</span>   |<span class="type">Spark</span> |</span><br><span class="line">|<span class="type">Michael</span>   |<span class="number">1</span>   |<span class="type">Java</span>  |</span><br><span class="line">|<span class="type">Michael</span>   |<span class="number">2</span>   |<span class="literal">null</span>  |</span><br><span class="line">|<span class="type">Robert</span>    |<span class="number">0</span>   |<span class="type">CSharp</span>|</span><br><span class="line">|<span class="type">Robert</span>    |<span class="number">1</span>   |      |</span><br><span class="line">|<span class="type">Washington</span>|<span class="literal">null</span>|<span class="literal">null</span>  |</span><br><span class="line">|<span class="type">Jeferson</span>  |<span class="literal">null</span>|<span class="literal">null</span>  |</span><br><span class="line">+----------+----+------+</span><br><span class="line"></span><br><span class="line">df.select($<span class="string">&quot;name&quot;</span>,posexplode_outer($<span class="string">&quot;properties&quot;</span>)).show(<span class="literal">false</span>)</span><br><span class="line">+----------+----+----+-----+</span><br><span class="line">|name      |pos |key |value|</span><br><span class="line">+----------+----+----+-----+</span><br><span class="line">|<span class="type">James</span>     |<span class="number">0</span>   |hair|black|</span><br><span class="line">|<span class="type">James</span>     |<span class="number">1</span>   |eye |brown|</span><br><span class="line">|<span class="type">Michael</span>   |<span class="number">0</span>   |hair|brown|</span><br><span class="line">|<span class="type">Michael</span>   |<span class="number">1</span>   |eye |<span class="literal">null</span> |</span><br><span class="line">|<span class="type">Robert</span>    |<span class="number">0</span>   |hair|red  |</span><br><span class="line">|<span class="type">Robert</span>    |<span class="number">1</span>   |eye |     |</span><br><span class="line">|<span class="type">Washington</span>|<span class="literal">null</span>|<span class="literal">null</span>|<span class="literal">null</span> |</span><br><span class="line">|<span class="type">Jeferson</span>  |<span class="literal">null</span>|<span class="literal">null</span>|<span class="literal">null</span> |</span><br><span class="line">+----------+----+----+-----+</span><br></pre></td></tr></table></figure></div><h4 id="pivot-stack-——-行转列-列转行"><a href="#pivot-stack-——-行转列-列转行" class="headerlink" title="pivot | stack —— 行转列 | 列转行"></a>pivot | stack —— 行转列 | 列转行</h4><ul><li><p>功能：</p><ul><li>pivot() 是一种聚合方法（类似于 Excel 中的数据透视表），用于将 DataFrame/Dataset 的行转列，该过程可以被分为三个步骤，① 按 x 列分组，x 的不同取值作为行向标签 ② 将 y 列的不同取值作为列向标签 ③ 将行列标签 (x,y) 对应 z 的聚合结果作为值，如果源表没有 (x,y) 对应的数据则补 null；</li><li>stack() 方法可以将 DataFrame/Dataset 的列转行，注意 Spark 没有 unpivot 方法；</li></ul></li><li><p>语法：</p></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">groupBy(x).pivot(y).sum(z)  <span class="comment">// x 列不同值作为行标签，y 列不同值作为列标签，z 列的聚合作为值</span></span><br><span class="line">stack(n, expr1, ..., exprk) <span class="comment">// 会将 expr1, ..., exprk 折叠为 n 行</span></span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建一个 DataFrame</span></span><br><span class="line"><span class="keyword">val</span> data = <span class="type">Seq</span>((<span class="string">&quot;Banana&quot;</span>,<span class="number">1000</span>,<span class="string">&quot;USA&quot;</span>), (<span class="string">&quot;Carrots&quot;</span>,<span class="number">1500</span>,<span class="string">&quot;USA&quot;</span>), (<span class="string">&quot;Beans&quot;</span>,<span class="number">1600</span>,<span class="string">&quot;USA&quot;</span>),</span><br><span class="line">      (<span class="string">&quot;Orange&quot;</span>,<span class="number">2000</span>,<span class="string">&quot;USA&quot;</span>),(<span class="string">&quot;Orange&quot;</span>,<span class="number">2000</span>,<span class="string">&quot;USA&quot;</span>),(<span class="string">&quot;Banana&quot;</span>,<span class="number">400</span>,<span class="string">&quot;China&quot;</span>),</span><br><span class="line">      (<span class="string">&quot;Carrots&quot;</span>,<span class="number">1200</span>,<span class="string">&quot;China&quot;</span>),(<span class="string">&quot;Beans&quot;</span>,<span class="number">1500</span>,<span class="string">&quot;China&quot;</span>),(<span class="string">&quot;Orange&quot;</span>,<span class="number">4000</span>,<span class="string">&quot;China&quot;</span>),</span><br><span class="line">      (<span class="string">&quot;Banana&quot;</span>,<span class="number">2000</span>,<span class="string">&quot;Canada&quot;</span>),(<span class="string">&quot;Carrots&quot;</span>,<span class="number">2000</span>,<span class="string">&quot;Canada&quot;</span>),(<span class="string">&quot;Beans&quot;</span>,<span class="number">2000</span>,<span class="string">&quot;Mexico&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> spark.sqlContext.implicits._</span><br><span class="line"><span class="keyword">val</span> df = data.toDF(<span class="string">&quot;Product&quot;</span>,<span class="string">&quot;Amount&quot;</span>,<span class="string">&quot;Country&quot;</span>)</span><br><span class="line">df.show()</span><br><span class="line"></span><br><span class="line">+-------+------+-------+</span><br><span class="line">|<span class="type">Product</span>|<span class="type">Amount</span>|<span class="type">Country</span>|</span><br><span class="line">+-------+------+-------+</span><br><span class="line">| <span class="type">Banana</span>|  <span class="number">1000</span>|    <span class="type">USA</span>|</span><br><span class="line">|<span class="type">Carrots</span>|  <span class="number">1500</span>|    <span class="type">USA</span>|</span><br><span class="line">|  <span class="type">Beans</span>|  <span class="number">1600</span>|    <span class="type">USA</span>|</span><br><span class="line">| <span class="type">Orange</span>|  <span class="number">2000</span>|    <span class="type">USA</span>|</span><br><span class="line">| <span class="type">Orange</span>|  <span class="number">2000</span>|    <span class="type">USA</span>|</span><br><span class="line">| <span class="type">Banana</span>|   <span class="number">400</span>|  <span class="type">China</span>|</span><br><span class="line">|<span class="type">Carrots</span>|  <span class="number">1200</span>|  <span class="type">China</span>|</span><br><span class="line">|  <span class="type">Beans</span>|  <span class="number">1500</span>|  <span class="type">China</span>|</span><br><span class="line">| <span class="type">Orange</span>|  <span class="number">4000</span>|  <span class="type">China</span>|</span><br><span class="line">| <span class="type">Banana</span>|  <span class="number">2000</span>| <span class="type">Canada</span>|</span><br><span class="line">|<span class="type">Carrots</span>|  <span class="number">2000</span>| <span class="type">Canada</span>|</span><br><span class="line">|  <span class="type">Beans</span>|  <span class="number">2000</span>| <span class="type">Mexico</span>|</span><br><span class="line">+-------+-----+-------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 行转列：不同 Product、不同 Country 下，Amount 的和</span></span><br><span class="line"><span class="keyword">val</span> pivotDF = df.groupBy(<span class="string">&quot;Product&quot;</span>).pivot(<span class="string">&quot;Country&quot;</span>).sum(<span class="string">&quot;Amount&quot;</span>)</span><br><span class="line">pivotDF.show()</span><br><span class="line"></span><br><span class="line">+-------+------+-----+------+----+</span><br><span class="line">|<span class="type">Product</span>|<span class="type">Canada</span>|<span class="type">China</span>|<span class="type">Mexico</span>| <span class="type">USA</span>|</span><br><span class="line">+-------+------+-----+------+----+</span><br><span class="line">| <span class="type">Orange</span>|  <span class="literal">null</span>| <span class="number">4000</span>|  <span class="literal">null</span>|<span class="number">4000</span>|</span><br><span class="line">|  <span class="type">Beans</span>|  <span class="literal">null</span>| <span class="number">1500</span>|  <span class="number">2000</span>|<span class="number">1600</span>|</span><br><span class="line">| <span class="type">Banana</span>|  <span class="number">2000</span>|  <span class="number">400</span>|  <span class="literal">null</span>|<span class="number">1000</span>|</span><br><span class="line">|<span class="type">Carrots</span>|  <span class="number">2000</span>| <span class="number">1200</span>|  <span class="literal">null</span>|<span class="number">1500</span>|</span><br><span class="line">+-------+------+-----+------+----+</span><br><span class="line"></span><br><span class="line"><span class="comment">// pivot 是一个非常耗时的操作，Spark 2.0 以后的版本对 pivot 的性能进行了优化，如果使用的是更低的版本，可以通过传递一个列值参数来加速计算过程</span></span><br><span class="line"><span class="keyword">val</span> pivotDF = df.groupBy(<span class="string">&quot;Product&quot;</span>).pivot(<span class="string">&quot;Country&quot;</span>, <span class="type">Seq</span>(<span class="string">&quot;USA&quot;</span>,<span class="string">&quot;China&quot;</span>)).sum(<span class="string">&quot;Amount&quot;</span>)</span><br><span class="line">pivotDF.show()</span><br><span class="line"></span><br><span class="line">+-------+----+-----+</span><br><span class="line">|<span class="type">Product</span>| <span class="type">USA</span>|<span class="type">China</span>|</span><br><span class="line">+-------+----+-----+</span><br><span class="line">| <span class="type">Orange</span>|<span class="number">4000</span>| <span class="number">4000</span>|</span><br><span class="line">|  <span class="type">Beans</span>|<span class="number">1600</span>| <span class="number">1500</span>|</span><br><span class="line">| <span class="type">Banana</span>|<span class="number">1000</span>|  <span class="number">400</span>|</span><br><span class="line">|<span class="type">Carrots</span>|<span class="number">1500</span>| <span class="number">1200</span>|</span><br><span class="line">+-------+----+-----+</span><br></pre></td></tr></table></figure></div><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// stack(n, 列1显示名, 列1, ..., 列n显示名, 列n)</span></span><br><span class="line"><span class="keyword">val</span> unPivotDF = pivotDF.select($<span class="string">&quot;Product&quot;</span>, expr(<span class="string">&quot;stack(2, &#x27;USA&#x27;, USA, &#x27;China&#x27;, China) as (Country,Total)&quot;</span>))</span><br><span class="line">    .where(<span class="string">&quot;Total is not null&quot;</span>)</span><br><span class="line">unPivotDF.show()</span><br><span class="line"></span><br><span class="line">+-------+-------+-----+</span><br><span class="line">|<span class="type">Product</span>|<span class="type">Country</span>|<span class="type">Total</span>|</span><br><span class="line">+-------+-------+-----+</span><br><span class="line">| <span class="type">Orange</span>|    <span class="type">USA</span>| <span class="number">4000</span>|</span><br><span class="line">| <span class="type">Orange</span>|  <span class="type">China</span>| <span class="number">4000</span>|</span><br><span class="line">|  <span class="type">Beans</span>|    <span class="type">USA</span>| <span class="number">1600</span>|</span><br><span class="line">|  <span class="type">Beans</span>|  <span class="type">China</span>| <span class="number">1500</span>|</span><br><span class="line">| <span class="type">Banana</span>|    <span class="type">USA</span>| <span class="number">1000</span>|</span><br><span class="line">| <span class="type">Banana</span>|  <span class="type">China</span>|  <span class="number">400</span>|</span><br><span class="line">|<span class="type">Carrots</span>|    <span class="type">USA</span>| <span class="number">1500</span>|</span><br><span class="line">|<span class="type">Carrots</span>|  <span class="type">China</span>| <span class="number">1200</span>|</span><br><span class="line">+-------+-------+-----+</span><br></pre></td></tr></table></figure></div><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://snaildove.github.io/2019/08/05/Chapter5_Basic-Structured-Operations(SparkTheDefinitiveGuide">《Spark 权威指南》</a>_online/)</li><li><a href="https://spark-reference-doc-cn.readthedocs.io/zh_CN/latest/programming-guide/sql-guide.html">Spark 2.2.x 中文文档</a></li><li><a href="https://sparkbyexamples.com/apache-spark-tutorial-with-scala-examples/">Spark By Examples</a></li><li><a href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Dataset.html">org.apache.spark.sql.Dataset</a>：Dataset 对象方法</li><li><a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Column.html">org.apache.spark.sql.Dataset.Column</a>：Column 对象方法</li></ul><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;从定义上讲，DataFrame 由一系列行和列组成，行的类型为 Row，列可以表示成每个单独行的计算表达式。Schema 定义了每个列的名称和类型，Partition 定义了整个集群中 DataFrame 的物理分布。&lt;/p&gt;
&lt;h2 id=&quot;Schema&quot;&gt;&lt;a href
      
    
    </summary>
    
      <category term="Spark" scheme="http://liketea.xyz/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://liketea.xyz/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>数据科学：因果推断（二）—— Rubin 因果模型（RCM）</title>
    <link href="http://liketea.xyz/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%EF%BC%9A%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%20Rubin%20%E5%9B%A0%E6%9E%9C%E6%A8%A1%E5%9E%8B%EF%BC%88RCM%EF%BC%89/"/>
    <id>http://liketea.xyz/数据科学/数据科学/数据科学：因果推断（二）—— Rubin 因果模型（RCM）/</id>
    <published>2021-02-08T07:29:53.000Z</published>
    <updated>2021-07-18T03:33:15.697Z</updated>
    
    <content type="html"><![CDATA[<p>鲁宾因果模型（Rubin causal model, RCM），也称内曼-鲁宾因果模型（Neyman–Rubin causal model），是一种基于潜在结果框架（framework of potential outcomes）的因果推断方法，以杰西·内曼（Jerzy Neyman）和唐纳德·鲁宾（Donald Rubin）的名字命名。潜在结果的概念最早是由 Neyman（1923）在研究重复随机化农业实验中提出的，由于该文用波兰语写成，当时没有引起学界的关注。Rubin（1974）重新独立地提出了潜在结果的概念，并将它的使用推广到观测研究领域，从而形成了目前的潜在结果框架。RCM 有三个基本要素：潜在结果、稳定性假设、分配机制。</p><h2 id="潜在结果"><a href="#潜在结果" class="headerlink" title="潜在结果"></a>潜在结果</h2><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/intervention_effect_Individual.png" width="80%" heigh="70%"></img></div><h3 id="干预"><a href="#干预" class="headerlink" title="干预"></a>干预</h3><p>在因果推断中，必须有干预（Intervention），没有干预就没有因果（Rubin，1974）。干预可以是一项政策、一项措施或一项活动等，比如实施 4 万亿财政刺激方案，服用某种新药等。本文主要讨论二值干预变量，两个值分别对应于积极的行动和被动的行动，分别称为干预和控制，受到对应干预的个体分别称为干预组和控制组。</p><p>干预和控制只是<strong>干预变量</strong>的两种状态的标签，具体哪个状态被称为干预，哪个状态称为控制并不重要，两种状态实际上是对称的，可以互换，取决于研究者的目的和偏好。比如，对于药物试验来说，干预是服用药物，控制是不服用药物。</p><h3 id="潜在结果-1"><a href="#潜在结果-1" class="headerlink" title="潜在结果"></a>潜在结果</h3><p>在干预状态实现之前，有几个干预状态就有几个<strong>潜在结果</strong>（Potential outcome），而干预状态实现之后，只有一个潜在结果是可以观测到的。可以将潜在结果看作<strong>常数</strong>，对于每个特定的个体，他在两种干预状态下的潜在结果是给定的，不依赖于最终实现的干预状态，这一点对于理解 Rubin 因果模型很关键。</p><p>比如，考察大学教育对个人收入的影响，干预变量或原因变量是大学教育，那么对于任意个体 $i$ 有两种干预状态，用 $D<em>i$ 来表示，$D_i=1$ 表示个体 $i$ 完成了大学教育，$D_i=0$ 表示个体 $i$ 完成高中教育。无论个体实际是完成大学教育还是高中教育，事前每个个体均有两种可能的状态：完成高中教育或完成大学教育。每一个状态下对应于一个潜在结果，$Y</em>{1i}$ 表示个体 $i$ 在状态$D<em>i=1$ 下的潜在结果，$Y</em>{0i}$ 表示个体 $i$ 在状态 $D<em>i=0$ 下的潜在结果。对个体而言，这两个潜在结果可以看作是确定性的变量，不因个体干预变量的实现状态而改变。比如个体 $i$ 完成大学教育状态下的收入为 $8000$ 元，即 $Y</em>{1i}=8000$，仅完成高中教育状态下收入为 6000 元，即 $Y_{0i}=6000$。如果个体 $i$ 最后实际完成了大学教育，那么其两种干预状态下的潜在结果仍然是（8000，6000），如果个体 $i$ 最后实际完成的是高中教育，其两种干预状态下的潜在结果还是（8000，6000），不因个体最后实现的状态而改变。</p><h3 id="观测结果-VS-反事实结果"><a href="#观测结果-VS-反事实结果" class="headerlink" title="观测结果 VS 反事实结果"></a>观测结果 VS 反事实结果</h3><p>当干预状态实现之后，我们仅能观测到实现状态下的潜在结果，称为<strong>观测结果</strong>（Observation outcome），没有实现状态下的潜在结果是无法观测的，通常称为<strong>反事实结果</strong>（Counterfactual outcome）。比如个体 $i$ 最终完成了大学教育，那么观测到的干预状态是 $D<em>i=1$，我们可以观测到潜在结果 $Y</em>{1i}$，即个体 $i$ 完成大学教育后的收入。他完成了大学教育，我们就不能观测到他没有完成大学教育时的潜在结果 $Y_{0i}$，即仅完成高中教育时的收入。一个人不可能同时踏入两条河流，不可能同时处于两种状态，因而，观测研究中，不可能同时看到个体所有的潜在结果。无法同时观测到个体所有潜在结果的现象称为<strong>因果推断的基本问题</strong>（Holland，1986）。</p><p>观测结果 $Y_i$ 与潜在结果之间的关系，可以用下面的公式表示：</p><script type="math/tex; mode=display">\begin{align*}Y_i&=D_iY_{1i}+(1-D_i)Y_{0i}\\&=\left\{\begin{matrix}Y_{1i}, & \text{如果}\ D_i = 1 \\ Y_{0i}, & \text{如果}\ D_i = 0\end{matrix}\right.\end{align*}\tag {1}</script><p>潜在结果和观测结果的区分是现代统计学和现代计量经济学的重要标志，是经济学经验研究“可信性革命”的关键，也是区分描述性研究（descriptive study）和因果研究（causal study）的标志。</p><h3 id="干预效应-因果效应"><a href="#干预效应-因果效应" class="headerlink" title="干预效应/因果效应"></a>干预效应/因果效应</h3><p>有了潜在结果的概念，个体因果效应的定义非常直观，不需要对分配机制进行任何内生性或外生性的假设，也不需要对结果变量的函数形式进行任何假设，对于个体 $i$，某项<strong>干预的因果效应</strong>是两种状态下的潜在结果的比较：</p><script type="math/tex; mode=display">\tau_i=Y_{1i}-Y_{0i} \tag {2}</script><p>关于因果效应的定义有两点说明：</p><ol><li>因果效应仅依赖于潜在结果，与观测结果无关：回到大学教育如何影响收入的例子，无论个体 $i$ 是否完成了大学教育，大学教育对其个人的因果影响都取决于其两种状态下的潜在结果，并且是固定不变的，不依赖于个体最终实现的干预状态；如果个体 $i$ 完成了大学教育，大学教育对其收入的影响是每个月收入增加 2000 元；如果个体 $i$ 仅完成高中教育，那么，如果他能完成大学教育，则其收入的影响也是每月增加 2000 元。</li><li>因果效应是干预后同一时间、同一物理个体潜在结果的比较：比如考察某种药物对感冒的治疗效果，干预状态是吃药或不吃药，对应的潜在结果是治愈感冒或没有治愈；因果效应应该定义为我现在吃药和不吃药对应潜在结果的比较，而不能用我现在吃药和昨天我没有吃药时的潜在结果比较；因为昨天的我和今天的我不是同一个我，我今天不吃药的潜在结果和昨天不吃药的潜在结果可能是不一样的，所以在评价今天我吃药的因果效应时，应该是今天我吃药和今天我不吃药时潜在结果的比较。</li></ol><h3 id="反事实结果估计"><a href="#反事实结果估计" class="headerlink" title="反事实结果估计"></a>反事实结果估计</h3><p>因果效应的定义仅依赖于不同潜在结果的比较，对于给定个体，研究者只能观察到该个体一个状态下的潜在结果，因而，如果仅有一个个体，我们是没有办法得到个体因果效应的。因果推断的核心内容，实际上是想办法将未观测到的潜在结果估计出来，即<strong>反事实结果估计</strong>。估计反事实结果必须要用到多个个体，多个个体的选择方式有两种：</p><ol><li>同一个体的不同时间：比如，判断一种药物是否对感冒有治疗效果，我们往往根据自己以往的经历。我以前感冒的时候吃药感冒就好了，我今天没吃药，头就很痛，因而，我们认为药物有治疗效果。其实这种推断中，我们进行了很强的假设，我们假设过去的经验可以作为今天吃药的反事实结果。如果这一假设不成立，我们就不能用过去吃药的结果作为今天吃药的反事实结果。因为今天的“我”与过去的“我”是不同的个体，我今天可能心情不好，不吃药头很痛，即使吃药，头仍然是痛的。这并不一定说明药没有治疗效果，而是因为我心情沮丧，使我的头更痛了，即我的头痛还混杂了其他的影响因素。</li><li>同一时间的不同个体：很多时候，我们的推断是利用同一时间不同个体的信息来估计反事实结果。比如考虑大学教育对收入的影响。在上大学之前，我们不确定大学能给我们带来什么。我们只知道目前我的结果是什么样子，或收入是什么水平。但不知道大学毕业之后收入会是什么水平。那我们在决定是否上大学时，是怎么作出决定的呢？我们可能会观察那些上了大学的人，可能是亲戚或朋友家的孩子，现在已经大学毕业了，有个很好的工作，获得比较满意的收入。那我们在作决策时是怎么做的呢？我们可能将他们的结果或收入作为我们上大学的潜在收入，从而决定是否上大学。</li></ol><h2 id="稳定性假设"><a href="#稳定性假设" class="headerlink" title="稳定性假设"></a>稳定性假设</h2><p>RCM 的第二个要素是稳定个体干预值假（Stable Unit Treatment Value Assumption, SUTVA），简称稳定性假设（Rubin，1980），SUTVA 有两层含义：</p><ol><li>不同个体的潜在结果之间<strong>不会交互影响</strong>：比如，我们住在同一间宿舍，我们两个都感冒了，如果药物对我头痛的治疗效果依赖于你有没有吃药，那就不满足稳定性假设；在社会科学中，没有交互影响的假设可能不成立，社会科学的研究对象往往是人的行为，个人行为之间往往存在交互影响；但是，在不存在交互影响的假设下，因果推断更加容易，通常假设不同个体之间不存在交互影响。</li><li>干预水平对所有个体都是<strong>相同</strong>的：比如考察药物的治疗效果，那么给所有病人的药物在药效上都应该是一样的，不能有的人有效成分是全额的，有的人是半额的；实际研究中，往往很难完全满足这一要求，通常会忽略掉这种差异，更加关注稳定性假设的第一项要求。</li></ol><h2 id="分配机制"><a href="#分配机制" class="headerlink" title="分配机制"></a>分配机制</h2><p>分配机制是描述为什么有的人在干预组，有的人在控制组的机制。分配机制决定了个体哪个潜在结果会被实现，可以被观测到。在因果推断中，分配机制非常重要，来看一个“手术相对于药物的治疗效果”的例子：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/qzjg0306.png" width="80%" heigh="70%"></img></div><p>在潜在结果列可以看出，对于病人 1 和病人 3 来说，手术治疗效果优于药物治疗，而对于病人 2 和病人 4 来说，药物治疗优于手术治疗。假设现实中医生具有很好的医术或鉴别力，可以让病人选择对他最有利的治疗方案，从而实现的分配机制如表中第 5 列所示，让 1 和 3 号病人接受手术治疗，让 2 和 4 号病人接受药物治疗，最终我们可以观测到 1、3 病人的 $Y<em>{1i}$ 以及 2、4 病人的 $Y</em>{0i}$，如观测结果列所示。如果不清楚分配机制，直接用两组观测结果进行比较，将会发现手术治疗平均寿命为 6 年，而药物治疗平均寿命为 7 年，从而得出药物治疗更有效的错误结论。而事实上，通过潜在结果计算出的平均因果效应，手术治疗要比药物治疗寿命长 2 年。</p><p>根据分配机制是否已知，可以将分配机制分成两类：</p><ol><li>随机实验：分配机制是由实验者控制的，是已知的；</li><li>观测研究：分配机制是未知的，观测研究的目的就是想办法识别出未知的分配机制，从而估计因果效应；</li></ol><h3 id="协变量"><a href="#协变量" class="headerlink" title="协变量"></a>协变量</h3><p>为了搞清楚分配机制，往往需要一些<strong>协变量</strong>（Covariates），也称混淆变量（Confusion variable），协变量的基本特征是这些变量不受干预变量的影响，但是却往往决定个体的干预状态，协变量包括两种：</p><ol><li>个体属性：不随干预状态变化而变化的变量，比如性别、民族等变量；</li><li>干预实施之前取值的变量：比如研究培训的作用时，培训前的收入水平及经济社会特征等；</li></ol><h3 id="条件独立性"><a href="#条件独立性" class="headerlink" title="条件独立性"></a>条件独立性</h3><p>非混杂性（Unconfoundedness），也称为<strong>条件独立性</strong>（Conditional independence），是指控制协变量 $X_i$ 后，个体干预状态的分配独立于潜在结果，非混杂性可以表示为：</p><script type="math/tex; mode=display">(Y_{0i},Y_{1i})\perp D_i|X_i \tag {3}</script><p>根据分配机制是否满足条件独立性条件，可以将分配机制分成三类：</p><ol><li>经典随机化实验：分配机制满足条件独立性，且函数形式已知；</li><li>规则分配机制（Regular assignment mechanism）：分配机制满足条件独立性，但函数形式未知；</li><li>不规则机制（Irregular assignment mechanism）：分配机制不满足条件独立性；</li></ol><h2 id="Lord-悖论"><a href="#Lord-悖论" class="headerlink" title="Lord 悖论"></a>Lord 悖论</h2><p>潜在结果的概念，对理清所要研究的因果问题、定义因果效应非常有帮助。有些因果问题的探讨，必须从潜在结果概念出发才能搞清楚因果效应是否有清晰的定义，从观测结果出发进行建模往往不能清晰地表述所研究的因果效应问题。</p><p>这一节介绍一个在统计学中很有名，但是在中文统计教科书中几乎从未介绍过的悖论 —— Lord 悖论（Lord’s Paradox）。这个悖论是由美国教育考试服务中心（EducationalTestingService, ETS）统计学家 FredericLord 于 1967 年提出来的，最终由同在 ETS 工作的另外两位统计学家 Paul Holland 和 Donald Rubin 于 1982 年圆满地找出了这个悖论的根源。</p><h3 id="悖论描述"><a href="#悖论描述" class="headerlink" title="悖论描述"></a>悖论描述</h3><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/LordPlot2.png" width="50%" heigh="70%"></img></div><p>Lord（1967）构造了一个假想的案例，一所大学想考察其食堂膳食对于学生体重是否有差异性的影响，尤其关心食堂对于男女学生体重影响是否相同，为此，收集了学生 9 月份入学时的体重，然后次年 6 月份又获得了学生在校一学年后的体重。两个统计学家分别利用这个数据考察了学校食堂对学生体重的影响，但得到了完全不同的结论：</p><ol><li>第一个统计学家用了比较初等的方法，计算了男生和女生入学时的平均体重，分别是 150 磅和 130 磅。然后又计算了入学一学年后男、女生的平均体重，发现仍然是 150 磅和 130 磅。因而，第一位统计学家认为学生食堂膳食对学生体重没有影响。</li><li>第二个统计学家采用了更加高等的方法 —— 回归分析，他认为为了考察食堂对学生体重的影响，必须比较两个初始体重相同的人，因而，他构造了一个回归模型，控制了个体入学时的体重，并考察了性别的差异。回归结果表明，同样体重的男生、女生相比，男生的体重增加更大，比女生平均高 7.3 磅。</li></ol><p>两个统计学家利用同一数据，采用不同的方法，得到几乎相反的结果，一个说无因果影响，一个说对男生的影响更大，这种矛盾的结果被称为 Lord 悖论。那么，这两个统计学家的分析，哪一个正确呢？</p><h3 id="悖论解释"><a href="#悖论解释" class="headerlink" title="悖论解释"></a>悖论解释</h3><p>我们首先用 Rubin 因果模型的框架套用到该问题上：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/qzjg.png" width="80%" heigh="70%"></img></div><p>表中的问号（?）是解决 Lord 悖论的关键，尽管积极干预是非常清晰的——学校食堂膳食，它对学生体重的影响是想要研究的问题，但没有清晰的控制干预，不在学校食堂吃饭时是在家吃饭还是在外面下馆子，我们并不清楚，这意味着潜在结果 $Y_0$ 的定义是模糊的，我们权且将 $Y_0$ 看做是假如期间学生没有在学校食堂吃饭时的体重。然而，没有学生在控制组，所有学生都在学校食堂吃饭，为了回答食堂对学生体重的影响，必然要引入一些有关 $Y_0$ 的不可检验的假设，这也正是两位统计学家产生分歧的地方。</p><p>食堂膳食对学生体重的个体影响可以写作 $Y_1 - Y_0$，对男女学生的平均影响可以写作:</p><script type="math/tex; mode=display">\Delta_i = E[Y_1-Y_0|G=i],\ i=1,2 \tag {4}</script><p>平均因果影响的性别差异为：</p><script type="math/tex; mode=display">\begin{align*}\Delta &= \Delta_1 - \Delta_2\\ &=E[Y_1-Y_0|G=1]-E[Y_1-Y_0|G=2]\\ &=(E[Y_1|G=1]-E[Y_1|G=2])-(E[Y_0|G=1]-E[Y_0|G=2])\end{align*}\tag {5}</script><p>第一位统计学家根据男女学生入学前和放假后平均体重的对比，得到学校膳食没有影响的结论。他所依据的假设是“<strong>假如学生不在学校食堂吃饭，他们的体重变化相同</strong>”，即 $Y_0 = X + C$，其中 $C$ 对男女学生都是相同的常量，基于该假设可以计算平均因果影响的性别差异：</p><script type="math/tex; mode=display">\begin{align*}\Delta &= \Delta_1 - \Delta_2\\ &=E[Y_1-Y_0|G=1]-E[Y_1-Y_0|G=2]\\ &=E[Y_1-X-C|G=1]-E[Y_1-X-C|G=2]\\ &=E[Y_1-X|G=1]-E[Y_1-X|G=2]\\ &=0-0\\ &=0\end{align*}\tag {6}</script><p>第二位统计学家认为应该控制开学时的体重，比较相同体重的人放假时体重的变化，对于初始体重为 X 的个体，体重的增加为 $\delta_i(X) = E[Y_i-X|X,G=i],\ i=1,2$，增量的性别差异为 $\delta(X) = \delta_1(X)-\delta_2(X)$，为简单起见，Lord 假设条件期望函数均为线性且男女生斜率相同，即 $E[Y_i|X,G=i]=a_i+bX,\ i=1,2$，则 $\delta(X)=a_1-a_2$。$\delta(X)$ 与因果效应参数 $\Delta$ 没有直接关系，但是在一定的假设下二者等价，比如假设“<strong>如果学生不在学校食堂吃饭，他们的体重是初始体重的线性函数</strong>”，即 $Y_0 = a + bX$，并且对所有性别的学生都一样，在此假设下，有：</p><script type="math/tex; mode=display">\begin{align*}\Delta &= \Delta_1 - \Delta_2\\ &=E[Y_1-Y_0|G=1]-E[Y_1-Y_0|G=2]\\ &=E[Y_1-a-bX|G=1]-E[Y_1-a-bX|G=2]\\ &=E[Y_1-bX|G=1]-E[Y_1-bX|G=2]\\ &=E[E[Y_1|X,G=1]-bX|G=1]-E[E[Y_1|X,G=2]-bX|G=2]\\ &=E[a_1+bX-bX|G=1]-E[a_2+bX-bX|G=2]\\ &=a_1-a_2\\\end{align*}\tag {7}</script><p>关于 Lord’s Paradox，我们有如下结论：</p><ol><li>Lord 悖论的根源在于整个研究没有控制组，我们甚至不知道什么是控制组，这导致 $Y_0$ 定义模糊；</li><li>统计学家一和二，都可能是对的，他们结论的正确性，依赖于不同的假定，而这些假定本身是不可能被检验的；</li><li>统计学家一和二，都是错的，他们有结论，但是却从未清楚地陈述结论回答的是什么问题；</li><li>潜在结果的概念，对理清所要研究的因果问题、定义因果效应非常有帮助；</li></ol><h2 id="因果效应参数"><a href="#因果效应参数" class="headerlink" title="因果效应参数"></a>因果效应参数</h2><h3 id="ATE-amp-ATT-amp-ATC-定义"><a href="#ATE-amp-ATT-amp-ATC-定义" class="headerlink" title="ATE &amp; ATT &amp; ATC 定义"></a>ATE &amp; ATT &amp; ATC 定义</h3><p>实证研究中，我们关心的往往不是某一特定个体的因果效应，而是干预的平均因果效应。假设有 N 个个体，用 i=1,……,N 表示，$D_i \in {0,1}$ 表示干预变量，个体因果效应为：</p><script type="math/tex; mode=display">\tau_i=Y_{1i}-Y_{0i},\ i=1,\cdots ,N \tag {8}</script><p>个体因果效应往往无法估计，因而，我们关注<strong>总体平均因果效应</strong>（Average Treatment Effect, ATE），它表示从总体中随机抽取一个个体进行干预的平均因果效应：</p><script type="math/tex; mode=display">\tau_{ATE}=E[Y_{1i}-Y_{0i}] \tag {9}</script><p>在政策评价中，我们更关心那些受到政策影响的个体的平均因果效应，称为<strong>干预组平均因果效应</strong>（Average Treatment Effect for the Treated,ATT）：</p><script type="math/tex; mode=display">\tau_{ATT}=E[Y_{1i}-Y_{0i}\mid D_i=1] \tag {10}</script><p>有些时候，我们关注那些没有受到政策影响的个体如果接受政策干预的话，其平均因果效应是多少，称为<strong>控制组平均因果效应</strong>（Average Treatment Effect for the Control, ATC）：</p><script type="math/tex; mode=display">\tau_{ATC}=E[Y_{1i}-Y_{0i}\mid D_i=0] \tag {11}</script><p>不同的因果效应参数回答不同的问题，比如考察大学教育对个体收入的影响，将大学教育看作一项积极干预，高中教育看作一项控制干预：</p><ol><li>ATE：如果想知道大学教育对所有国民的平均影响，估计的参数是总体的平均因果效应（ATE），它反映的是如果全部国民均接受大学教育相对于均接受高中教育全部国民的平均收入增长。</li><li>ATT：如果关心的政策问题是大学教育给接受者带来了多大程度的收入增加，需要估计的参数是干预组平均因果效应（ATT）。</li><li>ATC：如果想知道那些仅完成高中教育的个人，如果他们能够完成大学教育的话，他们的收入将增长多少，则需要估计的参数是控制组平均因果效应（ATC）。</li></ol><h3 id="ATE-amp-ATT-amp-ATC-计算"><a href="#ATE-amp-ATT-amp-ATC-计算" class="headerlink" title="ATE &amp; ATT &amp; ATC 计算"></a>ATE &amp; ATT &amp; ATC 计算</h3><p>下面通过一个简单的例子来示范三个因果效应参数的计算，假设有四个个体，并且我们可以同时看到两种干预状态下的潜在结果（现实中只能看到一种状态下的结果）:</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/ygxycs.png" width="90%" heigh="70%"></img></div><p>理论上，我们可以根据表中的潜在结果数据分别计算 ATE、ATT、ATC：</p><script type="math/tex; mode=display">\begin{align*}\tau_{ATE}&=E[Y_{1i}-Y_{0i}]=3\cdot 1/4 + 0 \cdot 1/4 + 1 \cdot 1/4 + 0 \cdot 1/4=1.0\\\tau_{ATT}&=E[Y_{1i}-Y_{0i}\mid D_i=1]=3\cdot 1/2 + 0 \cdot 1/2=1.5\\\tau_{ATC}&=E[Y_{1i}-Y_{0i}\mid D_i=0]=1\cdot 1/2 + 0 \cdot 1/2=0.5\end{align*}</script><p>实际上，我们仅能观测到每个个体在其中一种状态下的潜在结果。对于前两个个体，他们在干预组，我们可以观测到他们在积极干预状态下的潜在结果 $Y<em>{1i}=Y_i$，但观测不到他们在控制状态下的潜在结果 $Y</em>{0i}$；相反对于后两个个体，他们在控制组，我们可以观测到他们在被动控制状态下的潜在结果 $Y<em>{0i}=Y_i$，但却观测不到他们在干预状态下的潜在结果 $Y</em>{1i}$。从而，前面计算的三个因果效应参数也就没有办法计算出来了，现在我们再来看各个因果效应参数的定义：</p><script type="math/tex; mode=display">\begin{align*}\tau_{ATE}&=E[Y_{1i}-Y_{0i}]\\&=E[E[Y_{1i}-Y_{0i}|D_i]]\\&=E[Y_{1i}-Y_{0i}|D_i=1]\cdot P(D_i=1)+E[Y_{1i}-Y_{0i}|D_i=0]\cdot P(D_i=0) \\&=\tau_{ATT}\cdot P_t+\tau_{ATC}\cdot P_c\\\tau_{ATT}&=E[Y_{1i}-Y_{0i}|D_i=1]=E[Y_i|D_i=1]-E[Y_{0i}|D_i=1]\\\tau_{ATC}&=E[Y_{1i}-Y_{0i}|D_i=0]=E[Y_{1i}|D_i=0]-E[Y_i|D_i=0]\end{align*}\tag {12}</script><p>其中，反事实结果 $E[Y<em>{0i}|D_i=1]$ 和 $E[Y</em>{1i}|D_i=0]$ 是观测不到的，必须通过一定的方法将其估计出来，才能得到以上干预效应。</p><h3 id="回归分析与因果效应"><a href="#回归分析与因果效应" class="headerlink" title="回归分析与因果效应"></a>回归分析与因果效应</h3><p>学过回归分析的学生可能禁不住想用 $Y_i$ 对 $D_i$ 回归，这也是计量经济学的基本建模方式，但是这种回归并不能识别出任何因果效应参数。比如我们建立一个简单的双变量回归模型：</p><script type="math/tex; mode=display">Y_i=\alpha + \tau D_i + \varepsilon_i \tag {13}</script><p>根据初等计量经济学的知识，用一个容量为 N 的随机样本去估计上述简单回归模型，$D_i$ 的回归系数为：</p><script type="math/tex; mode=display">\hat{\tau}^{ols}=\frac{\sum_{i=1}^{N}(Y_i-\bar{Y})(D_i-\bar{D})}{\sum_{i=1}^{N}(D_i-\bar{D})^2} \tag {14}</script><p>当干预变量是 $0-1$ 二值变量时，可以证明 $Y_i$ 对 $D_i$ 的<strong>回归系数</strong> $\hat{\tau}^{ols}$ 等于干预组和控制组<strong>样本均值之差</strong>，在大样本的情况下：</p><script type="math/tex; mode=display">\hat{\tau}^{ols}=\bar{Y_t}-\bar{Y_c}\overset{p}{\rightarrow}E[Y_i|D_i=1]-E[Y_i|D_i=0]=\tau^{ols} \tag {15}</script><p>$\tau^{ols}$ 是总体回归系数，一般不能反映因果效应参数，除非施加一定的假设。</p><p>首先，考察总体回归系数和干预组平均因果效应（ATT）之间的关系：</p><script type="math/tex; mode=display">\begin{align*}\tau^{ols}&=E[Y_i|D_i=1]-E[Y_i|D_i=0]\\&=E[Y_{1i}|D_i=1]-E[Y_{0i}|D_i=0]\\&=E[Y_{1i}-Y_{0i}|D_i=1]+(E[Y_{0i}|D_i=1]-E[Y_{0i}|D_i=0])\\&=\tau_{ATT}+\Delta \tau_0\end{align*} \tag {16}</script><p>回归系数和因果效应参数 ATT 之间相差 $E[Y<em>{0i}｜D_i=1]-E[Y</em>{0i}｜D<em>i=0]$，它表示<strong>干预组和控制组个体在控制状态下的潜在结果差异</strong>，也称为基线潜在结果差异（difference in baseline potential outcomes），这一偏差通常称为<strong>选择偏差</strong>（selection bias）。$E[Y</em>{0i}｜D<em>i=1]$ 表示干预组个体在控制状态下的潜在结果，是观测不到的，但是在选择偏差为 0 的假设下，可以用控制组的观测结果 $E[Y</em>{0i}｜D<em>i=0]$ 来代替干预组的反事实结果 $E[Y</em>{0i}|D_i=1]$。比如教育收益率的例子，如果潜在收入高的人倾向于选择上大学，那么，上大学的人即使仅完成了高中教育，他们的收入也会比高中组高，那么大学组合高中组观测到的收入均值差就不能解释为大学教育对个人收入的因果影响，选择偏差为正，回归系数将高估教育对收入的影响。</p><p>类似地，总体回归系数也不是控制组平均因果效应（ATC），只有假设<strong>干预组和控制组的干预潜在结果相同</strong>，即 $E[Y<em>{1i}|D_i=1]=E[Y</em>{1i}|D_i=0]$，回归系数才等于 ATC：</p><script type="math/tex; mode=display">\begin{align*}\tau^{ols}&=E[Y_i|D_i=1]-E[Y_i|D_i=0]\\&=E[Y_{1i}|D_i=1]-E[Y_{0i}|D_i=0]\\&=E[Y_{1i}-Y_{0i}|D_i=0]+(E[Y_{1i}|D_i=1]-E[Y_{1i}|D_i=0])\\&=\tau_{ATC}+\Delta \tau_1\end{align*} \tag {17}</script><p>最后，总体回归系数通常也不是平均因果效应，只有同时施加假设 $\Delta \tau<em>0=0$ 和$\Delta \tau_1=0$ 时，总体回归系数才可解释为总体平均因果效应。将式 $(16)$ 和 $(17)$ 带入到 $\tau</em>{ATE}=\tau<em>{ATT}\cdot P_t+\tau</em>{ATC}\cdot P_c$，易得：</p><script type="math/tex; mode=display">\tau^{ols}=\tau_{ATE}+\Delta \tau_0+P_c\cdot (\tau_{ATT}-\tau_{ATC}) \tag {18}</script><p>我们可以得到分配机制、潜在结果、干预效应和回归系数之间的一般关系，如下图所示：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/Average_Treatment_Effect.png" width="60%" heigh="70%"></img></div><p>需要注意的是，潜在结果框架仅关注因果效应，不能说明变量之间的影响机制，因果效应是一个“黑箱”，只能给出因果效应的大小，不能给出产生这一因果效应的内在机制。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>赵西亮. 基本有用的计量经济学 (高等院校经济学管理学系列教材)</li><li><a href="https://cosx.org/2013/09/causality7-lord-paradox">因果推断简介之七：Lord’s Paradox</a></li></ul><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;鲁宾因果模型（Rubin causal model, RCM），也称内曼-鲁宾因果模型（Neyman–Rubin causal model），是一种基于潜在结果框架（framework of potential outcomes）的因果推断方法，以杰西·内曼（Jerzy N
      
    
    </summary>
    
      <category term="数据科学" scheme="http://liketea.xyz/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
    
      <category term="数据科学" scheme="http://liketea.xyz/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>数据科学：因果推断（一）—— 辛普森悖论</title>
    <link href="http://liketea.xyz/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%EF%BC%9A%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%20%E8%BE%9B%E6%99%AE%E6%A3%AE%E6%82%96%E8%AE%BA/"/>
    <id>http://liketea.xyz/数据科学/数据科学/数据科学：因果推断（一）—— 辛普森悖论/</id>
    <published>2021-02-07T07:29:53.000Z</published>
    <updated>2021-06-02T10:44:40.922Z</updated>
    
    <content type="html"><![CDATA[<div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201229113413.png" width="60%" heigh="55%"></img></div><blockquote><p>There are three kinds of lies: lies, damned lies, and statistics.</p><p align="right">——Mark Twain</p></blockquote><h2 id="辛普森悖论——描述"><a href="#辛普森悖论——描述" class="headerlink" title="辛普森悖论——描述"></a>辛普森悖论——描述</h2><p>辛普森悖论（Simpson’s paradox）是概率统计中的一种现象：在变量 Z 的每一个分层上，变量 X 和变量 Y 都表现出一致的相关性，但是在 Z 的整体上，X 和 Y 却呈现出与之相反的相关性。该现象于 20 世纪初就有人讨论，但一直到 1951 年 E.H.辛普森在他发表的论文中阐述此一现象后，该现象才算正式地被描述解释，辛普森悖论这个名字是由柯林·布莱斯（Colin R. Blyth）在 1972 年提出的。</p><p>以 BBG 药物（Bad/Bad/Good Drug）之谜为例，假设有一种新药 D，这种新药似乎可以降低心脏病发作的风险，我们通过临床观测收集到了如下数据（数据来自观测实验而非随机化实验）：</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201228173241.png" alt=""></p><p>整体来看，服药组和未服药组各有 60 人，男性和女性各有 60 人，不同人群的心脏发病率表现如下：</p><ol><li>对于女性患者：未服药组的心脏病发病率 5%  &lt; 服药组的心脏病发病率 8%；</li><li>对于男性患者：未服药组的心脏病发病率 30% &lt; 服药组的心脏病发病率 40%；</li><li>对于所有患者：未服药组的心脏病发病率 22% &gt; 服药组的心脏病发病率 18%；</li></ol><p>这种药物似乎对女性有害，对男性也有害，但却对整个人类有益！一个表面的解决方案是，当我们知道病人的性别是男性或者是女性时，我们不采用这种药物疗法，但如果病人的性别是未知的，我们就应该采用这种疗法！但显然，这个结论是荒谬的。这三句话中一定有一句是错的，但错的是哪一句？为什么？这种令人迷惑不解的情况究竟是如何发生的呢？</p><h2 id="辛普森悖论——解决"><a href="#辛普森悖论——解决" class="headerlink" title="辛普森悖论——解决"></a>辛普森悖论——解决</h2><p>任何声称能够解决悖论的方法都应该能够回答一些关于悖论的基本问题：</p><ol><li>解释悖论让人困惑的原因；</li><li>确定悖论出现的场景类别；</li><li>挖掘悖论掩盖的正确结论；</li></ol><h3 id="辛普森逆转"><a href="#辛普森逆转" class="headerlink" title="辛普森逆转"></a>辛普森逆转</h3><p>“辛普森逆转”是指在合并样本时，两个或多个不同样本关于某一特定事件的相对频率出现反转的现象。在上面的例子中，我们可以看到两组相对频率：<code>1/20 &lt; 3/40</code>，<code>12/40 &lt; 8/20</code>，然而 <code>(1 + 12)/(20 + 40) &gt; (3 + 8)/(40 + 20)</code>。</p><p>为了直观理解辛普森逆转机制，我们通过混合不同浓度的溶液来类比混合不同性别心脏发病率的场景，其中容器的形状代表性别，女性用圆形容器来表示，男性则用方形容器来表示，患者发病率用黑色阴影来表示，混合前圆形容器和方形容器干预组液体浓度都要大于对照组，混合后干预组液体浓度却高于对照组：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/Simpson.png" width="40%" heigh="55%"></img></div><p>辛普森逆转通常满足两个前提：</p><ol><li>不同 Z 分层对应的 Y 值相差很大：男性患者的发病率(33.3%)远高于女性患者的发病率(6.7%)；</li><li>Z 在干预组和对照组的分布有明显差异：男性在对照组占比(66.7%)远高于在干预组占比(33.3%)；</li></ol><h3 id="辛普森悖论"><a href="#辛普森悖论" class="headerlink" title="辛普森悖论"></a>辛普森悖论</h3><p>辛普森逆转只是一个纯粹的数字事实，本身并无新奇之处，它最多只是纠正了人们对“平均表现”的错误概念。而悖论的含义不止于此，它应该能够引起两种为绝大部分人深信不疑的信念之间的冲突。在 BBG 药物悖论中，当“对男性有害”“对女性有害”“对人类有益”这三个陈述被简单理解为比例增减时，它们在数学上并不矛盾，但是你可能认为这种情况在现实世界中不可能存在，因为一种药物不可能既导致心脏病发作又防止心脏病发作。幸运的是，你的直觉是对的，BBG 药物确实不存在！</p><blockquote><p>确凿性原则：假如无论事件 C 是否发生，某个行动都会增加某一结果的可能性，则该行动也将在我们不知道事件 C 是否发生的情况下增加这个结果的可能性，前提是该行动不会改变 C 的概率。</p></blockquote><p>根据确凿性原则，以下三种陈述之一必定为假：</p><ol><li>药物 D 增加了男性患者和女性患者的心脏病发作的概率；</li><li>药物 D 降低了整个总体的心脏病发作的概率；</li><li>药物 D 不会改变男性和女性的数量；</li></ol><p>因为药物改变病人性别的事不太可能发生，所以前两句陈述中一定有一句为假。那么，哪句陈述是假的？要回答这个问题，我们必须在数据之外探寻数据生成的过程。我们可以通过以下因果图对 BBG 药物数据的产生过程建模，这张图对性别对心脏病发作风险的影响（男性患者的风险更大），以及性别对患者是否选择服用药物 D 的影响（女性更倾向于服用药物 D）进行了编码，性别因素构成了是否服用药物和心脏病发作的<strong>混淆因子</strong>：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/ygt.png" width="40%" heigh="55%"></img></div><p>为了客观估计药物对心脏病的影响，我们必须对混淆因子进行控制，或按照一般总体中性别分布对不同性别下药物效果进行加权：</p><ol><li>对于女性患者：未服药组的心脏病发病率 5%  &lt; 服药组的心脏病发病率 8%；</li><li>对于男性患者：未服药组的心脏病发病率 30% &lt; 服药组的心脏病发病率 40%；</li><li>对于所有患者：未服药组的心脏病发病率 <code>5% × 0.5 + 30% × 0.5 = 17.5%</code> &lt; 服药组的心脏病发病率  <code>8% × 0.5 + 40% × 0.5 = 24%</code>；</li></ol><p>至此，我们找到了关于 BBG 药物最清晰、明确的答案：药物 D 不是 BBG 药物，而是 BBB 药物，对女性有害、对男性有害、对人类有害。</p><p>至此，我们回答了 BBG 药物悖论中的基本问题：</p><ol><li>解释悖论让人困惑的原因：从心脏病发病率来看，BBG 药物似乎对男性有害、对女性有害、对全体人类有益，这是荒谬的，违反了绝大多数人的直觉；</li><li>确定悖论出现的场景类别：BBG 药物悖论产生的前提有三，① 性别因素既是影响是否服用药物的原因，又是影响患者发病率的原因，即性别是药物服用和发病的混淆因子；② 不同性别下，发病率差别较大；③ 不同性别下，药物服用比例差别较大；</li><li>挖掘悖论掩盖的正确结论：控制混淆因子，分层看数据或者按混淆因子在一般总体中的分布情况对统计数据进行修正，可得正确结论，BBG 药物对男性有害、对女性有害、对人类有害；</li></ol><h3 id="分合取决于因果而非数据"><a href="#分合取决于因果而非数据" class="headerlink" title="分合取决于因果而非数据"></a>分合取决于因果而非数据</h3><p>关于辛普森悖论，还应明确：</p><ol><li>辛普森悖论的存在并不意味着聚合数据总是错的：是分是合取决于数据的生成过程，而非数据本身；</li><li>辛普森悖论没有出现也不意味着混淆因子不存在：潜在的混淆因子仍然会干扰统计推断，只是没有达到辛普森悖论的极端表现；</li></ol><p>假设高血压是心脏病发作的可能原因，而药物 B 能降低血压，研究人员向看看这种药物是否也能降低心脏病发作的风险，因此他们在病人服药后测量了病人的血压，并观察病人是否会出现心脏病发作的情况：</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201229111149.png" alt=""></p><p>这些数据看起来非常熟悉，其中的数字和 BBG 药物的统计数据是完全一致的。我们可以通过以下因果图对服用药物 B、血压、心脏病发作三者建模，与 BBG 因果图不同的是，血压不再是药物服用和心脏病发作的混淆因子，而是二者之间的中介物：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/ywb.png" width="40%" heigh="55%"></img></div><p>“服用药物 B -&gt; 心脏病发作”这一因果关系中没有混杂因子，所以数据分层是不必要的。事实上，如果控制血压会使其中一条因果路径失效（而且可能是最重要的那条因果路径），导致药物无法通过这条路径发挥作用。鉴于此，我们得出的结论与在 BBG 药物的例子中得到的结论完全相反：药物 B 能有效预防心脏病发作。</p><h2 id="辛普森悖论——实例"><a href="#辛普森悖论——实例" class="headerlink" title="辛普森悖论——实例"></a>辛普森悖论——实例</h2><h3 id="肾结石疗法"><a href="#肾结石疗法" class="headerlink" title="肾结石疗法"></a>肾结石疗法</h3><p>1996 年发表的一篇观察性研究报告表明，对于摘除小型肾结石而言，开腹手术比内窥镜手术的恢复率高，对于摘除较大的肾结石而言，开腹手术也有更高的恢复率。然而就总体而言，开腹手术的恢复率反而较低。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201229113552.png" width="40%" heigh="55%"></img></div><p>小肾结石被认为是不太严重的病例，开腹手术比内窥镜手术更加激进，因此对于小肾结石，医生更有可能推荐保守内窥镜手术，因为病情不太严重，患者也更有可能首先成功恢复。对于严重的大肾结石，医生往往选择更激进的开腹手术，较大肾结石的病人本身的恢复率较低。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201229115501.png" width="40%" heigh="55%"></img></div><h3 id="吸烟者存活率更高？"><a href="#吸烟者存活率更高？" class="headerlink" title="吸烟者存活率更高？"></a>吸烟者存活率更高？</h3><p>在 1995 年发表的一份关于甲状腺疾病的研究报告中，数据显示吸烟者的存活率（76%）比不吸烟者的存活率（69%）更高，寿命平均多出20年。然而，在样本的7个年龄组中，有6个年龄组中不吸烟者的存活率更高，而第7个年龄组中二者的差异微乎其微。年龄显然是吸烟和存活率的混杂因子：吸烟者的平均年龄比不吸烟者小（很可能是因为年老的吸烟者已经死了）。根据年龄来分割数据，我们就可以得出正确的结论：吸烟对存活率有负面影响。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201229115441.png" width="40%" heigh="55%"></img></div><h3 id="运动水平与体内胆固醇水平"><a href="#运动水平与体内胆固醇水平" class="headerlink" title="运动水平与体内胆固醇水平"></a>运动水平与体内胆固醇水平</h3><p>逆转也可能发生在包含连续变量的情况，假设有一项关于各年龄段群体每周的运动时间与其体内胆固醇水平之关系的研究。如左图所示，我们以 x 轴表示运动时间，以 y 轴表示胆固醇水平。一方面，我们在每个年龄组中都看到了向下的趋势，表明运动可能的确有降低人体胆固醇水平的效果。另一方面，如果我们使用相同的散点图，但不按年龄对数据进行分层，如右图所示，那么我们就会看到一个明显向上的趋势，表明运动得越多，人体胆固醇水平就越高。看起来我们再次遇到了 BBG 药物的情况，其中运动就是那个药物：它似乎对每个年龄组都产生了有益的影响，却对整个总体有害。</p><p>像往常一样，要决定运动是有益的还是有害的，我们需要考察数据背后的故事。数据显示，总体中年龄越大的人运动得越多。因为更可能发生的是年龄影响运动，而不是反过来。同时，年龄可能对胆固醇水平也有因果效应。因此我们得出结论，年龄可能是运动时间和胆固醇水平的混杂因子，我们应该对年龄进行变量控制。换言之，我们应该看的是按照年龄组别进行分层后的数据，并据其得出结论：无论年龄大小，运动都是有益的。</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201229115652.png" alt=""></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>为什么（美）朱迪亚·珀尔，（美）达纳·麦肯齐著；江生，于华译.北京：中信出版社，2019.7</li><li><a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">辛普森悖论·维基百科</a></li><li><a href="http://bayes.cs.ucla.edu/PRIMER/">JUDEA PEARL, MADELYN GLYMOUR, NICHOLAS P. JEWELL CAUSAL INFERENCE IN STATISTICS: A PRIMER</a></li><li><a href="https://cosx.org/2012/03/causality1-simpson-paradox/">因果推断简介之一：从 Yule-Simpson’s Paradox 讲起</a></li></ul><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=center&gt;
    &lt;img src=&quot;https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201229113413.png&quot; width=&quot;60%&quot; heig
      
    
    </summary>
    
      <category term="数据科学" scheme="http://liketea.xyz/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
    
      <category term="数据科学" scheme="http://liketea.xyz/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>数据科学：因果推断（〇）—— 综述</title>
    <link href="http://liketea.xyz/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%EF%BC%9A%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%EF%BC%88%E3%80%87%EF%BC%89%E2%80%94%E2%80%94%20%E7%BB%BC%E8%BF%B0/"/>
    <id>http://liketea.xyz/数据科学/数据科学/数据科学：因果推断（〇）—— 综述/</id>
    <published>2021-02-06T07:29:53.000Z</published>
    <updated>2021-06-02T10:44:40.921Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>我们生活在一个相信大数据能够解决所有问题的时代，然而数据远非万能，数据可以告诉你服药的病人比不服药的病人康复得快，却不能告诉你原因何在。也许，那些服药的人只是因为他们支付得起，即使不服用这种药，他们也能恢复得更快。正如 Kendall 和 Stuart 所说，统计关系无论有多强，有多紧密，也决不能建立起因果关系，因果关系的概念来自统计学之外的某个理论。</p></blockquote><h2 id="因果关系（causality）"><a href="#因果关系（causality）" class="headerlink" title="因果关系（causality）"></a>因果关系（causality）</h2><p>因果观念是人类认知事物的重要方式，我们相信，世界并非是由简单的事实堆砌而成，相反，这些事实是通过错综复杂的因果网络联系在一起的，科学正是建立在因果律的基础之上的。关于因果的讨论，已经持续了上千年，至今仍没有统一定论，在正式讨论“因果推断”之前，我们有必要搞清楚，当我们提到“因果”时，究竟是在谈论着什么。</p><h3 id="神话时代"><a href="#神话时代" class="headerlink" title="神话时代"></a>神话时代</h3><p>在神话思维时代，人类对诸如雷电、地震等自然现象都会归结为某个神灵的意志。这种拟人化的目的归因，是人类试图捕捉现象背后本质因果思维的最初尝试，并发展出交感巫术、祈祷等手段与神灵沟通，从而对自然过程进行干预。</p><h3 id="希腊时代"><a href="#希腊时代" class="headerlink" title="希腊时代"></a>希腊时代</h3><p>人类文明的轴心时代，是古希腊人最早发扬了理性精神。哲学和科学的诞生，不仅来自经验知识，更因为是有数学和几何。古希腊最早的哲学家，包括泰勒斯、毕达哥拉斯等，都同时也是数学家和自然科学家。数学对象之间的必然关系，放到经验世界，就产生了让哲学脱胎于神话的第一次天问：“世界是如何起源的？从此人类以理性思维探讨世界秩序成为了可能。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/wood123.png" width="50%"></img></div><p>希腊哲学家对世界起源的回答，无论是水、气、火、数、逻各斯或无定形，最后都被亚里士多德总结为四种原因：</p><ol><li>质料因（Matter - material cause）：构成事物的材料，例如木材就是桌子的质料因；</li><li>形式因（Form - formal cause）：构成事物的样式，例如木工心中桌子的样式，就是桌子的形式因；</li><li>动力因（Agent - efficient cause）：构成事物的过程，例如木工制作桌子的过程就是桌子的动力因；</li><li>目的因（Purpose - final cause）：构成事物的目的，例如放置物品就是桌子的目的因；</li></ol><h3 id="理性主义"><a href="#理性主义" class="headerlink" title="理性主义"></a>理性主义</h3><p>17 世纪，德国数学家和哲学家莱布尼茨，将自己的哲学建立在两个逻辑前提之上：矛盾律（在同一时刻，某个事物不可能在同一方面既是这样又不是这样）和充分理由律（任何事物都有其存在的充足理由）。这两个前提又都建立在一种“分析”命题的概念之上，而所谓的分析命题就是谓项被包含在主项之中的命题 —— 例如，“所有的白种人都是人”。矛盾律所陈述的是“所有分析命题都是真命题”，充分理由律所陈述的则是“所有的真命题都是分析命题”。这一点不仅适用于逻辑陈述，甚至对于那些我们必须当作关于实际问题的经验性陈述也适用。如果“我”做一次旅行，“我”的概念一定自永恒以来就将这次旅行的概念包括在内了，这次旅行就是“我”的谓项。</p><p>19 世纪德国哲学家、唯意志论创始人叔本华，在博士论文《充足理由律的四重根》中给出了莱布尼茨的充足理由律的四种表现形式：</p><blockquote><ol><li>因果关系（Becoming）：生成/变化的充足理由律，适用于<strong>现实对象</strong>；</li><li>逻辑推论（Knowing）：认识的充足理由律，适用于逻辑对象；</li><li>数学证明（Being）：存在的充足理由律，解释时间和空间的必然性；</li><li>行为动机（Willing）：行动的充足理由律，解释动机和行为之间的必然性。</li></ol></blockquote><h3 id="经验主义"><a href="#经验主义" class="headerlink" title="经验主义"></a>经验主义</h3><p>18 世纪，英国经验主义哲学家休谟将因果关系限定在了经验世界的具体对象中，先后在《人性论》和《人类理智研究》中给出了因果关系两个定义：</p><blockquote><p>我们无从得知因果之间的关系，只能得知某些事物总是会连结在一起，而这些事物在过去的经验里又是从不曾分开过的。我们并不能看透连结这些事物背后的理性为何，我们只能观察到这些事物的本身，并且发现这些事物总是透过一种<strong>恒常的连结</strong>而被我们在想像中归类。</p><p align="right">—— 休谟.人性论.1739</p><p>我们可以给一个因下定义说，它是先行于、接近于另一个对象的一个对象，而且在这里，凡与前一个对象类似的一切对象都和与后一个对象类似的那些对象处在类似的先行关系和接近关系中。或者，换言之，<strong>假如没有</strong>前一个对象，那么后一个对象就不可能存在。</p><p align="right">—— 休谟.人类理解研究.1748</p></blockquote><p>在《人性论》中，休谟对因果关系的客观性提出了怀疑，认为我们只能观察到事物本身及其恒常相继发生，并不能观察到事物背后的因果链接。在《人类理解研究》中，休谟提到了反事实推理的必要因，也即“若非因”。</p><h3 id="经典力学"><a href="#经典力学" class="headerlink" title="经典力学"></a>经典力学</h3><p>17 世纪，牛顿创立经典力学之后，决定论占据了所有学科领域的核心：万事万物都被包含在确定性的因果链条之中。法国数学家皮埃尔-西蒙·拉普拉斯在他的概率论导论中说：</p><blockquote><p>我们可以把宇宙现在的状态视为其过去的果以及未来的因，假若一位智者知道在某一时刻所有促使自然运动的力和所有物体的位置，假若他也能够对这些数据进行分析，则在宇宙里，从最大的物体到最小的粒子，它们的运动都包含在一条简单公式里。对于这位智者来说，没有任何事物会是含糊的，并且未来只会像过去般出现在他眼前。 </p></blockquote><p>拉普拉斯这里所说的“智者”（intelligence）便是后人所称的<strong>拉普拉斯妖</strong>。</p><h3 id="概率论"><a href="#概率论" class="headerlink" title="概率论"></a>概率论</h3><p>从赖欣巴哈和萨普斯开始，哲学家们开始使用“概率提高”的概念来定义因果关系：如果 X 提高了 Y 的概率，那么我们就说 X 导致了 Y，即 $P(Y|X) &gt; P(X) =&gt; X \rightarrow Y$。这个概念也存在于我们的直觉中，并且根深蒂固。但是这种解释是错的，因为“提高”是一个因果概念，意味着 X 对 Y 的因果效应。但是，这种概率提高完全可能是其他因素造成的，比如 Y 是 X 的原因，或者其他变量是它们二者的原因。</p><p>18 世纪，一位英国长老会牧师和业余数学家托马斯·贝叶斯（Thomas Bayes），将概率现象解释为<strong>主观信念程度</strong>的变化和更新，让概率本身也失去了客观性。但自 19 世纪中叶起，随着频率学派（经典统计学派）的兴起，贝叶斯解释逐渐被统计学主流所拒绝。现代贝叶斯统计学的复兴肇始于 Jeffreys(1939)，从 1950 年代开始，经过众多统计学家的努力，贝叶斯统计学才逐渐发展壮大。</p><script type="math/tex; mode=display">P(h|D)=P(h)\times \frac{P(D|h)}{P(D)}</script><p>在形式上，贝叶斯定理只是条件概率定义的一个初等推论，但在认识论上，它远远超出了初等的范畴。事实上，它作为一种规范性规则，能够用于<strong>根据证据更新信念</strong>这一重要操作。从许多层面来说，贝叶斯定理都是对科学方法的提炼：1. 提出一个假设 $h$；2. 推断假设的可检验结果；3. 进行实验并收集证据 $D$；4. 更新对假设的信念 $P(h|D)$。</p><p>贝叶斯定理所描述的仍然是“证据”和“假设”之间的相关性，证据所带来的“信念增强”并不意味着“证据”是“假设”的原因。</p><h3 id="统计学"><a href="#统计学" class="headerlink" title="统计学"></a>统计学</h3><p>然而“除了物理学之外，都是集邮”（卢瑟福），纷纷效法物理学的其他自然和社会科学并没有取得想象中确定性的成功。到了19 世纪，统计学创始人高尔顿在研究“遗传均值回归”现象的过程中，以寻找因果关系为起点，最终却发现了相关性 —— 一种无视因果的关系。高尔顿的学生，作为统计学之父的卡尔·皮尔逊，则干脆用相关关系（Correlation）取代了因果关系，认为因果关系只是相关关系的一个特例。</p><blockquote><p>我认为……高尔顿的本意是，存在一个比因果关系更广泛的范畴，即相关性，而因果关系只是被囊括于其中的一个有限的范畴。这种关于相关性的新概念在很大程度上将心理学、人类学、医学和社会学引向了数学处理的领域。</p><p align="right">—— 皮尔逊.1934</p><p>一个特定的事件序列在过去已经发生并且重复发生，这只是一个经验问题，对此我们可以借助因果关系的概念给出其表达式……在任何情况下，科学都不能证明该特定事件序列中存在任何内在的必然性，也不能绝对肯定地证明它必定会重复发生。</p><p align="right">—— 皮尔逊.科学语法.1892</p></blockquote><p>皮尔逊将因果关系从统计学中剔除，取而代之的是相关关系。统计学告诉我们“<strong>相关关系不等于因果关系</strong>”，但并没有告诉我们因果关系是什么。在统计学教科书的索引里查找“因果”这个词是徒劳的。统计学不允许学生们说 X 是 Y 的原因，只允许他们说 X 与 Y “相关”或“存在关联”。统计学唯一关注的是如何总结数据，而不关注如何解释数据。</p><p>继高尔顿和皮尔逊之后，罗纳德·艾尔默·费舍尔成为当时统计学界无可争议的领袖，他简洁地描述了这种差异：</p><blockquote><p>一旦你从统计学中删除因果关系，那么剩下的就只有数据约简了。</p></blockquote><h3 id="量子力学"><a href="#量子力学" class="headerlink" title="量子力学"></a>量子力学</h3><p>进入 20 世纪，就连在物理学中人们也发现了更多不确定性现象。量子力学对微观世界的描述，让很多人确信，世界在根基上就是不确定性的。混沌理论革命则让人们意识到，对复杂系统即使存在确定的关系，也会因为初始敏感导致计算不可约性。</p><p>在这些科学发展的背景下，不确定性完全占据了上风，大多数人认为可能只存在相关性，在科学实践和决策上也广泛采取统计学方法。科学反映客观实在的观念已一去不复返，物理定律也降格为基于某种观测数据拟合的理论模型。</p><h3 id="因果革命"><a href="#因果革命" class="headerlink" title="因果革命"></a>因果革命</h3><p>2020 年 6 月 21 日，在第二届北京智源大会开幕式及全体会议上，图灵奖得主、贝叶斯网络奠基人Judea Pearl 做了名为《The New Science of Cause and Effect with reflections on data science and artificial intelligence》的主题演讲。</p><p align="center"><iframe src="//player.bilibili.com/player.html?aid=328598977&bvid=BV1EA411i76n&cid=204165785&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="50%" height="200%"> </iframe></p><p>在演讲中，Judea Pearl 站在整个数据科学的视角，简单回顾了过去的“大数据革命”，指出数据科学正在从当前以数据为中心的范式向以科学为中心的范式偏移，现在正在发生一场席卷各个研究领域的“因果革命”。</p><blockquote><p>To Build Truly Intelligent Machines, Teach Them Cause and Effect 。</p><p align="right">——Judea Pearl</p></blockquote><p>因果革命和以数据为中心的第一次数据科学革命，也就是大数据革命（涉及机器学习，深度学习机器应用，例如 Alpha-Go、语音识别、机器翻译、自动驾驶等等）的不同之处在于，它以科学为中心，涉及从数据到政策、可解释性、机制的泛化，再到一些社会科学中的基础概念信用、责备和公平性， 甚至哲学中的创造性和自由意志 。可以说， 因果革命彻底改变了科学家处理因果问题的方式。</p><p>Judea Pearl 认为，统计学的其他分支，以及那些依赖统计学工具的学科仍然停留在禁令时代，错误地相信所有科学问题的答案都藏于数据之中，有待巧妙的数据挖掘手段将其揭示出来。因果分析绝不只是针对数据的分析，在因果分析中，我们必须将我们对数据生成过程的理解体现出来，并据此得出初始数据不包含的内容。与相关性分析和大多数主流统计学不同，因果分析要求研究者做出主观判断。研究者必须绘制出一个因果图，其反映的是他对于某个研究课题所涉及的因果过程拓扑结构的定性判断，或者更理想的是，他所属的专业领域的研究者对于该研究课题的共识。为了确保客观性，他反而必须放弃传统的客观性教条。在因果关系方面，睿智的主观性比任何客观性都更能阐明我们所处的这个真实世界。</p><h3 id="因果定义"><a href="#因果定义" class="headerlink" title="因果定义"></a>因果定义</h3><p>数据科学所研究的因果关系是<strong>经验世界中事件之间的因果关系</strong>，正如休谟所言，在经验世界中，我们实际所能观测到的只是事件本身，而无法观测到隐藏在事件背后的“因果机理”，事件间的因果关系本质上是对<strong>事件序列间特定关系</strong>的概括性称谓。目前，一个被广泛接受的因果关系的定义是由 Lazarsfeld（1959）给出的：</p><blockquote><p>如果变量 A 和变量 B 满足以下三个条件，则称 A 和 B 之间存在因果关系“A 导致 B”，其中 A 被称为 B 原因，B 被称为 A 的结果： </p><ol><li>A 在时间上必须先于 B；</li><li>A 和 B 应当在经验上相互关联；</li><li>A 和 B 之间观测到的经验相关不能被第三个导致 A 和 B 两者的变量所解释；</li></ol></blockquote><p>相关性只是因果性的一个必要非充分条件，即“相关性不一定意味着因果性”，A 和 B 相关可能是以下情形的结果：</p><ol><li>A 和 B 都由第三个变量 C 决定：如果通过控制 C，A 和 B 之间的相关性会消失，则说此相关是虚假的（spurious）；比如“是否携带打火机”与“癌症发病率”之间的相关性，本质上是因为抽烟的人通常会携带打火机，并且癌症发病率更高所导致的；</li><li>A 导致 B：我们对干扰变量进行了控制，但我们仍然观测到 A 和 B 之间高度相关；</li><li>B 导致 A：相关性本身并没有告诉我们因果关系的方向；比如“公鸡打鸣”和“太阳升起”有高度相关性，但是统计数据本身并不能告诉我们到底是公鸡打鸣导致了太阳升起，还是太阳升起导致了公鸡打鸣；</li></ol><p>至此，我们已经查勘了因果观念的全景，现在可以对数据科学所涉及到的因果关系概括如下：</p><blockquote><p>在<strong>经验世界</strong>中，我们所能观察到的只是事件（数据）本身，而如果仅凭数据间的关联，我们只能得到事件间的相关性，事件间的因果关系是对<strong>事件序列特定关系</strong>的概括：如果 A 和 B 同时满足以下条件 ① A 在时间上先于 B；② A 和 B 在经验上相关；③ A 和 B 间的相关性不能被其他变量所解释；则称 A 是 B 的原因，或称 A 导致了 B。</p></blockquote><h2 id="因果推断（Causal-Inference）"><a href="#因果推断（Causal-Inference）" class="headerlink" title="因果推断（Causal Inference）"></a>因果推断（Causal Inference）</h2><p>因果推断是研究变量间因果关系的学科，作为一门学科，因果推断目前仍然处于大众视野之外。朱迪亚·珀尔（Judea Pearl） 认为，一旦我们真正理解了因果思维背后的逻辑，就可以在现代计算机上模拟它，进而创造出一个“人工科学家”。这个智能机器人将会为我们发现未知的现象，解开悬而未决的科学之谜，设计新的实验，并不断从环境中提取更多的因果知识。</p><p>关于因果推断的讨论，可以有两个方向：</p><ol><li>考察结果的原因：看到结果，寻找结果背后的原因，这种研究往往是科学的起点，但寻找结果背后的原因，非常复杂。某一种结果产生的原因可能有很多，需要通过详细的调查、深入的分析才能找到。</li><li>考察原因的结果：主要关注某一干预对结果的影响，一项干预对结果变量产生的影响，通常称为因果效应（causal effects）或干预效应（treatment effects）。</li></ol><h3 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h3><p>按照所能回答问题的类型，Judea Pearl 将因果信息划分成了三个层级，其中，高层级信息可以回答低层级问题，但是低层级信息无法回答高层级问题：</p><div class="table-container"><table><thead><tr><th>层级</th><th>任务</th><th>活动</th><th>符号</th><th>问题</th><th>例子</th><th>评价</th></tr></thead><tbody><tr><td>关联</td><td>基于被动观察做出预测</td><td>观察</td><td>$P(Y\mid X)$</td><td>如果观察到X，如何预测Y？</td><td>购买啤酒的用户多大可能会购买尿布？</td><td>好的预测无需好的解释（因果）<br>  当前机器学习/深度学习/统计学几乎完全是在关联层级下，由一系列观察数据拟合出一个函数</td></tr><tr><td>干预</td><td>基于主动干预做出评估</td><td>行动</td><td>$P(Y\mid do(X))$</td><td>如果改变X，Y会怎样？</td><td>如果价格提高两倍，销量会怎么变化？</td><td>预测干预结果的方法是在严格控制的条件下进行实验</td></tr><tr><td>反事实</td><td>通过因果模型做出预测</td><td>想象</td><td>$P(y_x \mid X’,Y’)$</td><td>假如观察到的不是X’，Y会怎样?</td><td>假如过去没有抽烟，现在身体会更好吗？</td><td>﻿预测在尚未经历甚至未曾设想过的情况下会发生什么——这是所有科学的圣杯</td></tr></tbody></table></div><p>Judea Pearl 在《The Book of Why》一书中对以上三种因果层级进行了详细描述，并将其称为“<strong>因果关系之梯</strong>”：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210223114030.png" width="50%" heigh="55%"></img></div><p>Judea Pearl 认为，人类的大脑拥有某种简洁的信息表示方式，同时还拥有某种十分有效的程序用以正确解释每个问题，并从存储的信息表示中提取正确答案，这就是因果图。Judea Pearl 通过一个被他称作“迷你图灵测试”的例子，借助因果图语言介绍了以上三种因果层级之间的差异。</p><p>如下图所示，假设一个犯人将要被执行枪决，这件事的发生必然会以一连串的事件发生为前提：首先，法院方面要下令处决犯人；命令下达到行刑队长后，他将指示行刑队的士兵（A 和 B）执行枪决；我们假设他们是服从命令的专业抢手，只听命令射击，并且只要其中任何一个抢手开了枪，囚犯都必死无疑。借助这个因果图，我们就可以回答来自因果关系之梯不同层级的因果问题了。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210226144947.png" width="27%" heigh="55%"></img></div><p>（1）首先，我们可以回答<strong>关联</strong>问题（一个事实告诉我们有关另一事实的什么信息）。一个可能的问题是，如果犯人死了，那么这是否意味着法院已下令处决犯人？我们（或一台计算机）可以通过核查因果图，追踪每个箭头背后的规则，并根据标准逻辑得出结论：如果没有行刑队队长的命令，两名士兵就不会射击。同样，如果行刑队队长没有接到法院的命令，他就不会发出执行枪决的命令。因此，这个问题的答案是肯定的。另一个可能的问题是，假设我们发现士兵 A 射击了，它告诉了我们关于 B 的什么信息？通过追踪箭头，计算机将断定B一定也射击了。（原因在于，如果行刑队队长没有发出射击命令，士兵A就不会射击，因此接收到同样命令的士兵B也一定射击了。）即使士兵 A 的行为不是士兵 B 做出某一行为的原因（因为从 A 到 B 没有箭头），该判断依然为真。</p><p>（2）沿着因果关系之梯向上攀登，我们可以提出有关<strong>干预</strong>的问题。如果士兵 A 决定按自己的意愿射击，而不等待队长的命令，情况会怎样？犯人会不会死？如果我们希望计算机能理解因果关系，我们就必须教会它如何打破规则，让它懂得“观察到某事件”和“使某事件发生”之间的区别。我们需要告诉计算机：“无论何时，如果你想使某事发生，那就删除指向该事的所有箭头，之后继续根据逻辑规则进行分析，就好像那些箭头从未出现过一样。”如此一来，对于这个问题，我们就需要删除所有指向被干预变量（A）的箭头，并且还要将该变量手动设置为规定值（真）。这种特殊的“外科手术”的基本原理很简单：使某事发生就意味着将它从所有其他影响因子中解放出来，并使它受限于唯一的影响因子——能强制其发生的那个因子。下图表示出了根据这个例子生成的因果图，显然，这种干预会不可避免地导致犯人的死亡，这就是箭头 A 到 D 背后的因果作用。同时，我们还能判断出：B（极有可能）没有开枪，A 的决定不会影响模型中任何不受 A 的行为的影响的其他变量。需要注意的是，仅凭收集大数据无助于我们登上因果关系之梯去回答上面的问题。假设你是一个记者，每天的工作就是记录行刑场中的处决情况，那么你的数据会由两种事件组成：要么所有 5 个变量都为真，要么所有都为假。在未掌握“谁听从于谁”的相关知识的情况下，这种数据根本无法让你（或任何机器学习算法）预测“说服枪手 A 不射击”的结果。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210226145420.png" width="30%" heigh="55%"></img></div><p>（3）最后，为了说明因果关系之梯的第三层级，我们提出一个<strong>反事实</strong>问题。假设犯人现在已倒地身亡，从这一点我们（借助第一层级的知识）可以得出结论：A射击了，B射击了，行刑队队长发出了指令，法院下了判决。但是，假如 A 决定不开枪，犯人是否还活着？这个问题需要我们将现实世界和一个与现实世界相矛盾的虚构世界进行比较。在虚构世界中，A 没有射击，指向 A 的箭头被去除，这进而又解除了 A 与 C 的听命关系。现在，我们将A的值设置为假，并让A行动之前的所有其他变量的水平与现实世界保持一致。如此一来，这一虚构世界就如下图所示。为通过迷你图灵测试，计算机一定会得出这样的结论：在虚构世界里犯人也会死，因为B会开枪击毙他。所以，A勇敢改变主意的做法也救不了犯人的命。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210226150110.png" width="30%" heigh="55%"></img></div><p>看起来，我们刚刚像是花了很大一番力气回答了一些答案显而易见的小问题。的确，因果推理对你来说很容易，其原因在于你是人类，在你还是三岁儿童时，你所拥有的功能神奇的大脑就比任何动物或计算机都更能理解因果关系。“迷你图灵问题”的重点就是要让计算机也能够进行因果推理，而我们能从人类进行因果推断的做法中得到启示。如上述三个例子所示，我们必须教会计算机如何有选择地打破逻辑规则。计算机不擅长打破规则，而这是儿童的强项。</p><h3 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h3><p>用于因果推断的数据来源一般有三种：</p><ol><li>控制实验：对于实验组和控制组，严格控制混淆变量，结果的差异可以归因于原因变量的差异；控制实验对实验条件要求苛刻，一般用于自然科学研究领域；</li><li>随机实验：Fisher 认为我们不必控制其他变量差异，现实中也没有办法完全控制所有的其他变量，只要让随机机制决定干预变量的分配，就可以获得正确的因果效应；随机试验被称为因果推断的黄金标准；</li><li>观察实验：在很多场景下，尤其是在社会科学领域，我们既没有办法实施控制实验，也没有办法实施随机实验，只能获取到被动观察的自然数据；此时，可以通过一些近似手段模拟随机试验过程，进行因果推断；</li></ol><h3 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h3><h3 id="识别策略"><a href="#识别策略" class="headerlink" title="识别策略"></a>识别策略</h3><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>Judea Pearl.The Book of Why: the new science of cause and effect</li><li>赵西亮.基本有用的计量经济学</li><li>罗素.西方哲学史</li><li><a href="https://swarma.org/?p=19906">因果观念新革命？万字长文，解读复杂系统背后的暗因果</a></li><li><a href="https://dl.acm.org/doi/pdf/10.1145/3241036">Judea Pearl.The Seven Tools of Causal Inference, with Reflections on Machine Learning</a></li><li><a href="https://www.sohu.com/a/403958209_99979179">图灵奖得主Judea Pearl：从“大数据革命”到“因果革命”</a></li><li><a href="https://www.bilibili.com/video/av328598977/">Judea Pearl.The New Science of Cause and Effect with reflections on data science and AI 视频</a></li><li><a href="https://publications.mfo.de/handle/mfo/3758">Foundations and new horizons for causal inference 研讨会, 2019</a>（因果推断始于经济和生物统计等学科，它刚刚才开始成为人工智能的一个重要工具，数学基础依旧很零碎，该研讨会聚集了来自人工智能，生物统计学，计算机科学，经济学，流行病学，机器学习，数学和统计学的顶尖研究人员，研讨会上的报告和讨论将有助于在未来几年内塑造和改变这一领域的发展）</li><li>Causality for Machine Learning, Bernhard Schölkopf, 2019（这是一篇刚刚挂 arxiv 就被 Pearl 亲自 twitter 点赞的论文，是马普智能所所长 Bernhard Scholkopf 最引以为傲的论文之一，他将被 Pearl 点赞这事情写在其个人主页自我介绍的第一段中。Scholkopf 及其团队在因果结合机器学习方面做了最多的工作，此文总结和升华了提出了信息革命时代下因果结合机器学习的一般理论和深刻思考）</li><li>A Second Chance to Get Causal Inference Right: A Classification of Data Science Tasks, Miguel A. Hernán, John Hsu &amp;Brian Healy, 2019（来自哈佛教授 Migual A. Hernan 对当前数据科学的深刻反思，澄清了数据科学任务如何分类的基本问题：prediction, deion and counterfactual prediction.）</li><li>Causal Inference and Data-Fusion in Econometrics, P. Hünermund, E. Bareinboim.Dec, 2019.(该论文是因果革命，Pearl 的因果图模型框架如何影响某一个特定领域—计量经济学的范例)</li></ul><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;我们生活在一个相信大数据能够解决所有问题的时代，然而数据远非万能，数据可以告诉你服药的病人比不服药的病人康复得快，却不能告诉你原因何在。也许，那些服药的人只是因为他们支付得起，即使不服用这种药，他们也能恢复得更快。正如 Kendall 和 Stua
      
    
    </summary>
    
      <category term="数据科学" scheme="http://liketea.xyz/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
    
      <category term="数据科学" scheme="http://liketea.xyz/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>数据科学：综述（一）—— 工作内容</title>
    <link href="http://liketea.xyz/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%EF%BC%9A%E7%BB%BC%E8%BF%B0%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%20%E5%B7%A5%E4%BD%9C%E5%86%85%E5%AE%B9/"/>
    <id>http://liketea.xyz/数据科学/数据科学/数据科学：综述（一）—— 工作内容/</id>
    <published>2020-12-28T07:23:53.000Z</published>
    <updated>2021-06-02T10:44:40.924Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文转载自 <a href="https://www.linkedin.com/pulse/one-data-science-job-doesnt-fit-all-elena-grewal/">One Data Science Job Doesn’t Fit All</a></p></blockquote><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/ds.png" width="50%" heigh="80%"></img></div><p>在一家高速增长的公司里，当一名领导者的乐趣之一就是你不仅有机会去改变一些事情 —— 你还必须主动驱动变革以跟上步伐。而在数据科学（DS）这个新的、快速发展的领域工作，我们将同时置身于公司和行业的快速变化之中。</p><p>在 Airbnb，我们把数据看作是用户的声音，我们的目标是让数据科学家最大程度地发挥他们的影响，并对自己的工作充满期待。我们正在朝着这个方向努力，也一直在寻找改进的方法。作为这一演变的一部分，我们最近建立了一个角色定义框架，我希望我们在此过程中学到的知识可以对其他公司在定义数据科学角色方面具有参考意义。</p><p>我要分享的主要结论是：为了满足业务的需求，公司会考虑数据科学工作的三个通道 —— 分析、推断、算法。下面我将描述我们是如何发展到这三条工作通道上的，以及它是如何帮助我们的。</p><h3 id="数据科学家的其他名称"><a href="#数据科学家的其他名称" class="headerlink" title="数据科学家的其他名称"></a>数据科学家的其他名称</h3><p>我们从“分析团队”开始，最初雇用的是“分析专家”。 2012年，我被聘为“数据科学家”。后来，我们聘请了“数据架构师”来处理数据质量，然后聘请了“数据分析专家”来帮助解决数据访问和工具方面的空白。然后，我们看到了机器学习方面的其他需求，因此我们聘请了“机器学习数据科学家”。这些头衔的演变既是对团队需求的反应，也是对竞争格局的反应。我们在2015年成为了“数据科学”部门，尽管我们仍然使用“ A-team”，因为它很有趣并且拥有我们重视的历史。</p><p>当我在2017年中担任数据科学职能部门的负责人时，我们大约有80位数据科学家分布在各个团队中。一些正在构建报表，一些正在构建NLP（自然语言处理）模型，另一些正在构建用于决策和设计实验的模型。</p><h3 id="新兴学科快速发展"><a href="#新兴学科快速发展" class="headerlink" title="新兴学科快速发展"></a>新兴学科快速发展</h3><p>这种变化并不完全出乎意料，数据科学相对较新，而且发展迅速。我们在数据中看到了这一点。首先，从内部来看，我们发现 Airbnb 数据科学角色在2015-2018年间增长了4倍：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201223152729.png" width="50%" heigh="80%"></img></div><p>而且，根据谷歌趋势数据，对数据科学的查询也在增长：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201223152823.png" width="100%" heigh="80%"></img></div><p>数据科学不仅是一个新的领域，人们所说的“数据科学”的含义也千差万别，有时候，这纯粹是机器学习。有时是科技公司的商业智能。它是新的，而且在进化。</p><h3 id="认识到科学技能的多样性"><a href="#认识到科学技能的多样性" class="headerlink" title="认识到科学技能的多样性"></a>认识到科学技能的多样性</h3><p>我们发现人们对数据科学的预期并不明确。在一个给定的公司中，这种多样性的缺点是，它可能导致组织混乱和人员流失，因为合作伙伴团队不知道从数据科学家那里得到什么，而数据科学家自己可能也不清楚他们的角色。那些来自 DS 只做建模的地方的人可能不认为数据科学技能能很好地用于更简单的分析。其他来自 DS 只做分析的地方的人可能会觉得最好让工程师做建模。</p><p>我们还有一个额外的挑战：从事分析工作的团队成员觉得他们的工作没有机器学习工作那么重要，但他们的工作对业务至关重要。业务合作伙伴渴望更具可操作性的见解，以推动决策，并扩展工具以了解数据本身。我们通过我们非常受欢迎的数据大学对数据教育进行了投资，但我们仍然需要专家。我们确定的一个原因是，虽然团队成员是“数据科学”职能的一部分，但我们使用的是“数据分析专家”的头衔，而且我们谈论“数据科学工作”的方式中有一些暗示，给人的印象是，分析工作并不同等重要。</p><p>我与同行公司的领导进行了交谈，以了解其他团队是如何处理这一问题的——有一次，我甚至创建了一个与不同组织结构共享的电子表格。我听说过新的分析团队从零开始创建，团队从机器学习中分离出来，工具团队被整合到数据科学中，等等。</p><p>很明显，没有一刀切的方法，但在定义我们是谁以及如何增加价值方面，具有战略性和有意识的态度将是至关重要的。我们知道我们的目标是“捍卫使命”，即完成公司最需要的工作。因此，我们需要符合当前业务需求的角色，同时也允许个性化和明确的期望。</p><h3 id="解决办法：数据科学工作的三种风味"><a href="#解决办法：数据科学工作的三种风味" class="headerlink" title="解决办法：数据科学工作的三种风味"></a>解决办法：数据科学工作的三种风味</h3><p>我们决定沿着三个方向来重构数据科学，这三个方向描述了我们正在追寻的东西，也是我们想要吸引人才的领域：<br>The Algorithms track would be the home for those with expertise in machine learning, passionate about creating business value by infusing data in our product and processes. And the Inference track would be perfect for our statisticians, economists, and social scientists using statistics to improve our decision making and measure the impact of our work.</p><ol><li>对于那些善于提出好的问题、善于以揭示性的方式探索数据、善于通过报表和可视化工具进行自动分析、善于通过建议来驱动业务变化的人来说，Analytics 通道是理想的选择；</li><li>对于那些在机器学习方面具有专业知识，热衷于通过在我们的产品和流程中注入数据来创造业务价值的人来说，Algorithms 通道将成为他们的家；</li><li>对于我们的统计学家，经济学家和社会科学家来说，Inference 通道将是完美的选择，他们可以使用统计信息来改善我们的决策制定并衡量工作的影响；</li></ol><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201223154936.png" width="80%" heigh="80%"></img></div><p>团队中的每一位数据科学家都应具备这些领域的专业知识，并根据业务需求和自身兴趣获得这些领域的技能。在每一个通道中都可以有进一步的专业化，但是每个人都有“数据科学家”的头衔，然后下面的描述提供了更清晰的描述。</p><p>如果我们看另一门学科，比如工程学，这里有“前端”和“后端”工程学的简写，它可以帮助你了解某人的技能或关注的领域。我意识到这是一个不完美的区别，但它比简单的“工程”更能让人感觉到某人的专业知识。数据科学离这一点还很远；这是我们正在朝着的方向发展。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201223160614.png" width="60%" heigh="80%"></img></div><h3 id="明确预期"><a href="#明确预期" class="headerlink" title="明确预期"></a>明确预期</h3><p>我们还修改了我们的绩效评估标准，以反映我们的新结构。我们有多层次的数据科学家和管理者，我们通过观察对业务的影响来定义成功。对于那些在技术通道上的人，我们修改了我们的评估框架，使之与这些主要领域保持一致。</p><p>技术方面：</p><ol><li>分析：定义并监控指标，创建数据描述，并构建工具来推动决策；</li><li>算法：构建并解释驱动数据产品的算法；</li><li>推理：利用统计数据建立因果关系；</li><li>基础：展示数据质量和代码的所有权和责任（所有通道都需要）；</li></ol><p>业务方面（适用于所有通道）：</p><ol><li>Ownership：能够推动项目取得成功，帮助他人，拥有影响力；</li><li>影响力：清晰沟通，展示团队合作精神，建立人际关系；</li><li>Enrichment：通过指导、文化、招聘和多元化努力促进团队建设；</li></ol><p>我们可以在这里写很多东西，但主要的收获是，我们也明确改变了我们评估绩效的方式，以反映工作的三个方面，并明确了期望。</p><h3 id="何时专业化"><a href="#何时专业化" class="headerlink" title="何时专业化"></a>何时专业化</h3><p>Airbnb 足够大，拥有所有这些区别和细微差别是有意义的。当与那些想知道是否应该用专家组建团队的小公司交谈时，我建议他们从通用性开始。在早期，我们能够处理任何最紧迫的项目，而不是坐在一个僵硬的专业里，这真的很有帮助。随着时间的推移，专业化是有意义的，但最好是从通用开始，除非你能更早地看到它的商业案例。我们直到 2015 年左右才开始专攻，那时我们的团队只有 30 人。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201223171435.png" width="60%" heigh="80%"></img></div><p>我们还希望随着业务需求的变化，继续改变职能部门的角色。</p><h3 id="从中获益"><a href="#从中获益" class="headerlink" title="从中获益"></a>从中获益</h3><p>即使是在我们的专业领域，每个领域的数据科学家也会从事其他类型的工作，我们鼓励团队成员也成为多面手（有时这是一个混乱的问题）。总体而言，进行此更改后，我们所听到的混乱少了很多。我也开始听到合作伙伴说诸如“我们需要具有推理和算法专业知识的人”之类的东西。因此，该语言对于传达业务需求非常有用。</p><p>这有助于我们找出差距。我最近联系了一位产品经理，她表示担心团队没有想出创新的方法来在她富有挑战性的产品领域进行实验。我立刻诊断出了这个问题：在那个特定的数据科学团队中，没有一个具备推理专业知识的人。这是我们下一次招聘时可以解决的问题，或者鼓励团队成员向其他推理专家学习。</p><p>我们很高兴听到从事分析工作的团队成员不再感到疏远或自卑。分析专家了解，如果他们尝试将机器学习应用于他们正在处理的业务问题，那么它们的影响将较小。</p><h3 id="Where-we-go-from-here"><a href="#Where-we-go-from-here" class="headerlink" title="Where we go from here"></a>Where we go from here</h3><p>我希望与大家分享我们的故事，希望其他公司也能采用这个框架！当应聘者带着一个模糊的“数据科学”的名字，这可能意味着很多不同的东西，招聘就变得复杂起来。如果所有公司都使用类似的框架，这将使数据科学作为一个整体更容易传达我们的价值观。</p><p>如果您喜欢这个概念，请告诉您的数据科学领导者，或者如果您是数据科学的领导者，请自己进行更改。或者，如果你有一个更好的模型，我也很乐意听到这个-请伸出援手(data-science-org-ideas@airbnb.com). 考虑到数据科学领域是多么的新和快速发展，最好的命名约定将随着时间的推移而演变。在数据科学领域，我们越能联合起来制定规范，我们的行业就越快成熟，我们作为个人就越有能力驾驭它。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://www.yanxishe.com/TextTranslation/2999">5篇必读的数据科学论文</a></li><li><a href="https://www.linkedin.com/pulse/one-data-science-job-doesnt-fit-all-elena-grewal/">One Data Science Job Doesn’t Fit All</a></li></ul><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本文转载自 &lt;a href=&quot;https://www.linkedin.com/pulse/one-data-science-job-doesnt-fit-all-elena-grewal/&quot;&gt;One Data Science Job Doesn’
      
    
    </summary>
    
      <category term="数据科学" scheme="http://liketea.xyz/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
    
      <category term="数据科学" scheme="http://liketea.xyz/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Spark 指南：Spark 原理（三）—— 内存管理</title>
    <link href="http://liketea.xyz/Spark/Spark/Spark%20%E6%8C%87%E5%8D%97%EF%BC%9ASpark%20%E5%8E%9F%E7%90%86%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"/>
    <id>http://liketea.xyz/Spark/Spark/Spark 指南：Spark 原理（三）—— 内存管理/</id>
    <published>2020-11-14T07:29:53.000Z</published>
    <updated>2021-06-02T10:44:40.913Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>原文最初由 IBM developerWorks 中国网站发表，本文在此基础上进行了总结梳理，仅作为个人学习使用。</p></blockquote><p>Spark 作为一个基于内存的分布式计算引擎，其内存管理模块至关重要。理解 Spark 内存管理的基本原理，有助于更好地开发 Spark 应用程序和性能调优。本文基于 Spark 2.1 版本，旨在梳理 Spark 内存管理的基本脉络。</p><p>在执行 Spark 应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程：</p><ol><li>Driver 为主控进程，主要负责：<ol><li>创建 Spark 上下文；</li><li>提交 Spark 作业（Job）；</li><li>在各 Executor 进程间分配、协调任务（Task）调度；</li></ol></li><li>Executor 主要负责：<ol><li>在工作节点上执行具体的计算任务（Task）；</li><li>将结果返回给 Driver；</li><li>为需要持久化的 RDD 提供存储功能；</li></ol></li></ol><p>由于 Driver 的内存管理相对简单，本文主要对 Executor 的内存管理进行分析，下文中 Spark 内存均指 Executor 内存。</p><h2 id="内存规划"><a href="#内存规划" class="headerlink" title="内存规划"></a>内存规划</h2><p>作为一个 JVM 进程，Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内（On-heap）空间进行了更为详细的分配，以充分利用内存。同时，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210112235829.png" width="100%" heigh="80%"></img></div><h2 id="堆内内存（On-Heap）"><a href="#堆内内存（On-Heap）" class="headerlink" title="堆内内存（On-Heap）"></a>堆内内存（On-Heap）</h2><p>Executor 内运行的并发任务共享 JVM 堆内内存，堆内内存的大小由 Spark 应用程序启动时的 <code>–executor-memory</code> 或 <code>spark.executor.memory</code> 参数配置（默认 1g），Spark 对堆内内存进行了详细的规划：</p><ol><li>统一内存（Unified）：Spark 1.6 之后引入了统一内存管理机制，存储内存和执行内存共享该块空间，可以动态占用对方的空闲区域，统一内存的大小（占堆内内存比例）可以通过 Spark 参数 <code>spark.memory.fraction</code> 来设置（默认 0.6） <ol><li>存储内存（Storage）：在缓存 RDD 或广播（Broadcast）数据时占用的内存被规划为存储内存，存储内存的大小（占统一内存比例）可以通过 Spark 参数 <code>spark.memory.storagefraction</code> 来设置（默认 0.5）；</li><li>执行内存（Execution）：在执行 Shuffle、Join、Sort、Aggregation 等转换时占用的内存被规划为执行内存；</li></ol></li><li>剩余内存（Other）：Spark 内部的对象实例，或者用户定义的 Spark 应用程序中的对象实例，元数据占用剩余内存，Spark 对剩余内存不做特殊规划；</li><li>预留内存（Reserved）：默认 300M 的系统预留内存，主要用于程序运行，参见SPARK-12081；</li></ol><p>总结堆内内存的规划大小计算公式如下：</p><div class="table-container"><table><thead><tr><th>规划项</th><th>计算公式</th><th>默认值</th></tr></thead><tbody><tr><td>堆内内存（On-Heap）</td><td><code>spark.executor.memory</code></td><td>1g</td></tr><tr><td>统一内存（Unified）</td><td><code>spark.executor.memory * spark.memory.fraction</code></td><td>1g * 0.6 = 600M</td></tr><tr><td>存储内存（Storage）</td><td><code>spark.executor.memory * spark.memory.fraction * spark.memory.storagefraction</code></td><td>1g <em> 0.6 </em> 0.5 = 300M</td></tr><tr><td>执行内存（Execution）</td><td><code>spark.executor.memory * spark.memory.fraction * (1 - spark.memory.storagefraction)</code></td><td>1g <em> 0.6 </em> (1-0.5) = 300M</td></tr><tr><td>剩余内存（Other）</td><td><code>spark.executor.memory * (1 - spark.memory.fraction)</code></td><td>1g * (1-0.6) = 400M</td></tr><tr><td>预留内存（Reserved）</td><td>300M</td><td>300M</td></tr></tbody></table></div><p>Spark 对堆内内存的管理只是一种”规划式“的管理，因为对象实例占用内存的申请和释放都由 JVM 完成，Spark 只能在申请和释放前记录这些内存，其具体流程为：</p><ol><li>申请内存：<ol><li>Spark 在代码中创建一个对象实例；</li><li>JVM 从堆内内存分配空间，创建对象并返回对象引用；</li><li>Spark 保存该对象的引用，记录该对象占用的内存；</li></ol></li><li>释放内存：<ol><li>Spark 记录该对象释放的内存，删除该对象的引用；</li><li>等待 JVM 的垃圾回收机制释放该对象占用的堆内内存；</li></ol></li></ol><p>JVM 对象可以以序列化（将对象转化为二进制字节流）的方式存储，本质上可以理解为将非连续的链式存储转化为连续存储，在访问时则需要进行反序列化（将字节流转化为对象），这种方式节省了空间，但是增加了存储和读取的计算开销。对于序列化对象，由于是字节流的形式，其占用的内存大小可以直接计算，而对于非序列化对象，其占用的内存则通过周期采样近似估算，这种方式降低了时间开销但是可能误差较大，导致某一时刻的实际内存有可能远远超出预期。此外，在被 Spark 标记为释放的对象实例，很有可能在实际上并没有被 JVM 回收，导致实际可用的内存小于 Spark 记录的可用内存。所以 Spark 并不能准确记录实际可用的堆内内存，从而也就无法完全避免内存溢出（OOM, Out of Memory）的异常。</p><h3 id="统一内存管理"><a href="#统一内存管理" class="headerlink" title="统一内存管理"></a>统一内存管理</h3><p>Spark 1.6 之后引入了统一内存管理机制，存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域，如图所示：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/memory_0114.png" width="100%" heigh="80%"></img></div><p>统一内存的动态占用机制：</p><ol><li>当存储内存和执行内存都不足时，则存储到磁盘；当己方空间不足而对方空间空余时，可借用对方空间；</li><li>执行内存被存储占用时，可以让对方将占用的部分转存到硬盘，归还借用的空间；</li><li>存储内存被执行占用时，无法让对方归还，因为考虑 Shuffle 过程的很多因素，不好实现；</li></ol><p>凭借统一内存管理机制，Spark 在一定程度上提高了堆内和堆外内存资源的利用率，降低了开发者维护 Spark 内存的难度，但并不意味着开发者可以高枕无忧。譬如，所以如果存储内存的空间太大或者说缓存的数据过多，反而会导致频繁的全量垃圾回收，降低任务执行时的性能，因为缓存的 RDD 数据通常都是长期驻留内存的。所以要想充分发挥 Spark 的性能，需要开发者进一步了解存储内存和执行内存各自的管理方式和实现原理。</p><h3 id="存储内存管理"><a href="#存储内存管理" class="headerlink" title="存储内存管理"></a>存储内存管理</h3><h4 id="RDD-持久化机制"><a href="#RDD-持久化机制" class="headerlink" title="RDD 持久化机制"></a>RDD 持久化机制</h4><p>弹性分布式数据集（RDD）作为 Spark 最根本的数据抽象，是只读的分区记录（Partition）的集合，只能基于在稳定物理存储中的数据集上创建，或者在其他已有的 RDD 上执行转换（Transformation）操作产生一个新的 RDD。转换后的 RDD 与原始的 RDD 之间产生的依赖关系，构成了血统（Lineage）。凭借血统，Spark 保证了每一个 RDD 都可以被重新恢复。但 RDD 的所有转换都是惰性的，即只有当一个返回结果给 Driver 的行动（Action）发生时，Spark 才会创建任务读取 RDD，然后真正触发转换的执行。</p><p>Task 在启动之初读取一个分区时，会先判断这个分区是否已经被持久化，如果没有则需要检查 Checkpoint 或按照血统重新计算。所以如果一个 RDD 上要执行多次 Action，可以在第一次 Action 中使用 persist 或 cache 方法，在内存或磁盘中持久化或缓存这个 RDD，从而在后面的行动时提升计算速度。事实上，cache 方法是使用默认的 MEMORY_ONLY 的存储级别将 RDD 持久化到内存，故缓存是一种特殊的持久化。 堆内和堆外存储内存的设计，便可以对缓存 RDD 时使用的内存做统一的规划和管理。</p><p>RDD 的持久化由 Spark 的 Storage 模块负责，实现了 RDD 与物理存储的解耦合。Storage 模块负责管理 Spark 在计算过程中产生的数据，将那些在内存或磁盘、在本地或远程存取数据的功能封装了起来。在具体实现时 Driver 端和 Executor 端的 Storage 模块构成了主从式的架构，即 Driver 端的 BlockManager 为 Master，Executor 端的 BlockManager 为 Slave。Storage 模块在逻辑上以 Block 为基本存储单位，RDD 的每个 Partition 经过处理后唯一对应一个 Block（BlockId 的格式为 rdd_RDD-ID_PARTITION-ID ）。Master 负责整个 Spark 应用程序的 Block 的元数据信息的管理和维护，而 Slave 需要将 Block 的更新等状态上报到 Master，同时接收 Master 的命令，例如新增或删除一个 RDD。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/202101151555.png" width="60%" heigh="80%"></img></div><p>在对 RDD 持久化时，Spark 规定了 MEMORY_ONLY、MEMORY_AND_DISK 等 7 种不同的 <a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html">存储级别</a> ，而存储级别是以下 5 个变量的组合：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JAVA"><figure class="iseeu highlight /java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StorageLevel</span> <span class="title">private</span>(</span></span><br><span class="line"><span class="class">    <span class="title">private</span> <span class="title">var</span> <span class="title">_useDisk</span>: <span class="title">Boolean</span>,      // 磁盘</span></span><br><span class="line"><span class="class">    <span class="title">private</span> <span class="title">var</span> <span class="title">_useMemory</span>: <span class="title">Boolean</span>,    // 堆内内存</span></span><br><span class="line"><span class="class">    <span class="title">private</span> <span class="title">var</span> <span class="title">_useOffHeap</span>: <span class="title">Boolean</span>,   // 堆外内存</span></span><br><span class="line"><span class="class">    <span class="title">private</span> <span class="title">var</span> <span class="title">_deserialized</span>: <span class="title">Boolean</span>, // 是否为非序列化</span></span><br><span class="line"><span class="class">    <span class="title">private</span> <span class="title">var</span> <span class="title">_replication</span>: <span class="title">Int</span> </span>= <span class="number">1</span>   <span class="comment">// 副本个数</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></div><p>通过对数据结构的分析，可以看出存储级别从三个维度定义了 RDD 的 Partition（同时也就是 Block）的存储方式：</p><ol><li>存储位置：磁盘／堆内内存／堆外内存。如 MEMORY_AND_DISK 是同时在磁盘和堆内内存上存储，实现了冗余备份。OFF_HEAP 则是只在堆外内存存储，目前选择堆外内存时不能同时存储到其他位置；</li><li>存储形式：Block 缓存到存储内存后，是否为非序列化的形式。如 MEMORY_ONLY 是非序列化方式存储，OFF_HEAP 是序列化方式存储；</li><li>副本数量：大于 1 时需要远程冗余备份到其他节点。如 DISK_ONLY_2 需要远程备份 1 个副本；</li></ol><h4 id="RDD-缓存过程"><a href="#RDD-缓存过程" class="headerlink" title="RDD 缓存过程"></a>RDD 缓存过程</h4><p>RDD 缓存的过程是将对象从 other 内存区迁移至 Storage 区或 Disk 的过程：</p><ol><li>RDD 在缓存到存储内存之前：Partition 中的数据一般以迭代器（Iterator）的数据结构来访问，这是 Scala 语言中一种遍历数据集合的方法。通过 Iterator 可以获取分区中每一条序列化或者非序列化的数据项(Record)，这些 Record 的对象实例在逻辑上占用了 JVM 堆内内存的 other 部分的空间，同一 Partition 的不同 Record 的空间并不连续；</li><li>RDD 在缓存到存储内存之后：Partition 被转换成 Block，Record 在堆内或堆外存储内存中占用一块连续的空间，当存储空间不足时会根据动态占用机制进行处理。将 Partition 由不连续的存储空间转换为连续存储空间的过程，Spark 称之为”展开”（Unroll）。Block 有序列化和非序列化两种存储格式，具体以哪种方式取决于该 RDD 的存储级别<ol><li>非序列化的 Block 以一种 DeserializedMemoryEntry 的数据结构定义，用一个数组存储所有的对象实例；</li><li>序列化的 Block 则以 SerializedMemoryEntry的数据结构定义，用字节缓冲区（ByteBuffer）来存储二进制数据。每个 Executor 的 Storage 模块用一个链式 Map 结构（LinkedHashMap）来管理堆内和堆外存储内存中所有的 Block 对象的实例[6]，对这个 LinkedHashMap 新增和删除间接记录了内存的申请和释放；</li></ol></li></ol><p>因为不能保证存储空间可以一次容纳 Iterator 中的所有数据，当前的计算任务在 Unroll 时要向 MemoryManager 申请足够的 Unroll 空间来临时占位，空间不足则 Unroll 失败，空间足够时可以继续进行。对于序列化的 Partition，其所需的 Unroll 空间可以直接累加计算，一次申请。而非序列化的 Partition 则要在遍历 Record 的过程中依次申请，即每读取一条 Record，采样估算其所需的 Unroll 空间并进行申请，空间不足时可以中断，释放已占用的 Unroll 空间。如果最终 Unroll 成功，当前 Partition 所占用的 Unroll 空间被转换为正常的缓存 RDD 的存储空间，如下图所示：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/spark_unroll.png" width="70%" heigh="80%"></img></div><h4 id="淘汰和落盘"><a href="#淘汰和落盘" class="headerlink" title="淘汰和落盘"></a>淘汰和落盘</h4><p>由于同一个 Executor 的所有的计算任务共享有限的存储内存空间，当有新的 Block 需要缓存但是剩余内存空间不足且无法动态占用时，就要对 LinkedHashMap 中的旧 Block 进行淘汰（Eviction），而被淘汰的 Block 如果其存储级别中同时包含存储到磁盘的要求，则要对其进行落盘（Drop），否则直接删除该 Block。</p><p>存储内存的淘汰规则为：</p><ol><li>被淘汰的旧 Block 要与新 Block 的 MemoryMode 相同，即同属于堆外或堆内内存；</li><li>新旧 Block 不能属于同一个 RDD，避免循环淘汰；</li><li>旧 Block 所属 RDD 不能处于被读状态，避免引发一致性问题；</li><li>遍历 LinkedHashMap 中 Block，按照最近最少使用（LRU）的顺序淘汰，直到满足新 Block 所需的空间。其中 LRU 是 LinkedHashMap 的特性；</li></ol><p>存储内存的落盘规则为：如果其存储级别符合 <code>_useDisk</code> 为 true 的条件，再根据其<code>_deserialized</code> 判断是否是非序列化的形式，若是则对其进行序列化，最后将数据存储到磁盘，在 Storage 模块中更新其信息。</p><h3 id="执行内存管理"><a href="#执行内存管理" class="headerlink" title="执行内存管理"></a>执行内存管理</h3><h4 id="多任务间内存分配"><a href="#多任务间内存分配" class="headerlink" title="多任务间内存分配"></a>多任务间内存分配</h4><p>Executor 内运行的任务同样共享执行内存，Spark 用一个 HashMap 结构保存了任务到内存耗费的映射。每个任务可占用的执行内存大小的范围为 1/2N ~ 1/N，其中 N 为当前 Executor 内正在运行的任务的个数。每个任务在启动之时，要向 MemoryManager 请求申请最少为 1/2N 的执行内存，如果不能被满足要求则该任务被<strong>阻塞</strong>，直到有其他任务释放了足够的执行内存，该任务才可以被唤醒。</p><h4 id="Shuffle-内存占用"><a href="#Shuffle-内存占用" class="headerlink" title="Shuffle 内存占用"></a>Shuffle 内存占用</h4><p>执行内存主要用来存储任务在执行 Shuffle 时占用的内存，Shuffle 是按照一定规则对 RDD 数据重新分区的过程，我们来看 Shuffle 的 Write 和 Read 两阶段对执行内存的使用：</p><ol><li>Shuffle Write<ol><li>若在 map 端选择普通的排序方式，会采用 ExternalSorter 进行外排，在内存中存储数据时主要占用堆内执行空间；</li><li>若在 map 端选择 Tungsten 的排序方式，则采用 ShuffleExternalSorter 直接对以序列化形式存储的数据排序，在内存中存储数据时可以占用堆外或堆内执行空间，取决于用户是否开启了堆外内存以及堆外执行内存是否足够；</li></ol></li><li>Shuffle Read<ol><li>在对 reduce 端的数据进行聚合时，要将数据交给 Aggregator 处理，在内存中存储数据时占用堆内执行空间；</li><li>如果需要进行最终结果排序，则要再次将数据交给 ExternalSorter 处理，占用堆内执行空间；</li></ol></li></ol><p>在 ExternalSorter 和 Aggregator 中，Spark 会使用一种叫 AppendOnlyMap 的哈希表在堆内执行内存中存储数据，但在 Shuffle 过程中所有数据并不能都保存到该哈希表中，当这个哈希表占用的内存会进行周期性地采样估算，当其大到一定程度，无法再从 MemoryManager 申请到新的执行内存时，Spark 就会将其全部内容存储到磁盘文件中，这个过程被称为溢存(Spill)，溢存到磁盘的文件最后会被归并(Merge)。</p><p>Shuffle Write 阶段中用到的 Tungsten 是 Databricks 公司提出的对 Spark 优化内存和 CPU 使用的计划，解决了一些 JVM 在性能上的限制和弊端。Spark 会根据 Shuffle 的情况来自动选择是否采用 Tungsten 排序。Tungsten 采用的页式内存管理机制建立在 MemoryManager 之上，即 Tungsten 对执行内存的使用进行了一步的抽象，这样在 Shuffle 过程中无需关心数据具体存储在堆内还是堆外。每个内存页用一个 MemoryBlock 来定义，并用 Object obj 和 long offset 这两个变量统一标识一个内存页在系统内存中的地址。堆内的 MemoryBlock 是以 long 型数组的形式分配的内存，其 obj 的值为是这个数组的对象引用，offset 是 long 型数组的在 JVM 中的初始偏移地址，两者配合使用可以定位这个数组在堆内的绝对地址；堆外的 MemoryBlock 是直接申请到的内存块，其 obj 为 null，offset 是这个内存块在系统内存中的 64 位绝对地址。Spark 用 MemoryBlock 巧妙地将堆内和堆外内存页统一抽象封装，并用页表(pageTable)管理每个 Task 申请到的内存页。Tungsten 页式管理下的所有内存用 64 位的逻辑地址表示，由页号和页内偏移量组成：</p><ol><li>页号：占 13 位，唯一标识一个内存页，Spark 在申请内存页之前要先申请空闲页号。</li><li>页内偏移量：占 51 位，是在使用内存页存储数据时，数据在页内的偏移地址。</li></ol><p>有了统一的寻址方式，Spark 可以用 64 位逻辑地址的指针定位到堆内或堆外的内存，整个 Shuffle Write 排序的过程只需要对指针进行排序，并且无需反序列化，整个过程非常高效，对于内存访问效率和 CPU 使用效率带来了明显的提升。</p><p>Spark 的存储内存和执行内存有着截然不同的管理方式：对于存储内存来说，Spark 用一个 LinkedHashMap 来集中管理所有的 Block，Block 由需要缓存的 RDD 的 Partition 转化而成；而对于执行内存，Spark 用 AppendOnlyMap 来存储 Shuffle 过程中的数据，在 Tungsten 排序中甚至抽象成为页式内存管理，开辟了全新的 JVM 内存管理机制。</p><h2 id="堆外内存（Off-Heap）"><a href="#堆外内存（Off-Heap）" class="headerlink" title="堆外内存（Off-Heap）"></a>堆外内存（Off-Heap）</h2><p>为了进一步优化内存的使用以及提高 Shuffle 时排序的效率，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，存储经过序列化的二进制数据。利用 JDK Unsafe API（从 Spark 2.0 开始，在管理堆外的存储内存时不再基于 Tachyon，而是与堆外的执行内存一样，基于 JDK Unsafe API 实现），Spark 可以直接操作系统堆外内存，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。堆外内存可以被精确地申请和释放，而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说降低了管理的难度，也降低了误差。</p><p>在默认情况下堆外内存并不启用，可通过配置 <code>spark.memory.offHeap.enabled</code> 参数启用，并由 <code>spark.memory.offHeap.size</code> 参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存。</p><h2 id="运行实例"><a href="#运行实例" class="headerlink" title="运行实例"></a>运行实例</h2><p>假设 Spark 应用程序运行参数设置如下：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/202101152046.png" width="100%" heigh="80%"></img></div><p>Spark 应用程序运行过程中，我们可以在 Web UI -&gt; Executors 中查看 Excutor 内存实际使用大小/内存规划大小：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20212051.png" width="100%" heigh="80%"></img></div><p>从该实例可以看出 Executor 的统一内存为 5.9G，与理论计算出来的值相近（10G * 0.6 = 6G），存储内存为 5.8 G，动态占用机制使得存储内存占用了绝大部分统一内存，导致只有很少的内存用于 Shuffle，这也是影响本任务执行效率的关键问题。此外，Driver 的内存基本没有被存储占用，有充足的内存可以用于执行 Spark 程序，可以适当减少 Driver 端内存分配。</p><p>进一步考察存储内存占用过高的原因，可以看到该程序缓存了非常大的中间结果，可以选择把缓存数据全部存储到磁盘，在这个场景下不会对缓存过程有太大影响，却可以保证充足的执行内存：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/affdssgg.png" width="100%" heigh="80%"></img></div><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://developer.ibm.com/zh/articles/ba-cn-apache-spark-memory-management/">Apache Spark 内存管理详解</a><br><a href="https://spark.apache.org/docs/latest/configuration.html">Spark 配置</a><br><a href="https://blog.csdn.net/suifeng3051/article/details/45477773">yarn 资源管理参数设置</a><br><a href="https://my.oschina.net/cutexim/blog/4416369">Spark 性能优化指南(官网文档)</a></p><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;原文最初由 IBM developerWorks 中国网站发表，本文在此基础上进行了总结梳理，仅作为个人学习使用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Spark 作为一个基于内存的分布式计算引擎，其内存管理模块至关重要。理解 Spark 内
      
    
    </summary>
    
      <category term="Spark" scheme="http://liketea.xyz/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://liketea.xyz/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark 指南：Spark 原理（二）—— Partition 和 Shuffle</title>
    <link href="http://liketea.xyz/Spark/Spark/Spark%20%E6%8C%87%E5%8D%97%EF%BC%9ASpark%20%E5%8E%9F%E7%90%86%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%20partition%20%E5%92%8C%20Shuffle/"/>
    <id>http://liketea.xyz/Spark/Spark/Spark 指南：Spark 原理（二）—— partition 和 Shuffle/</id>
    <published>2020-11-13T07:29:53.000Z</published>
    <updated>2021-08-19T10:14:46.984Z</updated>
    
    <content type="html"><![CDATA[<div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210328183846.png" width="80%" heigh="55%"></img></div><h2 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h2><p>分区（Partition）是控制 RDD 在各节点上分布情况的高级特性，RDD 的存储和计算都是基于分区来进行的。为分布式数据集选择正确的分区方式和为本地数据选择合适的数据结构很相似 —— 数据分布都会极其明显地影响程序的性能。有时使用可控的分区方式把常被一起访问的数据放到同一个节点上，可以大大减少应用的通信开销，带来明显的性能提升。</p><h3 id="分区的特性"><a href="#分区的特性" class="headerlink" title="分区的特性"></a>分区的特性</h3><p>RDD、分区、TASK、节点、核之间的关系：</p><ol><li>一个 RDD 会被划分为一个或多个分区；</li><li>这些分区会被保存到多个节点，每个节点可能存储一个或多个分区，但是一个分区只能位于同一个节点，不能跨节点保存，分区是决定 RDD 分布的最小单位；</li><li>RDD 的分区数是可以配置的，默认会等于所有 executor 的核数；</li><li>Spark 会为每个分区分配一个 TASK，每个核一次处理一个 TASK；</li></ol><h3 id="默认分区"><a href="#默认分区" class="headerlink" title="默认分区"></a>默认分区</h3><p>RDD 创建方式不同，会产生不同的默认分区行为。比如，从 HDFS 中读取文件来创建 RDD 和通过一个 RDD 转换操作生成另一个新的 RDD 的分区行为是不同的。</p><ul><li>分布式化一个本地数据集：</li></ul><div class="table-container"><table><thead><tr><th>调用 API</th><th>默认分区数</th><th>分区器类</th></tr></thead><tbody><tr><td><code>sc.parallelize(...)</code></td><td><code>sc.defaultParallelism</code></td><td>无</td></tr></tbody></table></div><ul><li>从 HDFS 读取数据：</li></ul><div class="table-container"><table><thead><tr><th>调用 API</th><th>默认分区数</th><th>分区器类</th></tr></thead><tbody><tr><td><code>sc.textFile(...)</code></td><td><code>sc.defaultParallelism</code> 和文件 block 数中较大值</td><td>无</td></tr></tbody></table></div><ul><li>转换操作：由于 map、flatMap 操作结果可能会改变原 RDD 的 KEY，结果 RDD 会丢失分区器，如果希望继承父 RDD，可以使用 mapValues、flatMapValues，后两者会针对于 (K,V) 形式的类型只对 V 进行操作 </li></ul><div class="table-container"><table><thead><tr><th>调用 API</th><th>默认分区数</th><th>分区器类</th></tr></thead><tbody><tr><td>filter,map,flatMap,distinct</td><td>同父 RDD</td><td>filter同父 RDD，其他无分区器</td></tr><tr><td>mapValues, flatMapValues</td><td>同父 RDD</td><td>同父 RDD</td></tr><tr><td>union</td><td>union 的两个 RDD 分区数之和</td><td>无</td></tr><tr><td>subtract</td><td>同第一个RDD</td><td>无</td></tr><tr><td>cartesian</td><td>两个 RDD 分区数乘积</td><td>无</td></tr></tbody></table></div><ul><li>聚合操作：</li></ul><div class="table-container"><table><thead><tr><th>调用 API</th><th>默认分区数</th><th>分区器类</th></tr></thead><tbody><tr><td>reduceByKey,foldByKey,combineByKey</td><td>同父 RDD</td><td>HashPartitioner</td></tr><tr><td>sortByKey</td><td>同父 RDD</td><td>RangePartitioner</td></tr><tr><td>cogroup,groupByKey,join,leftOuterJoin,rightOuterJoin</td><td>取决于 RDD 的输入属性</td><td>HashPartitioner</td></tr></tbody></table></div><h3 id="分区器"><a href="#分区器" class="headerlink" title="分区器"></a>分区器</h3><p>Partitioner（分区器）定义了 RDD 的分区分布，决定了一个 RDD 可以被分成多少个分区，以及每个分区的数据量有多大，进而决定了每个 Task 将处理哪些数据。一般来说，分区器是针对 key-value 值 RDD 的，并通过对 key 的运算来划分分区，非 key-value 形式的 RDD 无法根据数据特征来进行分区，也就没有设置分区器，此时 Spark 会把数据均匀的分配到执行节点上。</p><p>目前的版本提供了三种分区器:</p><ol><li>HashPartitioner（哈希分区器）: HashPartitioner 是基于 Java 的 <code>Object.hashCode</code> 来实现的分区器，根据 <code>Object.hashCode</code> 来对 key 进行计算得到一个整数，再通过公式<code>Object.hashCode % numPartitions</code> 计算某个 key 该分到哪个分区，当 RDD 没有 Partitioner 时，会把 HashPartitioner 作为默认的 Partitioner；</li><li>RangePartitioner（范围分区器）: RangePartitioner 将 key 位于相同范围内的记录分配给给定分区，排序需要 RangePartitioner，因为 RangePartitioner 能够确保通过对给定分区内的记录进行排序，最终完成整个RDD的排序；</li><li>自定义分区器: 通过继承 Partitioner 抽象类，可以定制自己的分区器；</li></ol><h3 id="获取分区"><a href="#获取分区" class="headerlink" title="获取分区"></a>获取分区</h3><p>在 Scala 和 Java 中，你可以使用 RDD 的 partitioner 属性（Java 中使用 partitioner() 方法）来获取 RDD 的分区方式。它会返回一个 scala.Option 对象，这是 Scala 中用来存放可能存在的对象的容器类。你可以对这个 Option 对象调用 isDefined() 来检查其中是否有值，调用 get() 来获取其中的值。如果存在值的话，这个值会是一个 spark.Partitioner 对象。这本质上是一个告诉我们 RDD 中各个键分别属于哪个分区的函数。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pairs.groupByKey().partitioner.get</span><br><span class="line">res8: org.apache.spark.<span class="type">Partitioner</span> = org.apache.spark.<span class="type">HashPartitioner</span><span class="meta">@c</span></span><br></pre></td></tr></table></figure></div><h3 id="设置分区"><a href="#设置分区" class="headerlink" title="设置分区"></a>设置分区</h3><p>有三种方式可以用于设置 RDD 的分区数，但要注意，若改变分区数量或分区器通常会导致 Shuffle 操作，务必在调整分区后进行缓存：</p><ul><li>调用 <code>partitionBy</code> 方法：下面代码，我们自定义了一个分区器，并根据自定义的分区器对 RDD 进行重新分区，需要特别注意的是，在每次调用 <code>partitionBy</code> 之后，务必对结果进行缓存，否则后续每次惰性执行时都会重新执行分区动作，严重影响程序性能；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JAVA"><figure class="iseeu highlight /java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="function">Partitioner</span></span><br><span class="line"><span class="function">class <span class="title">CustTwoPartitioner</span><span class="params">(override val numPartitions: Int)</span> extends Partitioner </span>&#123;</span><br><span class="line">    <span class="function">def <span class="title">getPartition</span><span class="params">(key: Any)</span>: Int </span>= key match &#123;</span><br><span class="line">        <span class="keyword">case</span> s: String =&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> (s(<span class="number">0</span>).toUpper &gt; <span class="string">&#x27;C&#x27;</span>) <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        &#125;   </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> x = sc.parallelize(Array((<span class="string">&quot;aa&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;bb&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;cc&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;dd&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;ee&quot;</span>,<span class="number">1</span>)), <span class="number">3</span>)</span><br><span class="line"><span class="keyword">var</span> y = x.partitionBy(<span class="keyword">new</span> CustTwoPartitioner(<span class="number">2</span>)).persist()</span><br></pre></td></tr></table></figure></div><ul><li>通过转换操作返回带有特定分区的 RDD：这部分（读取数据源、转换继承）在上面默认分区器部分已讲过；</li><li>调用 <code>repartition</code> 或 <code>coalesec</code> 方法：<ul><li><code>coalesce(numPartitions: Int, shuffle: Boolean = false)</code>：对 RDD 进行重分区，使用 HashPartitioner，第一个参数为重分区的数目，第二个为是否进行 shuffle，默认为false（此时是合并分区，父 RDD 和子 RDD 是窄依赖，不会产生 Shuffle）；如果重分区的数目大于原来的分区数，那么必须指定 shuffle 参数为 true；</li><li><code>repartition(numPartitions: Int, partitionExprs: Column*)</code>：repartition 是 coalesce shuffle 参数为 true 的简易实现，返回一个按 partitionExprs 将原 RDD 划分为 numPartitions 个分区的新 RDD，过程中会发生 Shuffle，父 RDD 和子 RDD 之间构成宽依赖；</li></ul></li></ul><p>分区并不是对所有应用都有好处的，如果给定 RDD 只需要被扫描一次，我们完全没有必要对其预先进行分区处理，只有当数据集多次在诸如 JOIN 这种基于键的操作中使用时，分区才会有帮助。</p><h2 id="Shuffle"><a href="#Shuffle" class="headerlink" title="Shuffle"></a>Shuffle</h2><h3 id="Shuffle-定义"><a href="#Shuffle-定义" class="headerlink" title="Shuffle 定义"></a>Shuffle 定义</h3><p>你永远不会调用一个名为 shuffle 的方法，但是有很多方法会导致 shuffle 的发生，比如在 RDD 上调用 <code>groupByKey()</code> 方法时，会返回一个 <code>ShuffledRDD</code>：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> pairs = sc.parallelize(<span class="type">List</span>((<span class="number">1</span>, <span class="string">&quot;one&quot;</span>), (<span class="number">2</span>, <span class="string">&quot;two&quot;</span>), (<span class="number">3</span>, <span class="string">&quot;three&quot;</span>)))</span><br><span class="line">pairs.groupByKey()</span><br><span class="line"></span><br><span class="line">pairs: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">35</span></span><br><span class="line">res1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">Iterable</span>[<span class="type">String</span>])] = <span class="type">ShuffledRDD</span>[<span class="number">1</span>] at groupByKey at &lt;console&gt;:<span class="number">38</span></span><br></pre></td></tr></table></figure></div><p>要执行分布式 groupByKey 操作，我们通常必须在节点之间移动数据，以便数据可以按照它的 KEY 收集到单个机器上：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210326203725.png" width="80%" heigh="55%"></img></div><p><strong>数据通过网络在节点之间移动的过程</strong>，称为 Shuffle（洗牌或混洗）。</p><h3 id="Shuffle-过程"><a href="#Shuffle-过程" class="headerlink" title="Shuffle 过程"></a>Shuffle 过程</h3><p>以 Shuffle 为边界，Spark 将一个 Job 划分为不同的 Stage，这些 Stage 构成了一个大粒度的 DAG。Spark 的 Shuffle 过程分为 Write 和 Read 两个阶段，分属于两个不同的 Stage，前者是 Parent Stage 的最后一步，后者是 Child Stage 的第一步，如下图所示:</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210328184256.png" width="80%" heigh="55%"></img></div><p>Shuffle 过程首先会将前置 Stage 的 Map Task 结果写入本地磁盘（Shuffle Write），然后后续 Stage 的 reduce Task 再从磁盘中读取这些文件（Shuffle Read）来执行计算，这有两点好处：</p><ol><li>将 Shuffle 文件写入磁盘（称为 Shuffle 持久化），使得 Spark 能够在时间上串行地执行不同的 Stage；</li><li>出现故障时，只需要重启 Reduce Task ，而不用重新运行所有的任务。</li></ol><p>Spark 在 Shuffle 的实现上做了很多优化改进，Spark Shuffle 的演进过程如下（最早实现是 Hash Based Shuffle，2.0 以后就只有 Sort Based Shuffle 了）：</p><ul><li>Spark 0.8及以前 <strong>Hash Based Shuffle</strong></li><li>Spark 0.8.1 为 Hash Based Shuffle 引入 File Consolidation机制</li><li>Spark 0.9 引入 ExternalAppendOnlyMap</li><li>Spark 1.1 引入 Sort Based Shuffle，但默认仍为Hash Based Shuffle</li><li>Spark 1.2 默认的 Shuffle 方式改为 Sort Based Shuffle</li><li>Spark 1.4 引入 Tungsten-Sort Based Shuffle</li><li>Spark 1.6 Tungsten-sort 并入 <strong>Sort Based Shuffle</strong></li><li>Spark 2.0 Hash Based Shuffle 退出历史舞台</li></ul><h4 id="Hash-Based-Shuffle"><a href="#Hash-Based-Shuffle" class="headerlink" title="Hash Based Shuffle"></a>Hash Based Shuffle</h4><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210328183145.png" width="80%" heigh="55%"></img></div><p>Hash Based Shuffle 的基本流程：</p><ol><li>Shuffle Write: 每个 Map Task 将计算结果数据分成多份（bucket），每一份对应到下游 stage 的每个 Partition 中，写入当前节点的本地磁盘，bucket 的数量就是 $M\times R$，这样会产生大量的小文件，对文件系统压力很大，而且不利于 IO 吞吐量，后面 Spark 做了优化，把在统一 Core 上运行的多个 Mapper 输出合并到同一个文件，这样 bucket 的数量就是 $Cores\times R$；</li><li>Shuffle Read: 每个 Reduce Task 通过网络拉取属于当前任务的 bucket 数据，根据数据的 Key 进行聚合，然后判断是否需要排序，最后生成新的 RDD；</li></ol><h4 id="Sort-Based-Shuffle"><a href="#Sort-Based-Shuffle" class="headerlink" title="Sort Based Shuffle"></a>Sort Based Shuffle</h4><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210328192155.png" width="80%" heigh="55%"></img></div><p>Sort Based Shuffle 的基本流程：</p><ol><li>Shuffle Write: 不会为每个 Reduce Task 生成一个单独的文件，相反会把每个 Map Task 的结果数据写到一个 <strong>Data 文件</strong>中，并使用 <strong>Index 文件</strong>存储具体 Map Task 输出数据在同一个 Data 文件中是如何分类的信息；Shuffle Write 过程对每个 Map Task 生成两个文件 —— Data 文件和 Index 文件，因此生成的总文件数为 2M；Shuffle Write 阶段会按照 Reduce Task 的 PartitionId 和记录本身的 Key 进行排序，方便 Reducer 获取数据；</li><li>Shuffle Read: Reduce Task 首先找 Driver 获取每个 Map Task 输出的位置信息，根据位置信息获取 Index 文件，解析 Index 文件获取 Data 文件中属于自己的那部分数据；</li></ol><h3 id="Shuffle-规避"><a href="#Shuffle-规避" class="headerlink" title="Shuffle 规避"></a>Shuffle 规避</h3><p>和内存计算相比，网络通信和磁盘读写是非常耗时的过程，会严重影响程序执行效率，因此如非必要，应该尽可能避免数据 Shuffle。</p><h2 id="宽窄依赖"><a href="#宽窄依赖" class="headerlink" title="宽窄依赖"></a>宽窄依赖</h2><h3 id="宽窄依赖定义"><a href="#宽窄依赖定义" class="headerlink" title="宽窄依赖定义"></a>宽窄依赖定义</h3><p>为了更好地理解什么时候可能发生 Shuffle，我们需要先看看 RDD 是如何表示的：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210329151036.png" width="80%" heigh="55%"></img></div><p>RDD 由四部分组成：</p><ol><li>Partitions（分区）: 数据的原子性片段，每个节点有一个或多个分区；</li><li>Dependencies（依赖）: RDD 转化过程可以表示为一个 DAG，父 RDD 和子 RDD 之间的分区衍生关系；</li><li>Function（函数）: 基于父 RDD 的计算；</li><li>Metadata（元数据）: 分区 Schema 和数据位置；</li></ol><p>事实上，RDD 之间的依赖关系定义了数据何时需要在网络中进行移动，根据父 RDD 和子 RDD 之间的依赖关系，可以将 Transformation 划分为两种：</p><ol><li>Narrow Dependencies（窄依赖）: 父 RDD 的每个分区只被子 RDD 中的一个分区依赖，窄依赖不会发生 Shuffle，执行非常块，可以按照 pipeline 进行优化；</li><li>Wide Dependencies（宽依赖）: 父 RDD 的每个分区被子 RDD 中的多个分区依赖，宽依赖会导致 Shuffle，执行非常慢，是 Spark 用来划分 Stage 的依据；</li></ol><h3 id="宽窄依赖算子"><a href="#宽窄依赖算子" class="headerlink" title="宽窄依赖算子"></a>宽窄依赖算子</h3><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210328220015.png" width="80%" heigh="55%"></img></div><p>总结 Spark 中常见的宽窄依赖 Transformation:</p><ol><li>窄依赖:<ol><li>map、mapValues、flatMap、mapPartitions</li><li>filter</li><li>union</li><li>co-partitioned join: 两个 RDD 分区方式相同的 JOIN 操作</li><li>coalesce: shuffle=false</li></ol></li><li>窄依赖:<ol><li>groupByKey、reduceByKey、combineByKey、cogroup、groupWith</li><li>join、leftOuterJoin、rightOuterJoin</li><li>intersection、distinct</li><li>repartition</li></ol></li></ol><h3 id="容错机制"><a href="#容错机制" class="headerlink" title="容错机制"></a>容错机制</h3><p>通过追踪分区间的依赖关系可以从血缘图中重新计算丢失的分区数据：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210328215915.png" width="60%" heigh="55%"></img></div><p>重新计算窄依赖中丢失的分区数据很快，但是要重新计算宽依赖中丢失的分区数据很慢：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210328215853.png" width="60%" heigh="55%"></img></div><h2 id="使用分区器减少-Shuffle"><a href="#使用分区器减少-Shuffle" class="headerlink" title="使用分区器减少 Shuffle"></a>使用分区器减少 Shuffle</h2><p>有一些方法可以让你在使用宽依赖算子的同时尽量避免或减少 shuffle 的发生，其核心思想是通过重分区在集群中合理地组织数据。</p><h3 id="分组前预分区"><a href="#分组前预分区" class="headerlink" title="分组前预分区"></a>分组前预分区</h3><p>在使用 groupByKey 之类的算子之前先对 RDD 进行预分区（预 Shuffle），之后所有工作都可以在工作节点上的本地分区上完成，无需将数据重新 shuffle 到另一个节点上，在这种情况下，必须移动数据的唯一时间是将最终的 reduce 值从工作节点发送会 Driver 节点：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210328215725.png" width="60%" heigh="55%"></img></div><p>可以通过 toDebugString 方法查看执行计划：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210328220733.png" width="60%" heigh="55%"></img></div><h3 id="JOIN-前预分区"><a href="#JOIN-前预分区" class="headerlink" title="JOIN 前预分区"></a>JOIN 前预分区</h3><p>在执行 JOIN 前，使用相同的的分区器对连接的两个 RDD 进行预分区，可以避免 Shuffle，因为需要连接的两个 RDD 的数据已经被重新定位到同一分区中的相同节点上，不需要移动数据。</p><p>通过一个实际的例子来看，假设我们想统计有多少用户访问了他们没有订阅的主题，这可以通过用户订阅表和用户点击事件表进行 JOIN 得到：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>( ... )</span><br><span class="line"><span class="comment">// 大表：用户ID-用户订阅列表</span></span><br><span class="line"><span class="keyword">val</span> userData = sc.sequenceFile[<span class="type">UserID</span>, <span class="type">Userlnfo</span>](<span class="string">&quot;hdfs:// ... &quot;</span>).persist()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">processNewlogs</span></span>(logFileName: <span class="type">String</span>) &#123;</span><br><span class="line">    <span class="comment">// 小表：用户点击事件表</span></span><br><span class="line">    <span class="keyword">val</span> events = sc.sequenceFile[<span class="type">UserID</span>, <span class="type">Linklnfo</span>](logFileName)</span><br><span class="line">    <span class="keyword">val</span> joined = userData.join(events) </span><br><span class="line">    <span class="keyword">val</span> offTopicVisits = joined.filter &#123;</span><br><span class="line">        <span class="keyword">case</span> (userld, (userlnfo, linklnfo)) =&gt; </span><br><span class="line">            !userlnfo.topics.contains(linklnfo.topic)</span><br><span class="line">    &#125;.count()</span><br><span class="line">    println(&#x27;<span class="symbol">&#x27;Number</span> of visits to non-subscribed topics: &#x27;&#x27; + offTopicVisi ts)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210328215514.png" width="60%" heigh="55%"></img></div><p>“htt上面的 JOIN 操作会非常耗时，因为 JOIN 操作不知道任何关于数据的分区信息。JOIN 操作默认会 hash 两个数据集所有的 key，并将具有相同 hash 值的记录发送到同一个节点上进行 JOIN。解决办法很简单，就是在 JOIN 之前使用 partitionBy 对大表 RDD 进行重分区：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> userData = sc.sequenceFile[<span class="type">UserID</span>, <span class="type">Userlnfo</span>](<span class="string">&quot;hdfs:// ... &quot;</span>)</span><br><span class="line">    .partitionBy(<span class="keyword">new</span> <span class="type">HashPartitioner</span>(<span class="number">100</span>)) <span class="comment">// Create 100 partitions</span></span><br><span class="line">    .persist() </span><br></pre></td></tr></table></figure></div><p>我们在读入 userData 时调用了 partitionBy，Spark 会知道它被 hash 分区了，在后面调用 <code>userData.join(events)</code> 时会利用这一点，按照每个特定的 UserID 将 events RDD shuffle 到包含 userData 对应 hash 分区的节点上。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210328215435.png" width="60%" heigh="55%"></img></div><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://www.coursera.org/learn/scala-spark-big-data/lecture/Vkhm0/partitioning">Coursera: Big Data Analysis with Scala and Spark</a></li><li><a href="https://analyticsindiamag.com/shuffle-operation-hadoop-spark/">Shuffle Operation in Hadoop and Spark</a></li><li><a href="https://zhuanlan.zhihu.com/p/55954840">彻底搞懂spark的shuffle过程（shuffle write）</a></li><li><a href="https://blog.csdn.net/weixin_30697239/article/details/96647403?utm_medium=distribute.pc_relevant.none-task-blog-searchFromBaidu-8.control&amp;dist_request_id=&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-searchFromBaidu-8.control">Spark 2.1.0 中 Sort-Based Shuffle 产生的内幕</a></li></ul><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=center&gt;
    &lt;img src=&quot;https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210328183846.png&quot; width=&quot;80%&quot; heig
      
    
    </summary>
    
      <category term="Spark" scheme="http://liketea.xyz/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://liketea.xyz/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark 指南：Spark 原理（一）—— Spark 程序如何在集群上运行</title>
    <link href="http://liketea.xyz/Spark/Spark/Spark%20%E6%8C%87%E5%8D%97%EF%BC%9ASpark%20%E5%8E%9F%E7%90%86%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%20Spark%20%E7%A8%8B%E5%BA%8F%E5%A6%82%E4%BD%95%E5%9C%A8%E9%9B%86%E7%BE%A4%E4%B8%8A%E8%BF%90%E8%A1%8C/"/>
    <id>http://liketea.xyz/Spark/Spark/Spark 指南：Spark 原理（一）—— Spark 程序如何在集群上运行/</id>
    <published>2020-11-12T07:29:53.000Z</published>
    <updated>2021-06-02T10:44:40.913Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要讨论 Spark 在执行代码时会发生什么，我们以一种忽略具体实现的方式来讨论这个问题，既不依赖于所使用的集群管理器，也不依赖于正在运行的代码。</p><h2 id="Spark-运行时架构"><a href="#Spark-运行时架构" class="headerlink" title="Spark 运行时架构"></a>Spark 运行时架构</h2><h3 id="基本组件"><a href="#基本组件" class="headerlink" title="基本组件"></a>基本组件</h3><p>Spark 运行时架构包含以下三种基本组件：</p><ol><li>Driver：是 Spark 程序的主控进程，主要负责：<ol><li>创建 Spark 上下文；</li><li>提交 Spark 作业（job）；</li><li>在各 Executor 进程间分配、协调任务（Task）调度；</li></ol></li><li>Executor：是执行具体任务的进程，主要负责：<ol><li>执行计算任务（Task）；</li><li>将结果返回给 Driver；</li><li>为需要持久化的 RDD 提供存储功能；</li></ol></li><li>集群管理器：负责维护运行 Spark 程序的机器集群，集群管理器也有自己的 driver（称为主节点 master）和工作者（称为工作节点 worker），但是它们与物理机器而不是进程相关联。下图显示了一个基本的集群设置，左侧机器是群集管理器的 master 节点，右侧机器是集群管理器的 worker 节点，圆圈表示相应进程，目前为止，还没有运行 Spark 应用程序，这些只是来自集群管理器的进程。Spark 目前支持三个集群管理器：一个简单的内置独立集群管理器、Apache Mesos 和 Hadoop Yarn，但是，这个列表将继续增长；</li></ol><h3 id="执行模式"><a href="#执行模式" class="headerlink" title="执行模式"></a>执行模式</h3><p>执行模式使您能够在运行应用程序时确定上述资源的物理位置，有三种模式可供选择（在下面的部分中，带实心边框的矩形表示 driver 进程，而带虚线边框的矩形表示 executor 进程）：</p><ul><li>集群模式（Cluster mode）：集群模式是运行 Spark 应用程序最常见的方式，在集群模式下，用户向集群管理器提交预编译的 JAR、Python 脚本或 R 脚本。然后，除了 executor 之外，集群管理员在集群内的 worker 节点上启动 driver 进程。</li></ul><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210329110741.png" width="60%" heigh="55%"></img></div><ul><li>客户端模式（Client mode）：客户端模式与集群模式几乎相同，只是 Spark driver 程序保留在提交应用程序的客户端上，这意味着客户端负责维护 Spark driver 进程，集群管理器维护 executor 进程。</li></ul><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210329110846.png" width="60%" heigh="55%"></img></div><ul><li>本地模式（Local mode）：本地模式与前两种模式有很大不同，它在一台机器上运行整个 Spark 应用程序，它通过单个机器上的线程实现并行性。这是学习 Spark、测试应用程序或使用本地开发进行迭代实验的常用方法，但是，我们不建议在运行生产应用程序时使用本地模式。</li></ul><h2 id="Spark-程序的生命周期"><a href="#Spark-程序的生命周期" class="headerlink" title="Spark 程序的生命周期"></a>Spark 程序的生命周期</h2><h3 id="Spark-外部生命周期"><a href="#Spark-外部生命周期" class="headerlink" title="Spark 外部生命周期"></a>Spark 外部生命周期</h3><p>从 Spark 代码外部来看 Spark 应用程序的整个生命周期：</p><ol><li>客户端请求：<ol><li>第一步是在本地计算机上执行代码（预编译的 JAR），并向集群管理器 master 节点发出请求，为 Spark driver 进程提供资源；</li><li>集群管理器接受请求，并将 driver 程序放在集群的一个 worker 节点上；</li><li>提交原始作业的客户端进程退出；</li></ol></li><li>启动程序：<ol><li>Spark driver 开始运行用户代码，此代码必须包含初始化 Spark 集群的 SparkSession；</li><li>SparkSession 随后将与集群管理器（较暗的线）通信，要求它在集群中启动 Spark executor 进程（较亮的线），执行器（executor）的数量及其相关配置由用户通过原始 Spark-submit 调用中的命令行参数设置；</li><li>集群管理器通过启动 executor 进行响应，并将有关其位置的相关信息发送到 driver 进程，在所有的东西都连接正确之后，我们就有了一个 Spark 集群；</li></ol></li><li>执行：driver 和 executor 之间进行通信，执行代码并移动数据，driver 将任务分配到每个 executor，每个 executor 执行接收的具体任务，并将执行状态以及结果反馈给 driver；</li><li>完成：Spark 程序完成后，Driver 以成功或失败退出，然后，集群管理器为 driver 关闭该 Spark 集群中的 executor；</li></ol><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20210326123829.png" width="60%" heigh="55%"></img></div><h3 id="Spark-内部生命周期"><a href="#Spark-内部生命周期" class="headerlink" title="Spark 内部生命周期"></a>Spark 内部生命周期</h3><p>相比 Spark 的外部生命周期，Spark 内部（用户代码）生命周期更加重要：</p><ol><li>创建 SparkSession；</li><li>按照 Action 划分 Job；</li><li>按照 Shuffle 划分 Stage；</li><li>按照 Partition 划分 Task；</li></ol><h4 id="SparkSession（会话）"><a href="#SparkSession（会话）" class="headerlink" title="SparkSession（会话）"></a>SparkSession（会话）</h4><p>任何 Spark 应用程序的第一步都是创建 SparkSession，在许多交互模式中，这是为您完成的，但在应用程序中，您必须手动完成。一些遗留代码可能使用新的 SparkContext 模式。应该避免这样做，因为 SparkSession 上的 builder 方法更能有力地实例化 Spark 和 SQL 上下文，并确保没有上下文冲突，因为可能有多个库试图在同一Spark应用程序中创建会话。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Creating a SparkSession in Scala</span></span><br><span class="line"><span class="keyword">import</span> org.apache.<span class="type">Spark</span>.sql.<span class="type">SparkSession</span></span><br><span class="line"><span class="keyword">val</span> <span class="type">Spark</span> = <span class="type">SparkSession</span>.builder().appName(<span class="string">&quot;Databricks Spark Example&quot;</span>).config(<span class="string">&quot;Spark.sql.warehouse.dir&quot;</span>, <span class="string">&quot;/user/hive/warehouse&quot;</span>)</span><br><span class="line">.getOrCreate()</span><br></pre></td></tr></table></figure></div><p>在进行 SparkSession 之后，您应该能够运行 Spark 代码。通过 SparkSession，您还可以相应地访问所有低阶和遗留上下文和配置。请注意，SparkSession 类只添加在 Spark 2.x 中。您可能会发现，较旧的代码将直接为结构化API创建 SparkContext 和 sqlContext。</p><h4 id="Job（作业）——-划分标准：Action"><a href="#Job（作业）——-划分标准：Action" class="headerlink" title="Job（作业）—— 划分标准：Action"></a>Job（作业）—— 划分标准：Action</h4><p>Spark 代码基本上由转换（transformation）和动作（action）组成，在 Spark 中，所有的 transformation 类型操作都是延迟计算的，Spark 只是记录了将要对数据集进行的操作，只有需要将数据返回到 Driver 程序时（即触发 Action 类型操作），所有已记录的 transformation 才会执行，这被称为“惰性计算”。通常，Spark 会按照动作（action）将 Spark 程序划分为不同的 Job。</p><p>transformation 种类繁多，我们只需要记住那些会将数据返回到 Driver 程序的那些操作即可：</p><div class="table-container"><table><thead><tr><th>函数名</th><th>目的</th><th>示例</th><th>结果</th></tr></thead><tbody><tr><td>collect()</td><td>所有元素</td><td>rdd.collect()</td><td>{1,2,3,3}</td></tr><tr><td>count()</td><td>元素个数</td><td>rdd.count()</td><td>4</td></tr><tr><td>countByValue()</td><td>各元素在rdd中出现的次数</td><td>rdd.countByValue()</td><td>{(1,1),(2,1),(3,2)}</td></tr><tr><td>take(num)</td><td>从rdd中返回num个元素</td><td>rdd.take(2)</td><td>{1,2}</td></tr><tr><td>top(num)</td><td>从rdd中返回最前面的num个元素</td><td>rdd.top(2)</td><td>{3,3}</td></tr><tr><td>takeOrdered(num)(ordering)</td><td>按提供的顺序，返回最前面的 num 个元素</td><td>rdd.takeOrdered(2)(myOrdering)</td><td>{3,3}</td></tr><tr><td>takeSample(withReplacement,num,[seed])</td><td>从rdd中返回任意一些元素</td><td>rdd.takeSample(false,1)</td><td>非确定的</td></tr><tr><td>reduce(func)</td><td>整合RDD中的所有数据</td><td>rdd.reduce((x,y)=&gt;x+y)</td><td>9</td></tr><tr><td>fold(zero)(func)</td><td>和reduce一样，但是需要初始值</td><td>rdd.fold(0)((x,y)=&gt;x+y)</td><td>9</td></tr><tr><td>aggregate(zeroValue)(seqOp,combOp)</td><td>和reduce()相似，但是通常返回不同类型的函数</td><td>rdd.aggregate((0,0))((x,y)=&gt;(x,y)=&gt;(x._1+y,x._2+1),(x,y)=&gt;(x._1+y._1,x._2+y._2))</td><td>(9,4)</td></tr><tr><td>foreach(func)</td><td>对RDd中的每个元素使用给定的元素</td><td>rdd.foreach(func)</td><td>无</td></tr></tbody></table></div><h4 id="Stage（阶段）——-划分标准：Shuffle"><a href="#Stage（阶段）——-划分标准：Shuffle" class="headerlink" title="Stage（阶段）—— 划分标准：Shuffle"></a>Stage（阶段）—— 划分标准：Shuffle</h4><p>Spark 中的阶段（stage）表示可以一起执行以在多台计算机上<strong>并行</strong>计算相同操作的任务（task）组。一般来说，Spark 会尝试将尽可能多的工作（即工作中尽可能多的转换）打包到同一个阶段（stage），但引擎会在称为洗牌（Shuffle）的操作后启动新的阶段（stage）。</p><p>在“Spark 指南：Spark 原理（一）—— Partition 和 Shuffle”一文中我们讲过宽依赖算子会导致 Shuffle，这里重温一下那些会导致 Shuffle 的算子：</p><ol><li>groupByKey、reduceByKey、combineByKey、cogroup、groupWith</li><li>join、leftOuterJoin、rightOuterJoin</li><li>intersection、distinct</li><li>repartition</li></ol><p>Shuffle 过程首先会将前置 Stage 的 Map Task 结果写入本地磁盘（Shuffle Write），然后后续 Stage 的 reduce Task 会从磁盘中读取这些文件（Shuffle Read）来执行计算，这有两点好处：</p><ol><li>将 Shuffle 文件写入磁盘（称为 Shuffle 持久化），使得 Spark 能够在时间上串行地执行不同的 Stage；</li><li>出现故障时，只需要重启 Reduce Task ，而不用重新运行所有的任务。</li></ol><h4 id="Task（任务）划分标准：Partition"><a href="#Task（任务）划分标准：Partition" class="headerlink" title="Task（任务）划分标准：Partition"></a>Task（任务）划分标准：Partition</h4><p>每个任务（task）对应于将在单个执行器（executor）上运行的数据块（Partition）和一组转换的组合。Task 只是应用于数据单元（Partition）的计算单位，将数据划分为更多数量的分区意味着可以并行执行更多数据。如果我们的数据集中有一个大分区，我们将有一个任务；如果有1000个小分区，我们将有 1,000 个可以并行执行的任务。</p><p>使 Spark 成为“内存计算工具”的一个重要原因是，与之前的工具（如 MapReduce）不同，Spark 在将数据写入内存或磁盘前会尝试执行尽可能多的步骤。Spark 执行的关键优化之一是 pipelining，它发生在 RDD 及以下级别。使用流水线技术，任何可以将数据直接传递给彼此而无需在节点间移动的操作序列，都会被折叠成单个任务阶段，阶段内的所有操作会一起执行。例如，如果您编写一个基于 RDD 的程序，该程序执行一个 map，一个 filter，然后是另一个 map，则这些将导致单阶段任务，这些任务立即读取每个输入记录，将其传递给第一个 map，再将其传递给 filter，并在需要时将其传递给最后一个 map 函数。这种流水线式的计算比在每个步骤之后将中间结果写入内存或磁盘要快得多。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://snaildove.github.io/2019/08/05/Chapter15_HowSparkRuns-on-a-Cluster(SparkTheDefinitiveGuide">How Spark Runs on a Cluster Spark</a>_online/)</li></ul><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文主要讨论 Spark 在执行代码时会发生什么，我们以一种忽略具体实现的方式来讨论这个问题，既不依赖于所使用的集群管理器，也不依赖于正在运行的代码。&lt;/p&gt;
&lt;h2 id=&quot;Spark-运行时架构&quot;&gt;&lt;a href=&quot;#Spark-运行时架构&quot; class=&quot;header
      
    
    </summary>
    
      <category term="Spark" scheme="http://liketea.xyz/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://liketea.xyz/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark 指南：Spark SQL（五）—— SQL</title>
    <link href="http://liketea.xyz/Spark/Spark/Spark%20%E6%8C%87%E5%8D%97%EF%BC%9ASpark%20SQL%EF%BC%88%E4%BA%94%EF%BC%89%E2%80%94%E2%80%94%20SQL/"/>
    <id>http://liketea.xyz/Spark/Spark/Spark 指南：Spark SQL（五）—— SQL/</id>
    <published>2020-11-11T10:51:22.000Z</published>
    <updated>2021-06-02T10:44:40.912Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/sparksql_iteblog.png" alt=""></p><p>SQL（Structured Query Language） 是一种领域特定语言，用于表达对数据的关系型操作。SQL 无处不在，即使技术专家预言了它的消亡，它还是许多企业所依赖的及其灵活的数据工具。Spark 实现了 ANSI SQL:2003 的一个子集，该标准是大多数 SQL 数据库中可用的标准。Spark SQL 旨在用作联机分析处理（OLAP）数据库，而不是联机事务处理（OLTP）数据库，这意味着它不打算执行极低延迟的查询，即使将来肯定会支持原地修改，但是目前还不支持。</p><h2 id="Spark-SQL-amp-Hive"><a href="#Spark-SQL-amp-Hive" class="headerlink" title="Spark SQL &amp; Hive"></a>Spark SQL &amp; Hive</h2><p>Spark SQL 的前身是 Shark。为了给熟悉 RDBMS 但又不理解 MapReduce 的技术人员提供快速上手的工具，hive 应运而生，它是当时唯一运行在 Hadoop 上的 SQL-on-hadoop 工具。但是MapReduce 计算过程中大量的中间磁盘落地过程消耗了大量的 I/O，降低的运行效率，为了提高 SQL-on-Hadoop 的效率，Shark 应运而生，但又因为 Shark 对于 Hive 的太多依赖（如采用 Hive 的语法解析器、查询优化器等等)，2014 年 Spark 团队停止对 Shark 的开发，将所有资源放 Spark SQL 项目上。其中 Spark SQL 作为 Spark 生态的一员继续发展，而不再受限于 Hive，只是兼容 Hive；而 Hive on Spark 是一个 Hive 的发展计划，该计划将 Spark 作为 Hive 的底层引擎之一，也就是说，Hive 将不再受限于一个引擎，可以采用 Map-Reduce、Tez、Spark 等引擎。</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/apache_hive_vs._spark__article.jpg" alt=""></p><h2 id="执行-SQL"><a href="#执行-SQL" class="headerlink" title="执行 SQL"></a>执行 SQL</h2><p>Spark 提供了几个接口来执行 SQL 查询：</p><ul><li>Spark SQL CLI：你可以使用 Spark SQL CLI 从命令行在本地模式下进行基本的 Spark SQL 查询， Spark SQL CLI 无法与 Thrift JDBC 服务器通信，要启动 Spark SQL CLI，请在 Spark 目录下运行以下命令</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="ZSH"><figure class="iseeu highlight /zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-sql</span><br></pre></td></tr></table></figure></div><ul><li>Spark 编程接口：你可以通过任意 Spark 语言 API 以临时方式执行 SQL，你可以通过 SparkSession 对象上的 sql 方法执行此操作，这将返回一个 DataFrame</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.sql(sql_statement)</span><br></pre></td></tr></table></figure></div><h2 id="Catalog"><a href="#Catalog" class="headerlink" title="Catalog"></a>Catalog</h2><p>Catalog 是 Spark SQL 中最高级别的抽象，用于对数据库、表、视图、缓存、列、函数（UDF/UDAF）的元数据进行操作，其 API 可以在 <code>org.apache.spark.sql.catalog</code> 中查看。</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201111170644.png" alt=""></p><p>示例数据：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = <span class="type">Seq</span>(</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;M&quot;</span>, <span class="number">3000</span>, <span class="type">Row</span>(<span class="string">&quot;James &quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;Smith&quot;</span>), <span class="type">Seq</span>(<span class="number">1</span>,<span class="number">2</span>), <span class="type">Map</span>(<span class="string">&quot;1&quot;</span>-&gt;<span class="string">&quot;a&quot;</span>, <span class="string">&quot;11&quot;</span>-&gt;<span class="string">&quot;aa&quot;</span>)),</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;F&quot;</span>, <span class="number">4000</span>, <span class="type">Row</span>(<span class="string">&quot;Maria &quot;</span>,<span class="string">&quot;Anne&quot;</span>,<span class="string">&quot;Jones&quot;</span>), <span class="type">Seq</span>(<span class="number">3</span>,<span class="number">3</span>), <span class="type">Map</span>(<span class="string">&quot;4&quot;</span>-&gt;<span class="string">&quot;d&quot;</span>, <span class="string">&quot;44&quot;</span>-&gt;<span class="string">&quot;dd&quot;</span>)),</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;F&quot;</span>, <span class="number">-1</span>, <span class="type">Row</span>(<span class="string">&quot;Jen&quot;</span>,<span class="string">&quot;Mary&quot;</span>,<span class="string">&quot;Brown&quot;</span>), <span class="type">Seq</span>(<span class="number">5</span>,<span class="number">2</span>), <span class="type">Map</span>(<span class="string">&quot;5&quot;</span>-&gt;<span class="string">&quot;e&quot;</span>))</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> schema = <span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">      .add(<span class="string">&quot;gender&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      .add(<span class="string">&quot;salary&quot;</span>,<span class="type">IntegerType</span>)</span><br><span class="line">      .add(<span class="string">&quot;f_struct&quot;</span>,</span><br><span class="line">        <span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">          .add(<span class="string">&quot;firstname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">          .add(<span class="string">&quot;middlename&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">          .add(<span class="string">&quot;lastname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      )  </span><br><span class="line">      .add(<span class="string">&quot;f_array&quot;</span>, <span class="type">ArrayType</span>(<span class="type">IntegerType</span>))</span><br><span class="line">      .add(<span class="string">&quot;f_map&quot;</span>, <span class="type">MapType</span>(<span class="type">StringType</span>, <span class="type">StringType</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df = spark.createDataFrame(spark.sparkContext.parallelize(data),schema)</span><br><span class="line">df.show()</span><br><span class="line">df.printSchema</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line">|gender|salary|            f_struct|f_array|             f_map|</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">3000</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|</span><br><span class="line">|     <span class="type">F</span>|  <span class="number">4000</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...| [<span class="number">3</span>, <span class="number">3</span>]|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]|</span><br><span class="line">|     <span class="type">F</span>|    <span class="number">-1</span>|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]| [<span class="number">5</span>, <span class="number">2</span>]|          [<span class="number">5</span> -&gt; e]|</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- gender: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_struct: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- firstname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- middlename: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- lastname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_array: array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- element: integer (containsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- f_map: map (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- key: string</span><br><span class="line"> |    |-- value: string (valueContainsNull = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><p>获取 catalog 对象：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> c = spark.catalog</span><br></pre></td></tr></table></figure></div><h3 id="操作数据库"><a href="#操作数据库" class="headerlink" title="操作数据库"></a>操作数据库</h3><ul><li>API：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 返回当前使用的数据库，相当于select database()</span></span><br><span class="line">currentDatabase: <span class="type">String</span></span><br><span class="line"><span class="comment">// 设置当前使用的数据库，相当于use database_name;</span></span><br><span class="line">setCurrentDatabase(dbName: <span class="type">String</span>): <span class="type">Unit</span></span><br><span class="line"><span class="comment">// 查看所有数据库，相当于show databases;</span></span><br><span class="line">listDatabases(): <span class="type">Dataset</span>[<span class="type">Database</span>]</span><br><span class="line"><span class="comment">// 获取某数据库的元数据，返回值是Database类型的，如果指定的数据库不存在则会@throws[AnalysisException](&quot;database does not exist&quot;)</span></span><br><span class="line">getDatabase(dbName: <span class="type">String</span>): <span class="type">Database</span></span><br><span class="line"><span class="comment">// 判断某个数据库是否已经存在，返回boolean值</span></span><br><span class="line">databaseExists(dbName: <span class="type">String</span>): <span class="type">Boolean</span></span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">c.listDatabases().show(<span class="literal">false</span>)</span><br><span class="line">+-------+----------------+-----------------------------------------------+</span><br><span class="line">|name   |description     |locationUri                                    |</span><br><span class="line">+-------+----------------+-----------------------------------------------+</span><br><span class="line">|<span class="keyword">default</span>|<span class="keyword">default</span> database|file:/<span class="type">Users</span>/likewang/ilab/<span class="type">Spark</span>/spark-warehouse|</span><br><span class="line">+-------+----------------+-----------------------------------------------+</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> d = c.getDatabase(<span class="string">&quot;default&quot;</span>)</span><br><span class="line">println(<span class="string">s&quot;name:<span class="subst">$&#123;d.name&#125;</span> path:<span class="subst">$&#123;d.locationUri&#125;</span>&quot;</span>)</span><br><span class="line">name:<span class="keyword">default</span> path:file:/<span class="type">Users</span>/likewang/ilab/<span class="type">Spark</span>/spark-warehouse</span><br><span class="line"></span><br><span class="line">c.databaseExists(<span class="string">&quot;default&quot;</span>)</span><br><span class="line">res4: <span class="type">Boolean</span> = <span class="literal">true</span></span><br></pre></td></tr></table></figure></div><h3 id="操作表-视图"><a href="#操作表-视图" class="headerlink" title="操作表/视图"></a>操作表/视图</h3><ul><li>API：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 表/视图的属性</span></span><br><span class="line">name：表的名字</span><br><span class="line">database：表所属的数据库的名字</span><br><span class="line">description：表的描述信息</span><br><span class="line">tableType：用于区分是表还是视图，两个取值：table或view</span><br><span class="line">isTemporary：是否是临时表或临时视图，解释一下啥是临时表，临时表就是使用 <span class="type">Dataset</span> 或<span class="type">DataFrame</span> 的 createOrReplaceTempView 等类似的 <span class="type">API</span> 注册的视图或表，当此次 <span class="type">Spark</span> 任务结束后这些表就没了，再次使用的话还要再进行注册，而非临时表就是在 <span class="type">Hive</span> 中真实存在的，开启<span class="type">Hive</span>支持就能够直接使用的，本次 <span class="type">Spark</span> 任务结束后表仍然能存在，下次启动不需要重新做任何处理就能够使用，表是持久的，这种不是临时表</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查看所有表或视图，相当于show tables</span></span><br><span class="line">listTables(): <span class="type">Dataset</span>[<span class="type">Table</span>]</span><br><span class="line"><span class="comment">// 返回指定数据库下的表或视图，如果指定的数据库不存在则会抛出@throws[AnalysisException](&quot;database does not exist&quot;)表示数据库不存在。</span></span><br><span class="line">listTables(dbName: <span class="type">String</span>): <span class="type">Dataset</span>[<span class="type">Table</span>]</span><br><span class="line"><span class="comment">// 获取表的元信息，不存在则会抛出异常</span></span><br><span class="line">getTable(tableName: <span class="type">String</span>): <span class="type">Table</span></span><br><span class="line">getTable(dbName: <span class="type">String</span>, tableName: <span class="type">String</span>): <span class="type">Table</span></span><br><span class="line"><span class="comment">// 判断表或视图是否存在，返回boolean值</span></span><br><span class="line">tableExists(tableName: <span class="type">String</span>): <span class="type">Boolean</span></span><br><span class="line">tableExists(dbName: <span class="type">String</span>, tableName: <span class="type">String</span>): <span class="type">Boolean</span></span><br><span class="line"><span class="comment">// 使用createOrReplaceTempView类似API注册的临时视图可以使用此方法删除，如果这个视图已经被缓存过的话会自动清除缓存</span></span><br><span class="line">dropTempView(viewName: <span class="type">String</span>): <span class="type">Boolean</span></span><br><span class="line">dropGlobalTempView(viewName: <span class="type">String</span>): <span class="type">Boolean</span></span><br><span class="line"><span class="comment">// 用于判断一个表否已经缓存过了</span></span><br><span class="line">isCached(tableName: <span class="type">String</span>): <span class="type">Boolean</span></span><br><span class="line"><span class="comment">// 用于缓存表</span></span><br><span class="line">cacheTable(tableName: <span class="type">String</span>): <span class="type">Unit</span></span><br><span class="line">cacheTable(tableName: <span class="type">String</span>, storageLevel: <span class="type">StorageLevel</span>): <span class="type">Unit</span></span><br><span class="line"><span class="comment">// 对表取消缓存</span></span><br><span class="line">uncacheTable(tableName: <span class="type">String</span>): <span class="type">Unit</span></span><br><span class="line"><span class="comment">// 清空所有缓存</span></span><br><span class="line">clearCache(): <span class="type">Unit</span></span><br><span class="line"><span class="comment">// Spark为了性能考虑，对表的元数据做了缓存，所以当被缓存的表已经改变时也必须刷新元数据重新缓存</span></span><br><span class="line">refreshTable(tableName: <span class="type">String</span>): <span class="type">Unit</span></span><br><span class="line">refreshByPath(path: <span class="type">String</span>): <span class="type">Unit</span></span><br><span class="line"><span class="comment">// 根据给定路径创建表，并返回相关的 DataFrame</span></span><br><span class="line">createTable(tableName: <span class="type">String</span>, path: <span class="type">String</span>): <span class="type">DataFrame</span></span><br><span class="line">createTable(tableName: <span class="type">String</span>, path: <span class="type">String</span>, source: <span class="type">String</span>): <span class="type">DataFrame</span></span><br><span class="line">createTable(tableName: <span class="type">String</span>, source: <span class="type">String</span>, options: java.util.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]): <span class="type">DataFrame</span></span><br><span class="line">createTable(tableName: <span class="type">String</span>, source: <span class="type">String</span>, options: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]): <span class="type">DataFrame</span></span><br><span class="line">createTable(tableName: <span class="type">String</span>, source: <span class="type">String</span>, schema: <span class="type">StructType</span>, options: java.util.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]): <span class="type">DataFrame</span></span><br><span class="line">createTable(tableName: <span class="type">String</span>, source: <span class="type">String</span>, schema: <span class="type">StructType</span>, options: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]): <span class="type">DataFrame</span> </span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">c.listTables(<span class="string">&quot;default&quot;</span>).show()</span><br><span class="line">+----+--------+-----------+---------+-----------+</span><br><span class="line">|name|database|description|tableType|isTemporary|</span><br><span class="line">+----+--------+-----------+---------+-----------+</span><br><span class="line">+----+--------+-----------+---------+-----------+</span><br><span class="line"></span><br><span class="line">df.createOrReplaceTempView(<span class="string">&quot;df&quot;</span>)</span><br><span class="line">c.listTables(<span class="string">&quot;default&quot;</span>).show()</span><br><span class="line">+----+--------+-----------+---------+-----------+</span><br><span class="line">|name|database|description|tableType|isTemporary|</span><br><span class="line">+----+--------+-----------+---------+-----------+</span><br><span class="line">|  df|    <span class="literal">null</span>|       <span class="literal">null</span>|<span class="type">TEMPORARY</span>|       <span class="literal">true</span>|</span><br><span class="line">+----+--------+-----------+---------+-----------+</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> t = c.getTable(<span class="string">&quot;df&quot;</span>)</span><br><span class="line">println(<span class="string">s&quot;name:<span class="subst">$&#123;t.name&#125;</span> tableType:<span class="subst">$&#123;t.tableType&#125;</span> isTemporary:<span class="subst">$&#123;t.isTemporary&#125;</span>&quot;</span>)</span><br><span class="line">name:df tableType:<span class="type">TEMPORARY</span> isTemporary:<span class="literal">true</span></span><br><span class="line"></span><br><span class="line">c.tableExists(<span class="string">&quot;df&quot;</span>)</span><br><span class="line">res10: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">c.isCached(<span class="string">&quot;df&quot;</span>)</span><br><span class="line">res11: <span class="type">Boolean</span> = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">df.cache()</span><br><span class="line">c.isCached(<span class="string">&quot;df&quot;</span>)</span><br><span class="line">res13: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">c.uncacheTable(<span class="string">&quot;df&quot;</span>)</span><br><span class="line">c.isCached(<span class="string">&quot;df&quot;</span>)</span><br><span class="line">res14: <span class="type">Boolean</span> = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">c.refreshTable(<span class="string">&quot;df&quot;</span>)</span><br></pre></td></tr></table></figure></div><h3 id="函数相关"><a href="#函数相关" class="headerlink" title="函数相关"></a>函数相关</h3><ul><li>API：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 函数的属性</span></span><br><span class="line">database：函数注册在哪个数据库下，函数是跟数据库绑定的</span><br><span class="line">description：对函数的描述信息，可以理解成注释</span><br><span class="line">className：函数其实就是一个<span class="class"><span class="keyword">class</span><span class="title">，调用函数就是调用类的方法，className表示函数对应的class的全路径类名</span></span></span><br><span class="line">isTemporary：是否是临时函数</span><br><span class="line"></span><br><span class="line"><span class="comment">// 列出当前数据库下的所有函数，包括注册的临时函数</span></span><br><span class="line">listFunctions(): <span class="type">Dataset</span>[<span class="type">Function</span>]</span><br><span class="line"><span class="comment">// 列出指定数据库下注册的所有函数，包括临时函数，如果指定的数据库不存在的话则会抛出@throws[AnalysisException](&quot;database does not exist&quot;)表示数据库不存在</span></span><br><span class="line">listFunctions(dbName: <span class="type">String</span>): <span class="type">Dataset</span>[<span class="type">Function</span>]</span><br><span class="line"><span class="comment">// 获取函数的元信息，函数不存在则会抛出异常</span></span><br><span class="line">getFunction(functionName: <span class="type">String</span>): <span class="type">Function</span></span><br><span class="line">getFunction(dbName: <span class="type">String</span>, functionName: <span class="type">String</span>): <span class="type">Function</span></span><br><span class="line"><span class="comment">// 判断函数是否存在，返回boolean值</span></span><br><span class="line">functionExists(functionName: <span class="type">String</span>): <span class="type">Boolean</span></span><br><span class="line">functionExists(dbName: <span class="type">String</span>, functionName: <span class="type">String</span>): <span class="type">Boolean</span></span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">c.listFunctions.show(<span class="number">10</span>, <span class="literal">false</span>)</span><br><span class="line">+----+--------+-----------+---------------------------------------------------------+-----------+</span><br><span class="line">|name|database|description|className                                                |isTemporary|</span><br><span class="line">+----+--------+-----------+---------------------------------------------------------+-----------+</span><br><span class="line">|!   |<span class="literal">null</span>    |<span class="literal">null</span>       |org.apache.spark.sql.catalyst.expressions.<span class="type">Not</span>            |<span class="literal">true</span>       |</span><br><span class="line">|%   |<span class="literal">null</span>    |<span class="literal">null</span>       |org.apache.spark.sql.catalyst.expressions.<span class="type">Remainder</span>      |<span class="literal">true</span>       |</span><br><span class="line">|&amp;   |<span class="literal">null</span>    |<span class="literal">null</span>       |org.apache.spark.sql.catalyst.expressions.<span class="type">BitwiseAnd</span>     |<span class="literal">true</span>       |</span><br><span class="line">|*   |<span class="literal">null</span>    |<span class="literal">null</span>       |org.apache.spark.sql.catalyst.expressions.<span class="type">Multiply</span>       |<span class="literal">true</span>       |</span><br><span class="line">|+   |<span class="literal">null</span>    |<span class="literal">null</span>       |org.apache.spark.sql.catalyst.expressions.<span class="type">Add</span>            |<span class="literal">true</span>       |</span><br><span class="line">|-   |<span class="literal">null</span>    |<span class="literal">null</span>       |org.apache.spark.sql.catalyst.expressions.<span class="type">Subtract</span>       |<span class="literal">true</span>       |</span><br><span class="line">|/   |<span class="literal">null</span>    |<span class="literal">null</span>       |org.apache.spark.sql.catalyst.expressions.<span class="type">Divide</span>         |<span class="literal">true</span>       |</span><br><span class="line">|&lt;   |<span class="literal">null</span>    |<span class="literal">null</span>       |org.apache.spark.sql.catalyst.expressions.<span class="type">LessThan</span>       |<span class="literal">true</span>       |</span><br><span class="line">|&lt;=  |<span class="literal">null</span>    |<span class="literal">null</span>       |org.apache.spark.sql.catalyst.expressions.<span class="type">LessThanOrEqual</span>|<span class="literal">true</span>       |</span><br><span class="line">|&lt;=&gt; |<span class="literal">null</span>    |<span class="literal">null</span>       |org.apache.spark.sql.catalyst.expressions.<span class="type">EqualNullSafe</span>  |<span class="literal">true</span>       |</span><br><span class="line">+----+--------+-----------+---------------------------------------------------------+-----------+</span><br><span class="line"></span><br><span class="line">c.functionExists(<span class="string">&quot;!&quot;</span>)</span><br><span class="line">res21: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">c.getFunction(<span class="string">&quot;!&quot;</span>)</span><br><span class="line">res22: org.apache.spark.sql.catalog.<span class="type">Function</span> = <span class="type">Function</span>[name=&#x27;!&#x27;, className=<span class="symbol">&#x27;org</span>.apache.spark.sql.catalyst.expressions.<span class="type">Not</span>&#x27;, isTemporary=<span class="symbol">&#x27;tru</span>e&#x27;]</span><br></pre></td></tr></table></figure></div><h3 id="操作表-视图的列"><a href="#操作表-视图的列" class="headerlink" title="操作表/视图的列"></a>操作表/视图的列</h3><ul><li>API：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 列的属性</span></span><br><span class="line">name：列的名字</span><br><span class="line">description：列的描述信息，与注释差不多</span><br><span class="line">dataType：列的数据类型</span><br><span class="line">nullable：列是否允许为<span class="literal">null</span></span><br><span class="line">isPartition：是否是分区列</span><br><span class="line">isBucket：是否是桶列</span><br><span class="line"><span class="comment">// 列出指定的表或视图有哪些列，表不存在则抛异常</span></span><br><span class="line">listColumns(tableName: <span class="type">String</span>): <span class="type">Dataset</span>[<span class="type">Column</span>]</span><br><span class="line">listColumns(dbName: <span class="type">String</span>, tableName: <span class="type">String</span>): <span class="type">Dataset</span>[<span class="type">Column</span>]</span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">c.listColumns(<span class="string">&quot;df&quot;</span>).show()</span><br><span class="line">+--------+-----------+--------------------+--------+-----------+--------+</span><br><span class="line">|    name|description|            dataType|nullable|isPartition|isBucket|</span><br><span class="line">+--------+-----------+--------------------+--------+-----------+--------+</span><br><span class="line">|  gender|       <span class="literal">null</span>|              string|    <span class="literal">true</span>|      <span class="literal">false</span>|   <span class="literal">false</span>|</span><br><span class="line">|  salary|       <span class="literal">null</span>|                 int|    <span class="literal">true</span>|      <span class="literal">false</span>|   <span class="literal">false</span>|</span><br><span class="line">|f_struct|       <span class="literal">null</span>|struct&lt;firstname:...|    <span class="literal">true</span>|      <span class="literal">false</span>|   <span class="literal">false</span>|</span><br><span class="line">| f_array|       <span class="literal">null</span>|          array&lt;int&gt;|    <span class="literal">true</span>|      <span class="literal">false</span>|   <span class="literal">false</span>|</span><br><span class="line">|   f_map|       <span class="literal">null</span>|  map&lt;string,string&gt;|    <span class="literal">true</span>|      <span class="literal">false</span>|   <span class="literal">false</span>|</span><br><span class="line">+--------+-----------+--------------------+--------+-----------+--------+</span><br></pre></td></tr></table></figure></div><h2 id="Tables"><a href="#Tables" class="headerlink" title="Tables"></a>Tables</h2><p>要用 Spark SQL 做任何有用的事情，首先要定义表，表在逻辑上等效于 DataFrame，因为他们是运行命令所依据的数据结构，我们可以对表进行关联、过滤、汇总等操作，表和 DataFame 之间的核心区别在于：在编程语言范围内定义 DataFrame，在数据库中定义表。</p><h3 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h3><p>Spark 相当独特的功能是可以在 SQL 中重用整个数据源 API：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 从数据源读取数据，创建表，定义了一个非托管表</span></span><br><span class="line"><span class="keyword">val</span> sql = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">CREATE TABLE if not exists flights(</span></span><br><span class="line"><span class="string">a string comment &quot;name&quot;, </span></span><br><span class="line"><span class="string">b int comment &quot;level&quot;, </span></span><br><span class="line"><span class="string">c int comment &quot;age&quot;</span></span><br><span class="line"><span class="string">) using csv options (path &#x27;job.csv&#x27;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">spark.sql(sql)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从查询创建表，定义了一个托管表，Spark 会为其跟踪所有相关信息</span></span><br><span class="line"><span class="keyword">val</span> sql = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">CREATE  TABLE if not exists df_copy</span></span><br><span class="line"><span class="string">USING parquet AS SELECT * from df</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">spark.sql(sql)</span><br><span class="line"></span><br><span class="line">c.listTables().show()</span><br><span class="line">+-------+--------+-----------+---------+-----------+</span><br><span class="line">|   name|database|description|tableType|isTemporary|</span><br><span class="line">+-------+--------+-----------+---------+-----------+</span><br><span class="line">|df_copy| <span class="keyword">default</span>|       <span class="literal">null</span>|  <span class="type">MANAGED</span>|      <span class="literal">false</span>|</span><br><span class="line">|flights| <span class="keyword">default</span>|       <span class="literal">null</span>| <span class="type">EXTERNAL</span>|      <span class="literal">false</span>|</span><br><span class="line">|     df|    <span class="literal">null</span>|       <span class="literal">null</span>|<span class="type">TEMPORARY</span>|       <span class="literal">true</span>|</span><br><span class="line">+-------+--------+-----------+---------+-----------+</span><br><span class="line"></span><br><span class="line">spark.sql(<span class="string">&quot;select * from df_copy&quot;</span>).show()</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line">|gender|salary|            f_struct|f_array|             f_map|</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">3000</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|</span><br><span class="line">|     <span class="type">F</span>|  <span class="number">4000</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...| [<span class="number">3</span>, <span class="number">3</span>]|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]|</span><br><span class="line">|     <span class="type">F</span>|    <span class="number">-1</span>|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]| [<span class="number">5</span>, <span class="number">2</span>]|          [<span class="number">5</span> -&gt; e]|</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br></pre></td></tr></table></figure></div><h3 id="插入表"><a href="#插入表" class="headerlink" title="插入表"></a>插入表</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sql = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">insert into df_copy</span></span><br><span class="line"><span class="string">SELECT * from df limit 3</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">spark.sql(sql)</span><br><span class="line"></span><br><span class="line">spark.sql(<span class="string">&quot;select * from flights&quot;</span>).show()</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line">|gender|salary|            f_struct|f_array|             f_map|</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">3000</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|</span><br><span class="line">|     <span class="type">F</span>|  <span class="number">4000</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...| [<span class="number">3</span>, <span class="number">3</span>]|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]|</span><br><span class="line">|     <span class="type">F</span>|    <span class="number">-1</span>|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]| [<span class="number">5</span>, <span class="number">2</span>]|          [<span class="number">5</span> -&gt; e]|</span><br><span class="line">|     <span class="type">F</span>|  <span class="number">4000</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...| [<span class="number">3</span>, <span class="number">3</span>]|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]|</span><br><span class="line">|     <span class="type">F</span>|    <span class="number">-1</span>|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]| [<span class="number">5</span>, <span class="number">2</span>]|          [<span class="number">5</span> -&gt; e]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">3000</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br></pre></td></tr></table></figure></div><h3 id="描述表"><a href="#描述表" class="headerlink" title="描述表"></a>描述表</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">spark.sql(<span class="string">&quot;describe df_copy&quot;</span>).show()</span><br><span class="line">+--------+--------------------+-------+</span><br><span class="line">|col_name|           data_type|comment|</span><br><span class="line">+--------+--------------------+-------+</span><br><span class="line">|  gender|              string|   <span class="literal">null</span>|</span><br><span class="line">|  salary|                 int|   <span class="literal">null</span>|</span><br><span class="line">|f_struct|struct&lt;firstname:...|   <span class="literal">null</span>|</span><br><span class="line">| f_array|          array&lt;int&gt;|   <span class="literal">null</span>|</span><br><span class="line">|   f_map|  map&lt;string,string&gt;|   <span class="literal">null</span>|</span><br><span class="line">+--------+--------------------+-------+</span><br></pre></td></tr></table></figure></div><h3 id="刷新表"><a href="#刷新表" class="headerlink" title="刷新表"></a>刷新表</h3><p>REFRESH TALE 刷新与该表的所有缓存条目（实质上是文件），如果该表先前已被缓存，则下次扫描时将被延迟缓存：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.sql(<span class="string">&quot;refresh table df_copy&quot;</span>)</span><br></pre></td></tr></table></figure></div><h3 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h3><p>删除表会删除托管表中的数据，因此执行此操作时需要非常小心。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">spark.sql(<span class="string">&quot;drop table if exists df_copy&quot;</span>)</span><br><span class="line">c.listTables().show()</span><br><span class="line">+-------+--------+-----------+---------+-----------+</span><br><span class="line">|   name|database|description|tableType|isTemporary|</span><br><span class="line">+-------+--------+-----------+---------+-----------+</span><br><span class="line">|flights| <span class="keyword">default</span>|       <span class="literal">null</span>| <span class="type">EXTERNAL</span>|      <span class="literal">false</span>|</span><br><span class="line">|     df|    <span class="literal">null</span>|       <span class="literal">null</span>|<span class="type">TEMPORARY</span>|       <span class="literal">true</span>|</span><br><span class="line">+-------+--------+-----------+---------+-----------+</span><br></pre></td></tr></table></figure></div><h3 id="缓存表"><a href="#缓存表" class="headerlink" title="缓存表"></a>缓存表</h3><p>和 DataFrame 一样，你可以缓存表或者取消缓存表:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spark.sql(<span class="string">&quot;uncache table flights&quot;</span>)</span><br><span class="line">c.isCached(<span class="string">&quot;flights&quot;</span>)</span><br><span class="line">res60: <span class="type">Boolean</span> = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">spark.sql(<span class="string">&quot;cache table flights&quot;</span>)</span><br><span class="line">c.isCached(<span class="string">&quot;flights&quot;</span>)</span><br><span class="line">res59: <span class="type">Boolean</span> = <span class="literal">true</span></span><br></pre></td></tr></table></figure></div><h2 id="Views"><a href="#Views" class="headerlink" title="Views"></a>Views</h2><p>视图是保存的查询计划，可以方便地组织或重用查询逻辑。</p><h3 id="创建视图"><a href="#创建视图" class="headerlink" title="创建视图"></a>创建视图</h3><p>Spark 有几种不同的视图概念，视图可以是全局视图、数据库视图或会话视图：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 常规/数据库视图：在所属数据库可见，不能基于视图再创建常规视图</span></span><br><span class="line"><span class="keyword">val</span> sql = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">create view view_f as </span></span><br><span class="line"><span class="string">select * from flights</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">spark.sql(sql)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 会话临时视图：仅在当前会话期间可用，且未注册到数据库</span></span><br><span class="line"><span class="keyword">val</span> sql = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">create temp view temp_view_f as </span></span><br><span class="line"><span class="string">select * from flights</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">spark.sql(sql)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 全局临时视图：仅在当前会话期间可用，无论用哪个数据库都可见</span></span><br><span class="line"><span class="keyword">val</span> sql = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">create global temp view global_temp_view_f as </span></span><br><span class="line"><span class="string">select * from flights</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">spark.sql(sql)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 覆盖临时视图：如果临时视图已存在则覆盖</span></span><br><span class="line"><span class="keyword">val</span> sql = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">create or replace temp view replace_temp_view_f as </span></span><br><span class="line"><span class="string">select * from flights</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">spark.sql(sql)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 视图会在表列表中列出</span></span><br><span class="line">spark.sql(<span class="string">&quot;show tables&quot;</span>).show()</span><br><span class="line">+--------+-------------------+-----------+</span><br><span class="line">|database|          tableName|isTemporary|</span><br><span class="line">+--------+-------------------+-----------+</span><br><span class="line">| <span class="keyword">default</span>|            flights|      <span class="literal">false</span>|</span><br><span class="line">| <span class="keyword">default</span>|             view_f|      <span class="literal">false</span>|</span><br><span class="line">|        |                 df|       <span class="literal">true</span>|</span><br><span class="line">|        |replace_temp_view_f|       <span class="literal">true</span>|</span><br><span class="line">|        |        temp_view_f|       <span class="literal">true</span>|</span><br><span class="line">+--------+-------------------+-----------+</span><br></pre></td></tr></table></figure></div><h3 id="访问视图"><a href="#访问视图" class="headerlink" title="访问视图"></a>访问视图</h3><p>定义好视图，就可以像访问表一样在 SQL 中访问视图了：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">spark.sql(<span class="string">&quot;select * from replace_temp_view_f&quot;</span>).show()</span><br><span class="line">+------+---+---+</span><br><span class="line">|     a|  b|  c|</span><br><span class="line">+------+---+---+</span><br><span class="line">|     a|  b|  c|</span><br><span class="line">|caster|  <span class="number">0</span>| <span class="number">26</span>|</span><br><span class="line">|  like|  <span class="number">1</span>| <span class="number">30</span>|</span><br><span class="line">|   leo|  <span class="number">2</span>| <span class="number">30</span>|</span><br><span class="line">|rayray|  <span class="number">3</span>| <span class="number">27</span>|</span><br><span class="line">+------+---+---+</span><br></pre></td></tr></table></figure></div><h3 id="删除视图"><a href="#删除视图" class="headerlink" title="删除视图"></a>删除视图</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">spark.sql(<span class="string">&quot;drop view if exists replace_temp_view_f&quot;</span>)</span><br><span class="line">spark.sql(<span class="string">&quot;show tables&quot;</span>).show()</span><br><span class="line">+--------+-----------+-----------+</span><br><span class="line">|database|  tableName|isTemporary|</span><br><span class="line">+--------+-----------+-----------+</span><br><span class="line">| <span class="keyword">default</span>|    flights|      <span class="literal">false</span>|</span><br><span class="line">| <span class="keyword">default</span>|     view_f|      <span class="literal">false</span>|</span><br><span class="line">|        |         df|       <span class="literal">true</span>|</span><br><span class="line">|        |temp_view_f|       <span class="literal">true</span>|</span><br><span class="line">+--------+-----------+-----------+</span><br></pre></td></tr></table></figure></div><h2 id="Databases"><a href="#Databases" class="headerlink" title="Databases"></a>Databases</h2><p>数据库是用于组织表的工具，如果你没有定义数据库，Spark 将使用默认的数据库，在 Spark 中运行的所有 SQL 语句（包括 DataFrame 命令）都是在数据库的上下文中执行的，如果你更改数据库，则任何用户定义的表都将保留在先前的数据库中，并且要以其他方式查询。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建数据库</span></span><br><span class="line">spark.sql(<span class="string">&quot;create database if not exists some_db&quot;</span>)</span><br><span class="line"><span class="comment">// 查看所有数据库</span></span><br><span class="line">spark.sql(<span class="string">&quot;show databases&quot;</span>).show()</span><br><span class="line">+------------+</span><br><span class="line">|databaseName|</span><br><span class="line">+------------+</span><br><span class="line">|     <span class="keyword">default</span>|</span><br><span class="line">|     some_db|</span><br><span class="line">+------------+</span><br><span class="line"><span class="comment">// 切换数据库</span></span><br><span class="line">spark.sql(<span class="string">&quot;use some_db&quot;</span>)</span><br><span class="line">spark.sql(<span class="string">&quot;show tables&quot;</span>).show()</span><br><span class="line"><span class="comment">// 删除数据库</span></span><br><span class="line">spark.sql(<span class="string">&quot;drop database if exists some_db&quot;</span>)</span><br><span class="line">spark.sql(<span class="string">&quot;show databases&quot;</span>).show()</span><br><span class="line">+------------+</span><br><span class="line">|databaseName|</span><br><span class="line">+------------+</span><br><span class="line">|     <span class="keyword">default</span>|</span><br><span class="line">+------------+</span><br></pre></td></tr></table></figure></div><h2 id="查询语句"><a href="#查询语句" class="headerlink" title="查询语句"></a>查询语句</h2><p>Spark 中的查询支持以下 ANSI SQL 要求（此处列出了 SELECT 表达式的布局）：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SQL"><figure class="iseeu highlight /sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> [<span class="keyword">ALL</span><span class="operator">|</span><span class="keyword">DISTINCT</span>] named_expression[, named_expression, ...]</span><br><span class="line"><span class="keyword">FROM</span> relation[, relation, ...][lateral_view[, lateral_view, ...]]</span><br><span class="line">[<span class="keyword">WHERE</span> boolean_expression]</span><br><span class="line">[aggregation [<span class="keyword">HAVING</span> boolean_expression]]</span><br><span class="line">[<span class="keyword">ORDER</span> <span class="keyword">BY</span> sort_expressions]</span><br><span class="line">[CLUSTER <span class="keyword">BY</span> expressions]</span><br><span class="line">[DISTRIBUTE <span class="keyword">BY</span> expressions]</span><br><span class="line">[SORT <span class="keyword">BY</span> sort_expressions]</span><br><span class="line">[<span class="keyword">WINDOW</span> named_window[, <span class="keyword">WINDOW</span> named_window, ...]]</span><br><span class="line"></span><br><span class="line">named_expression: </span><br><span class="line">:expression [<span class="keyword">AS</span> alias]</span><br><span class="line"></span><br><span class="line">relation:</span><br><span class="line"><span class="operator">|</span> join_relation</span><br><span class="line"><span class="operator">|</span> (table_name<span class="operator">|</span>query<span class="operator">|</span>relation)[sample][<span class="keyword">AS</span> alias]</span><br><span class="line">: <span class="keyword">VALUES</span>(expressions)[, (expressions), ...]</span><br><span class="line">[<span class="keyword">AS</span> (column_name[, column_name, ...])]</span><br><span class="line"></span><br><span class="line">expressions:</span><br><span class="line">   : expressions[, expressions, ...]</span><br><span class="line"></span><br><span class="line">sort_expressions:</span><br><span class="line">    :expressions [<span class="keyword">ASC</span><span class="operator">|</span><span class="keyword">DESC</span>][, expressions [<span class="keyword">ASC</span><span class="operator">|</span><span class="keyword">DESC</span>], ...]</span><br></pre></td></tr></table></figure></div><h2 id="SQL-配置"><a href="#SQL-配置" class="headerlink" title="SQL 配置"></a>SQL 配置</h2><p>查看当前环境 SQL 参数的配置:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">spark.sql(<span class="string">&quot;SET -v&quot;</span>).show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">|key                                                  |value          |meaning                                                                                                                                                                                                                                                                                                                                                                                                                                                             |</span><br><span class="line">+-----------------------------------------------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">|spark.sql.adaptive.enabled                           |<span class="literal">false</span>          |<span class="type">When</span> <span class="literal">true</span>, enable adaptive query execution.                                                                                                                                                                                                                                                                                                                                                                                                                         |</span><br><span class="line">|spark.sql.adaptive.shuffle.targetPostShuffleInputSize|<span class="number">67108864</span>b      |<span class="type">The</span> target post-shuffle input size in bytes of a task.                                                                                                                                                                                                                                                                                                                                                                                                              |</span><br><span class="line">|spark.sql.autoBroadcastJoinThreshold                 |<span class="number">10485760</span>       |<span class="type">Configures</span> the maximum size in bytes <span class="keyword">for</span> a table that will be broadcast to all worker nodes when performing a join.  <span class="type">By</span> setting <span class="keyword">this</span> value to <span class="number">-1</span> broadcasting can be disabled. <span class="type">Note</span> that currently statistics are only supported <span class="keyword">for</span> <span class="type">Hive</span> <span class="type">Metastore</span> tables where the command &lt;code&gt;<span class="type">ANALYZE</span> <span class="type">TABLE</span> &amp;lt;tableName&amp;gt; <span class="type">COMPUTE</span> <span class="type">STATISTICS</span> noscan&lt;/code&gt; has been run, and file-based data source tables where the statistics are computed directly on the files of data.|</span><br><span class="line">|spark.sql.avro.compression.codec                     |snappy         |<span class="type">Compression</span> codec used in writing of <span class="type">AVRO</span> files. <span class="type">Supported</span> codecs: uncompressed, deflate, snappy, bzip2 and xz. <span class="type">Default</span> codec is snappy.                                                                                                                                                                                                                                                                                                                            |</span><br><span class="line">|spark.sql.avro.deflate.level                         |<span class="number">-1</span>             |<span class="type">Compression</span> level <span class="keyword">for</span> the deflate codec used in writing of <span class="type">AVRO</span> files. <span class="type">Valid</span> value must be in the range of from <span class="number">1</span> to <span class="number">9</span> inclusive or <span class="number">-1.</span> <span class="type">The</span> <span class="keyword">default</span> value is <span class="number">-1</span> which corresponds to <span class="number">6</span> level in the current implementation.                                                                                                                                                                                                                                         |</span><br><span class="line">|spark.sql.broadcastTimeout                           |<span class="number">300000</span>ms       |<span class="type">Timeout</span> in seconds <span class="keyword">for</span> the broadcast wait time in broadcast joins.                                                                                                                                                                                                                                                                                                                                                                                                  |</span><br><span class="line">|spark.sql.cbo.enabled                                |<span class="literal">false</span>          |<span class="type">Enables</span> <span class="type">CBO</span> <span class="keyword">for</span> estimation of plan statistics when set <span class="literal">true</span>.                                                                                                                                                                                                                                                                                                                                                                                                        |</span><br><span class="line">|spark.sql.cbo.joinReorder.dp.star.filter             |<span class="literal">false</span>          |<span class="type">Applies</span> star-join filter heuristics to cost based join enumeration.                                                                                                                                                                                                                                                                                                                                                                                                 |</span><br><span class="line">|spark.sql.cbo.joinReorder.dp.threshold               |<span class="number">12</span>             |<span class="type">The</span> maximum number of joined nodes allowed in the dynamic programming algorithm.                                                                                                                                                                                                                                                                                                                                                                                    |</span><br><span class="line">|spark.sql.cbo.joinReorder.enabled                    |<span class="literal">false</span>          |<span class="type">Enables</span> join reorder in <span class="type">CBO</span>.                                                                                                                                                                                                                                                                                                                                                                                                                                        |</span><br><span class="line">|spark.sql.cbo.starSchemaDetection                    |<span class="literal">false</span>          |<span class="type">When</span> <span class="literal">true</span>, it enables join reordering based on star schema detection.                                                                                                                                                                                                                                                                                                                                                                                               |</span><br><span class="line">|spark.sql.columnNameOfCorruptRecord                  |_corrupt_record|<span class="type">The</span> name of internal column <span class="keyword">for</span> storing raw/un-parsed <span class="type">JSON</span> and <span class="type">CSV</span> records that fail to parse.                                                                                                                                                                                                                                                                                                                                                                      |</span><br><span class="line">|spark.sql.crossJoin.enabled                          |<span class="literal">false</span>          |<span class="type">When</span> <span class="literal">false</span>, we will <span class="keyword">throw</span> an error <span class="keyword">if</span> a query contains a cartesian product without explicit <span class="type">CROSS</span> <span class="type">JOIN</span> syntax.                                                                                                                                                                                                                                                                                                                                                      |</span><br><span class="line">|spark.sql.execution.arrow.enabled                    |<span class="literal">false</span>          |<span class="type">When</span> <span class="literal">true</span>, make use of <span class="type">Apache</span> <span class="type">Arrow</span> <span class="keyword">for</span> columnar data transfers. <span class="type">Currently</span> available <span class="keyword">for</span> use <span class="keyword">with</span> pyspark.sql.<span class="type">DataFrame</span>.toPandas, and pyspark.sql.<span class="type">SparkSession</span>.createDataFrame when its input is a <span class="type">Pandas</span> <span class="type">DataFrame</span>. <span class="type">The</span> following data types are unsupported: <span class="type">BinaryType</span>, <span class="type">MapType</span>, <span class="type">ArrayType</span> of <span class="type">TimestampType</span>, and nested <span class="type">StructType</span>.                                                                                                                              |</span><br><span class="line">|spark.sql.execution.arrow.fallback.enabled           |<span class="literal">true</span>           |<span class="type">When</span> <span class="literal">true</span>, optimizations enabled by <span class="symbol">&#x27;spark</span>.sql.execution.arrow.enabled&#x27; will fallback automatically to non-optimized implementations <span class="keyword">if</span> an error occurs.                                                                                                                                                                                                                                                                                                            |</span><br><span class="line">|spark.sql.execution.arrow.maxRecordsPerBatch         |<span class="number">10000</span>          |<span class="type">When</span> using <span class="type">Apache</span> <span class="type">Arrow</span>, limit the maximum number of records that can be written to a single <span class="type">ArrowRecordBatch</span> in memory. <span class="type">If</span> set to zero or negative there is no limit.                                                                                                                                                                                                                                                                                              |</span><br><span class="line">|spark.sql.extensions                                 |&lt;undefined&gt;    |<span class="type">Name</span> of the <span class="class"><span class="keyword">class</span> <span class="title">used</span> <span class="title">to</span> <span class="title">configure</span> <span class="title">Spark</span> <span class="title">Session</span> <span class="title">extensions</span>. <span class="title">The</span> <span class="title">class</span> <span class="title">should</span> <span class="title">implement</span> <span class="title">Function1</span>[<span class="type">SparkSessionExtension</span>, <span class="type">Unit</span>], <span class="title">and</span> <span class="title">must</span> <span class="title">have</span> <span class="title">a</span> <span class="title">no-args</span> <span class="title">constructor</span>.                                                                                                                                                                                                                                                                                               <span class="title">|</span></span></span><br><span class="line">|spark.sql.files.ignoreCorruptFiles                   |<span class="literal">false</span>          |<span class="type">Whether</span> to ignore corrupt files. <span class="type">If</span> <span class="literal">true</span>, the <span class="type">Spark</span> jobs will <span class="keyword">continue</span> to run when encountering corrupted files and the contents that have been read will still be returned.                                                                                                                                                                                                                                                                                        |</span><br><span class="line">|spark.sql.files.ignoreMissingFiles                   |<span class="literal">false</span>          |<span class="type">Whether</span> to ignore missing files. <span class="type">If</span> <span class="literal">true</span>, the <span class="type">Spark</span> jobs will <span class="keyword">continue</span> to run when encountering missing files and the contents that have been read will still be returned.                                                                                                                                                                                                                                                                                          |</span><br><span class="line">|spark.sql.files.maxPartitionBytes                    |<span class="number">134217728</span>      |<span class="type">The</span> maximum number of bytes to pack into a single partition when reading files.                                                                                                                                                                                                                                                                                                                                                                                     |</span><br><span class="line">+-----------------------------------------------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure></div><h3 id="配置项"><a href="#配置项" class="headerlink" title="配置项"></a>配置项</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Job ID /Name</span></span><br><span class="line">spark.app.name=clsfd_ad_attr_map_w_mvca_ins</span><br><span class="line"></span><br><span class="line"><span class="comment">#yarn 进行调度，也可以是mesos，yarn，以及standalone</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#一个spark application，是一个spark应用。一个应用对应且仅对应一个sparkContext。每一个应用，运行一组独立的executor processes。一个应用，可以以多线程的方式提交多个作业job。spark可以运行在多种集群管理器上如：mesos，yarn，以及standalone，每种集群管理器都会提供跨应用的资源调度策略。</span></span><br><span class="line">spark.master=yarn</span><br><span class="line"></span><br><span class="line"><span class="comment">#激活外部shuffle服务。服务维护executor写的文件，因而executor可以被安全移除。</span></span><br><span class="line"><span class="comment">#需要设置spark.dynamicAllocation.enabled 为true，同事指定外部shuffle服务。</span></span><br><span class="line"><span class="comment">#对shuffle来说，executor现将自己的map输出写入到磁盘，然后，自己作为一个server，向其他executor提供这些map输出文件的数据。而动态资源调度将executor返还给集群后，这个shuffle数据服务就没有了。因此，如果要使用动态资源策略，解决这个问题的办法就是，将保持shuffle文件作为一个外部服务，始终运行在spark集群的每个节点上，独立于应用和executor</span></span><br><span class="line">spark.shuffle.service.enabled=true</span><br><span class="line"></span><br><span class="line"><span class="comment">#在默认情况下，三种集群管理器均不使用动态资源调度模式。所以要使用动态资源调度需要提前配置。</span></span><br><span class="line">spark.dynamicAllocation.enabled=true</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果所有的executor都移除了，重新请求时启动的初始executor数</span></span><br><span class="line">spark.dynamicAllocation.initialExecutors=<span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最少保留的executor数</span></span><br><span class="line">spark.dynamicAllocation.minExecutors=<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最多使用的executor数，默认为你申请的最大executor数</span></span><br><span class="line">spark.dynamicAllocation.maxExecutors=<span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以是cluster也可以是Client</span></span><br><span class="line">spark.submit.deployMode=cluster</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定提交到Yarn的资源池</span></span><br><span class="line">spark.yarn.queue=hdlq-data-batch-low</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在yarn-cluster模式下，申请Yarn App Master（包括Driver）所用的内存。</span></span><br><span class="line">spark.driver.memory=8g</span><br><span class="line"><span class="comment"># excutor的核心数</span></span><br><span class="line">spark.executor.cores=<span class="number">16</span></span><br><span class="line"><span class="comment"># 一个Executor对应一个JVM进程。Executor占用的内存分为两部分：ExecutorMemory和MemoryOverhead</span></span><br><span class="line">spark.executor.memory=32g</span><br><span class="line">spark.yarn.executor.memoryOverhead=2g</span><br><span class="line"></span><br><span class="line"><span class="comment"># shuffle分区数100，根据数据量进行调控，这儿配置了Join时shuffle的分区数和聚合数据时的分区数。</span></span><br><span class="line">spark.sql.shuffle.partitions=<span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果用户没有指定并行度，下面这个参数将是RDD中的分区数，它是由join,reducebykey和parallelize </span></span><br><span class="line"><span class="comment"># 这个参数只适用于未加工的RDD不适用于dataframe</span></span><br><span class="line"><span class="comment"># 没有join和聚合计算操作，这个参数将是无效设置</span></span><br><span class="line">spark.default.parallelism</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打包传入一个分区的最大字节，在读取文件的时候。</span></span><br><span class="line">spark.sql.files.maxPartitionBytes=128MB</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用相同时间内可以扫描的数据的大小来衡量打开一个文件的开销。当将多个文件写入同一个分区的时候该参数有用。</span></span><br><span class="line"><span class="comment"># 该值设置大一点有好处，有小文件的分区会比大文件分区处理速度更快（优先调度）。</span></span><br><span class="line">spark.sql.files.openCostInBytes=4MB</span><br><span class="line"></span><br><span class="line"><span class="comment"># Spark 事件总线是SparkListenerEvent事件的阻塞队列大小</span></span><br><span class="line">spark.scheduler.listenerbus.eventqueue.size=<span class="number">100000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 是否启动推测机制</span></span><br><span class="line">spark.speculation=false</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启spark的推测机制，开启推测机制后如果某一台机器的几个task特别慢，推测机制会将任务分配到其他机器执行，最后Spark会选取最快的作为最终结果。</span></span><br><span class="line"><span class="comment"># 2表示比其他task慢两倍时，启动推测机制</span></span><br><span class="line">spark.speculation.multiplier=<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 推测机制的检测周期</span></span><br><span class="line">spark.speculation.interval=5000ms</span><br><span class="line"></span><br><span class="line"><span class="comment"># 完成task的百分比时启动推测</span></span><br><span class="line">spark.speculation.quantile=<span class="number">0.6</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最多允许失败的Executor数量。</span></span><br><span class="line">spark.task.maxFailures=<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># spark序列化 对于优化&lt;网络性能&gt;极为重要，将RDD以序列化格式来保存减少内存占用.</span></span><br><span class="line">spark.serializer=org.apache.spark.serializer.KryoSerializer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为spark是基于内存的机制，所以默认是开启RDD的压缩</span></span><br><span class="line">spark.rdd.compress=true</span><br><span class="line"></span><br><span class="line"><span class="comment"># Spark的安全管理</span></span><br><span class="line"><span class="comment">#https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/SecurityManager.scala</span></span><br><span class="line">spark.ui.view.acls=*</span><br><span class="line">spark.ui.view.acls.groups=*</span><br><span class="line"></span><br><span class="line"><span class="comment"># 表示配置GC线程数为3</span></span><br><span class="line">spark.executor.extraJavaOptions=<span class="string">&quot;-XX:ParallelGCThreads=3&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最大广播表的大小。设置为-1可以禁止该功能。当前统计信息仅支持Hive Metastore表。这里设置的是10MB</span></span><br><span class="line">spark.sql.autoBroadcastJoinThreshold=<span class="number">104857600</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 广播等待超时，这里单位是秒</span></span><br><span class="line">spark.sql.broadcastTimeout=<span class="number">300</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 心跳检测间隔</span></span><br><span class="line">spark.yarn.scheduler.heartbeat.interval-ms=<span class="number">10000</span></span><br><span class="line"></span><br><span class="line">spark.sql.broadcastTimeout</span><br><span class="line"></span><br><span class="line"><span class="comment">#缓存表问题</span></span><br><span class="line"><span class="comment">#spark2.+采用：</span></span><br><span class="line"><span class="comment">#spark.catalog.cacheTable(&quot;tableName&quot;)缓存表，spark.catalog.uncacheTable(&quot;tableName&quot;)解除缓存。</span></span><br><span class="line"><span class="comment">#spark 1.+采用：</span></span><br><span class="line"><span class="comment">#sqlContext.cacheTable(&quot;tableName&quot;)缓存，sqlContext.uncacheTable(&quot;tableName&quot;) 解除缓存</span></span><br><span class="line"><span class="comment">#Sparksql仅仅会缓存必要的列，并且自动调整压缩算法来减少内存和GC压力。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#假如设置为true，SparkSql会根据统计信息自动的为每个列选择压缩方式进行压缩。</span></span><br><span class="line">spark.sql.inMemoryColumnarStorage.compressed=true</span><br><span class="line"></span><br><span class="line"><span class="comment">#控制列缓存的批量大小。批次大有助于改善内存使用和压缩，但是缓存数据会有OOM的风险</span></span><br><span class="line">spark.sql.inMemoryColumnarStorage.batchSize=<span class="number">10000</span></span><br></pre></td></tr></table></figure></div><h3 id="配置方法"><a href="#配置方法" class="headerlink" title="配置方法"></a>配置方法</h3><p>可以在应用程序初始化时或在应用程序执行过程中进行设置：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.conf.set(<span class="string">&quot;spark.sql.crossJoin.enabled&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br></pre></td></tr></table></figure></div><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《Spark 权威指南：Chapter 10》</li><li><a href="https://www.cnblogs.com/cc11001100/p/9463578.html">什么是Catalog</a></li><li><a href="https://spark.apache.org/docs/2.3.0/api/sql/">https://spark.apache.org/docs/2.3.0/api/sql/</a></li></ul><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/sparksql_iteblog.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;SQL（Structured Quer
      
    
    </summary>
    
      <category term="Spark" scheme="http://liketea.xyz/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://liketea.xyz/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark 指南：Spark SQL（四）—— 结构化函数</title>
    <link href="http://liketea.xyz/Spark/Spark/Spark%20%E6%8C%87%E5%8D%97%EF%BC%9ASpark%20SQL%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94%20%E7%BB%93%E6%9E%84%E5%8C%96%E5%87%BD%E6%95%B0/"/>
    <id>http://liketea.xyz/Spark/Spark/Spark 指南：Spark SQL（四）—— 结构化函数/</id>
    <published>2020-11-07T10:51:22.000Z</published>
    <updated>2021-06-02T10:44:40.912Z</updated>
    
    <content type="html"><![CDATA[<p>Spark SQL 结构化函数一般都在 <code>functions</code> 模块，要使用这些函数，需要先导入该模块：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types._</span><br></pre></td></tr></table></figure></div><h2 id="普通函数"><a href="#普通函数" class="headerlink" title="普通函数"></a>普通函数</h2><p>Spark SQL 函数众多，最好的做法就是当需要某个具体功能时在以下列表中检索，或者直接百度谷歌:</p><ul><li>字符串函数: <a href="https://sparkbyexamples.com/spark/usage-of-spark-sql-string-functions/">Spark SQL String Functions</a></li><li>日期时间函数: <a href="https://sparkbyexamples.com/spark/spark-sql-date-and-time-functions/">Spark SQL Date and Time Functions</a></li><li>数组函数: <a href="https://sparkbyexamples.com/spark/spark-sql-array-functions/">Spark SQL Array functions complete list</a></li><li>字典函数: <a href="https://sparkbyexamples.com/spark/spark-sql-map-functions/">Spark SQL Array functions complete list</a></li><li>排序函数: <a href="https://sparkbyexamples.com/spark/spark-sql-sort-functions/">Spark SQL Sort functions</a></li><li>聚合函数: <a href="https://sparkbyexamples.com/spark/spark-sql-aggregate-functions/">Spark SQL Aggregate Functions</a></li></ul><h2 id="聚合函数"><a href="#聚合函数" class="headerlink" title="聚合函数"></a>聚合函数</h2><p>在聚合中，您将指定一个分组和一个聚合函数，该函数必须为每个分组产生一个结果。Spark 的聚合功能是复杂巧妙且成熟的，具有各种不同的用例和可能性。通常，通过分组使用聚合函数去汇总数值型数据，也可以将任何类型的值聚合到 array、list 或 map 中。</p><p>Spark 支持以下分组类型，每个分组都会返回一个 <code>RelationalGroupedDataset</code>，可以在上面指定聚合函数：</p><ol><li>最简单的分组是通过在 <code>select</code> 语句中执行聚合来汇总一个完整的 DataFrame；</li><li><code>group by</code> 允许指定一个或多个 key 以及一个或多个聚合函数来转换列值；</li><li><code>window</code> 可以指定一个或多个 key 以及一个或多个聚合函数来转换列值，但是输入到函数的行以某种方式与当前行有关；</li><li><code>grouping set</code> 可用于在多个不同级别进行聚合，<code>grouping set</code> 可以作为 SQL 原语或通过 DataFrame 中的 <code>rollup</code> 和 <code>cube</code> 使用；<code>group by A, B grouping sets(A, B)</code> 等价于 <code>group by A union group by B</code>；</li><li><code>rollup</code> 可以指定一个或多个 key 以及一个或多个聚合函数来转换列值，这些列将按照层次进行聚合；<code>group by A,B,C with rollup</code> 首先会对 <code>A,B,C</code> 进行 group by，然后对 <code>A,B</code> 进行 group by，最后对 <code>A</code> 进行 group by，再对全表进行 group by，最后将结构进行 union，缺少字段补 null；</li><li><code>cube</code> 可以指定一个或多个 key 以及一个或多个聚合函数来转换列值，这些列将在所有列的组合中进行聚合；<code>group by A,B,C with cube</code>，会对 <code>A, B, C</code> 的所有可能组合进行 group by，最后再将结果 union；</li></ol><p>除了可以在 DataFrame 上或通过 <code>.stat</code> 出现的特殊情况之外，所有聚合都可用作函数，你可以在 <code>org.apache.spark.sql.functions</code> 包中找到大多数聚合函数。</p><h3 id="统计聚合"><a href="#统计聚合" class="headerlink" title="统计聚合"></a>统计聚合</h3><ul><li>DataFrame 级聚合：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// count(&quot;*&quot;) 会显示 count(1)，但是直接写 count(1) 却会报错</span></span><br><span class="line"><span class="comment">// 在整个 DataFrame 上使用 count 会把结果拉回 Driver，是 action，但是用在 select 中是 transformation</span></span><br><span class="line">df.select(count(<span class="string">&quot;stockCode&quot;</span>), count(<span class="string">&quot;*&quot;</span>)).show()</span><br><span class="line">+----------------+--------+</span><br><span class="line">|count(stockCode)|count(<span class="number">1</span>)|</span><br><span class="line">+----------------+--------+</span><br><span class="line">|          <span class="number">541909</span>|  <span class="number">541914</span>|</span><br><span class="line">+----------------+--------+</span><br><span class="line"><span class="comment">// 去重，近似去重（为加速），第二个参数指定允许的最大估计误差</span></span><br><span class="line">df.select(countDistinct(<span class="string">&quot;StockCode&quot;</span>), approx_count_distinct(<span class="string">&quot;StockCode&quot;</span>, <span class="number">0.05</span>)).show()</span><br><span class="line">+-------------------------+--------------------------------+</span><br><span class="line">|count(<span class="type">DISTINCT</span> <span class="type">StockCode</span>)|approx_count_distinct(<span class="type">StockCode</span>)|</span><br><span class="line">+-------------------------+--------------------------------+</span><br><span class="line">|                     <span class="number">4070</span>|                            <span class="number">3804</span>|</span><br><span class="line">+-------------------------+--------------------------------+</span><br><span class="line"><span class="comment">// 第一行、最后一行</span></span><br><span class="line">df.select(first(<span class="string">&quot;StockCode&quot;</span>), last(<span class="string">&quot;StockCode&quot;</span>)).show()</span><br><span class="line">+-----------------------+----------------------+</span><br><span class="line">|first(<span class="type">StockCode</span>, <span class="literal">false</span>)|last(<span class="type">StockCode</span>, <span class="literal">false</span>)|</span><br><span class="line">+-----------------------+----------------------+</span><br><span class="line">|                 <span class="number">85123</span>A|                  <span class="literal">null</span>|</span><br><span class="line">+-----------------------+----------------------+</span><br><span class="line"><span class="comment">// 最大、最小值</span></span><br><span class="line">df.select(min(<span class="string">&quot;Quantity&quot;</span>), max(<span class="string">&quot;Quantity&quot;</span>)).show()</span><br><span class="line">+-------------+-------------+</span><br><span class="line">|min(<span class="type">Quantity</span>)|max(<span class="type">Quantity</span>)|</span><br><span class="line">+-------------+-------------+</span><br><span class="line">|       <span class="number">-80995</span>|        <span class="number">80995</span>|</span><br><span class="line">+-------------+-------------+</span><br><span class="line"><span class="comment">// 求和、去重求和</span></span><br><span class="line">df.select(sum(<span class="string">&quot;Quantity&quot;</span>), sumDistinct(<span class="string">&quot;Quantity&quot;</span>)).show()</span><br><span class="line">+-------------+----------------------+</span><br><span class="line">|sum(<span class="type">Quantity</span>)|sum(<span class="type">DISTINCT</span> <span class="type">Quantity</span>)|</span><br><span class="line">+-------------+----------------------+</span><br><span class="line">|      <span class="number">5176450</span>|                 <span class="number">29310</span>|</span><br><span class="line">+-------------+----------------------+</span><br><span class="line"><span class="comment">// 均值、方差、标准差</span></span><br><span class="line">df.select(avg(<span class="string">&quot;Quantity&quot;</span>), var_pop(<span class="string">&quot;Quantity&quot;</span>), stddev_pop(<span class="string">&quot;Quantity&quot;</span>)).show()</span><br><span class="line">+----------------+------------------+--------------------+</span><br><span class="line">|   avg(<span class="type">Quantity</span>)| var_pop(<span class="type">Quantity</span>)|stddev_pop(<span class="type">Quantity</span>)|</span><br><span class="line">+----------------+------------------+--------------------+</span><br><span class="line">|<span class="number">9.55224954743324</span>|<span class="number">47559.303646609325</span>|  <span class="number">218.08095663447858</span>|</span><br><span class="line">+----------------+------------------+--------------------+</span><br><span class="line"><span class="comment">// 偏度、峰度</span></span><br><span class="line">df.select(skewness(<span class="string">&quot;Quantity&quot;</span>), kurtosis(<span class="string">&quot;Quantity&quot;</span>)).show()</span><br><span class="line">+-------------------+------------------+</span><br><span class="line">| skewness(<span class="type">Quantity</span>)|kurtosis(<span class="type">Quantity</span>)|</span><br><span class="line">+-------------------+------------------+</span><br><span class="line">|<span class="number">-0.2640755761052948</span>| <span class="number">119768.0549553411</span>|</span><br><span class="line">+-------------------+------------------+</span><br><span class="line"><span class="comment">// 相关系数、协方差</span></span><br><span class="line">df.select(corr(<span class="string">&quot;InvoiceNo&quot;</span>, <span class="string">&quot;Quantity&quot;</span>), covar_pop(<span class="string">&quot;InvoiceNo&quot;</span>, <span class="string">&quot;Quantity&quot;</span>)).show()</span><br><span class="line">+-------------------------+------------------------------+</span><br><span class="line">|corr(<span class="type">InvoiceNo</span>, <span class="type">Quantity</span>)|covar_pop(<span class="type">InvoiceNo</span>, <span class="type">Quantity</span>)|</span><br><span class="line">+-------------------------+------------------------------+</span><br><span class="line">|     <span class="number">4.912186085641252E-4</span>|            <span class="number">1052.7260778752557</span>|</span><br><span class="line">+-------------------------+------------------------------+</span><br></pre></td></tr></table></figure></div><ul><li>分组聚合：分组通常是针对分类数据完成的，我们先将数据按照某些列中的值进行分组，然后对被归入同一组的其他列执行聚合计算；事实上，DataFrame 级聚合只是分组聚合的一种特例；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 分组语法</span></span><br><span class="line">groupBy(col1: <span class="type">String</span>, cols: <span class="type">String</span>*)</span><br><span class="line">groupBy(cols: <span class="type">Column</span>*)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 示例，RelationalGroupedDataset 对象也有 count 方法，但是和 DataFrame 的 count 方法会将结果收集到 Driver 不同，这还是一个 transformation</span></span><br><span class="line">df.groupBy(<span class="string">&quot;InvoiceNo&quot;</span>, <span class="string">&quot;CustomerID&quot;</span>).count().show(<span class="number">3</span>)</span><br><span class="line">+---------+----------+-----+</span><br><span class="line">|<span class="type">InvoiceNo</span>|<span class="type">CustomerID</span>|count|</span><br><span class="line">+---------+----------+-----+</span><br><span class="line">|   <span class="number">536846</span>|     <span class="number">14573</span>|   <span class="number">76</span>|</span><br><span class="line">|   <span class="number">537026</span>|     <span class="number">12395</span>|   <span class="number">12</span>|</span><br><span class="line">|   <span class="number">537883</span>|     <span class="number">14437</span>|    <span class="number">5</span>|</span><br><span class="line">+---------+----------+-----+</span><br><span class="line"><span class="comment">// 分组聚合最常用的形式</span></span><br><span class="line">df.groupBy(<span class="string">&quot;InvoiceNo&quot;</span>).agg(</span><br><span class="line">    count(<span class="string">&quot;Quantity&quot;</span>).as(<span class="string">&quot;quan&quot;</span>),</span><br><span class="line">    expr(<span class="string">&quot;count(Quantity)&quot;</span>)</span><br><span class="line">).show(<span class="number">3</span>)</span><br><span class="line">+---------+----+---------------+</span><br><span class="line">|<span class="type">InvoiceNo</span>|quan|count(<span class="type">Quantity</span>)|</span><br><span class="line">+---------+----+---------------+</span><br><span class="line">|   <span class="number">536596</span>|   <span class="number">6</span>|              <span class="number">6</span>|</span><br><span class="line">|   <span class="number">536938</span>|  <span class="number">14</span>|             <span class="number">14</span>|</span><br><span class="line">|   <span class="number">537252</span>|   <span class="number">1</span>|              <span class="number">1</span>|</span><br><span class="line">+---------+----+---------------+</span><br><span class="line"><span class="comment">// map 形式</span></span><br><span class="line">df.groupBy(<span class="string">&quot;InvoiceNo&quot;</span>).agg(<span class="string">&quot;Quantity&quot;</span>-&gt;<span class="string">&quot;avg&quot;</span>, <span class="string">&quot;Quantity&quot;</span>-&gt;<span class="string">&quot;stddev_pop&quot;</span>).show(<span class="number">3</span>)</span><br><span class="line">+---------+------------------+--------------------+</span><br><span class="line">|<span class="type">InvoiceNo</span>|     avg(<span class="type">Quantity</span>)|stddev_pop(<span class="type">Quantity</span>)|</span><br><span class="line">+---------+------------------+--------------------+</span><br><span class="line">|   <span class="number">536596</span>|               <span class="number">1.5</span>|  <span class="number">1.1180339887498947</span>|</span><br><span class="line">|   <span class="number">536938</span>|<span class="number">33.142857142857146</span>|  <span class="number">20.698023172885524</span>|</span><br><span class="line">|   <span class="number">537252</span>|              <span class="number">31.0</span>|                 <span class="number">0.0</span>|</span><br><span class="line">+---------+------------------+--------------------+</span><br></pre></td></tr></table></figure></div><h3 id="多维分析"><a href="#多维分析" class="headerlink" title="多维分析"></a>多维分析</h3><ul><li><code>grouping sets</code>：<code>group by keys grouping sets(combine1(keys), ..., combinen(keys))</code>，其中，<code>keys</code> 包含了所有可能用于分组的字段，<code>combine(keys)</code> 是 keys 的一个子集，聚合函数会分别基于每组 <code>combine(keys)</code> 进行聚合，最后再把所有聚合结果按字段进行 union，不同类型的分组缺失字段补 null；可以通过 null 值在各列上的分布来判断各结果行所属的聚合类型，进一步地，我们可以用 <code>grouping_id()</code> 聚合函数值来标识每一结果行的聚合类型，<code>grouping_id()</code> 首先用二进制表示各个 key 是否为 null，如 <code>(a, null, null)</code> 对应二进制 <code>011</code>，然后再将该二进制数转化为对应的十进制数（在这个例子中，十进制数为 3）得到 <code>grouping_id()</code> 的值；<code>grouping sets</code> 仅在 SQL 中可用，是 group by 子句的扩展，要在 DataFrame 中执行相同的操作，请使用 rollup 和 cube 算子；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sql = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">select area, grade, honor, sum(value) as total_value, grouping_id() as groupId</span></span><br><span class="line"><span class="string">from df </span></span><br><span class="line"><span class="string">group by area, grade, honor grouping sets(area, grade, honor)</span></span><br><span class="line"><span class="string">order by 5</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">spark.sql(sql).show()</span><br><span class="line">+----+-----+-----+-----------+-------+</span><br><span class="line">|area|grade|honor|total_value|groupId|</span><br><span class="line">+----+-----+-----+-----------+-------+</span><br><span class="line">|   a| <span class="literal">null</span>| <span class="literal">null</span>|        <span class="number">915</span>|      <span class="number">3</span>|</span><br><span class="line">|   c| <span class="literal">null</span>| <span class="literal">null</span>|        <span class="number">155</span>|      <span class="number">3</span>|</span><br><span class="line">|   b| <span class="literal">null</span>| <span class="literal">null</span>|        <span class="number">155</span>|      <span class="number">3</span>|</span><br><span class="line">|<span class="literal">null</span>|   ac| <span class="literal">null</span>|        <span class="number">345</span>|      <span class="number">5</span>|</span><br><span class="line">|<span class="literal">null</span>|   ab| <span class="literal">null</span>|        <span class="number">360</span>|      <span class="number">5</span>|</span><br><span class="line">|<span class="literal">null</span>|   aa| <span class="literal">null</span>|        <span class="number">520</span>|      <span class="number">5</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aaf|         <span class="number">30</span>|      <span class="number">6</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aaa|        <span class="number">150</span>|      <span class="number">6</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aah|        <span class="number">180</span>|      <span class="number">6</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aac|        <span class="number">300</span>|      <span class="number">6</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aad|        <span class="number">240</span>|      <span class="number">6</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aae|        <span class="number">120</span>|      <span class="number">6</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aab|         <span class="number">70</span>|      <span class="number">6</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aag|        <span class="number">135</span>|      <span class="number">6</span>|</span><br><span class="line">+----+-----+-----+-----------+-------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// (area, grade) 代表按照 `area, grade` 进行 group by，() 代表在整个 DataFrame 上 group by</span></span><br><span class="line"><span class="keyword">val</span> sql = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">select area, grade, honor, sum(value) as total_value, grouping_id() as groupId</span></span><br><span class="line"><span class="string">from df </span></span><br><span class="line"><span class="string">group by area, grade, honor grouping sets(area, grade, honor, (area, grade), ())</span></span><br><span class="line"><span class="string">order by 5</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">spark.sql(sql).show()</span><br><span class="line">+----+-----+-----+-----------+-------+</span><br><span class="line">|area|grade|honor|total_value|groupId|</span><br><span class="line">+----+-----+-----+-----------+-------+</span><br><span class="line">|   a|   aa| <span class="literal">null</span>|        <span class="number">420</span>|      <span class="number">1</span>|</span><br><span class="line">|   c|   aa| <span class="literal">null</span>|         <span class="number">50</span>|      <span class="number">1</span>|</span><br><span class="line">|   c|   ac| <span class="literal">null</span>|         <span class="number">45</span>|      <span class="number">1</span>|</span><br><span class="line">|   a|   ab| <span class="literal">null</span>|        <span class="number">240</span>|      <span class="number">1</span>|</span><br><span class="line">|   a|   ac| <span class="literal">null</span>|        <span class="number">255</span>|      <span class="number">1</span>|</span><br><span class="line">|   c|   ab| <span class="literal">null</span>|         <span class="number">60</span>|      <span class="number">1</span>|</span><br><span class="line">|   b|   ac| <span class="literal">null</span>|         <span class="number">45</span>|      <span class="number">1</span>|</span><br><span class="line">|   b|   ab| <span class="literal">null</span>|         <span class="number">60</span>|      <span class="number">1</span>|</span><br><span class="line">|   b|   aa| <span class="literal">null</span>|         <span class="number">50</span>|      <span class="number">1</span>|</span><br><span class="line">|   a| <span class="literal">null</span>| <span class="literal">null</span>|        <span class="number">915</span>|      <span class="number">3</span>|</span><br><span class="line">|   c| <span class="literal">null</span>| <span class="literal">null</span>|        <span class="number">155</span>|      <span class="number">3</span>|</span><br><span class="line">|   b| <span class="literal">null</span>| <span class="literal">null</span>|        <span class="number">155</span>|      <span class="number">3</span>|</span><br><span class="line">|<span class="literal">null</span>|   ab| <span class="literal">null</span>|        <span class="number">360</span>|      <span class="number">5</span>|</span><br><span class="line">|<span class="literal">null</span>|   ac| <span class="literal">null</span>|        <span class="number">345</span>|      <span class="number">5</span>|</span><br><span class="line">|<span class="literal">null</span>|   aa| <span class="literal">null</span>|        <span class="number">520</span>|      <span class="number">5</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aaa|        <span class="number">150</span>|      <span class="number">6</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aah|        <span class="number">180</span>|      <span class="number">6</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aad|        <span class="number">240</span>|      <span class="number">6</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aag|        <span class="number">135</span>|      <span class="number">6</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aab|         <span class="number">70</span>|      <span class="number">6</span>|</span><br><span class="line">+----+-----+-----+-----------+-------+</span><br></pre></td></tr></table></figure></div><ul><li><code>rollup</code>：<code>group by A,B,C with rollup</code> 首先会对 <code>A,B,C</code> 进行 group by，然后对 <code>A,B</code> 进行 group by，最后对 <code>A</code> 进行 group by，再对全表进行 group by，最后将结构进行 union，缺少字段补 null；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sql = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">select area,grade,honor,sum(value) as total_value </span></span><br><span class="line"><span class="string">from df </span></span><br><span class="line"><span class="string">group by area,grade,honor with rollup</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">spark.sql(sql)</span><br><span class="line"></span><br><span class="line">df.rollup(<span class="string">&quot;area&quot;</span>, <span class="string">&quot;grade&quot;</span>, <span class="string">&quot;honor&quot;</span>)</span><br><span class="line">    .agg(grouping_id().as(<span class="string">&quot;groupId&quot;</span>), sum(<span class="string">&quot;value&quot;</span>).alias(<span class="string">&quot;total_value&quot;</span>))</span><br><span class="line">    .orderBy(<span class="string">&quot;groupId&quot;</span>)</span><br><span class="line">    .show(<span class="number">100</span>)</span><br><span class="line">+----+-----+-----+-------+-----------+</span><br><span class="line">|area|grade|honor|groupId|total_value|</span><br><span class="line">+----+-----+-----+-------+-----------+</span><br><span class="line">|   c|   ab|  aad|      <span class="number">0</span>|         <span class="number">60</span>|</span><br><span class="line">|   a|   ac|  aah|      <span class="number">0</span>|        <span class="number">180</span>|</span><br><span class="line">|   b|   ab|  aad|      <span class="number">0</span>|         <span class="number">60</span>|</span><br><span class="line">|   a|   ac|  aag|      <span class="number">0</span>|         <span class="number">45</span>|</span><br><span class="line">|   a|   ac|  aaf|      <span class="number">0</span>|         <span class="number">30</span>|</span><br><span class="line">|   a|   aa|  aaa|      <span class="number">0</span>|         <span class="number">50</span>|</span><br><span class="line">|   b|   aa|  aaa|      <span class="number">0</span>|         <span class="number">50</span>|</span><br><span class="line">|   c|   aa|  aaa|      <span class="number">0</span>|         <span class="number">50</span>|</span><br><span class="line">|   a|   aa|  aab|      <span class="number">0</span>|         <span class="number">70</span>|</span><br><span class="line">|   c|   ac|  aag|      <span class="number">0</span>|         <span class="number">45</span>|</span><br><span class="line">|   a|   ab|  aae|      <span class="number">0</span>|        <span class="number">120</span>|</span><br><span class="line">|   b|   ac|  aag|      <span class="number">0</span>|         <span class="number">45</span>|</span><br><span class="line">|   a|   aa|  aac|      <span class="number">0</span>|        <span class="number">300</span>|</span><br><span class="line">|   a|   ab|  aad|      <span class="number">0</span>|        <span class="number">120</span>|</span><br><span class="line">|   a|   ac| <span class="literal">null</span>|      <span class="number">1</span>|        <span class="number">255</span>|</span><br><span class="line">|   c|   ac| <span class="literal">null</span>|      <span class="number">1</span>|         <span class="number">45</span>|</span><br><span class="line">|   c|   aa| <span class="literal">null</span>|      <span class="number">1</span>|         <span class="number">50</span>|</span><br><span class="line">|   c|   ab| <span class="literal">null</span>|      <span class="number">1</span>|         <span class="number">60</span>|</span><br><span class="line">|   b|   aa| <span class="literal">null</span>|      <span class="number">1</span>|         <span class="number">50</span>|</span><br><span class="line">|   b|   ab| <span class="literal">null</span>|      <span class="number">1</span>|         <span class="number">60</span>|</span><br><span class="line">|   b|   ac| <span class="literal">null</span>|      <span class="number">1</span>|         <span class="number">45</span>|</span><br><span class="line">|   a|   ab| <span class="literal">null</span>|      <span class="number">1</span>|        <span class="number">240</span>|</span><br><span class="line">|   a|   aa| <span class="literal">null</span>|      <span class="number">1</span>|        <span class="number">420</span>|</span><br><span class="line">|   a| <span class="literal">null</span>| <span class="literal">null</span>|      <span class="number">3</span>|        <span class="number">915</span>|</span><br><span class="line">|   b| <span class="literal">null</span>| <span class="literal">null</span>|      <span class="number">3</span>|        <span class="number">155</span>|</span><br><span class="line">|   c| <span class="literal">null</span>| <span class="literal">null</span>|      <span class="number">3</span>|        <span class="number">155</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>| <span class="literal">null</span>|      <span class="number">7</span>|       <span class="number">1225</span>|</span><br><span class="line">+----+-----+-----+-------+-----------+</span><br></pre></td></tr></table></figure></div><ul><li><code>cube</code>：<code>group by A,B,C with cube</code>，会对 <code>A, B, C</code> 的所有可能组合进行 group by，最后再将结果 union；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sql = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">select area,grade,honor,sum(value) as total_value </span></span><br><span class="line"><span class="string">from df</span></span><br><span class="line"><span class="string">group by area,grade,honor with cube</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">spark.sql(sql)</span><br><span class="line"></span><br><span class="line">df.cube(<span class="string">&quot;area&quot;</span>, <span class="string">&quot;grade&quot;</span>, <span class="string">&quot;honor&quot;</span>)</span><br><span class="line">    .agg(grouping_id().as(<span class="string">&quot;groupId&quot;</span>),sum(<span class="string">&quot;value&quot;</span>).alias(<span class="string">&quot;total_value&quot;</span>))</span><br><span class="line">    .orderBy(<span class="string">&quot;groupId&quot;</span>)</span><br><span class="line">    .show(<span class="number">100</span>)</span><br><span class="line">+----+-----+-----+-------+-----------+</span><br><span class="line">|area|grade|honor|groupId|total_value|</span><br><span class="line">+----+-----+-----+-------+-----------+</span><br><span class="line">|   c|   ab|  aad|      <span class="number">0</span>|         <span class="number">60</span>|</span><br><span class="line">|   a|   aa|  aab|      <span class="number">0</span>|         <span class="number">70</span>|</span><br><span class="line">|   c|   ac|  aag|      <span class="number">0</span>|         <span class="number">45</span>|</span><br><span class="line">|   b|   aa|  aaa|      <span class="number">0</span>|         <span class="number">50</span>|</span><br><span class="line">|   b|   ab|  aad|      <span class="number">0</span>|         <span class="number">60</span>|</span><br><span class="line">|   c|   aa|  aaa|      <span class="number">0</span>|         <span class="number">50</span>|</span><br><span class="line">|   a|   aa|  aac|      <span class="number">0</span>|        <span class="number">300</span>|</span><br><span class="line">|   b|   ac|  aag|      <span class="number">0</span>|         <span class="number">45</span>|</span><br><span class="line">|   a|   ac|  aag|      <span class="number">0</span>|         <span class="number">45</span>|</span><br><span class="line">|   a|   ac|  aaf|      <span class="number">0</span>|         <span class="number">30</span>|</span><br><span class="line">|   a|   ac|  aah|      <span class="number">0</span>|        <span class="number">180</span>|</span><br><span class="line">|   a|   ab|  aad|      <span class="number">0</span>|        <span class="number">120</span>|</span><br><span class="line">|   a|   aa|  aaa|      <span class="number">0</span>|         <span class="number">50</span>|</span><br><span class="line">|   a|   ab|  aae|      <span class="number">0</span>|        <span class="number">120</span>|</span><br><span class="line">|   b|   aa| <span class="literal">null</span>|      <span class="number">1</span>|         <span class="number">50</span>|</span><br><span class="line">|   a|   ab| <span class="literal">null</span>|      <span class="number">1</span>|        <span class="number">240</span>|</span><br><span class="line">|   c|   ac| <span class="literal">null</span>|      <span class="number">1</span>|         <span class="number">45</span>|</span><br><span class="line">|   b|   ab| <span class="literal">null</span>|      <span class="number">1</span>|         <span class="number">60</span>|</span><br><span class="line">|   a|   ac| <span class="literal">null</span>|      <span class="number">1</span>|        <span class="number">255</span>|</span><br><span class="line">|   c|   ab| <span class="literal">null</span>|      <span class="number">1</span>|         <span class="number">60</span>|</span><br><span class="line">|   b|   ac| <span class="literal">null</span>|      <span class="number">1</span>|         <span class="number">45</span>|</span><br><span class="line">|   a|   aa| <span class="literal">null</span>|      <span class="number">1</span>|        <span class="number">420</span>|</span><br><span class="line">|   c|   aa| <span class="literal">null</span>|      <span class="number">1</span>|         <span class="number">50</span>|</span><br><span class="line">|   a| <span class="literal">null</span>|  aaf|      <span class="number">2</span>|         <span class="number">30</span>|</span><br><span class="line">|   a| <span class="literal">null</span>|  aag|      <span class="number">2</span>|         <span class="number">45</span>|</span><br><span class="line">|   a| <span class="literal">null</span>|  aac|      <span class="number">2</span>|        <span class="number">300</span>|</span><br><span class="line">|   a| <span class="literal">null</span>|  aaa|      <span class="number">2</span>|         <span class="number">50</span>|</span><br><span class="line">|   b| <span class="literal">null</span>|  aad|      <span class="number">2</span>|         <span class="number">60</span>|</span><br><span class="line">|   a| <span class="literal">null</span>|  aab|      <span class="number">2</span>|         <span class="number">70</span>|</span><br><span class="line">|   a| <span class="literal">null</span>|  aah|      <span class="number">2</span>|        <span class="number">180</span>|</span><br><span class="line">|   a| <span class="literal">null</span>|  aae|      <span class="number">2</span>|        <span class="number">120</span>|</span><br><span class="line">|   a| <span class="literal">null</span>|  aad|      <span class="number">2</span>|        <span class="number">120</span>|</span><br><span class="line">|   c| <span class="literal">null</span>|  aaa|      <span class="number">2</span>|         <span class="number">50</span>|</span><br><span class="line">|   c| <span class="literal">null</span>|  aad|      <span class="number">2</span>|         <span class="number">60</span>|</span><br><span class="line">|   b| <span class="literal">null</span>|  aag|      <span class="number">2</span>|         <span class="number">45</span>|</span><br><span class="line">|   b| <span class="literal">null</span>|  aaa|      <span class="number">2</span>|         <span class="number">50</span>|</span><br><span class="line">|   c| <span class="literal">null</span>|  aag|      <span class="number">2</span>|         <span class="number">45</span>|</span><br><span class="line">|   b| <span class="literal">null</span>| <span class="literal">null</span>|      <span class="number">3</span>|        <span class="number">155</span>|</span><br><span class="line">|   c| <span class="literal">null</span>| <span class="literal">null</span>|      <span class="number">3</span>|        <span class="number">155</span>|</span><br><span class="line">|   a| <span class="literal">null</span>| <span class="literal">null</span>|      <span class="number">3</span>|        <span class="number">915</span>|</span><br><span class="line">|<span class="literal">null</span>|   ab|  aad|      <span class="number">4</span>|        <span class="number">240</span>|</span><br><span class="line">|<span class="literal">null</span>|   aa|  aab|      <span class="number">4</span>|         <span class="number">70</span>|</span><br><span class="line">|<span class="literal">null</span>|   ac|  aah|      <span class="number">4</span>|        <span class="number">180</span>|</span><br><span class="line">|<span class="literal">null</span>|   aa|  aaa|      <span class="number">4</span>|        <span class="number">150</span>|</span><br><span class="line">|<span class="literal">null</span>|   ac|  aag|      <span class="number">4</span>|        <span class="number">135</span>|</span><br><span class="line">|<span class="literal">null</span>|   ab|  aae|      <span class="number">4</span>|        <span class="number">120</span>|</span><br><span class="line">|<span class="literal">null</span>|   aa|  aac|      <span class="number">4</span>|        <span class="number">300</span>|</span><br><span class="line">|<span class="literal">null</span>|   ac|  aaf|      <span class="number">4</span>|         <span class="number">30</span>|</span><br><span class="line">|<span class="literal">null</span>|   ab| <span class="literal">null</span>|      <span class="number">5</span>|        <span class="number">360</span>|</span><br><span class="line">|<span class="literal">null</span>|   ac| <span class="literal">null</span>|      <span class="number">5</span>|        <span class="number">345</span>|</span><br><span class="line">|<span class="literal">null</span>|   aa| <span class="literal">null</span>|      <span class="number">5</span>|        <span class="number">520</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aae|      <span class="number">6</span>|        <span class="number">120</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aaa|      <span class="number">6</span>|        <span class="number">150</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aaf|      <span class="number">6</span>|         <span class="number">30</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aad|      <span class="number">6</span>|        <span class="number">240</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aac|      <span class="number">6</span>|        <span class="number">300</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aab|      <span class="number">6</span>|         <span class="number">70</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aah|      <span class="number">6</span>|        <span class="number">180</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>|  aag|      <span class="number">6</span>|        <span class="number">135</span>|</span><br><span class="line">|<span class="literal">null</span>| <span class="literal">null</span>| <span class="literal">null</span>|      <span class="number">7</span>|       <span class="number">1225</span>|</span><br><span class="line">+----+-----+-----+-------+-----------+</span><br></pre></td></tr></table></figure></div><h3 id="聚合为复杂类型"><a href="#聚合为复杂类型" class="headerlink" title="聚合为复杂类型"></a>聚合为复杂类型</h3><p>可以通过 <code>collect_list</code> 和 <code>collect_set</code> 收集某列中的值，前者保留原始顺序，后者不保证顺序但会去重。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> res = df.select(collect_list(<span class="string">&quot;Country&quot;</span>), collect_set(<span class="string">&quot;Country&quot;</span>))</span><br><span class="line">res.show()</span><br><span class="line">res.printSchema</span><br><span class="line">+---------------------+--------------------+</span><br><span class="line">|collect_list(<span class="type">Country</span>)|collect_set(<span class="type">Country</span>)|</span><br><span class="line">+---------------------+--------------------+</span><br><span class="line">| [<span class="type">United</span> <span class="type">Kingdom</span>, ...|[<span class="type">Portugal</span>, <span class="type">Italy</span>,...|</span><br><span class="line">+---------------------+--------------------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- collect_list(<span class="type">Country</span>): array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- element: string (containsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- collect_set(<span class="type">Country</span>): array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- element: string (containsNull = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><h2 id="窗口函数"><a href="#窗口函数" class="headerlink" title="窗口函数"></a>窗口函数</h2><p>Spark 窗口函数对一组行（如frame、partition）进行操作，并为每个输入行返回一个值。窗口函数是一种特殊的聚合函数，但是输入到函数的行以某种方式与当前行有关，函数会为每一行返回一个值。Spark SQL支持三种窗口函数：</p><ol><li>排序函数：row_number() rank() dense_rank() percent_rank() ntile()</li><li>分析函数: cume_dist() lag() lead()</li><li>聚合函数: sum() first() last() max() min() mean() stddev()</li></ol><p>语法：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义窗口</span></span><br><span class="line"><span class="keyword">val</span> window = <span class="type">Window</span>...</span><br><span class="line"><span class="comment">// 在窗口上应用窗口函数，返回列对象</span></span><br><span class="line">windowFunc.over(<span class="type">Window</span>)</span><br></pre></td></tr></table></figure></div><p>示例数据：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Window</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> simpleData = <span class="type">Seq</span>((<span class="string">&quot;James&quot;</span>, <span class="string">&quot;Sales&quot;</span>, <span class="number">3000</span>),</span><br><span class="line">    (<span class="string">&quot;Michael&quot;</span>, <span class="string">&quot;Sales&quot;</span>, <span class="number">4600</span>),</span><br><span class="line">    (<span class="string">&quot;Robert&quot;</span>, <span class="string">&quot;Sales&quot;</span>, <span class="number">4100</span>),</span><br><span class="line">    (<span class="string">&quot;Maria&quot;</span>, <span class="string">&quot;Finance&quot;</span>, <span class="number">3000</span>),</span><br><span class="line">    (<span class="string">&quot;James&quot;</span>, <span class="string">&quot;Sales&quot;</span>, <span class="number">3000</span>),</span><br><span class="line">    (<span class="string">&quot;Scott&quot;</span>, <span class="string">&quot;Finance&quot;</span>, <span class="number">3300</span>),</span><br><span class="line">    (<span class="string">&quot;Jen&quot;</span>, <span class="string">&quot;Finance&quot;</span>, <span class="number">3900</span>),</span><br><span class="line">    (<span class="string">&quot;Jeff&quot;</span>, <span class="string">&quot;Marketing&quot;</span>, <span class="number">3000</span>),</span><br><span class="line">    (<span class="string">&quot;Kumar&quot;</span>, <span class="string">&quot;Marketing&quot;</span>, <span class="number">2000</span>),</span><br><span class="line">    (<span class="string">&quot;Saif&quot;</span>, <span class="string">&quot;Sales&quot;</span>, <span class="number">4100</span>)</span><br><span class="line">    )</span><br><span class="line"><span class="keyword">val</span> df = simpleData.toDF(<span class="string">&quot;employee_name&quot;</span>, <span class="string">&quot;department&quot;</span>, <span class="string">&quot;salary&quot;</span>)</span><br><span class="line">df.show()</span><br><span class="line"></span><br><span class="line">+-------------+----------+------+</span><br><span class="line">|employee_name|department|salary|</span><br><span class="line">+-------------+----------+------+</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|</span><br><span class="line">|      <span class="type">Michael</span>|     <span class="type">Sales</span>|  <span class="number">4600</span>|</span><br><span class="line">|       <span class="type">Robert</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|</span><br><span class="line">|        <span class="type">Maria</span>|   <span class="type">Finance</span>|  <span class="number">3000</span>|</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|</span><br><span class="line">|        <span class="type">Scott</span>|   <span class="type">Finance</span>|  <span class="number">3300</span>|</span><br><span class="line">|          <span class="type">Jen</span>|   <span class="type">Finance</span>|  <span class="number">3900</span>|</span><br><span class="line">|         <span class="type">Jeff</span>| <span class="type">Marketing</span>|  <span class="number">3000</span>|</span><br><span class="line">|        <span class="type">Kumar</span>| <span class="type">Marketing</span>|  <span class="number">2000</span>|</span><br><span class="line">|         <span class="type">Saif</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|</span><br><span class="line">+-------------+----------+------+</span><br></pre></td></tr></table></figure></div><h3 id="排序窗口函数"><a href="#排序窗口函数" class="headerlink" title="排序窗口函数"></a>排序窗口函数</h3><p>用于排序的窗口定义：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 按照指定字段分组，在分组内按照另一字段排序，得到排序窗口，如果需要降序，可以使用col(&quot;salary&quot;).desc </span></span><br><span class="line"><span class="keyword">val</span> windowSpec = <span class="type">Window</span>.partitionBy(<span class="string">&quot;department&quot;</span>).orderBy(<span class="string">&quot;salary&quot;</span>)</span><br></pre></td></tr></table></figure></div><ul><li>row_number: 返回每行排序字段在窗口内的行号；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">df.withColumn(<span class="string">&quot;row_number&quot;</span>,row_number.over(windowSpec))</span><br><span class="line">.show()</span><br><span class="line"></span><br><span class="line">+-------------+----------+------+----------+</span><br><span class="line">|employee_name|department|salary|row_number|</span><br><span class="line">+-------------+----------+------+----------+</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|         <span class="number">1</span>|</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|         <span class="number">2</span>|</span><br><span class="line">|       <span class="type">Robert</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|         <span class="number">3</span>|</span><br><span class="line">|         <span class="type">Saif</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|         <span class="number">4</span>|</span><br><span class="line">|      <span class="type">Michael</span>|     <span class="type">Sales</span>|  <span class="number">4600</span>|         <span class="number">5</span>|</span><br><span class="line">|        <span class="type">Maria</span>|   <span class="type">Finance</span>|  <span class="number">3000</span>|         <span class="number">1</span>|</span><br><span class="line">|        <span class="type">Scott</span>|   <span class="type">Finance</span>|  <span class="number">3300</span>|         <span class="number">2</span>|</span><br><span class="line">|          <span class="type">Jen</span>|   <span class="type">Finance</span>|  <span class="number">3900</span>|         <span class="number">3</span>|</span><br><span class="line">|        <span class="type">Kumar</span>| <span class="type">Marketing</span>|  <span class="number">2000</span>|         <span class="number">1</span>|</span><br><span class="line">|         <span class="type">Jeff</span>| <span class="type">Marketing</span>|  <span class="number">3000</span>|         <span class="number">2</span>|</span><br><span class="line">+-------------+----------+------+----------+</span><br></pre></td></tr></table></figure></div><ul><li>rank: 返回每行排序字段在窗口内的排名，rank=n+1，n 代表窗口内比当前行小的行数；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">df.withColumn(<span class="string">&quot;rank&quot;</span>,rank().over(windowSpec))</span><br><span class="line">.show()</span><br><span class="line"></span><br><span class="line">+-------------+----------+------+----+</span><br><span class="line">|employee_name|department|salary|rank|</span><br><span class="line">+-------------+----------+------+----+</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|   <span class="number">1</span>|</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|   <span class="number">1</span>|</span><br><span class="line">|       <span class="type">Robert</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|   <span class="number">3</span>|</span><br><span class="line">|         <span class="type">Saif</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|   <span class="number">3</span>|</span><br><span class="line">|      <span class="type">Michael</span>|     <span class="type">Sales</span>|  <span class="number">4600</span>|   <span class="number">5</span>|</span><br><span class="line">|        <span class="type">Maria</span>|   <span class="type">Finance</span>|  <span class="number">3000</span>|   <span class="number">1</span>|</span><br><span class="line">|        <span class="type">Scott</span>|   <span class="type">Finance</span>|  <span class="number">3300</span>|   <span class="number">2</span>|</span><br><span class="line">|          <span class="type">Jen</span>|   <span class="type">Finance</span>|  <span class="number">3900</span>|   <span class="number">3</span>|</span><br><span class="line">|        <span class="type">Kumar</span>| <span class="type">Marketing</span>|  <span class="number">2000</span>|   <span class="number">1</span>|</span><br><span class="line">|         <span class="type">Jeff</span>| <span class="type">Marketing</span>|  <span class="number">3000</span>|   <span class="number">2</span>|</span><br><span class="line">+-------------+----------+------+----+</span><br></pre></td></tr></table></figure></div><ul><li>dense_rank: 返回每行排序字段在窗口内的稠密排名，rank=n+1，n 代表窗口内比当前行小的不同取值数；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">df.withColumn(<span class="string">&quot;dense_rank&quot;</span>,dense_rank().over(windowSpec))</span><br><span class="line">.show()</span><br><span class="line"></span><br><span class="line">+-------------+----------+------+----------+</span><br><span class="line">|employee_name|department|salary|dense_rank|</span><br><span class="line">+-------------+----------+------+----------+</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|         <span class="number">1</span>|</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|         <span class="number">1</span>|</span><br><span class="line">|       <span class="type">Robert</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|         <span class="number">2</span>|</span><br><span class="line">|         <span class="type">Saif</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|         <span class="number">2</span>|</span><br><span class="line">|      <span class="type">Michael</span>|     <span class="type">Sales</span>|  <span class="number">4600</span>|         <span class="number">3</span>|</span><br><span class="line">|        <span class="type">Maria</span>|   <span class="type">Finance</span>|  <span class="number">3000</span>|         <span class="number">1</span>|</span><br><span class="line">|        <span class="type">Scott</span>|   <span class="type">Finance</span>|  <span class="number">3300</span>|         <span class="number">2</span>|</span><br><span class="line">|          <span class="type">Jen</span>|   <span class="type">Finance</span>|  <span class="number">3900</span>|         <span class="number">3</span>|</span><br><span class="line">|        <span class="type">Kumar</span>| <span class="type">Marketing</span>|  <span class="number">2000</span>|         <span class="number">1</span>|</span><br><span class="line">|         <span class="type">Jeff</span>| <span class="type">Marketing</span>|  <span class="number">3000</span>|         <span class="number">2</span>|</span><br><span class="line">+-------------+----------+------+----------+</span><br></pre></td></tr></table></figure></div><ul><li>percent_rank: 返回每行排序字段在窗口内的百分位排名；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//percent_rank</span></span><br><span class="line">df.withColumn(<span class="string">&quot;percent_rank&quot;</span>,percent_rank().over(windowSpec))</span><br><span class="line">.show()</span><br><span class="line"></span><br><span class="line">+-------------+----------+------+------------+</span><br><span class="line">|employee_name|department|salary|percent_rank|</span><br><span class="line">+-------------+----------+------+------------+</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|         <span class="number">0.0</span>|</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|         <span class="number">0.0</span>|</span><br><span class="line">|       <span class="type">Robert</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|         <span class="number">0.5</span>|</span><br><span class="line">|         <span class="type">Saif</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|         <span class="number">0.5</span>|</span><br><span class="line">|      <span class="type">Michael</span>|     <span class="type">Sales</span>|  <span class="number">4600</span>|         <span class="number">1.0</span>|</span><br><span class="line">|        <span class="type">Maria</span>|   <span class="type">Finance</span>|  <span class="number">3000</span>|         <span class="number">0.0</span>|</span><br><span class="line">|        <span class="type">Scott</span>|   <span class="type">Finance</span>|  <span class="number">3300</span>|         <span class="number">0.5</span>|</span><br><span class="line">|          <span class="type">Jen</span>|   <span class="type">Finance</span>|  <span class="number">3900</span>|         <span class="number">1.0</span>|</span><br><span class="line">|        <span class="type">Kumar</span>| <span class="type">Marketing</span>|  <span class="number">2000</span>|         <span class="number">0.0</span>|</span><br><span class="line">|         <span class="type">Jeff</span>| <span class="type">Marketing</span>|  <span class="number">3000</span>|         <span class="number">1.0</span>|</span><br><span class="line">+-------------+----------+------+------------+</span><br></pre></td></tr></table></figure></div><ul><li>ntile: 返回窗口分区中结果行的相对排名，在下面的示例中，我们使用2作为ntile的参数，因此它返回介于2个值（1和2）之间的排名；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">df.withColumn(<span class="string">&quot;ntile&quot;</span>,ntile(<span class="number">2</span>).over(windowSpec))</span><br><span class="line">.show()</span><br><span class="line"></span><br><span class="line">+-------------+----------+------+-----+</span><br><span class="line">|employee_name|department|salary|ntile|</span><br><span class="line">+-------------+----------+------+-----+</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|    <span class="number">1</span>|</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|    <span class="number">1</span>|</span><br><span class="line">|       <span class="type">Robert</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|    <span class="number">1</span>|</span><br><span class="line">|         <span class="type">Saif</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|    <span class="number">2</span>|</span><br><span class="line">|      <span class="type">Michael</span>|     <span class="type">Sales</span>|  <span class="number">4600</span>|    <span class="number">2</span>|</span><br><span class="line">|        <span class="type">Maria</span>|   <span class="type">Finance</span>|  <span class="number">3000</span>|    <span class="number">1</span>|</span><br><span class="line">|        <span class="type">Scott</span>|   <span class="type">Finance</span>|  <span class="number">3300</span>|    <span class="number">1</span>|</span><br><span class="line">|          <span class="type">Jen</span>|   <span class="type">Finance</span>|  <span class="number">3900</span>|    <span class="number">2</span>|</span><br><span class="line">|        <span class="type">Kumar</span>| <span class="type">Marketing</span>|  <span class="number">2000</span>|    <span class="number">1</span>|</span><br><span class="line">|         <span class="type">Jeff</span>| <span class="type">Marketing</span>|  <span class="number">3000</span>|    <span class="number">2</span>|</span><br><span class="line">+-------------+----------+------+-----+</span><br></pre></td></tr></table></figure></div><h3 id="分析窗口函数"><a href="#分析窗口函数" class="headerlink" title="分析窗口函数"></a>分析窗口函数</h3><ul><li>cume_dist: 窗口函数用于获取窗口分区内值的累积分布，和 SQL 中的 DENSE_RANK 作用相同</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">df.withColumn(<span class="string">&quot;cume_dist&quot;</span>,cume_dist().over(windowSpec)).show()</span><br><span class="line"></span><br><span class="line">+-------------+----------+------+------------------+</span><br><span class="line">|employee_name|department|salary|         cume_dist|</span><br><span class="line">+-------------+----------+------+------------------+</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|               <span class="number">0.4</span>|</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|               <span class="number">0.4</span>|</span><br><span class="line">|       <span class="type">Robert</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|               <span class="number">0.8</span>|</span><br><span class="line">|         <span class="type">Saif</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|               <span class="number">0.8</span>|</span><br><span class="line">|      <span class="type">Michael</span>|     <span class="type">Sales</span>|  <span class="number">4600</span>|               <span class="number">1.0</span>|</span><br><span class="line">|        <span class="type">Maria</span>|   <span class="type">Finance</span>|  <span class="number">3000</span>|<span class="number">0.3333333333333333</span>|</span><br><span class="line">|        <span class="type">Scott</span>|   <span class="type">Finance</span>|  <span class="number">3300</span>|<span class="number">0.6666666666666666</span>|</span><br><span class="line">|          <span class="type">Jen</span>|   <span class="type">Finance</span>|  <span class="number">3900</span>|               <span class="number">1.0</span>|</span><br><span class="line">|        <span class="type">Kumar</span>| <span class="type">Marketing</span>|  <span class="number">2000</span>|               <span class="number">0.5</span>|</span><br><span class="line">|         <span class="type">Jeff</span>| <span class="type">Marketing</span>|  <span class="number">3000</span>|               <span class="number">1.0</span>|</span><br><span class="line">+-------------+----------+------+------------------+</span><br></pre></td></tr></table></figure></div><ul><li>lag: 和 SQL 中的 LAG 函数相同，返回值为当前行之前的 offset 行，如果当前行之前的行少于 offset，则返回“ null”。</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">df.withColumn(<span class="string">&quot;lag&quot;</span>,lag(<span class="string">&quot;salary&quot;</span>,<span class="number">2</span>).over(windowSpec)).show()</span><br><span class="line"></span><br><span class="line">+-------------+----------+------+----+</span><br><span class="line">|employee_name|department|salary| lag|</span><br><span class="line">+-------------+----------+------+----+</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|<span class="literal">null</span>|</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|<span class="literal">null</span>|</span><br><span class="line">|       <span class="type">Robert</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|<span class="number">3000</span>|</span><br><span class="line">|         <span class="type">Saif</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|<span class="number">3000</span>|</span><br><span class="line">|      <span class="type">Michael</span>|     <span class="type">Sales</span>|  <span class="number">4600</span>|<span class="number">4100</span>|</span><br><span class="line">|        <span class="type">Maria</span>|   <span class="type">Finance</span>|  <span class="number">3000</span>|<span class="literal">null</span>|</span><br><span class="line">|        <span class="type">Scott</span>|   <span class="type">Finance</span>|  <span class="number">3300</span>|<span class="literal">null</span>|</span><br><span class="line">|          <span class="type">Jen</span>|   <span class="type">Finance</span>|  <span class="number">3900</span>|<span class="number">3000</span>|</span><br><span class="line">|        <span class="type">Kumar</span>| <span class="type">Marketing</span>|  <span class="number">2000</span>|<span class="literal">null</span>|</span><br><span class="line">|         <span class="type">Jeff</span>| <span class="type">Marketing</span>|  <span class="number">3000</span>|<span class="literal">null</span>|</span><br><span class="line">+-------------+----------+------+----+</span><br></pre></td></tr></table></figure></div><ul><li>lead: 和 SQL 中的 LEAD 函数相同，返回值为当前行之后的 offset 行，如果当前行之后的行少于 offset，则返回“ null”。</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">df.withColumn(<span class="string">&quot;lead&quot;</span>,lead(<span class="string">&quot;salary&quot;</span>,<span class="number">2</span>).over(windowSpec)).show()</span><br><span class="line"></span><br><span class="line">+-------------+----------+------+----+</span><br><span class="line">|employee_name|department|salary|lead|</span><br><span class="line">+-------------+----------+------+----+</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|<span class="number">4100</span>|</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|<span class="number">4100</span>|</span><br><span class="line">|       <span class="type">Robert</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|<span class="number">4600</span>|</span><br><span class="line">|         <span class="type">Saif</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|<span class="literal">null</span>|</span><br><span class="line">|      <span class="type">Michael</span>|     <span class="type">Sales</span>|  <span class="number">4600</span>|<span class="literal">null</span>|</span><br><span class="line">|        <span class="type">Maria</span>|   <span class="type">Finance</span>|  <span class="number">3000</span>|<span class="number">3900</span>|</span><br><span class="line">|        <span class="type">Scott</span>|   <span class="type">Finance</span>|  <span class="number">3300</span>|<span class="literal">null</span>|</span><br><span class="line">|          <span class="type">Jen</span>|   <span class="type">Finance</span>|  <span class="number">3900</span>|<span class="literal">null</span>|</span><br><span class="line">|        <span class="type">Kumar</span>| <span class="type">Marketing</span>|  <span class="number">2000</span>|<span class="literal">null</span>|</span><br><span class="line">|         <span class="type">Jeff</span>| <span class="type">Marketing</span>|  <span class="number">3000</span>|<span class="literal">null</span>|</span><br><span class="line">+-------------+----------+------+----+</span><br></pre></td></tr></table></figure></div><h3 id="聚合窗口函数"><a href="#聚合窗口函数" class="headerlink" title="聚合窗口函数"></a>聚合窗口函数</h3><p>在本部分中，我将解释如何使用 Spark SQL Aggregate 窗口函数和 WindowSpec 计算每个分组的总和，最小值，最大值，使用聚合函数时，order by 子句特别重要，影响着最后聚合的具体范围。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> windowSpec = <span class="type">Window</span>.partitionBy(<span class="string">&quot;department&quot;</span>).orderBy(<span class="string">&quot;salary&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> res = df.withColumn(<span class="string">&quot;row&quot;</span>,row_number.over(windowSpec))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 不排序: 每一行都是基于全组做聚合，默认所有行有相同的次序</span></span><br><span class="line"><span class="keyword">val</span> windowSpecAgg  = <span class="type">Window</span>.partitionBy(<span class="string">&quot;department&quot;</span>)</span><br><span class="line"><span class="comment">// 通过某个字段 f 排序，每一行对全组所有 &lt;= 当前行该字段值的做聚合</span></span><br><span class="line"><span class="keyword">val</span> windowSpecSalaryAgg  = <span class="type">Window</span>.partitionBy(<span class="string">&quot;department&quot;</span>).orderBy(<span class="string">&quot;salary&quot;</span>)</span><br><span class="line"><span class="comment">// 以 row 排序，每一行对全组所有 row &lt;= 当前 row 值的做聚合，等价于累积聚合</span></span><br><span class="line"><span class="keyword">val</span> windowSpecRowAgg  = <span class="type">Window</span>.partitionBy(<span class="string">&quot;department&quot;</span>).orderBy(<span class="string">&quot;row&quot;</span>)</span><br><span class="line"><span class="comment">// 以 row 排序，每一行对附近偏移范围内的数据做聚合</span></span><br><span class="line"><span class="keyword">val</span> windowSpecBetweenAgg  = <span class="type">Window</span>.partitionBy(<span class="string">&quot;department&quot;</span>).orderBy(<span class="string">&quot;row&quot;</span>).rowsBetween(<span class="number">-2</span>, <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">res.withColumn(<span class="string">&quot;sum&quot;</span>, sum(col(<span class="string">&quot;salary&quot;</span>)).over(windowSpecAgg))</span><br><span class="line">   .withColumn(<span class="string">&quot;salarysum&quot;</span>, sum(col(<span class="string">&quot;salary&quot;</span>)).over(windowSpecSalaryAgg))</span><br><span class="line">   .withColumn(<span class="string">&quot;rowsum&quot;</span>, sum(col(<span class="string">&quot;salary&quot;</span>)).over(windowSpecRowAgg))</span><br><span class="line">   .withColumn(<span class="string">&quot;betweensum&quot;</span>, sum(col(<span class="string">&quot;salary&quot;</span>)).over(windowSpecBetweenAgg))</span><br><span class="line">   .show()</span><br><span class="line"></span><br><span class="line">+-------------+----------+------+---+-----+---------+------+----------+</span><br><span class="line">|employee_name|department|salary|row|  sum|salarysum|rowsum|betweensum|</span><br><span class="line">+-------------+----------+------+---+-----+---------+------+----------+</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|  <span class="number">1</span>|<span class="number">18800</span>|     <span class="number">6000</span>|  <span class="number">3000</span>|      <span class="literal">null</span>|</span><br><span class="line">|        <span class="type">James</span>|     <span class="type">Sales</span>|  <span class="number">3000</span>|  <span class="number">2</span>|<span class="number">18800</span>|     <span class="number">6000</span>|  <span class="number">6000</span>|      <span class="number">3000</span>|</span><br><span class="line">|       <span class="type">Robert</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|  <span class="number">3</span>|<span class="number">18800</span>|    <span class="number">14200</span>| <span class="number">10100</span>|      <span class="number">6000</span>|</span><br><span class="line">|         <span class="type">Saif</span>|     <span class="type">Sales</span>|  <span class="number">4100</span>|  <span class="number">4</span>|<span class="number">18800</span>|    <span class="number">14200</span>| <span class="number">14200</span>|      <span class="number">7100</span>|</span><br><span class="line">|      <span class="type">Michael</span>|     <span class="type">Sales</span>|  <span class="number">4600</span>|  <span class="number">5</span>|<span class="number">18800</span>|    <span class="number">18800</span>| <span class="number">18800</span>|      <span class="number">8200</span>|</span><br><span class="line">|        <span class="type">Maria</span>|   <span class="type">Finance</span>|  <span class="number">3000</span>|  <span class="number">1</span>|<span class="number">10200</span>|     <span class="number">3000</span>|  <span class="number">3000</span>|      <span class="literal">null</span>|</span><br><span class="line">|        <span class="type">Scott</span>|   <span class="type">Finance</span>|  <span class="number">3300</span>|  <span class="number">2</span>|<span class="number">10200</span>|     <span class="number">6300</span>|  <span class="number">6300</span>|      <span class="number">3000</span>|</span><br><span class="line">|          <span class="type">Jen</span>|   <span class="type">Finance</span>|  <span class="number">3900</span>|  <span class="number">3</span>|<span class="number">10200</span>|    <span class="number">10200</span>| <span class="number">10200</span>|      <span class="number">6300</span>|</span><br><span class="line">|        <span class="type">Kumar</span>| <span class="type">Marketing</span>|  <span class="number">2000</span>|  <span class="number">1</span>| <span class="number">5000</span>|     <span class="number">2000</span>|  <span class="number">2000</span>|      <span class="literal">null</span>|</span><br><span class="line">|         <span class="type">Jeff</span>| <span class="type">Marketing</span>|  <span class="number">3000</span>|  <span class="number">2</span>| <span class="number">5000</span>|     <span class="number">5000</span>|  <span class="number">5000</span>|      <span class="number">2000</span>|</span><br><span class="line">+-------------+----------+------+---+-----+---------+------+----------+</span><br></pre></td></tr></table></figure></div><h2 id="自定义函数"><a href="#自定义函数" class="headerlink" title="自定义函数"></a>自定义函数</h2><p>自定义函数是 Spark SQL 最有用的特性之一，它扩展了 Spark 的内置函数，允许用户实现更加复杂的计算逻辑。但是，自定义函数是 Spark 的黑匣子，无法利用 Spark SQL 的优化器，自定义函数将失去 Spark 在 Dataframe / Dataset 上所做的所有优化，通常性能和安全性较差。如果可能，应尽量选用 Spark SQL 内置函数，因为这些函数提供了优化。</p><p>根据自定义函数是作用于单行还是多行，可以将其划分为两类：</p><ol><li>UDF：User Defined Function，即用户自定义函数，接收一行输入并返回一个输出；</li><li>UDAF：User Defined Aggregate Function，即用户自定义的聚合函数，接收多行输入并返回一个输出；</li></ol><h3 id="UDF"><a href="#UDF" class="headerlink" title="UDF"></a>UDF</h3><p>使用 UDF 的一般步骤：</p><ol><li><strong>定义普通函数</strong>：与定义一般函数的方式完全相同，但是需要额外注意<ol><li>UDF 中参数和返回值类型并不是我们可以随意定义的，因为涉及到数据的序列化和反序列化，详情参考“传递复杂数据类型”一节；</li><li><code>null</code> 值的处理，如果设计不当，UDF 很容易出错，最好的做法是在函数内部检查 <code>null</code>，而不是在外部检查 <code>null</code>；</li></ol></li><li><strong>注册 UDF</strong>：在 DataFrame API 和 SQL 表达式中使用的 UDF 注册方式有所差异<ol><li>如果要在 DataFrame API 中使用：<code>val 函数名 = org.apache.spark.sql.functions.udf(函数值)</code>；</li><li>如果要在 SQL 表达式中使用：<code>sparkSession.udf.register(函数名, 函数值)</code>；</li></ol></li><li><strong>应用 UDF</strong>：与应用 Spark 内置函数的方法完全相同，只不过原始函数中的变长参数会被注册为 <code>ArrayType</code> 类型，实际传参时也要传入 <code>ArrayType</code> 类型的实参；</li></ol><h4 id="传递简单数据类型"><a href="#传递简单数据类型" class="headerlink" title="传递简单数据类型"></a>传递简单数据类型</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 示例数据</span></span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"><span class="keyword">val</span> columns = <span class="type">Seq</span>(<span class="string">&quot;Seqno&quot;</span>,<span class="string">&quot;Quote&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> data = <span class="type">Seq</span>((<span class="string">&quot;1&quot;</span>, <span class="string">&quot;Be the change that you wish to see in the world&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;2&quot;</span>, <span class="string">&quot;Everyone thinks of changing the world, but no one thinks of changing himself.&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;3&quot;</span>, <span class="string">&quot;The purpose of our lives is to be happy.&quot;</span>)</span><br><span class="line">  )</span><br><span class="line"><span class="keyword">val</span> df = data.toDF(columns:_*)</span><br><span class="line">df.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+-----+-----------------------------------------------------------------------------+</span><br><span class="line">|<span class="type">Seqno</span>|<span class="type">Quote</span>                                                                        |</span><br><span class="line">+-----+-----------------------------------------------------------------------------+</span><br><span class="line">|<span class="number">1</span>    |<span class="type">Be</span> the change that you wish to see in the world                              |</span><br><span class="line">|<span class="number">2</span>    |<span class="type">Everyone</span> thinks of changing the world, but no one thinks of changing himself.|</span><br><span class="line">|<span class="number">3</span>    |<span class="type">The</span> purpose of our lives is to be happy.                                     |</span><br><span class="line">+-----+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure></div><ul><li>创建一个普通函数:</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// convertCase 是一个函数值，将句子中每个单词首字母改为大写</span></span><br><span class="line"><span class="keyword">val</span> convertCase =  (strQuote:<span class="type">String</span>) =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> arr = strQuote.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">    arr.map(f=&gt;  f.substring(<span class="number">0</span>,<span class="number">1</span>).toUpperCase + f.substring(<span class="number">1</span>,f.length)).mkString(<span class="string">&quot; &quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><ul><li>在 DataFrame 中使用 UDF:</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.udf</span><br><span class="line"><span class="comment">// 1. 创建 Spark UDF，传给 udf 的是一个函数值，如果 x 只是一个普通函数名，则需传入 x _</span></span><br><span class="line"><span class="keyword">val</span> convertUDF = udf(convertCase)</span><br><span class="line">convertUDF: org.apache.spark.sql.expressions.<span class="type">UserDefinedFunction</span> = <span class="type">UserDefinedFunction</span>(&lt;function1&gt;,<span class="type">StringType</span>,<span class="type">Some</span>(<span class="type">List</span>(<span class="type">StringType</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 在 DataFrame 中使用 UDF</span></span><br><span class="line">df.select(col(<span class="string">&quot;Seqno&quot;</span>), convertUDF(col(<span class="string">&quot;Quote&quot;</span>)).as(<span class="string">&quot;Quote&quot;</span>) ).show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">+-----+-----------------------------------------------------------------------------+</span><br><span class="line">|<span class="type">Seqno</span>|<span class="type">Quote</span>                                                                        |</span><br><span class="line">+-----+-----------------------------------------------------------------------------+</span><br><span class="line">|<span class="number">1</span>    |<span class="type">Be</span> <span class="type">The</span> <span class="type">Change</span> <span class="type">That</span> <span class="type">You</span> <span class="type">Wish</span> <span class="type">To</span> <span class="type">See</span> <span class="type">In</span> <span class="type">The</span> <span class="type">World</span>                              |</span><br><span class="line">|<span class="number">2</span>    |<span class="type">Everyone</span> <span class="type">Thinks</span> <span class="type">Of</span> <span class="type">Changing</span> <span class="type">The</span> <span class="type">World</span>, <span class="type">But</span> <span class="type">No</span> <span class="type">One</span> <span class="type">Thinks</span> <span class="type">Of</span> <span class="type">Changing</span> <span class="type">Himself</span>.|</span><br><span class="line">|<span class="number">3</span>    |<span class="type">The</span> <span class="type">Purpose</span> <span class="type">Of</span> <span class="type">Our</span> <span class="type">Lives</span> <span class="type">Is</span> <span class="type">To</span> <span class="type">Be</span> <span class="type">Happy</span>.                                     |</span><br></pre></td></tr></table></figure></div><ul><li>在 SQL 中使用 UDF:</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. 注册 UDF</span></span><br><span class="line">spark.udf.register(<span class="string">&quot;convertUDF&quot;</span>, convertCase)</span><br><span class="line"><span class="comment">// 2. 在 SQL 中使用 UDF，得到同样的结果输出</span></span><br><span class="line">df.createOrReplaceTempView(<span class="string">&quot;QUOTE_TABLE&quot;</span>)</span><br><span class="line">spark.sql(<span class="string">&quot;select Seqno, convertUDF(Quote) from QUOTE_TABLE&quot;</span>).show(<span class="literal">false</span>)</span><br></pre></td></tr></table></figure></div><h4 id="传递复杂数据类型"><a href="#传递复杂数据类型" class="headerlink" title="传递复杂数据类型"></a>传递复杂数据类型</h4><p>在 “Spark SQL 数据类型”一文曾介绍过 Spark 类型和 Scala 类型之间的对应关系，当 UDF 在 Spark 和 Scala 之间传递参数和返回值时也遵循同样的对应关系，下面列出了 Spark 中复杂类型与 Scala 本地类型之间的对应关系：</p><div class="table-container"><table><thead><tr><th>Spark 类型</th><th>udf 参数类型</th><th>udf 返回值类型</th></tr></thead><tbody><tr><td>StructType</td><td>Row</td><td>Tuple/case class</td></tr><tr><td>ArrayType</td><td>Seq</td><td>Seq/Array/List</td></tr><tr><td>MapType</td><td>Map</td><td>Map</td></tr></tbody></table></div><p>本部分将使用如下示例数据来演示以上各种场景：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = <span class="type">Seq</span>(</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;M&quot;</span>, <span class="number">3000</span>, <span class="type">Row</span>(<span class="string">&quot;James &quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;Smith&quot;</span>), <span class="type">Seq</span>(<span class="number">1</span>,<span class="number">2</span>), <span class="type">Map</span>(<span class="string">&quot;1&quot;</span>-&gt;<span class="string">&quot;a&quot;</span>, <span class="string">&quot;11&quot;</span>-&gt;<span class="string">&quot;aa&quot;</span>)),</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;M&quot;</span>, <span class="number">4000</span>, <span class="type">Row</span>(<span class="string">&quot;Michael &quot;</span>,<span class="string">&quot;Rose&quot;</span>,<span class="string">&quot;&quot;</span>), <span class="type">Seq</span>(<span class="number">3</span>,<span class="number">2</span>), <span class="type">Map</span>(<span class="string">&quot;2&quot;</span>-&gt;<span class="string">&quot;b&quot;</span>, <span class="string">&quot;22&quot;</span>-&gt;<span class="string">&quot;bb&quot;</span>)),</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;M&quot;</span>, <span class="number">4000</span>, <span class="type">Row</span>(<span class="string">&quot;Robert &quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;Williams&quot;</span>), <span class="type">Seq</span>(<span class="number">1</span>,<span class="number">2</span>), <span class="type">Map</span>(<span class="string">&quot;3&quot;</span>-&gt;<span class="string">&quot;c&quot;</span>, <span class="string">&quot;33&quot;</span>-&gt;<span class="string">&quot;cc&quot;</span>)),</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;F&quot;</span>, <span class="number">4000</span>, <span class="type">Row</span>(<span class="string">&quot;Maria &quot;</span>,<span class="string">&quot;Anne&quot;</span>,<span class="string">&quot;Jones&quot;</span>), <span class="type">Seq</span>(<span class="number">3</span>,<span class="number">3</span>), <span class="type">Map</span>(<span class="string">&quot;4&quot;</span>-&gt;<span class="string">&quot;d&quot;</span>, <span class="string">&quot;44&quot;</span>-&gt;<span class="string">&quot;dd&quot;</span>)),</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;F&quot;</span>, <span class="number">-1</span>, <span class="type">Row</span>(<span class="string">&quot;Jen&quot;</span>,<span class="string">&quot;Mary&quot;</span>,<span class="string">&quot;Brown&quot;</span>), <span class="type">Seq</span>(<span class="number">5</span>,<span class="number">2</span>), <span class="type">Map</span>(<span class="string">&quot;5&quot;</span>-&gt;<span class="string">&quot;e&quot;</span>))</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> schema = <span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">      .add(<span class="string">&quot;gender&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      .add(<span class="string">&quot;salary&quot;</span>,<span class="type">IntegerType</span>)</span><br><span class="line">      .add(<span class="string">&quot;f_struct&quot;</span>,</span><br><span class="line">        <span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">          .add(<span class="string">&quot;firstname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">          .add(<span class="string">&quot;middlename&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">          .add(<span class="string">&quot;lastname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      )  </span><br><span class="line">      .add(<span class="string">&quot;f_array&quot;</span>, <span class="type">ArrayType</span>(<span class="type">IntegerType</span>))</span><br><span class="line">      .add(<span class="string">&quot;f_map&quot;</span>, <span class="type">MapType</span>(<span class="type">StringType</span>, <span class="type">StringType</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df = spark.createDataFrame(spark.sparkContext.parallelize(data),schema)</span><br><span class="line">df.show()</span><br><span class="line">df.printSchema</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line">|gender|salary|            f_struct|f_array|             f_map|</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">3000</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]| [<span class="number">3</span>, <span class="number">2</span>]|[<span class="number">2</span> -&gt; b, <span class="number">22</span> -&gt; bb]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|[<span class="type">Robert</span> , , <span class="type">Willi</span>...| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">3</span> -&gt; c, <span class="number">33</span> -&gt; cc]|</span><br><span class="line">|     <span class="type">F</span>|  <span class="number">4000</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...| [<span class="number">3</span>, <span class="number">3</span>]|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]|</span><br><span class="line">|     <span class="type">F</span>|    <span class="number">-1</span>|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]| [<span class="number">5</span>, <span class="number">2</span>]|          [<span class="number">5</span> -&gt; e]|</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- gender: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_struct: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- firstname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- middlename: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- lastname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_array: array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- element: integer (containsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- f_map: map (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- key: string</span><br><span class="line"> |    |-- value: string (valueContainsNull = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><h5 id="StructType"><a href="#StructType" class="headerlink" title="StructType"></a>StructType</h5><p>如果传给 udf 的是 <code>StructType</code> 类型，udf 参数类型应该定义为 <code>Row</code>类型；如果需要 udf 返回 <code>StructType</code> 类型，udf 返回值类型应该定义为 <code>Tuple</code> 或 <code>case class</code>；</p><ul><li>udf 返回值类型可以是 <code>Tuple</code>：<code>Tuple</code> 返回值会被转化为 <code>struct</code>，<code>Tuple</code> 的各个元素分别对应 <code>struct</code> 的各个子域 <code>_1</code>、<code>_2</code>……</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 数据类型转化过程：Struct =&gt; Row =&gt; Tuple =&gt; Struct</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myF</span></span>(gender:<span class="type">String</span>, r:<span class="type">Row</span>):(<span class="type">String</span>, <span class="type">String</span>) = &#123;</span><br><span class="line">    r <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Row</span>(firstname:<span class="type">String</span>, middlename: <span class="type">String</span>, lastname: <span class="type">String</span>) =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> x = <span class="keyword">if</span> (firstname.isEmpty) <span class="string">&quot;&quot;</span> <span class="keyword">else</span> (firstname + <span class="string">&quot;:&quot;</span> + gender)</span><br><span class="line">            (x, firstname)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">val</span> myUdf = udf(myF _)</span><br><span class="line"><span class="comment">// udf 签名：&lt;function2&gt; 代表 udf 包含两个参数；StructType(StructField(_1,StringType,true), StructField(_2,StringType,true)) 代表 udf 返回的是一个 struct，且该 struuct 包含了两个子域 _1、_2；None 是 udf 的入参类型，入参有 Row 就会变成 None，尚不清楚其中机理</span></span><br><span class="line">myUdf: org.apache.spark.sql.expressions.<span class="type">UserDefinedFunction</span> = <span class="type">UserDefinedFunction</span>(&lt;function2&gt;,<span class="type">StructType</span>(<span class="type">StructField</span>(_1,<span class="type">StringType</span>,<span class="literal">true</span>), <span class="type">StructField</span>(_2,<span class="type">StringType</span>,<span class="literal">true</span>)),<span class="type">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> res = df.withColumn(<span class="string">&quot;f_udf&quot;</span>, myUdf(col(<span class="string">&quot;gender&quot;</span>), col(<span class="string">&quot;f_struct&quot;</span>)))</span><br><span class="line">res.show()</span><br><span class="line">res.printSchema</span><br><span class="line"></span><br><span class="line">+------+------+--------------------+-------+------------------+--------------------+</span><br><span class="line">|gender|salary|            f_struct|f_array|             f_map|               f_udf|</span><br><span class="line">+------+------+--------------------+-------+------------------+--------------------+</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">3000</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|  [<span class="type">James</span> :<span class="type">M</span>, <span class="type">James</span> ]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]| [<span class="number">3</span>, <span class="number">2</span>]|[<span class="number">2</span> -&gt; b, <span class="number">22</span> -&gt; bb]|[<span class="type">Michael</span> :<span class="type">M</span>, <span class="type">Mich</span>...|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|[<span class="type">Robert</span> , , <span class="type">Willi</span>...| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">3</span> -&gt; c, <span class="number">33</span> -&gt; cc]|[<span class="type">Robert</span> :<span class="type">M</span>, <span class="type">Robert</span> ]|</span><br><span class="line">|     <span class="type">F</span>|  <span class="number">4000</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...| [<span class="number">3</span>, <span class="number">3</span>]|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]|  [<span class="type">Maria</span> :<span class="type">F</span>, <span class="type">Maria</span> ]|</span><br><span class="line">|     <span class="type">F</span>|    <span class="number">-1</span>|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]| [<span class="number">5</span>, <span class="number">2</span>]|          [<span class="number">5</span> -&gt; e]|        [<span class="type">Jen</span>:<span class="type">F</span>, <span class="type">Jen</span>]|</span><br><span class="line">+------+------+--------------------+-------+------------------+--------------------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- gender: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_struct: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- firstname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- middlename: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- lastname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_array: array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- element: integer (containsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- f_map: map (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- key: string</span><br><span class="line"> |    |-- value: string (valueContainsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- f_udf: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- _1: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- _2: string (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><ul><li>udf 的返回值可以是样例类：样例类型返回值会以一种更加自然的方式转化为 <code>struct</code>，样例类的不同属性构成了 <code>struct</code> 的各个子域；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">P</span>(<span class="params">x:<span class="type">String</span>, y:<span class="type">Int</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myF</span></span>(gender:<span class="type">String</span>, r:<span class="type">Row</span>):<span class="type">P</span> = &#123;</span><br><span class="line">    r <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Row</span>(firstname:<span class="type">String</span>, middlename: <span class="type">String</span>, lastname: <span class="type">String</span>) =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> x = <span class="keyword">if</span> (firstname.isEmpty) <span class="string">&quot;&quot;</span> <span class="keyword">else</span> (firstname + <span class="string">&quot;:&quot;</span> + gender)</span><br><span class="line">            <span class="type">P</span>(x, <span class="number">1</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">val</span> myUdf = udf(myF _)</span><br><span class="line"></span><br><span class="line">myUdf: org.apache.spark.sql.expressions.<span class="type">UserDefinedFunction</span> = <span class="type">UserDefinedFunction</span>(&lt;function2&gt;,<span class="type">StructType</span>(<span class="type">StructField</span>(x,<span class="type">StringType</span>,<span class="literal">true</span>), <span class="type">StructField</span>(y,<span class="type">IntegerType</span>,<span class="literal">false</span>)),<span class="type">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> res = df.withColumn(<span class="string">&quot;f_udf&quot;</span>, myUdf(col(<span class="string">&quot;gender&quot;</span>), col(<span class="string">&quot;f_struct&quot;</span>)))</span><br><span class="line">res.show()</span><br><span class="line">res.printSchema</span><br><span class="line">+------+------+--------------------+-------+------------------+---------------+</span><br><span class="line">|gender|salary|            f_struct|f_array|             f_map|          f_udf|</span><br><span class="line">+------+------+--------------------+-------+------------------+---------------+</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">3000</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|  [<span class="type">James</span> :<span class="type">M</span>, <span class="number">1</span>]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]| [<span class="number">3</span>, <span class="number">2</span>]|[<span class="number">2</span> -&gt; b, <span class="number">22</span> -&gt; bb]|[<span class="type">Michael</span> :<span class="type">M</span>, <span class="number">1</span>]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|[<span class="type">Robert</span> , , <span class="type">Willi</span>...| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">3</span> -&gt; c, <span class="number">33</span> -&gt; cc]| [<span class="type">Robert</span> :<span class="type">M</span>, <span class="number">1</span>]|</span><br><span class="line">|     <span class="type">F</span>|  <span class="number">4000</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...| [<span class="number">3</span>, <span class="number">3</span>]|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]|  [<span class="type">Maria</span> :<span class="type">F</span>, <span class="number">1</span>]|</span><br><span class="line">|     <span class="type">F</span>|    <span class="number">-1</span>|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]| [<span class="number">5</span>, <span class="number">2</span>]|          [<span class="number">5</span> -&gt; e]|     [<span class="type">Jen</span>:<span class="type">F</span>, <span class="number">1</span>]|</span><br><span class="line">+------+------+--------------------+-------+------------------+---------------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- gender: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_struct: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- firstname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- middlename: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- lastname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_array: array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- element: integer (containsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- f_map: map (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- key: string</span><br><span class="line"> |    |-- value: string (valueContainsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- f_udf: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- x: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- y: integer (nullable = <span class="literal">false</span>)</span><br></pre></td></tr></table></figure></div><h5 id="ArrayType"><a href="#ArrayType" class="headerlink" title="ArrayType"></a>ArrayType</h5><ul><li>返回值类型也可以是 Seq、Array 或 List，不会影响到 udf 签名</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myF</span></span>(gender:<span class="type">String</span>, a:<span class="type">Seq</span>[<span class="type">Int</span>]):<span class="type">Seq</span>[<span class="type">String</span>] = a.map(x =&gt; gender * x.toInt)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myF</span></span>(gender:<span class="type">String</span>, a:<span class="type">Seq</span>[<span class="type">Int</span>]):<span class="type">Array</span>[<span class="type">String</span>] = a.map(x =&gt; gender * x.toInt).toArray</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myF</span></span>(gender:<span class="type">String</span>, a:<span class="type">Seq</span>[<span class="type">Int</span>]):<span class="type">List</span>[<span class="type">String</span>] = a.map(x =&gt; gender * x.toInt).toList</span><br><span class="line"><span class="keyword">val</span> myUdf = udf(myF _)</span><br><span class="line"></span><br><span class="line">myUdf: org.apache.spark.sql.expressions.<span class="type">UserDefinedFunction</span> = <span class="type">UserDefinedFunction</span>(&lt;function2&gt;,<span class="type">ArrayType</span>(<span class="type">StringType</span>,<span class="literal">true</span>),<span class="type">Some</span>(<span class="type">List</span>(<span class="type">StringType</span>, <span class="type">ArrayType</span>(<span class="type">IntegerType</span>,<span class="literal">false</span>))))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> res = df.withColumn(<span class="string">&quot;f_udf&quot;</span>, myUdf(col(<span class="string">&quot;gender&quot;</span>), col(<span class="string">&quot;f_array&quot;</span>)))</span><br><span class="line">res.show()</span><br><span class="line">res.printSchema</span><br><span class="line">+------+------+--------------------+-------+------------------+-----------+</span><br><span class="line">|gender|salary|            f_struct|f_array|             f_map|      f_udf|</span><br><span class="line">+------+------+--------------------+-------+------------------+-----------+</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">3000</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|    [<span class="type">M</span>, <span class="type">MM</span>]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]| [<span class="number">3</span>, <span class="number">2</span>]|[<span class="number">2</span> -&gt; b, <span class="number">22</span> -&gt; bb]|  [<span class="type">MMM</span>, <span class="type">MM</span>]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|[<span class="type">Robert</span> , , <span class="type">Willi</span>...| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">3</span> -&gt; c, <span class="number">33</span> -&gt; cc]|    [<span class="type">M</span>, <span class="type">MM</span>]|</span><br><span class="line">|     <span class="type">F</span>|  <span class="number">4000</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...| [<span class="number">3</span>, <span class="number">3</span>]|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]| [<span class="type">FFF</span>, <span class="type">FFF</span>]|</span><br><span class="line">|     <span class="type">F</span>|    <span class="number">-1</span>|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]| [<span class="number">5</span>, <span class="number">2</span>]|          [<span class="number">5</span> -&gt; e]|[<span class="type">FFFFF</span>, <span class="type">FF</span>]|</span><br><span class="line">+------+------+--------------------+-------+------------------+-----------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- gender: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_struct: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- firstname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- middlename: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- lastname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_array: array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- element: integer (containsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- f_map: map (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- key: string</span><br><span class="line"> |    |-- value: string (valueContainsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- f_udf: array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- element: string (containsNull = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><ul><li>参数不能是 Array 或 List，否则会报无法进行类型转换的错误</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala.collection.mutable.<span class="type">WrappedArray</span>$ofRef cannot be cast to scala.collection.immutable.<span class="type">List</span>`</span><br></pre></td></tr></table></figure></div><ul><li>变长参数会被注册为 ArrayType 类型：使用变长参数和使用 Seq 参数效果是一样的</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myF</span></span>(gender:<span class="type">String</span>, a:<span class="type">String</span> *):<span class="type">Seq</span>[<span class="type">String</span>] = &#123;</span><br><span class="line">    a.map(x =&gt; gender * x.toInt)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">val</span> myUdf = udf(myF _)</span><br><span class="line"></span><br><span class="line">myUdf: org.apache.spark.sql.expressions.<span class="type">UserDefinedFunction</span> = <span class="type">UserDefinedFunction</span>(&lt;function2&gt;,<span class="type">ArrayType</span>(<span class="type">StringType</span>,<span class="literal">true</span>),<span class="type">Some</span>(<span class="type">List</span>(<span class="type">StringType</span>, <span class="type">ArrayType</span>(<span class="type">StringType</span>,<span class="literal">true</span>))))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> res = df.withColumn(<span class="string">&quot;f_udf&quot;</span>, myUdf(col(<span class="string">&quot;gender&quot;</span>), col(<span class="string">&quot;f_array&quot;</span>)))</span><br><span class="line">res.show()</span><br><span class="line">res.printSchema</span><br><span class="line">+------+------+--------------------+-------+------------------+-----------+</span><br><span class="line">|gender|salary|            f_struct|f_array|             f_map|      f_udf|</span><br><span class="line">+------+------+--------------------+-------+------------------+-----------+</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">3000</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|    [<span class="type">M</span>, <span class="type">MM</span>]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]| [<span class="number">3</span>, <span class="number">2</span>]|[<span class="number">2</span> -&gt; b, <span class="number">22</span> -&gt; bb]|  [<span class="type">MMM</span>, <span class="type">MM</span>]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|[<span class="type">Robert</span> , , <span class="type">Willi</span>...| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">3</span> -&gt; c, <span class="number">33</span> -&gt; cc]|    [<span class="type">M</span>, <span class="type">MM</span>]|</span><br><span class="line">|     <span class="type">F</span>|  <span class="number">4000</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...| [<span class="number">3</span>, <span class="number">3</span>]|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]| [<span class="type">FFF</span>, <span class="type">FFF</span>]|</span><br><span class="line">|     <span class="type">F</span>|    <span class="number">-1</span>|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]| [<span class="number">5</span>, <span class="number">2</span>]|          [<span class="number">5</span> -&gt; e]|[<span class="type">FFFFF</span>, <span class="type">FF</span>]|</span><br><span class="line">+------+------+--------------------+-------+------------------+-----------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- gender: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_struct: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- firstname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- middlename: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- lastname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_array: array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- element: integer (containsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- f_map: map (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- key: string</span><br><span class="line"> |    |-- value: string (valueContainsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- f_udf: array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- element: string (containsNull = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><h5 id="MapType"><a href="#MapType" class="headerlink" title="MapType"></a>MapType</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myF</span></span>(gender:<span class="type">String</span>, m:<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]):<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>] = &#123;</span><br><span class="line">    m.filter(kv =&gt; kv._1.toInt &lt; <span class="number">10</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">val</span> myUdf = udf(myF _)</span><br><span class="line"></span><br><span class="line">myUdf: org.apache.spark.sql.expressions.<span class="type">UserDefinedFunction</span> = <span class="type">UserDefinedFunction</span>(&lt;function2&gt;,<span class="type">MapType</span>(<span class="type">StringType</span>,<span class="type">StringType</span>,<span class="literal">true</span>),<span class="type">Some</span>(<span class="type">List</span>(<span class="type">StringType</span>, <span class="type">MapType</span>(<span class="type">StringType</span>,<span class="type">StringType</span>,<span class="literal">true</span>))))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> res = df.withColumn(<span class="string">&quot;f_udf&quot;</span>, myUdf(col(<span class="string">&quot;gender&quot;</span>), col(<span class="string">&quot;f_map&quot;</span>)))</span><br><span class="line">res.show()</span><br><span class="line">res.printSchema</span><br><span class="line">+------+------+--------------------+-------+------------------+--------+</span><br><span class="line">|gender|salary|            f_struct|f_array|             f_map|   f_udf|</span><br><span class="line">+------+------+--------------------+-------+------------------+--------+</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">3000</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|[<span class="number">1</span> -&gt; a]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]| [<span class="number">3</span>, <span class="number">2</span>]|[<span class="number">2</span> -&gt; b, <span class="number">22</span> -&gt; bb]|[<span class="number">2</span> -&gt; b]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|[<span class="type">Robert</span> , , <span class="type">Willi</span>...| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">3</span> -&gt; c, <span class="number">33</span> -&gt; cc]|[<span class="number">3</span> -&gt; c]|</span><br><span class="line">|     <span class="type">F</span>|  <span class="number">4000</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...| [<span class="number">3</span>, <span class="number">3</span>]|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]|[<span class="number">4</span> -&gt; d]|</span><br><span class="line">|     <span class="type">F</span>|    <span class="number">-1</span>|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]| [<span class="number">5</span>, <span class="number">2</span>]|          [<span class="number">5</span> -&gt; e]|[<span class="number">5</span> -&gt; e]|</span><br><span class="line">+------+------+--------------------+-------+------------------+--------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- gender: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_struct: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- firstname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- middlename: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- lastname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_array: array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- element: integer (containsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- f_map: map (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- key: string</span><br><span class="line"> |    |-- value: string (valueContainsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- f_udf: map (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- key: string</span><br><span class="line"> |    |-- value: string (valueContainsNull = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><h3 id="UDAF"><a href="#UDAF" class="headerlink" title="UDAF"></a>UDAF</h3><p>UDAF（User Defined Aggregate Function，即用户自定义的聚合函数）相比 UDF 要复杂很多，UDF 接收一行输入并产生一个输出，UDAF 则是接收一组（一般是多行）输入并产生一个输出，Spark 维护了一个 <code>AggregationBuffer</code> 来存储每组输入数据的中间结果。使用 UDAF 的一般步骤：</p><ol><li>自定义类继承 <code>UserDefinedAggregateFunction</code>，对每个阶段方法做实现；</li><li>在 spark 中注册 UDAF，为其绑定一个名字；</li><li>然后就可以在sql语句中使用上面绑定的名字调用；</li></ol><h4 id="定义-UDAF"><a href="#定义-UDAF" class="headerlink" title="定义 UDAF"></a>定义 UDAF</h4><p>我们通过一个计算平均值的 UDAF 实际例子来了解定义 UDAF 的过程：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.&#123;<span class="type">MutableAggregationBuffer</span>, <span class="type">UserDefinedAggregateFunction</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types._</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">AverageUserDefinedAggregateFunction</span> <span class="keyword">extends</span> <span class="title">UserDefinedAggregateFunction</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 聚合函数的输入数据结构</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">inputSchema</span></span>: <span class="type">StructType</span> = <span class="type">StructType</span>(<span class="type">StructField</span>(<span class="string">&quot;input&quot;</span>, <span class="type">LongType</span>) :: <span class="type">Nil</span>)</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 缓存区数据结构</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">bufferSchema</span></span>: <span class="type">StructType</span> = <span class="type">StructType</span>(<span class="type">StructField</span>(<span class="string">&quot;sum&quot;</span>, <span class="type">LongType</span>) :: <span class="type">StructField</span>(<span class="string">&quot;count&quot;</span>, <span class="type">LongType</span>) :: <span class="type">Nil</span>)</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 聚合函数返回值数据结构</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">dataType</span></span>: <span class="type">DataType</span> = <span class="type">DoubleType</span></span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 聚合函数是否是幂等的，即相同输入是否总是能得到相同输出</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">deterministic</span></span>: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 初始化缓冲区</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">initialize</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    buffer(<span class="number">0</span>) = <span class="number">0</span>L</span><br><span class="line">    buffer(<span class="number">1</span>) = <span class="number">0</span>L</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 给聚合函数传入一条新数据进行处理</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">update</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>, input: <span class="type">Row</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (input.isNullAt(<span class="number">0</span>)) <span class="keyword">return</span></span><br><span class="line">    buffer(<span class="number">0</span>) = buffer.getLong(<span class="number">0</span>) + input.getLong(<span class="number">0</span>)</span><br><span class="line">    buffer(<span class="number">1</span>) = buffer.getLong(<span class="number">1</span>) + <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 合并聚合函数缓冲区</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(buffer1: <span class="type">MutableAggregationBuffer</span>, buffer2: <span class="type">Row</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    buffer1(<span class="number">0</span>) = buffer1.getLong(<span class="number">0</span>) + buffer2.getLong(<span class="number">0</span>)</span><br><span class="line">    buffer1(<span class="number">1</span>) = buffer1.getLong(<span class="number">1</span>) + buffer2.getLong(<span class="number">1</span>)</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 计算最终结果</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">evaluate</span></span>(buffer: <span class="type">Row</span>): <span class="type">Any</span> = buffer.getLong(<span class="number">0</span>).toDouble / buffer.getLong(<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h4 id="注册-使用-UDAF"><a href="#注册-使用-UDAF" class="headerlink" title="注册-使用 UDAF"></a>注册-使用 UDAF</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkSqlUDAFDemo_001</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder().master(<span class="string">&quot;local[*]&quot;</span>).appName(<span class="string">&quot;SparkStudy&quot;</span>).getOrCreate()</span><br><span class="line">    spark.read.json(<span class="string">&quot;data/user&quot;</span>).createOrReplaceTempView(<span class="string">&quot;v_user&quot;</span>)</span><br><span class="line">    spark.udf.register(<span class="string">&quot;u_avg&quot;</span>, <span class="type">AverageUserDefinedAggregateFunction</span>)</span><br><span class="line">    <span class="comment">// 将整张表看做是一个分组对求所有人的平均年龄</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select count(1) as count, u_avg(age) as avg_age from v_user&quot;</span>).show()</span><br><span class="line">    <span class="comment">// 按照性别分组求平均年龄</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select sex, count(1) as count, u_avg(age) as avg_age from v_user group by sex&quot;</span>).show()</span><br><span class="line"> </span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《Spark 权威指南 Chapter 7.Aggregations》</li></ul><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Spark SQL 结构化函数一般都在 &lt;code&gt;functions&lt;/code&gt; 模块，要使用这些函数，需要先导入该模块：&lt;/p&gt;
&lt;div class=&quot;highlight-wrap&quot;autocomplete=&quot;off&quot; autocorrect=&quot;off&quot; autoc
      
    
    </summary>
    
      <category term="Spark" scheme="http://liketea.xyz/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://liketea.xyz/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark 指南：Spark SQL（三）—— 结构化类型</title>
    <link href="http://liketea.xyz/Spark/Spark/Spark%20%E6%8C%87%E5%8D%97%EF%BC%9ASpark%20SQL%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94%20%E7%BB%93%E6%9E%84%E5%8C%96%E7%B1%BB%E5%9E%8B/"/>
    <id>http://liketea.xyz/Spark/Spark/Spark 指南：Spark SQL（三）—— 结构化类型/</id>
    <published>2020-11-06T13:16:46.000Z</published>
    <updated>2021-06-02T10:44:40.910Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Spark-Types"><a href="#Spark-Types" class="headerlink" title="Spark Types"></a>Spark Types</h2><h3 id="Spark-Scala-数据类型"><a href="#Spark-Scala-数据类型" class="headerlink" title="Spark-Scala 数据类型"></a>Spark-Scala 数据类型</h3><p>Spark SQL 具有大量内部类型表示形式，下表列出了 Scala 绑定的类型信息：</p><div class="table-container"><table><thead><tr><th>id</th><th>Data Type</th><th>Value type in Scala</th><th>API to create a data Type</th></tr></thead><tbody><tr><td>1</td><td>ByteType</td><td>Byte</td><td>ByteType</td></tr><tr><td>2</td><td>ShortType</td><td>Short</td><td>ShortType</td></tr><tr><td>3</td><td>IntegerType</td><td>Int</td><td>IntegerType</td></tr><tr><td>4</td><td>LongType</td><td>Long</td><td>LongType</td></tr><tr><td>5</td><td>FloatType</td><td>Float</td><td>FloatType</td></tr><tr><td>6</td><td>DoubleType</td><td>Double</td><td>DoubleType</td></tr><tr><td>7</td><td>DecimalType</td><td>java.math.BigDecimal</td><td>DecimalType</td></tr><tr><td>8</td><td>StringType</td><td>String</td><td>StringType</td></tr><tr><td>9</td><td>BinaryType</td><td>Array[Byte]</td><td>BinaryType</td></tr><tr><td>10</td><td>BooleanType</td><td>Boolean</td><td>BooleanType</td></tr><tr><td>11</td><td>TimestampType</td><td>java.Timestamp</td><td>TimestampType</td></tr><tr><td>12</td><td>DateType</td><td>java.sql.Date</td><td>DateType</td></tr><tr><td>13</td><td>ArrayType</td><td>scala.collection.Seq</td><td>ArrayType(<br>elementType,<br>[containsNull])</td></tr><tr><td>14</td><td>MapType</td><td>scala.collection.Map</td><td>MapType(<br>keyType,<br>valueType,<br>[valueContainsNull])</td></tr><tr><td>15</td><td>StructType</td><td>org.apache.spark.sql.Row</td><td>tructType(<br>fields: Array[StructField])</td></tr><tr><td>16</td><td>StructField</td><td>Scala中此字段的数据类型的值类型</td><td>StructField(<br>name,dataType,[nullable])</td></tr></tbody></table></div><p>在 Scala 中，要使用 Spark 类型，需要先导入 <code>org.apache.spark.sql.types._</code>：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> data = <span class="type">Seq</span>(</span><br><span class="line">      <span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;James &quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;Smith&quot;</span>),<span class="string">&quot;36636&quot;</span>,<span class="string">&quot;M&quot;</span>,<span class="string">&quot;3000&quot;</span>),</span><br><span class="line">      <span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;Michael &quot;</span>,<span class="string">&quot;Rose&quot;</span>,<span class="string">&quot;&quot;</span>),<span class="string">&quot;40288&quot;</span>,<span class="string">&quot;M&quot;</span>,<span class="string">&quot;4000&quot;</span>),</span><br><span class="line">      <span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;Robert &quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;Williams&quot;</span>),<span class="string">&quot;42114&quot;</span>,<span class="string">&quot;M&quot;</span>,<span class="string">&quot;4000&quot;</span>),</span><br><span class="line">      <span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;Maria &quot;</span>,<span class="string">&quot;Anne&quot;</span>,<span class="string">&quot;Jones&quot;</span>),<span class="string">&quot;39192&quot;</span>,<span class="string">&quot;F&quot;</span>,<span class="string">&quot;4000&quot;</span>),</span><br><span class="line">      <span class="type">Row</span>(<span class="type">Row</span>(<span class="string">&quot;Jen&quot;</span>,<span class="string">&quot;Mary&quot;</span>,<span class="string">&quot;Brown&quot;</span>),<span class="string">&quot;&quot;</span>,<span class="string">&quot;F&quot;</span>,<span class="string">&quot;-1&quot;</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> schema = <span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">      .add(<span class="string">&quot;name&quot;</span>,<span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">          .add(<span class="string">&quot;firstname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">          .add(<span class="string">&quot;middlename&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">          .add(<span class="string">&quot;lastname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      )  </span><br><span class="line">      .add(<span class="string">&quot;dob&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      .add(<span class="string">&quot;gender&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      .add(<span class="string">&quot;salary&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df = spark.createDataFrame(spark.sparkContext.parallelize(data),schema)</span><br><span class="line">df.show()</span><br><span class="line">df.printSchema</span><br><span class="line"></span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|                name|  dob|gender|salary|</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|</span><br><span class="line">|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- name: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- firstname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- middlename: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- lastname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- dob: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- gender: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: string (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><h3 id="数据类型转换"><a href="#数据类型转换" class="headerlink" title="数据类型转换"></a>数据类型转换</h3><h4 id="本地类型-amp-Spark-类型"><a href="#本地类型-amp-Spark-类型" class="headerlink" title="本地类型 &amp; Spark 类型"></a>本地类型 &amp; Spark 类型</h4><p>我们经常需要在本地类型和 Spark 类型之间进行转换，以利用各自在数据处理不同方面的优势，在转化过程中本地类型和 Spark 类型要符合上表中列出的对应关系，如果无法进行隐式转换就会报错：</p><ol><li>本地类型 -&gt; Spark 类型：<ol><li>通过本地对象创建 DataFrame：<code>toDF()</code>、<code>createDataFrame()</code>；</li><li>将本地基本类型转化为 Spark 基本类型：<code>lit()</code>；</li><li>udf 返回值会被隐式地转化为 Spark 对应的类型；</li></ol></li><li>Spark 类型 -&gt; 本地类型：<ol><li>将 DataFrame 收集到 driver端：<code>collect()</code>；</li><li>向 udf 传递参数时，会将 Spark 类型隐式地转化为对应的本地类型；</li></ol></li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.lit</span><br><span class="line">df.select(lit(<span class="number">5</span>).as(<span class="string">&quot;f_integer&quot;</span>), lit(<span class="string">&quot;five&quot;</span>).as(<span class="string">&quot;f_string&quot;</span>), lit(<span class="number">5.0</span>).as(<span class="string">&quot;f_double&quot;</span>))</span><br></pre></td></tr></table></figure></div><p>需要注意的是，如果传给 <code>lit()</code> 的参数本身就是 <code>Column</code> 对象，<code>lit()</code> 将原样返回该 <code>Column</code> 对象：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Creates a [[Column]] of literal value.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * The passed in object is returned directly if it is already a [[Column]].</span></span><br><span class="line"><span class="comment"> * If the object is a Scala Symbol, it is converted into a [[Column]] also.</span></span><br><span class="line"><span class="comment"> * Otherwise, a new [[Column]] is created to represent the literal value.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @group normal_funcs</span></span><br><span class="line"><span class="comment"> * @since 1.3.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lit</span></span>(literal: <span class="type">Any</span>): <span class="type">Column</span> = &#123;</span><br><span class="line">  literal <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> c: <span class="type">Column</span> =&gt; <span class="keyword">return</span> c</span><br><span class="line">    <span class="keyword">case</span> s: <span class="type">Symbol</span> =&gt; <span class="keyword">return</span> <span class="keyword">new</span> <span class="type">ColumnName</span>(literal.asInstanceOf[<span class="type">Symbol</span>].name)</span><br><span class="line">    <span class="keyword">case</span> _ =&gt;  <span class="comment">// continue</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> literalExpr = <span class="type">Literal</span>(literal)</span><br><span class="line">  <span class="type">Column</span>(literalExpr)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h4 id="Spark-类型-amp-Spark-类型"><a href="#Spark-类型-amp-Spark-类型" class="headerlink" title="Spark 类型 &amp; Spark 类型"></a>Spark 类型 &amp; Spark 类型</h4><p>将 DataFrame 列类型从一种类型转换到另一种类型有很多种方法：<code>withColumn()</code>、<code>cast()</code>、<code>selectExpr</code>、SQL 表达式，需要注意的是目标类型必须是 DataType 的子类。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 示例数据</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types._</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> simpleData = <span class="type">Seq</span>(<span class="type">Row</span>(<span class="string">&quot;James&quot;</span>,<span class="number">34</span>,<span class="string">&quot;2006-01-01&quot;</span>,<span class="string">&quot;true&quot;</span>,<span class="string">&quot;M&quot;</span>,<span class="number">3000.60</span>),</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;Michael&quot;</span>,<span class="number">33</span>,<span class="string">&quot;1980-01-10&quot;</span>,<span class="string">&quot;true&quot;</span>,<span class="string">&quot;F&quot;</span>,<span class="number">3300.80</span>),</span><br><span class="line">    <span class="type">Row</span>(<span class="string">&quot;Robert&quot;</span>,<span class="number">37</span>,<span class="string">&quot;06-01-1992&quot;</span>,<span class="string">&quot;false&quot;</span>,<span class="string">&quot;M&quot;</span>,<span class="number">5000.50</span>)</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> simpleSchema = <span class="type">StructType</span>(<span class="type">Array</span>(</span><br><span class="line">    <span class="type">StructField</span>(<span class="string">&quot;firstName&quot;</span>,<span class="type">StringType</span>,<span class="literal">true</span>),</span><br><span class="line">    <span class="type">StructField</span>(<span class="string">&quot;age&quot;</span>,<span class="type">IntegerType</span>,<span class="literal">true</span>),</span><br><span class="line">    <span class="type">StructField</span>(<span class="string">&quot;jobStartDate&quot;</span>,<span class="type">StringType</span>,<span class="literal">true</span>),</span><br><span class="line">    <span class="type">StructField</span>(<span class="string">&quot;isGraduated&quot;</span>, <span class="type">StringType</span>, <span class="literal">true</span>),</span><br><span class="line">    <span class="type">StructField</span>(<span class="string">&quot;gender&quot;</span>, <span class="type">StringType</span>, <span class="literal">true</span>),</span><br><span class="line">    <span class="type">StructField</span>(<span class="string">&quot;salary&quot;</span>, <span class="type">DoubleType</span>, <span class="literal">true</span>)</span><br><span class="line">))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df = spark.createDataFrame(spark.sparkContext.parallelize(simpleData),simpleSchema)</span><br><span class="line">df.printSchema()</span><br><span class="line">df.show(<span class="literal">false</span>)</span><br><span class="line">root</span><br><span class="line"> |-- firstName: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- age: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- jobStartDate: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- isGraduated: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- gender: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: double (nullable = <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">+---------+---+------------+-----------+------+------+</span><br><span class="line">|firstName|age|jobStartDate|isGraduated|gender|salary|</span><br><span class="line">+---------+---+------------+-----------+------+------+</span><br><span class="line">|<span class="type">James</span>    |<span class="number">34</span> |<span class="number">2006</span><span class="number">-01</span><span class="number">-01</span>  |<span class="literal">true</span>       |<span class="type">M</span>     |<span class="number">3000.6</span>|</span><br><span class="line">|<span class="type">Michael</span>  |<span class="number">33</span> |<span class="number">1980</span><span class="number">-01</span><span class="number">-10</span>  |<span class="literal">true</span>       |<span class="type">F</span>     |<span class="number">3300.8</span>|</span><br><span class="line">|<span class="type">Robert</span>   |<span class="number">37</span> |<span class="number">06</span><span class="number">-01</span><span class="number">-1992</span>  |<span class="literal">false</span>      |<span class="type">M</span>     |<span class="number">5000.5</span>|</span><br><span class="line">+---------+---+------------+-----------+------+------+</span><br></pre></td></tr></table></figure></div><ul><li>通过 <code>withColumn()</code>、<code>cast()</code>：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> df2 = df</span><br><span class="line">    .withColumn(<span class="string">&quot;age&quot;</span>,col(<span class="string">&quot;age&quot;</span>).cast(<span class="type">StringType</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;isGraduated&quot;</span>,col(<span class="string">&quot;isGraduated&quot;</span>).cast(<span class="type">BooleanType</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;jobStartDate&quot;</span>,col(<span class="string">&quot;jobStartDate&quot;</span>).cast(<span class="type">DateType</span>))</span><br><span class="line">df2.printSchema()</span><br><span class="line">root</span><br><span class="line"> |-- firstName: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- age: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- jobStartDate: date (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- isGraduated: boolean (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- gender: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: double (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><ul><li>通过 <code>select</code>：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> cast_df = df.select(df.columns.map &#123;</span><br><span class="line">    <span class="keyword">case</span> column@<span class="string">&quot;age&quot;</span> =&gt;</span><br><span class="line">      col(column).cast(<span class="string">&quot;String&quot;</span>).as(column)</span><br><span class="line">    <span class="keyword">case</span> column@<span class="string">&quot;salary&quot;</span> =&gt;</span><br><span class="line">      col(column).cast(<span class="string">&quot;String&quot;</span>).as(column)</span><br><span class="line">    <span class="keyword">case</span> column =&gt;</span><br><span class="line">      col(column)</span><br><span class="line">  &#125;: _*)</span><br><span class="line"></span><br><span class="line">cast_df.printSchema()</span><br><span class="line">root</span><br><span class="line"> |-- firstName: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- age: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- jobStartDate: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- isGraduated: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- gender: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: string (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><ul><li>通过 <code>selectExpr</code>：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> df3 = df2.selectExpr(<span class="string">&quot;cast(age as int) age&quot;</span>,</span><br><span class="line">    <span class="string">&quot;cast(isGraduated as string) isGraduated&quot;</span>,</span><br><span class="line">    <span class="string">&quot;cast(jobStartDate as string) jobStartDate&quot;</span>)</span><br><span class="line">df3.printSchema()</span><br><span class="line">df3.show(<span class="literal">false</span>)</span><br></pre></td></tr></table></figure></div><h2 id="布尔类型"><a href="#布尔类型" class="headerlink" title="布尔类型"></a>布尔类型</h2><p>布尔类型是所有过滤的基础：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">df.where(col(<span class="string">&quot;salary&quot;</span>) &lt; <span class="number">4000</span>).show()</span><br><span class="line">+------------------+-----+------+------+</span><br><span class="line">|              name|  dob|gender|salary|</span><br><span class="line">+------------------+-----+------+------+</span><br><span class="line">| [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|</span><br><span class="line">|[<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|</span><br><span class="line">+------------------+-----+------+------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// Scala 中判断列是否相等使用 ===，=!=</span></span><br><span class="line">df.where(col(<span class="string">&quot;salary&quot;</span>) === <span class="number">4000</span>).show()</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|                name|  dob|gender|salary|</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|</span><br><span class="line">+--------------------+-----+------+------+</span><br><span class="line">df.where(col(<span class="string">&quot;salary&quot;</span>) =!= <span class="number">4000</span>).show()</span><br><span class="line">+------------------+-----+------+------+</span><br><span class="line">|              name|  dob|gender|salary|</span><br><span class="line">+------------------+-----+------+------+</span><br><span class="line">| [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|</span><br><span class="line">|[<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|</span><br><span class="line">+------------------+-----+------+------+</span><br><span class="line">df.select((col(<span class="string">&quot;salary&quot;</span>) =!= <span class="number">4000</span>).as(<span class="string">&quot;equal_400&quot;</span>)).show()</span><br><span class="line">+---------+</span><br><span class="line">|equal_400|</span><br><span class="line">+---------+</span><br><span class="line">|     <span class="literal">true</span>|</span><br><span class="line">|    <span class="literal">false</span>|</span><br><span class="line">|    <span class="literal">false</span>|</span><br><span class="line">|    <span class="literal">false</span>|</span><br><span class="line">|     <span class="literal">true</span>|</span><br><span class="line">+---------+</span><br><span class="line"></span><br><span class="line">df.select((col(<span class="string">&quot;salary&quot;</span>) =!= <span class="number">4000</span>).as(<span class="string">&quot;equal_400&quot;</span>)).printSchema</span><br><span class="line">root</span><br><span class="line"> |-- equal_400: boolean (nullable = <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 布尔表达式更简洁的表达方式是使用 SQL 表达式</span></span><br><span class="line">df.where(<span class="string">&quot;salary=4000 and gender=&#x27;M&#x27;&quot;</span>).show()</span><br></pre></td></tr></table></figure></div><h2 id="数字类型"><a href="#数字类型" class="headerlink" title="数字类型"></a>数字类型</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">df.describe().show()</span><br><span class="line">+-------+------------------+------+------------------+</span><br><span class="line">|summary|               dob|gender|            salary|</span><br><span class="line">+-------+------------------+------+------------------+</span><br><span class="line">|  count|                 <span class="number">5</span>|     <span class="number">5</span>|                 <span class="number">5</span>|</span><br><span class="line">|   mean|           <span class="number">39557.5</span>|  <span class="literal">null</span>|            <span class="number">2999.8</span>|</span><br><span class="line">| stddev|<span class="number">2290.4202671125668</span>|  <span class="literal">null</span>|<span class="number">1732.4838238783068</span>|</span><br><span class="line">|    min|                  |     <span class="type">F</span>|                <span class="number">-1</span>|</span><br><span class="line">|    max|             <span class="number">42114</span>|     <span class="type">M</span>|              <span class="number">4000</span>|</span><br><span class="line">+-------+------------------+------+------------------+</span><br></pre></td></tr></table></figure></div><h3 id="运算"><a href="#运算" class="headerlink" title="运算"></a>运算</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> df2 = df.withColumn(<span class="string">&quot;f_diff&quot;</span>, (col(<span class="string">&quot;dob&quot;</span>) - col(<span class="string">&quot;salary&quot;</span>))/col(<span class="string">&quot;salary&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;f_round&quot;</span>, round(col(<span class="string">&quot;f_diff&quot;</span>),<span class="number">2</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;f_pow&quot;</span>, pow(col(<span class="string">&quot;salary&quot;</span>), <span class="number">2</span>))</span><br><span class="line">df2.show()</span><br><span class="line"></span><br><span class="line">+--------------------+-----+------+------+------+-------+---------+</span><br><span class="line">|                name|  dob|gender|salary|f_diff|f_round|    f_pow|</span><br><span class="line">+--------------------+-----+------+------+------+-------+---------+</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|<span class="number">11.212</span>|  <span class="number">11.21</span>|<span class="number">9000000.0</span>|</span><br><span class="line">|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>| <span class="number">9.072</span>|   <span class="number">9.07</span>|    <span class="number">1.6E7</span>|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|<span class="number">9.5285</span>|   <span class="number">9.53</span>|    <span class="number">1.6E7</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>| <span class="number">8.798</span>|    <span class="number">8.8</span>|    <span class="number">1.6E7</span>|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|  <span class="literal">null</span>|   <span class="literal">null</span>|      <span class="number">1.0</span>|</span><br><span class="line">+--------------------+-----+------+------+------+-------+---------+</span><br><span class="line"><span class="comment">// 计算两列的协方差</span></span><br><span class="line">df2.select(corr(<span class="string">&quot;salary&quot;</span>,<span class="string">&quot;f_pow&quot;</span>)).show()</span><br><span class="line">+-------------------+</span><br><span class="line">|corr(salary, f_pow)|</span><br><span class="line">+-------------------+</span><br><span class="line">| <span class="number">0.9817491111765669</span>|</span><br><span class="line">+-------------------+</span><br></pre></td></tr></table></figure></div><h3 id="统计"><a href="#统计" class="headerlink" title="统计"></a>统计</h3><p>StatFunctions 程序包中提供了许多统计功能，可以通过 <code>df.stat</code> 访问。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 交叉表</span></span><br><span class="line">df.stat.crosstab(<span class="string">&quot;gender&quot;</span>, <span class="string">&quot;salary&quot;</span>).show()</span><br><span class="line">+-------------+---+----+----+</span><br><span class="line">|gender_salary| <span class="number">-1</span>|<span class="number">3000</span>|<span class="number">4000</span>|</span><br><span class="line">+-------------+---+----+----+</span><br><span class="line">|            <span class="type">M</span>|  <span class="number">0</span>|   <span class="number">1</span>|   <span class="number">2</span>|</span><br><span class="line">|            <span class="type">F</span>|  <span class="number">1</span>|   <span class="number">0</span>|   <span class="number">1</span>|</span><br><span class="line">+-------------+---+----+----+</span><br><span class="line"><span class="comment">// 频次最高的值</span></span><br><span class="line">df.stat.freqItems(<span class="type">Seq</span>(<span class="string">&quot;gender&quot;</span>, <span class="string">&quot;salary&quot;</span>)).show()</span><br><span class="line">+----------------+----------------+</span><br><span class="line">|gender_freqItems|salary_freqItems|</span><br><span class="line">+----------------+----------------+</span><br><span class="line">|          [<span class="type">M</span>, <span class="type">F</span>]|[<span class="number">3000</span>, <span class="number">4000</span>, <span class="number">-1</span>]|</span><br><span class="line">+----------------+----------------+</span><br></pre></td></tr></table></figure></div><h3 id="自增-ID"><a href="#自增-ID" class="headerlink" title="自增 ID"></a>自增 ID</h3><p>monotonically_increasing_id 生成一个单调递增并且是唯一的 ID。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.withColumn(<span class="string">&quot;f_id&quot;</span>, monotonically_increasing_id()).show()</span><br></pre></td></tr></table></figure></div><h2 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h2><h3 id="截取"><a href="#截取" class="headerlink" title="截取"></a>截取</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 语法：pos 从 1 开始</span></span><br><span class="line">substring(str: <span class="type">Column</span>, pos: <span class="type">Int</span>, len: <span class="type">Int</span>)</span><br><span class="line"><span class="comment">// 示例</span></span><br><span class="line">df.withColumn(<span class="string">&quot;f_substring&quot;</span>, substring(col(<span class="string">&quot;dob&quot;</span>), <span class="number">2</span>, <span class="number">3</span>)).show()</span><br><span class="line">+--------------------+-----+------+------+-----------+</span><br><span class="line">|                name|  dob|gender|salary|f_substring|</span><br><span class="line">+--------------------+-----+------+------+-----------+</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|        <span class="number">663</span>|</span><br><span class="line">|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|        <span class="number">028</span>|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|        <span class="number">211</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|        <span class="number">919</span>|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|           |</span><br><span class="line">+--------------------+-----+------+------+-----------+</span><br></pre></td></tr></table></figure></div><h3 id="拆分"><a href="#拆分" class="headerlink" title="拆分"></a>拆分</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 语法：pattern 是一个正则表达式，返回一个 Array</span></span><br><span class="line">split(str: <span class="type">Column</span>, pattern: <span class="type">String</span>)</span><br><span class="line"><span class="comment">// 示例</span></span><br><span class="line">df.withColumn(<span class="string">&quot;f_split&quot;</span>, split(col(<span class="string">&quot;dob&quot;</span>), <span class="string">&quot;6&quot;</span>)).show()</span><br><span class="line">+--------------------+-----+------+------+----------+</span><br><span class="line">|                name|  dob|gender|salary|   f_split|</span><br><span class="line">+--------------------+-----+------+------+----------+</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|[<span class="number">3</span>, , <span class="number">3</span>, ]|</span><br><span class="line">|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|   [<span class="number">40288</span>]|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|   [<span class="number">42114</span>]|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|   [<span class="number">39192</span>]|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|        []|</span><br><span class="line">+--------------------+-----+------+------+----------+</span><br></pre></td></tr></table></figure></div><h3 id="拼接"><a href="#拼接" class="headerlink" title="拼接"></a>拼接</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 语法</span></span><br><span class="line">concat(exprs: <span class="type">Column</span>*)</span><br><span class="line">concat_ws(sep: <span class="type">String</span>, exprs: <span class="type">Column</span>*)</span><br><span class="line"><span class="comment">// 示例，第二个参数是变长参数，可以接收一个 array() 或者多个 Column</span></span><br><span class="line">df.withColumn(<span class="string">&quot;f_concat&quot;</span>, concat(col(<span class="string">&quot;gender&quot;</span>), lit(<span class="string">&quot;-&quot;</span>), col(<span class="string">&quot;dob&quot;</span>)))</span><br><span class="line">  .withColumn(<span class="string">&quot;f_concat_ws1&quot;</span>, concat_ws(<span class="string">&quot;~&quot;</span>, col(<span class="string">&quot;gender&quot;</span>), col(<span class="string">&quot;dob&quot;</span>)))</span><br><span class="line">  .withColumn(<span class="string">&quot;f_concat_ws2&quot;</span>, concat_ws(<span class="string">&quot;~&quot;</span>, array(col(<span class="string">&quot;gender&quot;</span>), col(<span class="string">&quot;dob&quot;</span>))))</span><br><span class="line">  .show()</span><br><span class="line">+--------------------+-----+------+------+--------+------------+------------+</span><br><span class="line">|                name|  dob|gender|salary|f_concat|f_concat_ws1|f_concat_ws2|</span><br><span class="line">+--------------------+-----+------+------+--------+------------+------------+</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>| <span class="type">M</span><span class="number">-36636</span>|     <span class="type">M</span>~<span class="number">36636</span>|     <span class="type">M</span>~<span class="number">36636</span>|</span><br><span class="line">|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>| <span class="type">M</span><span class="number">-40288</span>|     <span class="type">M</span>~<span class="number">40288</span>|     <span class="type">M</span>~<span class="number">40288</span>|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>| <span class="type">M</span><span class="number">-42114</span>|     <span class="type">M</span>~<span class="number">42114</span>|     <span class="type">M</span>~<span class="number">42114</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>| <span class="type">F</span><span class="number">-39192</span>|     <span class="type">F</span>~<span class="number">39192</span>|     <span class="type">F</span>~<span class="number">39192</span>|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|      <span class="type">F</span>-|          <span class="type">F</span>~|          <span class="type">F</span>~|</span><br><span class="line">+--------------------+-----+------+------+--------+------------+------------+</span><br></pre></td></tr></table></figure></div><h3 id="增删两侧"><a href="#增删两侧" class="headerlink" title="增删两侧"></a>增删两侧</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 语法</span></span><br><span class="line">trim(e: <span class="type">Column</span>)</span><br><span class="line">trim(e: <span class="type">Column</span>, trimString: <span class="type">String</span>)</span><br><span class="line"><span class="comment">// 示例</span></span><br><span class="line">df.select(</span><br><span class="line">    ltrim(lit(<span class="string">&quot;  HELLO  &quot;</span>)).as(<span class="string">&quot;f_ltrim&quot;</span>),</span><br><span class="line">    rtrim(lit(<span class="string">&quot;  HELLO  &quot;</span>)).as(<span class="string">&quot;f_rtrim&quot;</span>),</span><br><span class="line">    trim(lit(<span class="string">&quot;---HELLO+++&quot;</span>), <span class="string">&quot;+&quot;</span>).as(<span class="string">&quot;f_trim&quot;</span>),</span><br><span class="line">    lpad(lit(<span class="string">&quot;HELLO&quot;</span>), <span class="number">10</span>, <span class="string">&quot;+&quot;</span>).as(<span class="string">&quot;f_lpad&quot;</span>),</span><br><span class="line">    rpad(lit(<span class="string">&quot;HELLO&quot;</span>), <span class="number">10</span>, <span class="string">&quot;+&quot;</span>).as(<span class="string">&quot;f_rpad&quot;</span>)</span><br><span class="line">).show(<span class="number">1</span>)</span><br><span class="line">+-------+-------+--------+----------+----------+</span><br><span class="line">|f_ltrim|f_rtrim|  f_trim|    f_lpad|    f_rpad|</span><br><span class="line">+-------+-------+--------+----------+----------+</span><br><span class="line">|<span class="type">HELLO</span>  |  <span class="type">HELLO</span>|---<span class="type">HELLO</span>|+++++<span class="type">HELLO</span>|<span class="type">HELLO</span>+++++|</span><br><span class="line">+-------+-------+--------+----------+----------+</span><br></pre></td></tr></table></figure></div><h3 id="字符替换"><a href="#字符替换" class="headerlink" title="字符替换"></a>字符替换</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">df.withColumn(<span class="string">&quot;f_translate&quot;</span>, translate(col(<span class="string">&quot;dob&quot;</span>), <span class="string">&quot;36&quot;</span>, <span class="string">&quot;+-&quot;</span>)).show()</span><br><span class="line">+--------------------+-----+------+------+-----------+</span><br><span class="line">|                name|  dob|gender|salary|f_translate|</span><br><span class="line">+--------------------+-----+------+------+-----------+</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|      +--+-|</span><br><span class="line">|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|      <span class="number">40288</span>|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|      <span class="number">42114</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|      +<span class="number">9192</span>|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|           |</span><br><span class="line">+--------------------+-----+------+------+-----------+</span><br></pre></td></tr></table></figure></div><h3 id="子串查询"><a href="#子串查询" class="headerlink" title="子串查询"></a>子串查询</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 语法，other 可以是 Column 对象，将逐行判断</span></span><br><span class="line">contains(other: <span class="type">Any</span>)</span><br><span class="line"><span class="comment">// 示例</span></span><br><span class="line">df.withColumn(<span class="string">&quot;f_contain&quot;</span>, col(<span class="string">&quot;dob&quot;</span>).contains(<span class="number">66</span>)).show()</span><br><span class="line">+--------------------+-----+------+------+---------+</span><br><span class="line">|                name|  dob|gender|salary|f_contain|</span><br><span class="line">+--------------------+-----+------+------+---------+</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|     <span class="literal">true</span>|</span><br><span class="line">|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|    <span class="literal">false</span>|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|    <span class="literal">false</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|    <span class="literal">false</span>|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|    <span class="literal">false</span>|</span><br><span class="line">+--------------------+-----+------+------+---------+</span><br></pre></td></tr></table></figure></div><h3 id="正则替换"><a href="#正则替换" class="headerlink" title="正则替换"></a>正则替换</h3><p>正则详细规则参见<a href="https://www.runoob.com/regexp/regexp-tutorial.html">这里</a>。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 语法</span></span><br><span class="line">regexp_replace(e: <span class="type">Column</span>, pattern: <span class="type">String</span>, replacement: <span class="type">String</span>)</span><br><span class="line">regexp_replace(e: <span class="type">Column</span>, pattern: <span class="type">Column</span>, replacement: <span class="type">Column</span>)</span><br><span class="line"><span class="comment">// 示例</span></span><br><span class="line">df.withColumn(<span class="string">&quot;f_regex_replace&quot;</span>, regexp_replace(col(<span class="string">&quot;dob&quot;</span>), <span class="string">&quot;6|3&quot;</span>, <span class="string">&quot;+&quot;</span>)).show()</span><br><span class="line">+--------------------+-----+------+------+---------------+</span><br><span class="line">|                name|  dob|gender|salary|f_regex_replace|</span><br><span class="line">+--------------------+-----+------+------+---------------+</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|          +++++|</span><br><span class="line">|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|          <span class="number">40288</span>|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|          <span class="number">42114</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|          +<span class="number">9192</span>|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|               |</span><br><span class="line">+--------------------+-----+------+------+---------------+</span><br></pre></td></tr></table></figure></div><h3 id="正则抽取"><a href="#正则抽取" class="headerlink" title="正则抽取"></a>正则抽取</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 语法</span></span><br><span class="line">regexp_extract(e: <span class="type">Column</span>, exp: <span class="type">String</span>, groupIdx: <span class="type">Int</span>)</span><br><span class="line"><span class="comment">// 示例：重复连续出现两次的子串，(\\d) 作为编号为 1 的分组，整体正则串默认标号为0，\\1 使用分组 1 的内容</span></span><br><span class="line">df.withColumn(<span class="string">&quot;f_regex_extract&quot;</span>, regexp_extract(col(<span class="string">&quot;dob&quot;</span>), <span class="string">&quot;(\\d)\\1&#123;1&#125;&quot;</span>, <span class="number">0</span>)).show()</span><br><span class="line">+--------------------+-----+------+------+---------------+</span><br><span class="line">|                name|  dob|gender|salary|f_regex_extract|</span><br><span class="line">+--------------------+-----+------+------+---------------+</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|<span class="number">36636</span>|     <span class="type">M</span>|  <span class="number">3000</span>|             <span class="number">66</span>|</span><br><span class="line">|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|<span class="number">40288</span>|     <span class="type">M</span>|  <span class="number">4000</span>|             <span class="number">88</span>|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|<span class="number">42114</span>|     <span class="type">M</span>|  <span class="number">4000</span>|             <span class="number">11</span>|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|<span class="number">39192</span>|     <span class="type">F</span>|  <span class="number">4000</span>|               |</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|     |     <span class="type">F</span>|    <span class="number">-1</span>|               |</span><br><span class="line">+--------------------+-----+------+------+---------------+</span><br></pre></td></tr></table></figure></div><h2 id="日期类型"><a href="#日期类型" class="headerlink" title="日期类型"></a>日期类型</h2><p>在 Spark 中，有四种日期相关的数据类型：</p><ol><li>DateType：日期，专注于日历日期；</li><li>TimestampType：时间戳，包括日期和时间信息，仅支持秒级精度，如果要使用毫秒或微秒则需要进行额外处理；</li><li>StringType：经常将日期和时间戳存储为字符串，并在其运行时转换为日期类型；</li><li>LongType：Long 型时间戳，注意当通过 Spark SQL 内置函数返回整型时间戳时单位为秒；</li></ol><p>本部分只介绍 Spark 内置的日期处理工具，更复杂的操作可以借助 <code>java.text.SimpleDateFormat</code> 和 <code>java.util.&#123;Calendar, Date&#125;</code> 使用 UDF 来解决。</p><h3 id="日期获取"><a href="#日期获取" class="headerlink" title="日期获取"></a>日期获取</h3><h4 id="获取当前日期"><a href="#获取当前日期" class="headerlink" title="获取当前日期"></a>获取当前日期</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> df = spark.range(<span class="number">3</span>)</span><br><span class="line">    .withColumn(<span class="string">&quot;date&quot;</span>, current_date())</span><br><span class="line">    .withColumn(<span class="string">&quot;timestamp&quot;</span>, current_timestamp())</span><br><span class="line">    .withColumn(<span class="string">&quot;dateStr&quot;</span>,lit(<span class="string">&quot;2020-11-07&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;timestampLong&quot;</span>, unix_timestamp())</span><br><span class="line">df.show(<span class="literal">false</span>)</span><br><span class="line">df.printSchema</span><br><span class="line">+---+----------+-----------------------+----------+-------------+</span><br><span class="line">|id |date      |timestamp              |dateStr   |timestampLong|</span><br><span class="line">+---+----------+-----------------------+----------+-------------+</span><br><span class="line">|<span class="number">0</span>  |<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">18</span>:<span class="number">55</span>:<span class="number">38.947</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">1604746538</span>   |</span><br><span class="line">|<span class="number">1</span>  |<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">18</span>:<span class="number">55</span>:<span class="number">38.947</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">1604746538</span>   |</span><br><span class="line">|<span class="number">2</span>  |<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">18</span>:<span class="number">55</span>:<span class="number">38.947</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">1604746538</span>   |</span><br><span class="line">+---+----------+-----------------------+----------+-------------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- id: long (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- date: date (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestamp: timestamp (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- dateStr: string (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestampLong: long (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><h4 id="从日期中提取字段"><a href="#从日期中提取字段" class="headerlink" title="从日期中提取字段"></a>从日期中提取字段</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tmp = spark.range(<span class="number">1</span>).select(lit(<span class="string">&quot;2020-11-07 19:45:12&quot;</span>).as(<span class="string">&quot;date&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;year&quot;</span>, year(col(<span class="string">&quot;date&quot;</span>)))</span><br><span class="line">    .withColumn(<span class="string">&quot;month&quot;</span>, month(col(<span class="string">&quot;date&quot;</span>)))</span><br><span class="line">    .withColumn(<span class="string">&quot;day&quot;</span>, dayofmonth(col(<span class="string">&quot;date&quot;</span>)))</span><br><span class="line">    .withColumn(<span class="string">&quot;hour&quot;</span>, hour(col(<span class="string">&quot;date&quot;</span>)))</span><br><span class="line">    .withColumn(<span class="string">&quot;minute&quot;</span>, minute(col(<span class="string">&quot;date&quot;</span>)))</span><br><span class="line">    .withColumn(<span class="string">&quot;second&quot;</span>, second(col(<span class="string">&quot;date&quot;</span>)))</span><br><span class="line">tmp.show(<span class="number">1</span>)</span><br><span class="line">tmp.printSchema</span><br><span class="line">+-------------------+----+-----+---+----+------+------+</span><br><span class="line">|               date|year|month|day|hour|minute|second|</span><br><span class="line">+-------------------+----+-----+---+----+------+------+</span><br><span class="line">|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">45</span>:<span class="number">12</span>|<span class="number">2020</span>|   <span class="number">11</span>|  <span class="number">7</span>|  <span class="number">19</span>|    <span class="number">45</span>|    <span class="number">12</span>|</span><br><span class="line">+-------------------+----+-----+---+----+------+------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- date: string (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- year: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- month: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- day: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- hour: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- minute: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- second: integer (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><h4 id="获取特殊日期"><a href="#获取特殊日期" class="headerlink" title="获取特殊日期"></a>获取特殊日期</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tmp = spark.range(<span class="number">1</span>).select(lit(<span class="string">&quot;2020-11-07 19:45:12&quot;</span>).as(<span class="string">&quot;date&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;dayofyear&quot;</span>, dayofyear(col(<span class="string">&quot;date&quot;</span>)))</span><br><span class="line">    .withColumn(<span class="string">&quot;dayofmonth&quot;</span>, dayofmonth(col(<span class="string">&quot;date&quot;</span>)))</span><br><span class="line">    .withColumn(<span class="string">&quot;dayofweek&quot;</span>, dayofweek(col(<span class="string">&quot;date&quot;</span>)))</span><br><span class="line">    .withColumn(<span class="string">&quot;weekofyear&quot;</span>, weekofyear(col(<span class="string">&quot;date&quot;</span>)))</span><br><span class="line">    <span class="comment">// date_sub 第二个参数不支持 Column 只能用表达式，解决此问题更好的方式是使用 next_day</span></span><br><span class="line">    .withColumn(<span class="string">&quot;monday_expr&quot;</span>, expr(<span class="string">&quot;date_sub(date, (dayofweek(date) -2) % 7)&quot;</span>))</span><br><span class="line">    <span class="comment">// next_day 获取相对指定日期下一周某天的日期，dayOfWeek 参数对大小写不敏感，而且接受以下简写</span></span><br><span class="line">    <span class="comment">// &quot;Mon&quot;, &quot;Tue&quot;, &quot;Wed&quot;, &quot;Thu&quot;, &quot;Fri&quot;, &quot;Sat&quot;, &quot;Sun&quot;</span></span><br><span class="line">    .withColumn(<span class="string">&quot;monday&quot;</span>, date_sub(next_day(col(<span class="string">&quot;date&quot;</span>), <span class="string">&quot;monday&quot;</span>), <span class="number">7</span>))</span><br><span class="line">    <span class="comment">// trunc截取某部分的日期，其他部分默认为01</span></span><br><span class="line">    .withColumn(<span class="string">&quot;trunc&quot;</span>, trunc(col(<span class="string">&quot;date&quot;</span>), <span class="string">&quot;MONTH&quot;</span>))</span><br><span class="line">tmp.show(<span class="number">1</span>)</span><br><span class="line">tmp.printSchema</span><br><span class="line">+-------------------+---------+----------+---------+----------+-----------+----------+----------+</span><br><span class="line">|               date|dayofyear|dayofmonth|dayofweek|weekofyear|monday_expr|    monday|     trunc|</span><br><span class="line">+-------------------+---------+----------+---------+----------+-----------+----------+----------+</span><br><span class="line">|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">45</span>:<span class="number">12</span>|      <span class="number">312</span>|         <span class="number">7</span>|        <span class="number">7</span>|        <span class="number">45</span>| <span class="number">2020</span><span class="number">-11</span><span class="number">-02</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-02</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-01</span>|</span><br><span class="line">+-------------------+---------+----------+---------+----------+-----------+----------+----------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- date: string (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- dayofyear: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- dayofmonth: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- dayofweek: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- weekofyear: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- monday_expr: date (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- monday: date (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- trunc: date (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><h3 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h3><p>日期相关的四种数据类型之间的转换方法如下图所示，其中，格式串遵守 <a href="https://docs.oracle.com/javase/8/docs/api/java/text/SimpleDateFormat.html">Java SimpleDateFormat 标准</a>。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/Spark-date.png" width="50%" heigh="50%"></img></div><h4 id="Long-amp-String"><a href="#Long-amp-String" class="headerlink" title="Long &amp; String"></a>Long &amp; String</h4><p><code>from_unixtime</code> 函数可以将 Long 型时间戳转化为 String 类型的日期，<code>unix_timestamp</code> 函数可以将 String 类型的日期转化为 Long 型时间戳。</p><ul><li>语法：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 默认返回当前秒级时间戳，在同一个查询中对 unix_timestamp 的所有调用都会返回相同值，unix_timestamp 会在查询开始时进行计算</span></span><br><span class="line">unix_timestamp()</span><br><span class="line"><span class="comment">// 将 yyyy-MM-dd HH:mm:ss 格式的时间字符串转化为秒级时间戳，如果失败则会返回 null</span></span><br><span class="line">unix_timestamp(s: <span class="type">Column</span>)</span><br><span class="line"><span class="comment">// 按照指定格式将时间字符串转化为秒级时间戳，格式串可参考 http://docs.oracle.com/javase/tutorial/i18n/format/simpleDateFormat.html</span></span><br><span class="line">unix_timestamp(s: <span class="type">Column</span>, p: <span class="type">String</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将秒级时间戳转化为 yyyy-MM-dd HH:mm:ss 格式的时间字符串</span></span><br><span class="line">from_unixtime(ut: <span class="type">Column</span>)</span><br><span class="line"><span class="comment">// 按指定格式将秒级时间戳转化为时间字符串</span></span><br><span class="line">from_unixtime(ut: <span class="type">Column</span>, f: <span class="type">String</span>)</span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tmp = df.withColumn(<span class="string">&quot;long_string&quot;</span>, from_unixtime(col(<span class="string">&quot;timestampLong&quot;</span>)))</span><br><span class="line">    .withColumn(<span class="string">&quot;long_string2&quot;</span>, from_unixtime(col(<span class="string">&quot;timestampLong&quot;</span>), <span class="string">&quot;yyyyMMdd&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;string_long&quot;</span>, unix_timestamp(col(<span class="string">&quot;dateStr&quot;</span>), <span class="string">&quot;yyyy-MM-dd&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;date_long&quot;</span>, unix_timestamp(col(<span class="string">&quot;date&quot;</span>), <span class="string">&quot;yyyy-MM-dd&quot;</span>))</span><br><span class="line">tmp.show()</span><br><span class="line">tmp.printSchema</span><br><span class="line">+---+----------+--------------------+----------+-------------+-------------------+------------+-----------+----------+</span><br><span class="line">| id|      date|           timestamp|   dateStr|timestampLong|        long_string|long_string2|string_long| date_long|</span><br><span class="line">+---+----------+--------------------+----------+-------------+-------------------+------------+-----------+----------+</span><br><span class="line">|  <span class="number">0</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">10</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604747436</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">10</span>:<span class="number">36</span>|    <span class="number">20201107</span>| <span class="number">1604678400</span>|<span class="number">1604678400</span>|</span><br><span class="line">|  <span class="number">1</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">10</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604747436</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">10</span>:<span class="number">36</span>|    <span class="number">20201107</span>| <span class="number">1604678400</span>|<span class="number">1604678400</span>|</span><br><span class="line">|  <span class="number">2</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">10</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604747436</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">10</span>:<span class="number">36</span>|    <span class="number">20201107</span>| <span class="number">1604678400</span>|<span class="number">1604678400</span>|</span><br><span class="line">+---+----------+--------------------+----------+-------------+-------------------+------------+-----------+----------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- id: long (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- date: date (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestamp: timestamp (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- dateStr: string (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestampLong: long (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- long_string: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- long_string2: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- string_long: long (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- date_long: long (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><h4 id="String-amp-Date"><a href="#String-amp-Date" class="headerlink" title="String &amp; Date"></a>String &amp; Date</h4><p><code>to_date</code> 函数可以将时间字符串转化为 date 类型，如果不指定具体的格式串，则等价于 <code>cast(&quot;date&quot;)</code>；<code>date_format</code> 函数可以将 date/timestamp/string 类型的日期时间转化为指定格式的时间字符串，如果只是希望将他们按原样转化为字符串，也可直接通过 <code>cast(&quot;string&quot;)</code> 来实现。</p><ul><li>语法：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 等价于 col(e: Column).cast(&quot;date&quot;)</span></span><br><span class="line">to_date(e: <span class="type">Column</span>)</span><br><span class="line"><span class="comment">// 按照指定格式将时间字符串转化为date</span></span><br><span class="line">to_date(e: <span class="type">Column</span>, fmt: <span class="type">String</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 date/timestamp/string 按照指定格式转化为时间字符串</span></span><br><span class="line">date_format(dateExpr: <span class="type">Column</span>, format: <span class="type">String</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div><ul><li>示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tmp = df.withColumn(<span class="string">&quot;date_string&quot;</span>, date_format(col(<span class="string">&quot;date&quot;</span>), <span class="string">&quot;yyyyMMdd&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;string_date&quot;</span>, to_date(col(<span class="string">&quot;dateStr&quot;</span>), <span class="string">&quot;yyyy-MM-dd&quot;</span>))</span><br><span class="line">tmp.show()</span><br><span class="line">tmp.printSchema</span><br><span class="line"></span><br><span class="line">+---+----------+--------------------+----------+-------------+-----------+-----------+</span><br><span class="line">| id|      date|           timestamp|   dateStr|timestampLong|date_string|string_date|</span><br><span class="line">+---+----------+--------------------+----------+-------------+-----------+-----------+</span><br><span class="line">|  <span class="number">0</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">15</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604747711</span>|   <span class="number">20201107</span>| <span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|</span><br><span class="line">|  <span class="number">1</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">15</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604747711</span>|   <span class="number">20201107</span>| <span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|</span><br><span class="line">|  <span class="number">2</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">15</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604747711</span>|   <span class="number">20201107</span>| <span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|</span><br><span class="line">+---+----------+--------------------+----------+-------------+-----------+-----------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- id: long (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- date: date (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestamp: timestamp (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- dateStr: string (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestampLong: long (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- date_string: string (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- string_date: date (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><h4 id="String-amp-Timestamp"><a href="#String-amp-Timestamp" class="headerlink" title="String &amp; Timestamp"></a>String &amp; Timestamp</h4><p>和 string &amp; date 之间的转换基本一致，不再赘述，这里只通过几个示例来做说明：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tmp = df.withColumn(<span class="string">&quot;timestamp_string&quot;</span>, date_format(col(<span class="string">&quot;timestamp&quot;</span>), <span class="string">&quot;yyyyMMdd&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;string_timestamp&quot;</span>, to_timestamp(col(<span class="string">&quot;dateStr&quot;</span>), <span class="string">&quot;yyyy-MM-dd&quot;</span>))</span><br><span class="line">tmp.show()</span><br><span class="line">tmp.printSchema</span><br><span class="line">+---+----------+--------------------+----------+-------------+----------------+-------------------+</span><br><span class="line">| id|      date|           timestamp|   dateStr|timestampLong|timestamp_string|   string_timestamp|</span><br><span class="line">+---+----------+--------------------+----------+-------------+----------------+-------------------+</span><br><span class="line">|  <span class="number">0</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">24</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604748297</span>|        <span class="number">20201107</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>|</span><br><span class="line">|  <span class="number">1</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">24</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604748297</span>|        <span class="number">20201107</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>|</span><br><span class="line">|  <span class="number">2</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">24</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604748297</span>|        <span class="number">20201107</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>|</span><br><span class="line">+---+----------+--------------------+----------+-------------+----------------+-------------------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- id: long (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- date: date (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestamp: timestamp (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- dateStr: string (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestampLong: long (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- timestamp_string: string (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- string_timestamp: timestamp (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><h4 id="Date-amp-Timestamp"><a href="#Date-amp-Timestamp" class="headerlink" title="Date &amp; Timestamp"></a>Date &amp; Timestamp</h4><p>date &amp; timestamp 之间的转换直接通过 <code>cast</code> 即可实现，无需赘言：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tmp = df.withColumn(<span class="string">&quot;timestamp_date&quot;</span>, col(<span class="string">&quot;timestamp&quot;</span>).cast(<span class="string">&quot;date&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;date_timestamp&quot;</span>, col(<span class="string">&quot;date&quot;</span>).cast(<span class="string">&quot;timestamp&quot;</span>))</span><br><span class="line">tmp.show()</span><br><span class="line">tmp.printSchema</span><br><span class="line">+---+----------+--------------------+----------+-------------+--------------+-------------------+</span><br><span class="line">| id|      date|           timestamp|   dateStr|timestampLong|timestamp_date|     date_timestamp|</span><br><span class="line">+---+----------+--------------------+----------+-------------+--------------+-------------------+</span><br><span class="line">|  <span class="number">0</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">27</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604748466</span>|    <span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>|</span><br><span class="line">|  <span class="number">1</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">27</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604748466</span>|    <span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>|</span><br><span class="line">|  <span class="number">2</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">27</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604748466</span>|    <span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>|</span><br><span class="line">+---+----------+--------------------+----------+-------------+--------------+-------------------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- id: long (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- date: date (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestamp: timestamp (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- dateStr: string (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestampLong: long (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- timestamp_date: date (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- date_timestamp: timestamp (nullable = <span class="literal">false</span>)</span><br></pre></td></tr></table></figure></div><h3 id="日期运算"><a href="#日期运算" class="headerlink" title="日期运算"></a>日期运算</h3><p>用到的时候搜索 API 即可，这里还是有必要列出最常用到的：</p><h4 id="日期-±-天数"><a href="#日期-±-天数" class="headerlink" title="日期 ± 天数"></a>日期 ± 天数</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 原型，start 必须是date或者可以隐式地通过 cast(&quot;date&quot;) 转化为 date (timestamp 或 yyyy-MM-dd HH:ss 格式的字符串)</span></span><br><span class="line"><span class="comment">// 奇怪的是 days 是 int 类型，而不是 Column，导致days 参数不能传入另一列，但是 SQL 表达式可以</span></span><br><span class="line">date_add(start: <span class="type">Column</span>, days: <span class="type">Int</span>)</span><br><span class="line">date_sub(start: <span class="type">Column</span>, days: <span class="type">Int</span>)</span><br><span class="line"><span class="comment">// 示例</span></span><br><span class="line"><span class="keyword">val</span> tmp = df</span><br><span class="line">    .withColumn(<span class="string">&quot;n&quot;</span>, lit(<span class="number">1</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;date_add&quot;</span>, date_add(col(<span class="string">&quot;date&quot;</span>), <span class="number">2</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;timestamp_add&quot;</span>, date_add(col(<span class="string">&quot;timestamp&quot;</span>), <span class="number">2</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;string_add&quot;</span>, date_add(col(<span class="string">&quot;dateStr&quot;</span>), <span class="number">2</span>))</span><br><span class="line"><span class="comment">//     .withColumn(&quot;string_sub&quot;, date_sub(col(&quot;dateStr&quot;), col(&quot;n&quot;)))</span></span><br><span class="line">    .withColumn(<span class="string">&quot;string_sub&quot;</span>, expr(<span class="string">&quot;date_sub(dateStr, n)&quot;</span>))</span><br><span class="line">tmp.show()</span><br><span class="line">tmp.printSchema</span><br><span class="line">+---+----------+--------------------+----------+-------------+---+----------+-------------+----------+----------+</span><br><span class="line">| id|      date|           timestamp|   dateStr|timestampLong|  n|  date_add|timestamp_add|string_add|string_sub|</span><br><span class="line">+---+----------+--------------------+----------+-------------+---+----------+-------------+----------+----------+</span><br><span class="line">|  <span class="number">0</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">20</span>:<span class="number">14</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604751268</span>|  <span class="number">1</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-09</span>|   <span class="number">2020</span><span class="number">-11</span><span class="number">-09</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-09</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-06</span>|</span><br><span class="line">|  <span class="number">1</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">20</span>:<span class="number">14</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604751268</span>|  <span class="number">1</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-09</span>|   <span class="number">2020</span><span class="number">-11</span><span class="number">-09</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-09</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-06</span>|</span><br><span class="line">|  <span class="number">2</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">20</span>:<span class="number">14</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604751268</span>|  <span class="number">1</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-09</span>|   <span class="number">2020</span><span class="number">-11</span><span class="number">-09</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-09</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-06</span>|</span><br><span class="line">+---+----------+--------------------+----------+-------------+---+----------+-------------+----------+----------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- id: long (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- date: date (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestamp: timestamp (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- dateStr: string (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestampLong: long (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- n: integer (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- date_add: date (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestamp_add: date (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- string_add: date (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- string_sub: date (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><h4 id="日期-日期"><a href="#日期-日期" class="headerlink" title="日期 - 日期"></a>日期 - 日期</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 返回 end - start 的天数</span></span><br><span class="line">datediff(end: <span class="type">Column</span>, start: <span class="type">Column</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> tmp = df.withColumn(<span class="string">&quot;date_diff&quot;</span>, datediff(col(<span class="string">&quot;date&quot;</span>), lit(<span class="string">&quot;2020-11-01&quot;</span>)))</span><br><span class="line">tmp.show()</span><br><span class="line">tmp.printSchema</span><br><span class="line">+---+----------+--------------------+----------+-------------+---------+</span><br><span class="line">| id|      date|           timestamp|   dateStr|timestampLong|date_diff|</span><br><span class="line">+---+----------+--------------------+----------+-------------+---------+</span><br><span class="line">|  <span class="number">0</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">39</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604749181</span>|        <span class="number">6</span>|</span><br><span class="line">|  <span class="number">1</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">39</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604749181</span>|        <span class="number">6</span>|</span><br><span class="line">|  <span class="number">2</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">39</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604749181</span>|        <span class="number">6</span>|</span><br><span class="line">+---+----------+--------------------+----------+-------------+---------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- id: long (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- date: date (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestamp: timestamp (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- dateStr: string (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestampLong: long (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- date_diff: integer (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><h4 id="月份运算"><a href="#月份运算" class="headerlink" title="月份运算"></a>月份运算</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tmp = df.withColumn(<span class="string">&quot;month_diff&quot;</span>, months_between(col(<span class="string">&quot;date&quot;</span>), lit(<span class="string">&quot;2020-09-01&quot;</span>)))</span><br><span class="line">    .withColumn(<span class="string">&quot;add_months&quot;</span>, add_months(col(<span class="string">&quot;date&quot;</span>), <span class="number">1</span>))</span><br><span class="line">tmp.show()</span><br><span class="line">tmp.printSchema</span><br><span class="line">+---+----------+--------------------+----------+-------------+----------+----------+</span><br><span class="line">| id|      date|           timestamp|   dateStr|timestampLong|month_diff|add_months|</span><br><span class="line">+---+----------+--------------------+----------+-------------+----------+----------+</span><br><span class="line">|  <span class="number">0</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">41</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604749312</span>|<span class="number">2.19354839</span>|<span class="number">2020</span><span class="number">-12</span><span class="number">-07</span>|</span><br><span class="line">|  <span class="number">1</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">41</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604749312</span>|<span class="number">2.19354839</span>|<span class="number">2020</span><span class="number">-12</span><span class="number">-07</span>|</span><br><span class="line">|  <span class="number">2</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">41</span>:...|<span class="number">2020</span><span class="number">-11</span><span class="number">-07</span>|   <span class="number">1604749312</span>|<span class="number">2.19354839</span>|<span class="number">2020</span><span class="number">-12</span><span class="number">-07</span>|</span><br><span class="line">+---+----------+--------------------+----------+-------------+----------+----------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- id: long (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- date: date (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestamp: timestamp (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- dateStr: string (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- timestampLong: long (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- month_diff: double (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- add_months: date (nullable = <span class="literal">false</span>)</span><br></pre></td></tr></table></figure></div><h2 id="处理空值"><a href="#处理空值" class="headerlink" title="处理空值"></a>处理空值</h2><p>最佳实践是，你应该始终使用 <code>null</code> 来表示 DataFrame 中缺失或为空的数据，与使用空字符串或其他值相比，Spark 可以优化使用 null 的工作。对于空值的处理，要么删除要么填充，与 null 交互的主要方式是在 DataFrame 上调用 <code>.na</code> 子包。</p><h3 id="填充空值"><a href="#填充空值" class="headerlink" title="填充空值"></a>填充空值</h3><ul><li><code>ifnull(expr1, expr2)</code>：默认返回 <code>expr1</code>，如果 <code>expr1</code> 值为 null 则返回 <code>expr2</code>；只用于 SQL 表达式；<code>nullif(expr1, expr2)</code>：如果条件为真则返回 null，否则返回 <code>expr1</code>；只用于 SQL 表达式；<code>nvl(expr1, expr2)</code>：同 ifnull；<code>nvl2(expr1, expr2, expr3)</code>：如果 <code>expr1</code> 为 null 则返回 <code>expr2</code>，否则返回 <code>expr3</code>；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SQL"><figure class="iseeu highlight /sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">df.createOrReplaceTempView(&quot;df&quot;)</span><br><span class="line">spark.sql(&quot;&quot;&quot;</span><br><span class="line">select</span><br><span class="line">ifnull(null, &#x27;return_value&#x27;) as a,</span><br><span class="line">nullif(&#x27;value&#x27;, &#x27;value&#x27;) as b,</span><br><span class="line">nvl(null, &#x27;return_value&#x27;) as c,</span><br><span class="line">nvl2(&#x27;not_null&#x27;, &#x27;return_value&#x27;, &#x27;else_value&#x27;) as d</span><br><span class="line">from df limit 1</span><br><span class="line">&quot;&quot;&quot;).<span class="keyword">show</span>()</span><br><span class="line"><span class="operator">+</span><span class="comment">------------+----+------------+------------+</span></span><br><span class="line"><span class="operator">|</span>           a<span class="operator">|</span>   b<span class="operator">|</span>           c<span class="operator">|</span>           d<span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+----+------------+------------+</span></span><br><span class="line"><span class="operator">|</span>return_value<span class="operator">|</span><span class="keyword">null</span><span class="operator">|</span>return_value<span class="operator">|</span>return_value<span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+----+------------+------------+</span></span><br></pre></td></tr></table></figure></div><ul><li><code>coalesce(e: Column*)</code>：从左向右，返回第一个不为 null 的值；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df.select(coalesce(lit(<span class="literal">null</span>), lit(<span class="literal">null</span>), lit(<span class="number">1</span>)).as(<span class="string">&quot;coalesce&quot;</span>)).show(<span class="number">1</span>)</span><br><span class="line">+--------+</span><br><span class="line">|coalesce|</span><br><span class="line">+--------+</span><br><span class="line">|       <span class="number">1</span>|</span><br><span class="line">+--------+</span><br></pre></td></tr></table></figure></div><ul><li><code>na.fill</code>：用法比较灵活：只有 value 的类型和所在列的原有类型可隐式转换时才会填充<ul><li>如果对所有列都用相同的值填充空值，可以用 <code>df.na.fill(value)</code>；</li><li>如果对几个列都用相同的值填充空值，可以用 <code>df.na.fill(value, Seq(cols_name*))</code>；</li><li>如果对几个列分别用不同的值填充空值，可以用 <code>df.na.fill(Map(col-&gt;value))</code></li></ul></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> df = spark.range(<span class="number">1</span>).select(</span><br><span class="line">    lit(<span class="literal">null</span>).cast(<span class="string">&quot;string&quot;</span>).as(<span class="string">&quot;f_string1&quot;</span>),</span><br><span class="line">    lit(<span class="string">&quot;x&quot;</span>).cast(<span class="string">&quot;string&quot;</span>).as(<span class="string">&quot;f_string2&quot;</span>),</span><br><span class="line">    lit(<span class="literal">null</span>).cast(<span class="string">&quot;int&quot;</span>).as(<span class="string">&quot;f_int&quot;</span>),</span><br><span class="line">    lit(<span class="literal">null</span>).cast(<span class="string">&quot;double&quot;</span>).as(<span class="string">&quot;f_double&quot;</span>),</span><br><span class="line">    lit(<span class="literal">null</span>).cast(<span class="string">&quot;boolean&quot;</span>).as(<span class="string">&quot;f_bool&quot;</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">df.show()</span><br><span class="line">df.printSchema</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line">|f_string1|f_string2|f_int|f_double|f_bool|</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line">|     <span class="literal">null</span>|        x| <span class="literal">null</span>|    <span class="literal">null</span>|  <span class="literal">null</span>|</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- f_string1: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_string2: string (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- f_int: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_double: double (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_bool: boolean (nullable = <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">df.na.fill(<span class="number">1</span>).show()</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line">|f_string1|f_string2|f_int|f_double|f_bool|</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line">|     <span class="literal">null</span>|        x|    <span class="number">1</span>|     <span class="number">1.0</span>|  <span class="literal">null</span>|</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line"></span><br><span class="line">df.na.fill(<span class="number">1</span>, <span class="type">Seq</span>(<span class="string">&quot;f_int&quot;</span>)).show()</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line">|f_string1|f_string2|f_int|f_double|f_bool|</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line">|     <span class="literal">null</span>|        x|    <span class="number">1</span>|    <span class="literal">null</span>|  <span class="literal">null</span>|</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line"></span><br><span class="line">df.na.fill(<span class="type">Map</span>(<span class="string">&quot;f_int&quot;</span>-&gt;<span class="number">1</span>, <span class="string">&quot;f_string1&quot;</span>-&gt;<span class="string">&quot;&quot;</span>)).show()</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line">|f_string1|f_string2|f_int|f_double|f_bool|</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line">|         |        x|    <span class="number">1</span>|    <span class="literal">null</span>|  <span class="literal">null</span>|</span><br><span class="line">+---------+---------+-----+--------+------+</span><br></pre></td></tr></table></figure></div><h3 id="删除空值"><a href="#删除空值" class="headerlink" title="删除空值"></a>删除空值</h3><p>删除空值可以分为以下几种情况：</p><ul><li>删除某列为空的行：直接通过 <code>.where(&quot;col is not null&quot;)</code> 即可完成；</li><li>删除包含空值的行：<code>na.drop()</code>;</li><li>删除所有列均为空的行：<code>na.drop(&quot;all&quot;)</code> 仅当改行所有列均为 null 或 NaN 时，才会删除；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">df.na.drop().show()</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line">|f_string1|f_string2|f_int|f_double|f_bool|</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line"></span><br><span class="line">df.na.drop(<span class="string">&quot;all&quot;</span>).show()</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line">|f_string1|f_string2|f_int|f_double|f_bool|</span><br><span class="line">+---------+---------+-----+--------+------+</span><br><span class="line">|     <span class="literal">null</span>|        x| <span class="literal">null</span>|    <span class="literal">null</span>|  <span class="literal">null</span>|</span><br><span class="line">+---------+---------+-----+--------+------+</span><br></pre></td></tr></table></figure></div><h2 id="处理复杂类型"><a href="#处理复杂类型" class="headerlink" title="处理复杂类型"></a>处理复杂类型</h2><p>复杂类型可以帮助你以对问题更有意义的方式组织和构造数据，Spark SQL 中复杂类型共有三种：</p><div class="table-container"><table><thead><tr><th style="text-align:center">id</th><th>Data Type</th><th>Scala Type</th><th>API to create a data Type</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td>StructType</td><td>org.apache.spark.sql.Row</td><td>tructType(<br>fields: Array[StructField])</td></tr><tr><td style="text-align:center">2</td><td>ArrayType</td><td>scala.collection.Seq</td><td>ArrayType(<br>elementType,<br>[containsNull])</td></tr><tr><td style="text-align:center">3</td><td>MapType</td><td>scala.collection.Map</td><td>MapType(<br>keyType,<br>valueType,<br>[valueContainsNull])</td></tr></tbody></table></div><p>示例数据：创建 DataFrame 时，显式定义 struct/array/map 类型</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = <span class="type">Seq</span>(</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;M&quot;</span>, <span class="number">3000</span>, <span class="type">Row</span>(<span class="string">&quot;James &quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;Smith&quot;</span>), <span class="type">Seq</span>(<span class="number">1</span>,<span class="number">2</span>), <span class="type">Map</span>(<span class="string">&quot;1&quot;</span>-&gt;<span class="string">&quot;a&quot;</span>, <span class="string">&quot;11&quot;</span>-&gt;<span class="string">&quot;aa&quot;</span>)),</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;M&quot;</span>, <span class="number">4000</span>, <span class="type">Row</span>(<span class="string">&quot;Michael &quot;</span>,<span class="string">&quot;Rose&quot;</span>,<span class="string">&quot;&quot;</span>), <span class="type">Seq</span>(<span class="number">3</span>,<span class="number">2</span>), <span class="type">Map</span>(<span class="string">&quot;2&quot;</span>-&gt;<span class="string">&quot;b&quot;</span>, <span class="string">&quot;22&quot;</span>-&gt;<span class="string">&quot;bb&quot;</span>)),</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;M&quot;</span>, <span class="number">4000</span>, <span class="type">Row</span>(<span class="string">&quot;Robert &quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;Williams&quot;</span>), <span class="type">Seq</span>(<span class="number">1</span>,<span class="number">2</span>), <span class="type">Map</span>(<span class="string">&quot;3&quot;</span>-&gt;<span class="string">&quot;c&quot;</span>, <span class="string">&quot;33&quot;</span>-&gt;<span class="string">&quot;cc&quot;</span>)),</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;F&quot;</span>, <span class="number">4000</span>, <span class="type">Row</span>(<span class="string">&quot;Maria &quot;</span>,<span class="string">&quot;Anne&quot;</span>,<span class="string">&quot;Jones&quot;</span>), <span class="type">Seq</span>(<span class="number">3</span>,<span class="number">3</span>), <span class="type">Map</span>(<span class="string">&quot;4&quot;</span>-&gt;<span class="string">&quot;d&quot;</span>, <span class="string">&quot;44&quot;</span>-&gt;<span class="string">&quot;dd&quot;</span>)),</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;F&quot;</span>, <span class="number">-1</span>, <span class="type">Row</span>(<span class="string">&quot;Jen&quot;</span>,<span class="string">&quot;Mary&quot;</span>,<span class="string">&quot;Brown&quot;</span>), <span class="type">Seq</span>(<span class="number">5</span>,<span class="number">2</span>), <span class="type">Map</span>(<span class="string">&quot;5&quot;</span>-&gt;<span class="string">&quot;e&quot;</span>))</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> schema = <span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">      .add(<span class="string">&quot;gender&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      .add(<span class="string">&quot;salary&quot;</span>,<span class="type">IntegerType</span>)</span><br><span class="line">      .add(<span class="string">&quot;f_struct&quot;</span>,</span><br><span class="line">        <span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">          .add(<span class="string">&quot;firstname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">          .add(<span class="string">&quot;middlename&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">          .add(<span class="string">&quot;lastname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      )  </span><br><span class="line">      .add(<span class="string">&quot;f_array&quot;</span>, <span class="type">ArrayType</span>(<span class="type">IntegerType</span>))</span><br><span class="line">      .add(<span class="string">&quot;f_map&quot;</span>, <span class="type">MapType</span>(<span class="type">StringType</span>, <span class="type">StringType</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df = spark.createDataFrame(spark.sparkContext.parallelize(data),schema)</span><br><span class="line">df.show()</span><br><span class="line">df.printSchema</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line">|gender|salary|            f_struct|f_array|             f_map|</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">3000</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]| [<span class="number">3</span>, <span class="number">2</span>]|[<span class="number">2</span> -&gt; b, <span class="number">22</span> -&gt; bb]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|[<span class="type">Robert</span> , , <span class="type">Willi</span>...| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">3</span> -&gt; c, <span class="number">33</span> -&gt; cc]|</span><br><span class="line">|     <span class="type">F</span>|  <span class="number">4000</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...| [<span class="number">3</span>, <span class="number">3</span>]|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]|</span><br><span class="line">|     <span class="type">F</span>|    <span class="number">-1</span>|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]| [<span class="number">5</span>, <span class="number">2</span>]|          [<span class="number">5</span> -&gt; e]|</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- gender: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_struct: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- firstname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- middlename: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- lastname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_array: array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- element: integer (containsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- f_map: map (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- key: string</span><br><span class="line"> |    |-- value: string (valueContainsNull = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><h3 id="StructType"><a href="#StructType" class="headerlink" title="StructType"></a>StructType</h3><p>可以将 struct 视为 DataFrame 中的 DataFrame，struct 是一个拥有命名子域的结构体。</p><ul><li>基于现有列生成 struct: 在 Column 对象上使用 struct 函数，或者在表达式中使用一对括号</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">df.select(struct(col(<span class="string">&quot;gender&quot;</span>), col(<span class="string">&quot;salary&quot;</span>)), expr(<span class="string">&quot;(gender, salary)&quot;</span>)).show()</span><br><span class="line">+--------------------------------------------+--------------------------------------------+</span><br><span class="line">|named_struct(gender, gender, salary, salary)|named_struct(gender, gender, salary, salary)|</span><br><span class="line">+--------------------------------------------+--------------------------------------------+</span><br><span class="line">|                                   [<span class="type">M</span>, <span class="number">3000</span>]|                                   [<span class="type">M</span>, <span class="number">3000</span>]|</span><br><span class="line">|                                   [<span class="type">M</span>, <span class="number">4000</span>]|                                   [<span class="type">M</span>, <span class="number">4000</span>]|</span><br><span class="line">|                                   [<span class="type">M</span>, <span class="number">4000</span>]|                                   [<span class="type">M</span>, <span class="number">4000</span>]|</span><br><span class="line">|                                   [<span class="type">F</span>, <span class="number">4000</span>]|                                   [<span class="type">F</span>, <span class="number">4000</span>]|</span><br><span class="line">|                                     [<span class="type">F</span>, <span class="number">-1</span>]|                                     [<span class="type">F</span>, <span class="number">-1</span>]|</span><br><span class="line">+--------------------------------------------+--------------------------------------------+</span><br></pre></td></tr></table></figure></div><ul><li>提取 struct 中的值：点操作会直接提取子域的值，列名为子域名，特别的，<code>.*</code> 可以提取 struct 中所有的子域；<code>getField</code> 方法也可以提取子域的值，但列名为完整带点号的名称</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">df.select(coldf.select(col(<span class="string">&quot;f_struct.firstname&quot;</span>), expr(<span class="string">&quot;f_struct.firstname&quot;</span>), col(<span class="string">&quot;f_struct&quot;</span>).getField(<span class="string">&quot;firstname&quot;</span>), col(<span class="string">&quot;f_struct.*&quot;</span>)).show()</span><br><span class="line">+---------+---------+------------------+---------+----------+--------+</span><br><span class="line">|firstname|firstname|f_struct.firstname|firstname|middlename|lastname|</span><br><span class="line">+---------+---------+------------------+---------+----------+--------+</span><br><span class="line">|   <span class="type">James</span> |   <span class="type">James</span> |            <span class="type">James</span> |   <span class="type">James</span> |          |   <span class="type">Smith</span>|</span><br><span class="line">| <span class="type">Michael</span> | <span class="type">Michael</span> |          <span class="type">Michael</span> | <span class="type">Michael</span> |      <span class="type">Rose</span>|        |</span><br><span class="line">|  <span class="type">Robert</span> |  <span class="type">Robert</span> |           <span class="type">Robert</span> |  <span class="type">Robert</span> |          |<span class="type">Williams</span>|</span><br><span class="line">|   <span class="type">Maria</span> |   <span class="type">Maria</span> |            <span class="type">Maria</span> |   <span class="type">Maria</span> |      <span class="type">Anne</span>|   <span class="type">Jones</span>|</span><br><span class="line">|      <span class="type">Jen</span>|      <span class="type">Jen</span>|               <span class="type">Jen</span>|      <span class="type">Jen</span>|      <span class="type">Mary</span>|   <span class="type">Brown</span>|</span><br><span class="line">+---------+---------+------------------+---------+----------+--------+</span><br></pre></td></tr></table></figure></div><h3 id="ArrayType"><a href="#ArrayType" class="headerlink" title="ArrayType"></a>ArrayType</h3><ul><li>基于现有列生成 array：列对象和表达式用法相同，都是在多列外使用 <code>array</code> 函数；<code>split</code>、<code>collect_list</code> 等函数也会返回 array；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">df.select(array(col(<span class="string">&quot;gender&quot;</span>), col(<span class="string">&quot;salary&quot;</span>)), expr(<span class="string">&quot;array(gender, salary)&quot;</span>)).show()</span><br><span class="line">+---------------------+-------------------------------------+</span><br><span class="line">|array(gender, salary)|array(gender, <span class="type">CAST</span>(salary <span class="type">AS</span> <span class="type">STRING</span>))|</span><br><span class="line">+---------------------+-------------------------------------+</span><br><span class="line">|            [<span class="type">M</span>, <span class="number">3000</span>]|                            [<span class="type">M</span>, <span class="number">3000</span>]|</span><br><span class="line">|            [<span class="type">M</span>, <span class="number">4000</span>]|                            [<span class="type">M</span>, <span class="number">4000</span>]|</span><br><span class="line">|            [<span class="type">M</span>, <span class="number">4000</span>]|                            [<span class="type">M</span>, <span class="number">4000</span>]|</span><br><span class="line">|            [<span class="type">F</span>, <span class="number">4000</span>]|                            [<span class="type">F</span>, <span class="number">4000</span>]|</span><br><span class="line">|              [<span class="type">F</span>, <span class="number">-1</span>]|                              [<span class="type">F</span>, <span class="number">-1</span>]|</span><br><span class="line">+---------------------+-------------------------------------+</span><br><span class="line"></span><br><span class="line">df.groupBy().agg(collect_list(col(<span class="string">&quot;gender&quot;</span>)).as(<span class="string">&quot;collect_list&quot;</span>)).show()</span><br><span class="line">+---------------+</span><br><span class="line">|   collect_list|</span><br><span class="line">+---------------+</span><br><span class="line">|[<span class="type">M</span>, <span class="type">M</span>, <span class="type">M</span>, <span class="type">F</span>, <span class="type">F</span>]|</span><br><span class="line">+---------------+</span><br></pre></td></tr></table></figure></div><ul><li>提取 array 中的元素：通过 <code>[index]</code> 按索引提取数组中的值；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">df.select(col(<span class="string">&quot;f_array&quot;</span>).getItem(<span class="number">0</span>), expr(<span class="string">&quot;f_array[0]&quot;</span>)).show()</span><br><span class="line">+----------+----------+</span><br><span class="line">|f_array[<span class="number">0</span>]|f_array[<span class="number">0</span>]|</span><br><span class="line">+----------+----------+</span><br><span class="line">|         <span class="number">1</span>|         <span class="number">1</span>|</span><br><span class="line">|         <span class="number">3</span>|         <span class="number">3</span>|</span><br><span class="line">|         <span class="number">1</span>|         <span class="number">1</span>|</span><br><span class="line">|         <span class="number">3</span>|         <span class="number">3</span>|</span><br><span class="line">|         <span class="number">5</span>|         <span class="number">5</span>|</span><br><span class="line">+----------+----------+</span><br></pre></td></tr></table></figure></div><ul><li>处理 array 的函数：参考 <a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/functions$.html"><code>org.apache.spark.functions</code></a></li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/11082009.png" alt=""></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">df.select(</span><br><span class="line">    size(col(<span class="string">&quot;f_array&quot;</span>)).as(<span class="string">&quot;f_array_size&quot;</span>),</span><br><span class="line">    array_contains(col(<span class="string">&quot;f_array&quot;</span>), <span class="number">1</span>).as(<span class="string">&quot;f_array_contain&quot;</span>),</span><br><span class="line">    array_max(col(<span class="string">&quot;f_array&quot;</span>)).as(<span class="string">&quot;f_array_max&quot;</span>),</span><br><span class="line">    array_distinct(col(<span class="string">&quot;f_array&quot;</span>)).as(<span class="string">&quot;f_array_distinct&quot;</span>),</span><br><span class="line">    array_position(col(<span class="string">&quot;f_array&quot;</span>), <span class="number">3</span>).as(<span class="string">&quot;f_array_pos&quot;</span>),</span><br><span class="line">    array_sort(col(<span class="string">&quot;f_array&quot;</span>)).as(<span class="string">&quot;f_array_sort&quot;</span>),</span><br><span class="line">    array_remove(col(<span class="string">&quot;f_array&quot;</span>), <span class="number">2</span>).as(<span class="string">&quot;f_array_remove&quot;</span>)</span><br><span class="line">).show()</span><br><span class="line">+------------+---------------+-----------+----------------+-----------+------------+--------------+</span><br><span class="line">|f_array_size|f_array_contain|f_array_max|f_array_distinct|f_array_pos|f_array_sort|f_array_remove|</span><br><span class="line">+------------+---------------+-----------+----------------+-----------+------------+--------------+</span><br><span class="line">|           <span class="number">2</span>|           <span class="literal">true</span>|          <span class="number">2</span>|          [<span class="number">1</span>, <span class="number">2</span>]|          <span class="number">0</span>|      [<span class="number">1</span>, <span class="number">2</span>]|           [<span class="number">1</span>]|</span><br><span class="line">|           <span class="number">2</span>|          <span class="literal">false</span>|          <span class="number">3</span>|          [<span class="number">3</span>, <span class="number">2</span>]|          <span class="number">1</span>|      [<span class="number">2</span>, <span class="number">3</span>]|           [<span class="number">3</span>]|</span><br><span class="line">|           <span class="number">2</span>|           <span class="literal">true</span>|          <span class="number">2</span>|          [<span class="number">1</span>, <span class="number">2</span>]|          <span class="number">0</span>|      [<span class="number">1</span>, <span class="number">2</span>]|           [<span class="number">1</span>]|</span><br><span class="line">|           <span class="number">2</span>|          <span class="literal">false</span>|          <span class="number">3</span>|             [<span class="number">3</span>]|          <span class="number">1</span>|      [<span class="number">3</span>, <span class="number">3</span>]|        [<span class="number">3</span>, <span class="number">3</span>]|</span><br><span class="line">|           <span class="number">2</span>|          <span class="literal">false</span>|          <span class="number">5</span>|          [<span class="number">5</span>, <span class="number">2</span>]|          <span class="number">0</span>|      [<span class="number">2</span>, <span class="number">5</span>]|           [<span class="number">5</span>]|</span><br><span class="line">+------------+---------------+-----------+----------------+-----------+------------+--------------+</span><br><span class="line"></span><br><span class="line"><span class="comment">// explode 会将数组中的所有元素取出，为每个值创建一个行，其他字段保持原样不变，默认忽略空数组</span></span><br><span class="line">df.withColumn(<span class="string">&quot;f_array_val&quot;</span>, explode(col(<span class="string">&quot;f_array&quot;</span>))).show()</span><br><span class="line">+------+------+--------------------+-------+------------------+-----------+</span><br><span class="line">|gender|salary|            f_struct|f_array|             f_map|f_array_val|</span><br><span class="line">+------+------+--------------------+-------+------------------+-----------+</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">3000</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|          <span class="number">1</span>|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">3000</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|          <span class="number">2</span>|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]| [<span class="number">3</span>, <span class="number">2</span>]|[<span class="number">2</span> -&gt; b, <span class="number">22</span> -&gt; bb]|          <span class="number">3</span>|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]| [<span class="number">3</span>, <span class="number">2</span>]|[<span class="number">2</span> -&gt; b, <span class="number">22</span> -&gt; bb]|          <span class="number">2</span>|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|[<span class="type">Robert</span> , , <span class="type">Willi</span>...| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">3</span> -&gt; c, <span class="number">33</span> -&gt; cc]|          <span class="number">1</span>|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|[<span class="type">Robert</span> , , <span class="type">Willi</span>...| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">3</span> -&gt; c, <span class="number">33</span> -&gt; cc]|          <span class="number">2</span>|</span><br><span class="line">|     <span class="type">F</span>|  <span class="number">4000</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...| [<span class="number">3</span>, <span class="number">3</span>]|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]|          <span class="number">3</span>|</span><br><span class="line">|     <span class="type">F</span>|  <span class="number">4000</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...| [<span class="number">3</span>, <span class="number">3</span>]|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]|          <span class="number">3</span>|</span><br><span class="line">|     <span class="type">F</span>|    <span class="number">-1</span>|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]| [<span class="number">5</span>, <span class="number">2</span>]|          [<span class="number">5</span> -&gt; e]|          <span class="number">5</span>|</span><br><span class="line">|     <span class="type">F</span>|    <span class="number">-1</span>|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]| [<span class="number">5</span>, <span class="number">2</span>]|          [<span class="number">5</span> -&gt; e]|          <span class="number">2</span>|</span><br><span class="line">+------+------+--------------------+-------+------------------+-----------+</span><br></pre></td></tr></table></figure></div><h3 id="MapType"><a href="#MapType" class="headerlink" title="MapType"></a>MapType</h3><ul><li>基于现有列生成 map：Column 和表达式用法相同，<code>map(key1, value1, key2, value2, ...)</code>；其中，输入列必须可以被分组为 <code>key-value</code> 对，所有 key 列必须具有相同类型且不能为 null，value 列也必须具有相同类型（或者可以通过 cast 转化为相同类型）；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dfmap = df.select(</span><br><span class="line">    map(col(<span class="string">&quot;gender&quot;</span>), lit(<span class="number">1</span>), col(<span class="string">&quot;salary&quot;</span>), lit(<span class="string">&quot;2&quot;</span>)),</span><br><span class="line">    expr(<span class="string">&quot;map(gender, 1, salary, 2)&quot;</span>)</span><br><span class="line">)</span><br><span class="line">dfmap.show()</span><br><span class="line">dfmap.printSchema</span><br><span class="line">+-------------------------+-----------------------------------------+</span><br><span class="line">|map(gender, <span class="number">1</span>, salary, <span class="number">2</span>)|map(gender, <span class="number">1</span>, <span class="type">CAST</span>(salary <span class="type">AS</span> <span class="type">STRING</span>), <span class="number">2</span>)|</span><br><span class="line">+-------------------------+-----------------------------------------+</span><br><span class="line">|      [<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">3000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">3000</span> -&gt; <span class="number">2</span>]|</span><br><span class="line">|      [<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|</span><br><span class="line">|      [<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|</span><br><span class="line">|      [<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|</span><br><span class="line">|        [<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">-1</span> -&gt; <span class="number">2</span>]|                        [<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">-1</span> -&gt; <span class="number">2</span>]|</span><br><span class="line">+-------------------------+-----------------------------------------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- map(gender, <span class="number">1</span>, salary, <span class="number">2</span>): map (nullable = <span class="literal">false</span>)</span><br><span class="line"> |    |-- key: string</span><br><span class="line"> |    |-- value: string (valueContainsNull = <span class="literal">false</span>)</span><br><span class="line"> |-- map(gender, <span class="number">1</span>, <span class="type">CAST</span>(salary <span class="type">AS</span> <span class="type">STRING</span>), <span class="number">2</span>): map (nullable = <span class="literal">false</span>)</span><br><span class="line"> |    |-- key: string</span><br><span class="line"> |    |-- value: integer (valueContainsNull = <span class="literal">false</span>)</span><br></pre></td></tr></table></figure></div><ul><li>处理 map 的函数：</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/202011082030.png" alt=""></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">dfmap</span><br><span class="line">    .withColumn(<span class="string">&quot;map_keys&quot;</span>, map_keys(col(<span class="string">&quot;f_map&quot;</span>)))</span><br><span class="line">    .withColumn(<span class="string">&quot;map_values&quot;</span>, map_values(col(<span class="string">&quot;f_map&quot;</span>)))</span><br><span class="line">    <span class="comment">// 返回 map 中指定 key 对应的 value，如果没有找到对应的 key 则返回 null </span></span><br><span class="line">    .withColumn(<span class="string">&quot;f_value&quot;</span>, expr(<span class="string">&quot;f_map[&#x27;M&#x27;]&quot;</span>))</span><br><span class="line">    .show()</span><br><span class="line">+-------------------+-----------------------------------------+---------+----------+-------+</span><br><span class="line">|              f_map|map(gender, <span class="number">1</span>, <span class="type">CAST</span>(salary <span class="type">AS</span> <span class="type">STRING</span>), <span class="number">2</span>)| map_keys|map_values|f_value|</span><br><span class="line">+-------------------+-----------------------------------------+---------+----------+-------+</span><br><span class="line">|[<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">3000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">3000</span> -&gt; <span class="number">2</span>]|[<span class="type">M</span>, <span class="number">3000</span>]|    [<span class="number">1</span>, <span class="number">2</span>]|      <span class="number">1</span>|</span><br><span class="line">|[<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|[<span class="type">M</span>, <span class="number">4000</span>]|    [<span class="number">1</span>, <span class="number">2</span>]|      <span class="number">1</span>|</span><br><span class="line">|[<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|[<span class="type">M</span>, <span class="number">4000</span>]|    [<span class="number">1</span>, <span class="number">2</span>]|      <span class="number">1</span>|</span><br><span class="line">|[<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|[<span class="type">F</span>, <span class="number">4000</span>]|    [<span class="number">1</span>, <span class="number">2</span>]|   <span class="literal">null</span>|</span><br><span class="line">|  [<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">-1</span> -&gt; <span class="number">2</span>]|                        [<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">-1</span> -&gt; <span class="number">2</span>]|  [<span class="type">F</span>, <span class="number">-1</span>]|    [<span class="number">1</span>, <span class="number">2</span>]|   <span class="literal">null</span>|</span><br><span class="line">+-------------------+-----------------------------------------+---------+----------+-------+</span><br><span class="line"></span><br><span class="line">dfmap.select(col(<span class="string">&quot;*&quot;</span>), explode(col(<span class="string">&quot;f_map&quot;</span>))).show()</span><br><span class="line">+-------------------+-----------------------------------------+----+-----+</span><br><span class="line">|              f_map|map(gender, <span class="number">1</span>, <span class="type">CAST</span>(salary <span class="type">AS</span> <span class="type">STRING</span>), <span class="number">2</span>)| key|value|</span><br><span class="line">+-------------------+-----------------------------------------+----+-----+</span><br><span class="line">|[<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">3000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">3000</span> -&gt; <span class="number">2</span>]|   <span class="type">M</span>|    <span class="number">1</span>|</span><br><span class="line">|[<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">3000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">3000</span> -&gt; <span class="number">2</span>]|<span class="number">3000</span>|    <span class="number">2</span>|</span><br><span class="line">|[<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|   <span class="type">M</span>|    <span class="number">1</span>|</span><br><span class="line">|[<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|<span class="number">4000</span>|    <span class="number">2</span>|</span><br><span class="line">|[<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|   <span class="type">M</span>|    <span class="number">1</span>|</span><br><span class="line">|[<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">M</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|<span class="number">4000</span>|    <span class="number">2</span>|</span><br><span class="line">|[<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|   <span class="type">F</span>|    <span class="number">1</span>|</span><br><span class="line">|[<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|                      [<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">4000</span> -&gt; <span class="number">2</span>]|<span class="number">4000</span>|    <span class="number">2</span>|</span><br><span class="line">|  [<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">-1</span> -&gt; <span class="number">2</span>]|                        [<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">-1</span> -&gt; <span class="number">2</span>]|   <span class="type">F</span>|    <span class="number">1</span>|</span><br><span class="line">|  [<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">-1</span> -&gt; <span class="number">2</span>]|                        [<span class="type">F</span> -&gt; <span class="number">1</span>, <span class="number">-1</span> -&gt; <span class="number">2</span>]|  <span class="number">-1</span>|    <span class="number">2</span>|</span><br><span class="line">+-------------------+-----------------------------------------+----+-----+</span><br></pre></td></tr></table></figure></div><h2 id="处理-JSON"><a href="#处理-JSON" class="headerlink" title="处理 JSON"></a>处理 JSON</h2><p>Spark 对 JSON 数据提供了一些独特的支持，可以直接在 Spark 中对 JSON 字符串进行处理，并从 JSON 字符串解析或提取 JSON 对象（返回字符串）。</p><ul><li>创建一个 JSON 列：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> df = spark.range(<span class="number">1</span>).selectExpr(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    &#x27;&#123;&quot;myJSONKey&quot;: &#123;&quot;myJSONValue&quot;: [1,2,3]&#125;&#125;&#x27; as f_json</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>)</span><br><span class="line">df.show(<span class="literal">false</span>)</span><br><span class="line">df.printSchema</span><br></pre></td></tr></table></figure></div><ul><li>提取 JSON 字符串中的值：可以使用 <code>get_json_object</code> 内联查询 JSON 对象，如果只有一层嵌套，也可以使用 <code>json_tuple</code></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> res = df</span><br><span class="line">    .withColumn(<span class="string">&quot;f_myJSONKey&quot;</span>, get_json_object(col(<span class="string">&quot;f_json&quot;</span>), <span class="string">&quot;$.myJSONKey&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;f_myJSONKey2&quot;</span>, json_tuple(col(<span class="string">&quot;f_json&quot;</span>), <span class="string">&quot;myJSONKey&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;myJSONValue&quot;</span>, get_json_object(col(<span class="string">&quot;f_json&quot;</span>), <span class="string">&quot;$.myJSONKey.myJSONValue&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;f_value&quot;</span>, get_json_object(col(<span class="string">&quot;f_json&quot;</span>), <span class="string">&quot;$.myJSONKey.myJSONValue[0]&quot;</span>))</span><br><span class="line"></span><br><span class="line">res.show(<span class="literal">false</span>)</span><br><span class="line">res.printSchema</span><br><span class="line"></span><br><span class="line">+---------------------------------------+-----------------------+-----------------------+-----------+-------+</span><br><span class="line">|f_json                                 |f_myJSONKey            |f_myJSONKey2           |myJSONValue|f_value|</span><br><span class="line">+---------------------------------------+-----------------------+-----------------------+-----------+-------+</span><br><span class="line">|&#123;<span class="string">&quot;myJSONKey&quot;</span>: &#123;<span class="string">&quot;myJSONValue&quot;</span>: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]&#125;&#125;|&#123;<span class="string">&quot;myJSONValue&quot;</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]&#125;|&#123;<span class="string">&quot;myJSONValue&quot;</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]&#125;|[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]    |<span class="number">1</span>      |</span><br><span class="line">+---------------------------------------+-----------------------+-----------------------+-----------+-------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- f_json: string (nullable = <span class="literal">false</span>)</span><br><span class="line"> |-- f_myJSONKey: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_myJSONKey2: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- myJSONValue: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_value: string (nullable = <span class="literal">true</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div><ul><li>将 struct/map 列转化为 json 列：<code>to_json</code> 函数可以将 <code>StructType</code> 或 <code>MapType</code> 列转化为 JSON 字符串；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dfjson = df.select(<span class="string">&quot;f_struct&quot;</span>, <span class="string">&quot;f_map&quot;</span>)</span><br><span class="line">    .withColumn(<span class="string">&quot;f_struct_json&quot;</span>, to_json(col(<span class="string">&quot;f_struct&quot;</span>)))</span><br><span class="line">    .withColumn(<span class="string">&quot;f_map_json&quot;</span>, to_json(col(<span class="string">&quot;f_map&quot;</span>)))</span><br><span class="line">dfjson.show(<span class="literal">false</span>)</span><br><span class="line">dfjson.printSchema</span><br><span class="line">+---------------------+------------------+-------------------------------------------------------------+-------------------+</span><br><span class="line">|f_struct             |f_map             |f_struct_json                                                |f_map_json         |</span><br><span class="line">+---------------------+------------------+-------------------------------------------------------------+-------------------+</span><br><span class="line">|[<span class="type">James</span> , , <span class="type">Smith</span>]    |[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|&#123;<span class="string">&quot;firstname&quot;</span>:<span class="string">&quot;James &quot;</span>,<span class="string">&quot;middlename&quot;</span>:<span class="string">&quot;&quot;</span>,<span class="string">&quot;lastname&quot;</span>:<span class="string">&quot;Smith&quot;</span>&#125;    |&#123;<span class="string">&quot;1&quot;</span>:<span class="string">&quot;a&quot;</span>,<span class="string">&quot;11&quot;</span>:<span class="string">&quot;aa&quot;</span>&#125;|</span><br><span class="line">|[<span class="type">Michael</span> , <span class="type">Rose</span>, ]   |[<span class="number">2</span> -&gt; b, <span class="number">22</span> -&gt; bb]|&#123;<span class="string">&quot;firstname&quot;</span>:<span class="string">&quot;Michael &quot;</span>,<span class="string">&quot;middlename&quot;</span>:<span class="string">&quot;Rose&quot;</span>,<span class="string">&quot;lastname&quot;</span>:<span class="string">&quot;&quot;</span>&#125;   |&#123;<span class="string">&quot;2&quot;</span>:<span class="string">&quot;b&quot;</span>,<span class="string">&quot;22&quot;</span>:<span class="string">&quot;bb&quot;</span>&#125;|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Williams</span>]|[<span class="number">3</span> -&gt; c, <span class="number">33</span> -&gt; cc]|&#123;<span class="string">&quot;firstname&quot;</span>:<span class="string">&quot;Robert &quot;</span>,<span class="string">&quot;middlename&quot;</span>:<span class="string">&quot;&quot;</span>,<span class="string">&quot;lastname&quot;</span>:<span class="string">&quot;Williams&quot;</span>&#125;|&#123;<span class="string">&quot;3&quot;</span>:<span class="string">&quot;c&quot;</span>,<span class="string">&quot;33&quot;</span>:<span class="string">&quot;cc&quot;</span>&#125;|</span><br><span class="line">|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jones</span>]|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]|&#123;<span class="string">&quot;firstname&quot;</span>:<span class="string">&quot;Maria &quot;</span>,<span class="string">&quot;middlename&quot;</span>:<span class="string">&quot;Anne&quot;</span>,<span class="string">&quot;lastname&quot;</span>:<span class="string">&quot;Jones&quot;</span>&#125;|&#123;<span class="string">&quot;4&quot;</span>:<span class="string">&quot;d&quot;</span>,<span class="string">&quot;44&quot;</span>:<span class="string">&quot;dd&quot;</span>&#125;|</span><br><span class="line">|[<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]   |[<span class="number">5</span> -&gt; e]          |&#123;<span class="string">&quot;firstname&quot;</span>:<span class="string">&quot;Jen&quot;</span>,<span class="string">&quot;middlename&quot;</span>:<span class="string">&quot;Mary&quot;</span>,<span class="string">&quot;lastname&quot;</span>:<span class="string">&quot;Brown&quot;</span>&#125;   |&#123;<span class="string">&quot;5&quot;</span>:<span class="string">&quot;e&quot;</span>&#125;          |</span><br><span class="line">+---------------------+------------------+-------------------------------------------------------------+-------------------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- f_struct: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- firstname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- middlename: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- lastname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_map: map (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- key: string</span><br><span class="line"> |    |-- value: string (valueContainsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- f_struct_json: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_map_json: string (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><ul><li>将 json 列解析回 struct/map 列：<code>from_json</code> 函数可以将 json 列解析回 struct/map 列，但是要求制定一个 Schema</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> structSchema = <span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">    .add(<span class="string">&quot;firstname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">    .add(<span class="string">&quot;middlename&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">    .add(<span class="string">&quot;lastname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> mapSchema = <span class="type">MapType</span>(<span class="type">StringType</span>, <span class="type">StringType</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> dffromjson = dfjson</span><br><span class="line">    .withColumn(<span class="string">&quot;json_strcut&quot;</span>, from_json(col(<span class="string">&quot;f_struct_json&quot;</span>), structSchema))</span><br><span class="line">    .withColumn(<span class="string">&quot;json_map&quot;</span>, from_json(col(<span class="string">&quot;f_map_json&quot;</span>), mapSchema))</span><br><span class="line"></span><br><span class="line">dffromjson.show()</span><br><span class="line">dffromjson.printSchema</span><br><span class="line"></span><br><span class="line">+--------------------+------------------+--------------------+-------------------+--------------------+------------------+</span><br><span class="line">|            f_struct|             f_map|       f_struct_json|         f_map_json|         json_strcut|          json_map|</span><br><span class="line">+--------------------+------------------+--------------------+-------------------+--------------------+------------------+</span><br><span class="line">|   [<span class="type">James</span> , , <span class="type">Smith</span>]|[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|&#123;<span class="string">&quot;firstname&quot;</span>:<span class="string">&quot;Jam...|&#123;&quot;</span><span class="number">1</span><span class="string">&quot;:&quot;</span><span class="string">a&quot;,&quot;</span><span class="number">11</span><span class="string">&quot;:&quot;</span><span class="string">aa&quot;&#125;|   [James , , Smith]|[1 -&gt; a, 11 -&gt; aa]|</span></span><br><span class="line"><span class="string">|  [Michael , Rose, ]|[2 -&gt; b, 22 -&gt; bb]|&#123;&quot;</span><span class="string">firstname&quot;:&quot;</span><span class="type">Mic</span>...|&#123;<span class="string">&quot;2&quot;</span>:<span class="string">&quot;b&quot;</span>,<span class="string">&quot;22&quot;</span>:<span class="string">&quot;bb&quot;</span>&#125;|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]|[<span class="number">2</span> -&gt; b, <span class="number">22</span> -&gt; bb]|</span><br><span class="line">|[<span class="type">Robert</span> , , <span class="type">Willi</span>...|[<span class="number">3</span> -&gt; c, <span class="number">33</span> -&gt; cc]|&#123;<span class="string">&quot;firstname&quot;</span>:<span class="string">&quot;Rob...|&#123;&quot;</span><span class="number">3</span><span class="string">&quot;:&quot;</span><span class="string">c&quot;,&quot;</span><span class="number">33</span><span class="string">&quot;:&quot;</span><span class="string">cc&quot;&#125;|[Robert , , Willi...|[3 -&gt; c, 33 -&gt; cc]|</span></span><br><span class="line"><span class="string">|[Maria , Anne, Jo...|[4 -&gt; d, 44 -&gt; dd]|&#123;&quot;</span><span class="string">firstname&quot;:&quot;</span><span class="type">Mar</span>...|&#123;<span class="string">&quot;4&quot;</span>:<span class="string">&quot;d&quot;</span>,<span class="string">&quot;44&quot;</span>:<span class="string">&quot;dd&quot;</span>&#125;|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]|</span><br><span class="line">|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]|          [<span class="number">5</span> -&gt; e]|&#123;<span class="string">&quot;firstname&quot;</span>:<span class="string">&quot;Jen...|          &#123;&quot;</span><span class="number">5</span><span class="string">&quot;:&quot;</span><span class="string">e&quot;&#125;|  [Jen, Mary, Brown]|          [5 -&gt; e]|</span></span><br><span class="line"><span class="string">+--------------------+------------------+--------------------+-------------------+--------------------+------------------+</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">root</span></span><br><span class="line"><span class="string"> |-- f_struct: struct (nullable = true)</span></span><br><span class="line"><span class="string"> |    |-- firstname: string (nullable = true)</span></span><br><span class="line"><span class="string"> |    |-- middlename: string (nullable = true)</span></span><br><span class="line"><span class="string"> |    |-- lastname: string (nullable = true)</span></span><br><span class="line"><span class="string"> |-- f_map: map (nullable = true)</span></span><br><span class="line"><span class="string"> |    |-- key: string</span></span><br><span class="line"><span class="string"> |    |-- value: string (valueContainsNull = true)</span></span><br><span class="line"><span class="string"> |-- f_struct_json: string (nullable = true)</span></span><br><span class="line"><span class="string"> |-- f_map_json: string (nullable = true)</span></span><br><span class="line"><span class="string"> |-- json_strcut: struct (nullable = true)</span></span><br><span class="line"><span class="string"> |    |-- firstname: string (nullable = true)</span></span><br><span class="line"><span class="string"> |    |-- middlename: string (nullable = true)</span></span><br><span class="line"><span class="string"> |    |-- lastname: string (nullable = true)</span></span><br><span class="line"><span class="string"> |-- json_map: map (nullable = true)</span></span><br><span class="line"><span class="string"> |    |-- key: string</span></span><br><span class="line"><span class="string"> |    |-- value: string (valueContainsNull = true)</span></span><br></pre></td></tr></table></figure></div><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://snaildove.github.io/2019/08/05/Chapter6_Working-with-Different-Types-of-Data(SparkTheDefinitiveGuide">《Spark 权威指南 Chapter 6》</a>_online/)</li><li><a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/functions$.html"><code>org.apache.spark.functions</code></a></li></ul><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Spark-Types&quot;&gt;&lt;a href=&quot;#Spark-Types&quot; class=&quot;headerlink&quot; title=&quot;Spark Types&quot;&gt;&lt;/a&gt;Spark Types&lt;/h2&gt;&lt;h3 id=&quot;Spark-Scala-数据类型&quot;&gt;&lt;a href=&quot;#S
      
    
    </summary>
    
      <category term="Spark" scheme="http://liketea.xyz/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://liketea.xyz/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark 指南：Spark SQL（一）—— 结构化对象</title>
    <link href="http://liketea.xyz/Spark/Spark/Spark%20%E6%8C%87%E5%8D%97%EF%BC%9ASpark%20SQL%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%20%E7%BB%93%E6%9E%84%E5%8C%96%E5%AF%B9%E8%B1%A1/"/>
    <id>http://liketea.xyz/Spark/Spark/Spark 指南：Spark SQL（一）—— 结构化对象/</id>
    <published>2020-11-04T06:16:46.000Z</published>
    <updated>2021-06-02T10:44:40.909Z</updated>
    
    <content type="html"><![CDATA[<p>SparkSession 是 Dataset 与 DataFrame API 的编程入口，从 Spark2.0 开始支持，用于统一原来的 HiveContext 和 SQLContext，统一入口提高了 Spark 的易用性，但为了兼容向后兼容，新版本仍然保留了这两个入口。下面的代码展示了如何创建一个 SparkSession：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> spark = <span class="type">SparkSession</span></span><br><span class="line">  .builder()</span><br><span class="line">  .appName(<span class="string">&quot;Spark SQL basic example&quot;</span>)</span><br><span class="line">  .config(<span class="string">&quot;spark.some.config.option&quot;</span>, <span class="string">&quot;some-value&quot;</span>)</span><br><span class="line">  .getOrCreate()</span><br></pre></td></tr></table></figure></div><p>DataFrame 仅仅只是 <strong>Dataset[Row]</strong> 的一个类型别名，创建 Dataset 的方式和创建 DataFrame 基本相同。</p><h2 id="从内置方法创建"><a href="#从内置方法创建" class="headerlink" title="从内置方法创建"></a>从内置方法创建</h2><p><code>spark.range</code> 方法可以创建一个单列 DataFrame，其中列名为 id，列的类型为 LongType 类型，列中的值取 range 生成的值。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 语法</span></span><br><span class="line">range(end: <span class="type">Long</span>)</span><br><span class="line">range(start: <span class="type">Long</span>, end: <span class="type">Long</span>)</span><br><span class="line">range(start: <span class="type">Long</span>, end: <span class="type">Long</span>, step: <span class="type">Long</span>)</span><br><span class="line"><span class="comment">// 示例</span></span><br><span class="line"><span class="keyword">val</span> ddf = spark.range(<span class="number">3</span>)</span><br><span class="line">    .withColumn(<span class="string">&quot;today&quot;</span>, current_date())</span><br><span class="line">    .withColumn(<span class="string">&quot;now&quot;</span>, current_timestamp())</span><br><span class="line">ddf.show(<span class="literal">false</span>)</span><br><span class="line">+---+----------+-----------------------+</span><br><span class="line">|id |today     |now                    |</span><br><span class="line">+---+----------+-----------------------+</span><br><span class="line">|<span class="number">0</span>  |<span class="number">2020</span><span class="number">-11</span><span class="number">-03</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">26.657</span>|</span><br><span class="line">|<span class="number">1</span>  |<span class="number">2020</span><span class="number">-11</span><span class="number">-03</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">26.657</span>|</span><br><span class="line">|<span class="number">2</span>  |<span class="number">2020</span><span class="number">-11</span><span class="number">-03</span>|<span class="number">2020</span><span class="number">-11</span><span class="number">-03</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">26.657</span>|</span><br><span class="line">+---+----------+-----------------------+</span><br></pre></td></tr></table></figure></div><h2 id="从对象序列创建"><a href="#从对象序列创建" class="headerlink" title="从对象序列创建"></a>从对象序列创建</h2><p>spark 提供了一系列隐式转换方法，可以将指定类型的对象序列 <code>Seq[T]</code> 或 <code>RDD[T]</code> 转化为 <code>Dataset[T]</code> 或 <code>DataFrame</code>，使用前需要先导入隐式转换：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// spark 为入口 SparkSession 对象</span></span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br></pre></td></tr></table></figure></div><h3 id="toDF-amp-toDS"><a href="#toDF-amp-toDS" class="headerlink" title="toDF &amp; toDS"></a>toDF &amp; toDS</h3><p>如果 <code>T</code> 是 <code>Int</code>、<code>Long</code>、<code>String</code> 或 <code>T &lt;: scala.Product</code>(Tuple 或 case class) 类型中的一种，则可以通过 <code>toDs()</code> 或 <code>toDf()</code> 方法转化为 <code>Dataset[T]</code> 或 <code>DataFrame</code>。</p><ul><li><code>toDF(): DataFrame</code> 和 <code>toDF(colNames: String*): DataFrame</code> 方法提供了一种非常简洁的方式，将对象序列转化为一个 DataFrame；<ul><li>列名：如果不提供 colNames，当结果只有一列时默认列名为 <code>value</code>，如果结果有多列 <code>_1, _2,...</code> 会作为默认列名；</li><li>类型：默认列类型将会通过输入数据的类型进行推断，如果要显式指定列的类型，可以通过 createDataFrame() 方法指定对应的 schema；</li></ul></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 序列元素为简单类型</span></span><br><span class="line"><span class="keyword">val</span> seq = <span class="type">Seq</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">seq.toDF().show()</span><br><span class="line">+-----+</span><br><span class="line">|value|</span><br><span class="line">+-----+</span><br><span class="line">|    <span class="number">1</span>|</span><br><span class="line">|    <span class="number">2</span>|</span><br><span class="line">|    <span class="number">3</span>|</span><br><span class="line">+-----+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 序列元素为元组</span></span><br><span class="line"><span class="keyword">val</span> df = <span class="type">Seq</span>(</span><br><span class="line">    (<span class="string">&quot;Arya&quot;</span>, <span class="string">&quot;Woman&quot;</span>, <span class="number">30</span>),</span><br><span class="line">    (<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;Man&quot;</span>, <span class="number">28</span>)</span><br><span class="line">).toDF(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;sex&quot;</span>, <span class="string">&quot;age&quot;</span>)</span><br><span class="line">df.show()</span><br><span class="line"></span><br><span class="line">+----+-----+---+</span><br><span class="line">|name|  sex|age|</span><br><span class="line">+----+-----+---+</span><br><span class="line">|<span class="type">Arya</span>|<span class="type">Woman</span>| <span class="number">30</span>|</span><br><span class="line">| <span class="type">Bob</span>|  <span class="type">Man</span>| <span class="number">28</span>|</span><br><span class="line">+----+-----+---+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 序列元素为样例类，通过反射读取样例类的参数名称，并映射成column的名称</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="keyword">val</span> df = <span class="type">Seq</span>(<span class="type">Person</span>(<span class="string">&quot;Andy&quot;</span>, <span class="number">32</span>)).toDF</span><br><span class="line">df.show()</span><br><span class="line">+----+---+</span><br><span class="line">|name|age|</span><br><span class="line">+----+---+</span><br><span class="line">|<span class="type">Andy</span>| <span class="number">32</span>|</span><br><span class="line">+----+---+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从 RDD 创建 DataFrame，parallelize 用于将序列转化为 RDD</span></span><br><span class="line"><span class="keyword">val</span> rdd = spark.sparkContext.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line"><span class="keyword">val</span> df = rdd.map(x=&gt;(x,x^<span class="number">2</span>)).toDF(<span class="string">&quot;org&quot;</span>,<span class="string">&quot;xor&quot;</span>)</span><br><span class="line">df.show()</span><br><span class="line">+---+---+</span><br><span class="line">|org|xor|</span><br><span class="line">+---+---+</span><br><span class="line">|  <span class="number">1</span>|  <span class="number">3</span>|</span><br><span class="line">|  <span class="number">2</span>|  <span class="number">0</span>|</span><br><span class="line">+---+---+</span><br></pre></td></tr></table></figure></div><ul><li><code>toDS(): Dataset[T]</code> 提供了一种将指定类型的对象序列转化为 DataSet 的简易方法</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 序列元素为简单类型</span></span><br><span class="line"><span class="keyword">val</span> ds = <span class="type">Seq</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>).toDS()</span><br><span class="line">ds.show(<span class="literal">false</span>)</span><br><span class="line">+-----+</span><br><span class="line">|value|</span><br><span class="line">+-----+</span><br><span class="line">|<span class="number">1</span>    |</span><br><span class="line">|<span class="number">2</span>    |</span><br><span class="line">|<span class="number">3</span>    |</span><br><span class="line">+-----+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 序列元素是元组</span></span><br><span class="line"><span class="keyword">val</span> ds = <span class="type">Seq</span>((<span class="string">&quot;Arya&quot;</span>,<span class="number">20</span>,<span class="string">&quot;woman&quot;</span>), (<span class="string">&quot;Bob&quot;</span>,<span class="number">28</span>,<span class="string">&quot;man&quot;</span>)).toDS()</span><br><span class="line">ds.show(<span class="literal">false</span>)</span><br><span class="line">+----+---+-----+</span><br><span class="line">|_1  |_2 |_3   |</span><br><span class="line">+----+---+-----+</span><br><span class="line">|<span class="type">Arya</span>|<span class="number">20</span> |woman|</span><br><span class="line">|<span class="type">Bob</span> |<span class="number">28</span> |man  |</span><br><span class="line">+----+---+-----+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 序列元素为样例类实例，样例类的字段会成为 DataSet 的字段</span></span><br><span class="line"><span class="comment">// 注意，case class 的定义要在引用 case class函数的外面，否则即使 import spark.implicits._ 也还是会报错 value toDF is not a member of ***</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Long</span>, sex:<span class="type">String</span></span>)</span></span><br><span class="line"><span class="keyword">val</span> ds = <span class="type">Seq</span>(<span class="type">Person</span>(<span class="string">&quot;Arya&quot;</span>, <span class="number">20</span>, <span class="string">&quot;woman&quot;</span>), <span class="type">Person</span>(<span class="string">&quot;Bob&quot;</span>, <span class="number">28</span>, <span class="string">&quot;man&quot;</span>))</span><br><span class="line">            .toDS().show()</span><br><span class="line">+----+---+-----+</span><br><span class="line">|name|age|  sex|</span><br><span class="line">+----+---+-----+</span><br><span class="line">|<span class="type">Arya</span>| <span class="number">20</span>|woman|</span><br><span class="line">| <span class="type">Bob</span>| <span class="number">28</span>|  man|</span><br><span class="line">+----+---+-----+    </span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 RDD 转化为 DataSet</span></span><br><span class="line"><span class="keyword">val</span> rdd = spark.sparkContext.parallelize(<span class="type">Seq</span>((<span class="string">&quot;Arya&quot;</span>,<span class="number">20</span>,<span class="string">&quot;woman&quot;</span>), (<span class="string">&quot;Bob&quot;</span>,<span class="number">28</span>,<span class="string">&quot;man&quot;</span>)))</span><br><span class="line">rdd.toDS().show()</span><br><span class="line">+----+---+-----+</span><br><span class="line">|  _1| _2|   _3|</span><br><span class="line">+----+---+-----+</span><br><span class="line">|<span class="type">Arya</span>| <span class="number">20</span>|woman|</span><br><span class="line">| <span class="type">Bob</span>| <span class="number">28</span>|  man|</span><br><span class="line">+----+---+-----+      </span><br></pre></td></tr></table></figure></div><p>toDF 方法对 null 类型处理的不好，不建议在生产环境中使用。</p><h3 id="createDataFrame-amp-createDataSet"><a href="#createDataFrame-amp-createDataSet" class="headerlink" title="createDataFrame &amp; createDataSet"></a>createDataFrame &amp; createDataSet</h3><p>相比 toDF 和 toDS，createDataFrame 和 createDataSet 方法支持更多的数据类型，特别是 <code>Seq[Row]</code> 和 <code>RDD[Row]</code> 只能通过 create 方法来转化为 DataFrame。</p><ul><li>createDataFrame 有多个重载方法：如果只传入数据，则数据只能是一个包含 Product 元素的序列或 RDD；如果传入 Schema，数据可以是 RDD[Row] 或 java.util.List[Row]；如果传入 beanClass，数据可以是 RDD[Java Bean] 或java.util.List[Java Bean]<ul><li><code>createDataFrame[A &lt;: Product : TypeTag](data: Seq[A]): DataFrame</code>: 通过 Product 序列创建 DataFrame，如 tuple、case class</li><li><code>createDataFrame[A &lt;: Product : TypeTag](rdd: RDD[A]): DataFrame</code>: 通过 Product RDD 创建 DataFrame，如 tuple、case class</li><li><code>createDataFrame(rows: List[Row], schema: StructType): DataFrame</code>: 通过 java.util.List[Row] 并指定 Schema 创建 DataFrame</li><li><code>createDataFrame(rowRDD: RDD[Row], schema: StructType): DataFrame</code>: 通过 RDD[Row] 并指定 Schema 创建 DataFrame</li><li><code>createDataFrame(rdd: RDD[_], beanClass: Class[_]): DataFrame</code>: Applies a schema to an RDD of Java Beans</li><li><code>createDataFrame(data: List[_], beanClass: Class[_]): DataFrame</code>: Applies a schema to a List of Java Beans</li></ul></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 只传入 Seq[Tuple]，列名为 &quot;_1&quot; &quot;_2&quot;</span></span><br><span class="line"><span class="keyword">val</span> dfData = <span class="type">Seq</span>((<span class="number">1</span>,<span class="string">&quot;a&quot;</span>), (<span class="number">2</span>, <span class="string">&quot;b&quot;</span>))</span><br><span class="line"><span class="keyword">val</span> ds = spark.createDataFrame(dfData)</span><br><span class="line">ds.show()</span><br><span class="line">+---+---+</span><br><span class="line">| _1| _2|</span><br><span class="line">+---+---+</span><br><span class="line">|  <span class="number">1</span>|  a|</span><br><span class="line">|  <span class="number">2</span>|  b|</span><br><span class="line">+---+---+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 只传入 Seq[case class]，列名为样例类字段名</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name:<span class="type">String</span>, sex:<span class="type">String</span>, age:<span class="type">Int</span></span>)</span></span><br><span class="line"><span class="keyword">val</span> dfData = <span class="type">Seq</span>(<span class="type">Person</span>(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="number">1</span>))</span><br><span class="line"><span class="keyword">val</span> ds = spark.createDataFrame(dfData)</span><br><span class="line">ds.show()</span><br><span class="line">+----+---+---+</span><br><span class="line">|name|sex|age|</span><br><span class="line">+----+---+---+</span><br><span class="line">|   a|  b|  <span class="number">1</span>|</span><br><span class="line">+----+---+---+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 只传入 RDD[Tuple]</span></span><br><span class="line"><span class="keyword">val</span> dfData = spark.sparkContext.parallelize(<span class="type">Seq</span>((<span class="number">1</span>,<span class="string">&quot;a&quot;</span>), (<span class="number">2</span>, <span class="string">&quot;b&quot;</span>)))</span><br><span class="line"><span class="keyword">val</span> ds = spark.createDataFrame(dfData)</span><br><span class="line">ds.show()</span><br><span class="line">+---+---+</span><br><span class="line">| _1| _2|</span><br><span class="line">+---+---+</span><br><span class="line">|  <span class="number">1</span>|  a|</span><br><span class="line">|  <span class="number">2</span>|  b|</span><br><span class="line">+---+---+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 传入 schema，数据可以是 RDD[Row]</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.&#123;<span class="type">StructType</span>, <span class="type">StructField</span>, <span class="type">StringType</span>, <span class="type">IntegerType</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> dfData = spark.sparkContext.parallelize(</span><br><span class="line">    <span class="type">Seq</span>(</span><br><span class="line">        <span class="type">Row</span>(<span class="string">&quot;Arya&quot;</span>, <span class="string">&quot;Woman&quot;</span>, <span class="number">30</span>),</span><br><span class="line">        <span class="type">Row</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;Man&quot;</span>, <span class="number">28</span>)</span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line"><span class="keyword">val</span> dfSchema = <span class="type">StructType</span>(</span><br><span class="line">    <span class="type">Seq</span>(</span><br><span class="line">    <span class="type">StructField</span>(<span class="string">&quot;name&quot;</span>, <span class="type">StringType</span>, <span class="literal">true</span>),</span><br><span class="line">    <span class="type">StructField</span>(<span class="string">&quot;sex&quot;</span>, <span class="type">StringType</span>, <span class="literal">true</span>),</span><br><span class="line">    <span class="type">StructField</span>(<span class="string">&quot;age&quot;</span>, <span class="type">IntegerType</span>, <span class="literal">true</span>)</span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df = spark.createDataFrame(dfData, dfSchema)</span><br><span class="line">df.show()</span><br><span class="line">+----+-----+---+</span><br><span class="line">|name|  sex|age|</span><br><span class="line">+----+-----+---+</span><br><span class="line">|<span class="type">Arya</span>|<span class="type">Woman</span>| <span class="number">30</span>|</span><br><span class="line">| <span class="type">Bob</span>|  <span class="type">Man</span>| <span class="number">28</span>|</span><br><span class="line">+----+-----+---+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 传入 schema，数据可以是 java.util.List[Row]</span></span><br><span class="line"><span class="keyword">val</span> dfData = <span class="keyword">new</span> java.util.<span class="type">ArrayList</span>[<span class="type">Row</span>]()</span><br><span class="line">dfData.add(<span class="type">Row</span>(<span class="string">&quot;Arya&quot;</span>, <span class="string">&quot;Woman&quot;</span>, <span class="number">30</span>))</span><br><span class="line">dfData.add(<span class="type">Row</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;Man&quot;</span>, <span class="number">28</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df = spark.createDataFrame(dfData, dfSchema)</span><br><span class="line">df.show()</span><br><span class="line">+----+-----+---+</span><br><span class="line">|name|  sex|age|</span><br><span class="line">+----+-----+---+</span><br><span class="line">|<span class="type">Arya</span>|<span class="type">Woman</span>| <span class="number">30</span>|</span><br><span class="line">| <span class="type">Bob</span>|  <span class="type">Man</span>| <span class="number">28</span>|</span><br><span class="line">+----+-----+---+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 构造复杂 Schema 时，使用实例化 StructType 对象的 add 方法更方便</span></span><br><span class="line"><span class="keyword">val</span> data = <span class="type">Seq</span>(</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;M&quot;</span>, <span class="number">3000</span>, <span class="type">Row</span>(<span class="string">&quot;James &quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;Smith&quot;</span>), <span class="type">Seq</span>(<span class="number">1</span>,<span class="number">2</span>), <span class="type">Map</span>(<span class="string">&quot;1&quot;</span>-&gt;<span class="string">&quot;a&quot;</span>, <span class="string">&quot;11&quot;</span>-&gt;<span class="string">&quot;aa&quot;</span>)),</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;M&quot;</span>, <span class="number">4000</span>, <span class="type">Row</span>(<span class="string">&quot;Michael &quot;</span>,<span class="string">&quot;Rose&quot;</span>,<span class="string">&quot;&quot;</span>), <span class="type">Seq</span>(<span class="number">3</span>,<span class="number">2</span>), <span class="type">Map</span>(<span class="string">&quot;2&quot;</span>-&gt;<span class="string">&quot;b&quot;</span>, <span class="string">&quot;22&quot;</span>-&gt;<span class="string">&quot;bb&quot;</span>)),</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;M&quot;</span>, <span class="number">4000</span>, <span class="type">Row</span>(<span class="string">&quot;Robert &quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;Williams&quot;</span>), <span class="type">Seq</span>(<span class="number">1</span>,<span class="number">2</span>), <span class="type">Map</span>(<span class="string">&quot;3&quot;</span>-&gt;<span class="string">&quot;c&quot;</span>, <span class="string">&quot;33&quot;</span>-&gt;<span class="string">&quot;cc&quot;</span>)),</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;F&quot;</span>, <span class="number">4000</span>, <span class="type">Row</span>(<span class="string">&quot;Maria &quot;</span>,<span class="string">&quot;Anne&quot;</span>,<span class="string">&quot;Jones&quot;</span>), <span class="type">Seq</span>(<span class="number">3</span>,<span class="number">3</span>), <span class="type">Map</span>(<span class="string">&quot;4&quot;</span>-&gt;<span class="string">&quot;d&quot;</span>, <span class="string">&quot;44&quot;</span>-&gt;<span class="string">&quot;dd&quot;</span>)),</span><br><span class="line">      <span class="type">Row</span>(<span class="string">&quot;F&quot;</span>, <span class="number">-1</span>, <span class="type">Row</span>(<span class="string">&quot;Jen&quot;</span>,<span class="string">&quot;Mary&quot;</span>,<span class="string">&quot;Brown&quot;</span>), <span class="type">Seq</span>(<span class="number">5</span>,<span class="number">2</span>), <span class="type">Map</span>(<span class="string">&quot;5&quot;</span>-&gt;<span class="string">&quot;e&quot;</span>))</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> schema = <span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">      .add(<span class="string">&quot;gender&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      .add(<span class="string">&quot;salary&quot;</span>,<span class="type">IntegerType</span>)</span><br><span class="line">      .add(<span class="string">&quot;f_struct&quot;</span>,</span><br><span class="line">        <span class="keyword">new</span> <span class="type">StructType</span>()</span><br><span class="line">          .add(<span class="string">&quot;firstname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">          .add(<span class="string">&quot;middlename&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">          .add(<span class="string">&quot;lastname&quot;</span>,<span class="type">StringType</span>)</span><br><span class="line">      )  </span><br><span class="line">      .add(<span class="string">&quot;f_array&quot;</span>, <span class="type">ArrayType</span>(<span class="type">IntegerType</span>))</span><br><span class="line">      .add(<span class="string">&quot;f_map&quot;</span>, <span class="type">MapType</span>(<span class="type">StringType</span>, <span class="type">StringType</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df = spark.createDataFrame(spark.sparkContext.parallelize(data),schema)</span><br><span class="line">df.show()</span><br><span class="line">df.printSchema</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line">|gender|salary|            f_struct|f_array|             f_map|</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">3000</span>|   [<span class="type">James</span> , , <span class="type">Smith</span>]| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">1</span> -&gt; a, <span class="number">11</span> -&gt; aa]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|  [<span class="type">Michael</span> , <span class="type">Rose</span>, ]| [<span class="number">3</span>, <span class="number">2</span>]|[<span class="number">2</span> -&gt; b, <span class="number">22</span> -&gt; bb]|</span><br><span class="line">|     <span class="type">M</span>|  <span class="number">4000</span>|[<span class="type">Robert</span> , , <span class="type">Willi</span>...| [<span class="number">1</span>, <span class="number">2</span>]|[<span class="number">3</span> -&gt; c, <span class="number">33</span> -&gt; cc]|</span><br><span class="line">|     <span class="type">F</span>|  <span class="number">4000</span>|[<span class="type">Maria</span> , <span class="type">Anne</span>, <span class="type">Jo</span>...| [<span class="number">3</span>, <span class="number">3</span>]|[<span class="number">4</span> -&gt; d, <span class="number">44</span> -&gt; dd]|</span><br><span class="line">|     <span class="type">F</span>|    <span class="number">-1</span>|  [<span class="type">Jen</span>, <span class="type">Mary</span>, <span class="type">Brown</span>]| [<span class="number">5</span>, <span class="number">2</span>]|          [<span class="number">5</span> -&gt; e]|</span><br><span class="line">+------+------+--------------------+-------+------------------+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- gender: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- salary: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_struct: struct (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- firstname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- middlename: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- lastname: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- f_array: array (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- element: integer (containsNull = <span class="literal">true</span>)</span><br><span class="line"> |-- f_map: map (nullable = <span class="literal">true</span>)</span><br><span class="line"> |    |-- key: string</span><br><span class="line"> |    |-- value: string (valueContainsNull = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><ul><li><code>createDataSet(x)</code> 是 <code>x.toDS()</code> 的等价形式：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 序列元素为简单类型</span></span><br><span class="line"><span class="keyword">val</span> ds = spark.createDataset(<span class="type">Seq</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">ds.show()</span><br><span class="line">+-----+</span><br><span class="line">|value|</span><br><span class="line">+-----+</span><br><span class="line">|    <span class="number">1</span>|</span><br><span class="line">|    <span class="number">2</span>|</span><br><span class="line">|    <span class="number">3</span>|</span><br><span class="line">+-----+</span><br><span class="line"><span class="comment">// 序列元素是元组</span></span><br><span class="line"><span class="keyword">val</span> ds = spark.createDataset(<span class="type">Seq</span>((<span class="string">&quot;Arya&quot;</span>,<span class="number">20</span>,<span class="string">&quot;woman&quot;</span>), (<span class="string">&quot;Bob&quot;</span>,<span class="number">28</span>,<span class="string">&quot;man&quot;</span>)))</span><br><span class="line">ds.show()</span><br><span class="line">+----+---+-----+</span><br><span class="line">|  _1| _2|   _3|</span><br><span class="line">+----+---+-----+</span><br><span class="line">|<span class="type">Arya</span>| <span class="number">20</span>|woman|</span><br><span class="line">| <span class="type">Bob</span>| <span class="number">28</span>|  man|</span><br><span class="line">+----+---+-----+</span><br><span class="line"></span><br><span class="line"><span class="comment">// 序列元素为样例类实例，样例类的字段会成为 DataSet 的字段</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Long</span>, sex:<span class="type">String</span></span>)</span></span><br><span class="line"><span class="keyword">val</span> ds = spark.createDataset(<span class="type">Seq</span>(<span class="type">Person</span>(<span class="string">&quot;Arya&quot;</span>, <span class="number">20</span>, <span class="string">&quot;woman&quot;</span>), <span class="type">Person</span>(<span class="string">&quot;Bob&quot;</span>, <span class="number">28</span>, <span class="string">&quot;man&quot;</span>)))</span><br><span class="line">ds.show()</span><br><span class="line">+----+---+-----+</span><br><span class="line">|name|age|  sex|</span><br><span class="line">+----+---+-----+</span><br><span class="line">|<span class="type">Arya</span>| <span class="number">20</span>|woman|</span><br><span class="line">| <span class="type">Bob</span>| <span class="number">28</span>|  man|</span><br><span class="line">+----+---+-----+</span><br><span class="line"><span class="comment">// 将 RDD 转化为 DataSet</span></span><br><span class="line"><span class="keyword">val</span> ds = spark.createDataset(spark.sparkContext.parallelize(<span class="type">Seq</span>((<span class="string">&quot;Arya&quot;</span>,<span class="number">20</span>,<span class="string">&quot;woman&quot;</span>), (<span class="string">&quot;Bob&quot;</span>,<span class="number">28</span>,<span class="string">&quot;man&quot;</span>))))</span><br><span class="line">ds.show()</span><br><span class="line">+----+---+-----+</span><br><span class="line">|  _1| _2|   _3|</span><br><span class="line">+----+---+-----+</span><br><span class="line">|<span class="type">Arya</span>| <span class="number">20</span>|woman|</span><br><span class="line">| <span class="type">Bob</span>| <span class="number">28</span>|  man|</span><br><span class="line">+----+---+-----+</span><br></pre></td></tr></table></figure></div><h2 id="从数据源加载"><a href="#从数据源加载" class="headerlink" title="从数据源加载"></a>从数据源加载</h2><p>Spark 有六个核心数据源和社区编写的数百个外部数据源（Cassandra、HBase、MongoDB、XML）：</p><ol><li>CSV</li><li>JSON</li><li>Parquet</li><li>ORC</li><li>JDBC/ODBC connections</li><li>Plain-text files 纯文本文件</li></ol><h3 id="API-格式"><a href="#API-格式" class="headerlink" title="API 格式"></a>API 格式</h3><h4 id="Read-API"><a href="#Read-API" class="headerlink" title="Read API"></a>Read API</h4><p>读取数据源的通用 API 结构如下：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">DataFrameReader</span>.format(...).option(<span class="string">&quot;key&quot;</span>, <span class="string">&quot;value&quot;</span>).schema(...).load(path)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 示例</span></span><br><span class="line">spark.read.format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;mode&quot;</span>, <span class="string">&quot;FAILFAST&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;inferSchema&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;path&quot;</span>, <span class="string">&quot;path/to/file&quot;</span>)</span><br><span class="line">    .schema(someSchema)</span><br><span class="line">    .load()</span><br></pre></td></tr></table></figure></div><p>读取数据的基本要素：</p><ol><li><code>DataFrameReader</code> 是 DataFrame 读取器，可以通过 <code>SparkSession</code> 的 <code>read</code> 属性来使用；</li><li><code>format</code> 是可选的，默认使用 Parquet 格式；</li><li><code>option</code> 允许设置键值配置，以参数化如何读取数据，也可以传入一个 Map；</li><li><code>schema</code> 如果数据源提供了 schema，或者你打算使用 schema 推断，则 schema 是可选的；每种格式都有一些必选项，我们将在讨论每种格式时进行详细讨论；</li></ol><p>Read modes 用于指定当 Spark 遇到格式错误的记录时如何处理：</p><ol><li><code>permissive</code>    ：默认值，遇到损坏的记录时，将所有损坏记录放在名为<code>called_corrupt_record</code>的字符串列中，将所有字段设置为 null；</li><li><code>dropMalformed</code>    ：删除包含格式错误的行；</li><li><code>failFast</code> ：遇到格式错误的记录立即失败；</li></ol><h4 id="Write-API"><a href="#Write-API" class="headerlink" title="Write API"></a>Write API</h4><p>写入数据的通用 API 结构如下：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">DataFrameWriter</span>.format(...).option(...).partitionBy(...).bucketBy(...).sortBy(...).save()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 示例</span></span><br><span class="line">df.write.format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;mode&quot;</span>, <span class="string">&quot;OVERWRITE&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;dataFormat&quot;</span>, <span class="string">&quot;yyyy-MM-dd&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;path&quot;</span>, <span class="string">&quot;path/to/file&quot;</span>)</span><br><span class="line">    .save(path)</span><br></pre></td></tr></table></figure></div><p>数据写入的基本要素：</p><ol><li><code>DataFrameWriter</code> 是 DataFrame 写入器，可以通过 <code>DataFrame</code> 的 <code>write</code> 属性来使用；</li><li><code>format</code> 是可选的，默认使用 Parquet 格式；</li><li><code>option</code> 允许设置键值配置，以参数化如何读取数据，也可以传入一个 Map；必须至少提供一个保存路径；</li></ol><p>Save modes 用于指定当 Spark 在指定位置找到数据将发生什么：</p><ol><li><code>apppend</code>：将输出文件追加到该位置已存在的文件列表中；</li><li><code>overwrite</code>：将完全覆盖那里已经存在的任何数据；</li><li><code>errorIfExists</code>：默认值，如果指定位置已经存在数据或文件，则会引发错误并导致写入失败；</li><li><code>ignore</code>：如果该位置存在数据或文件，则不执行任何操作；</li></ol><h3 id="CSV"><a href="#CSV" class="headerlink" title="CSV"></a>CSV</h3><p>CSV 文件虽然看起来结构良好，但实际上是你将遇到的最棘手的文件格式之一，因为在生产方案中无法对其所包含的内容或结果进行很多假设，因此，CSV 读取器具有大量选项。</p><ul><li>option 说明：</li></ul><div class="table-container"><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>sep</td><td>默认是, 指定单个字符分割字段和值</td></tr><tr><td>encoding</td><td>默认是uft-8通过给定的编码类型进行解码</td></tr><tr><td>quote</td><td>默认是“，其中分隔符可以是值的一部分，设置用于转义带引号的值的单个字符。<br>如果您想关闭引号，则需要设置一个空字符串，而不是null。</td></tr><tr><td>escape</td><td>默认(\)设置单个字符用于在引号里面转义引号</td></tr><tr><td>charToEscapeQuoteEscaping</td><td>默认是转义字符（上面的escape）或者\0，当转义字符和引号(quote)字符<br>不同的时候，默认是转义字符(escape)，否则为\0</td></tr><tr><td>comment</td><td>默认是空值，设置用于跳过行的单个字符，以该字符开头。默认情况下，它是禁用的</td></tr><tr><td>header</td><td>默认是false，将第一行作为列名</td></tr><tr><td>enforceSchema</td><td>默认是true， 如果将其设置为true，则指定或推断的模式将强制应用于数据源文件，<br>而CSV文件中的标头将被忽略。 如果选项设置为false，则在header选项设置为true的情况下，<br>将针对CSV文件中的所有标题验证模式。模式中的字段名称和CSV标头<br>中的列名称是根据它们的位置检查的，并考虑了*spark.sql.caseSensitive。<br>虽然默认值为true，但是建议禁用 enforceSchema选项，以避免产生错误的结果</td></tr><tr><td>inferSchema</td><td>inferSchema（默认为false`）：从数据自动推断输入模式。 <br>*需要对数据进行一次额外的传递</td></tr><tr><td>samplingRatio</td><td>默认为1.0,定义用于模式推断的行的分数</td></tr><tr><td>ignoreLeadingWhiteSpace</td><td>默认为false,一个标志，指示是否应跳过正在读取的值中的前导空格</td></tr><tr><td>ignoreTrailingWhiteSpace</td><td>默认为false一个标志，指示是否应跳过正在读取的值的结尾空格</td></tr><tr><td>nullValue</td><td>默认是空的字符串,设置null值的字符串表示形式。从2.0.1开始，<br>这适用于所有支持的类型，包括字符串类型</td></tr><tr><td>emptyValue</td><td>默认是空字符串,设置一个空值的字符串表示形式</td></tr><tr><td>nanValue</td><td>默认是Nan,设置非数字的字符串表示形式</td></tr><tr><td>positiveInf</td><td>默认是Inf</td></tr><tr><td>negativeInf</td><td>默认是-Inf 设置负无穷值的字符串表示形式</td></tr><tr><td>dateFormat</td><td>默认是yyyy-MM-dd,设置指示日期格式的字符串。自定义日期格式遵循<br>java.text.SimpleDateFormat中的格式。这适用于日期类型</td></tr><tr><td>timestampFormat</td><td>默认是yyyy-MM-dd’T’HH:mm:ss.SSSXXX，设置表示时间戳格式的字符串。<br>自定义日期格式遵循java.text.SimpleDateFormat中的格式。这适用于时间戳记类型</td></tr><tr><td>maxColumns</td><td>默认是20480定义多少列数目的硬性设置</td></tr><tr><td>maxCharsPerColumn</td><td>默认是-1定义读取的任何给定值允许的最大字符数。默认情况下为-1，表示长度不受限制</td></tr><tr><td>mode</td><td>默认（允许）允许一种在解析过程中处理损坏记录的模式。它支持以下不区分大小写的模式。<br>请注意，Spark尝试在列修剪下仅解析CSV中必需的列。<br>因此，损坏的记录可以根据所需的字段集而有所不同。<br>可以通过spark.sql.csv.parser.columnPruning.enabled（默认启用）来控制此行为。</td></tr><tr><td>columnNameOfCorruptRecord</td><td>默认值指定在spark.sql.columnNameOfCorruptRecord,<br>允许重命名由PERMISSIVE模式创建的格式错误的新字段。<br>这会覆盖spark.sql.columnNameOfCorruptRecord</td></tr><tr><td>multiLine</td><td>默认是false,解析一条记录，该记录可能跨越多行   </td></tr></tbody></table></div><ul><li>读取 CSV 示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> mySchema = <span class="keyword">new</span> <span class="type">StructType</span>(</span><br><span class="line">    <span class="type">Array</span>(</span><br><span class="line">        <span class="keyword">new</span> <span class="type">StructField</span>(<span class="string">&quot;a&quot;</span>, <span class="type">StringType</span>, <span class="literal">true</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="type">StructField</span>(<span class="string">&quot;b&quot;</span>, <span class="type">IntegerType</span>, <span class="literal">true</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="type">StructField</span>(<span class="string">&quot;c&quot;</span>, <span class="type">StringType</span>, <span class="literal">false</span>)</span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df = spark.read.format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;header&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;mode&quot;</span>, <span class="string">&quot;permissive&quot;</span>)</span><br><span class="line">    .schema(mySchema)</span><br><span class="line">    .load(<span class="string">&quot;job.csv&quot;</span>)</span><br><span class="line">df.show()</span><br><span class="line">df.printSchema</span><br><span class="line">+------+---+---+</span><br><span class="line">|     a|  b|  c|</span><br><span class="line">+------+---+---+</span><br><span class="line">|caster|  <span class="number">0</span>| <span class="number">26</span>|</span><br><span class="line">|  like|  <span class="number">1</span>| <span class="number">30</span>|</span><br><span class="line">|   leo|  <span class="number">2</span>| <span class="number">30</span>|</span><br><span class="line">|rayray|  <span class="number">3</span>| <span class="number">27</span>|</span><br><span class="line">+------+---+---+</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- a: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- b: integer (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- c: string (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></div><ul><li>写入 CSV 示例：<code>job2.csv</code> 实际上是一个目录，其中包含很多文件，文件数对应分区数；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df.write.format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">    .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;seq&quot;</span>, <span class="string">&quot;\t&quot;</span>)</span><br><span class="line">    .save(<span class="string">&quot;job2.csv&quot;</span>)</span><br></pre></td></tr></table></figure></div><h3 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h3><p>在 Spark 中，当我们谈到 JSON 文件时，指的的是 <code>line-delimited</code> JSON 文件，这与每个文件具有较大 JSON 对象或数组的文件形成对比。<code>line-delimited</code> 和 <code>multiline</code> 由选项 <code>multiLine</code> 控制，当将此选项设置为 true 时，可以将整个文件作为一个 json 对象读取。<code>line-delimited</code> 的 JSON 实际上是一种更加稳定的格式，它允许你将具有新记录的文件追加到文件中，这也是建议你使用的格式。</p><ul><li>option 说明：</li></ul><div class="table-container"><table><thead><tr><th>属性名称</th><th>默认值</th><th>含义</th></tr></thead><tbody><tr><td>primitivesAsString</td><td>FALSE</td><td>将所有原始类型推断为字符串类型</td></tr><tr><td>prefersDecimal</td><td>FALSE</td><td>将所有浮点类型推断为 decimal 类型，如果不适合，<br>则推断为 double 类型</td></tr><tr><td>allowComments</td><td>FALSE</td><td>忽略 JSON 记录中的 Java / C ++样式注释</td></tr><tr><td>allowUnquotedFieldNames</td><td>FALSE</td><td>允许不带引号的 JSON 字段名称</td></tr><tr><td>allowSingleQuotes</td><td>TRUE</td><td>除双引号外，还允许使用单引号</td></tr><tr><td>allowNumericLeadingZeros</td><td>FALSE</td><td>允许数字前有零</td></tr><tr><td>allowBackslashEscapingAnyCharacter</td><td>FALSE</td><td>允许反斜杠转义任何字符</td></tr><tr><td>allowUnquotedControlChars</td><td>FALSE</td><td>允许JSON字符串包含不带引号的控制字符（值小于32的ASCII字符，<br>包括制表符和换行符）或不包含。</td></tr><tr><td>mode</td><td>PERMISSIVE</td><td>PERMISSIVE：允许在解析过程中处理损坏记录； DROPMALFORMED：<br>忽略整个损坏的记录；FAILFAST：遇到损坏的记录时抛出异常。</td></tr><tr><td>columnNameOfCorruptRecord</td><td></td><td>columnNameOfCorruptRecord（默认值是spark.sql.columnNameOfCorruptRecord中指定的值）：<br>允许重命名由PERMISSIVE 模式创建的新字段（存储格式错误的字符串）。<br>这会覆盖spark.sql.columnNameOfCorruptRecord。</td></tr><tr><td>dateFormat</td><td></td><td>dateFormat（默认yyyy-MM-dd）：设置表示日期格式的字符串。<br>自定义日期格式遵循java.text.SimpleDateFormat中的格式。</td></tr><tr><td>timestampFormat</td><td></td><td>timestampFormat（默认yyyy-MM-dd’T’HH：mm：ss.SSSXXX）：<br>设置表示时间戳格式的字符串。 自定义日期格式遵循java.text.SimpleDateFormat中的格式。</td></tr><tr><td>multiLine</td><td>FALSE</td><td>解析可能跨越多行的一条记录</td></tr></tbody></table></div><ul><li>读取 JSON 示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">spark.read.format(<span class="string">&quot;json&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;mode&quot;</span>, <span class="string">&quot;FAILFAST&quot;</span>)</span><br><span class="line">    .schema(mySchema)</span><br><span class="line">    .load(path)</span><br></pre></td></tr></table></figure></div><ul><li>写入 JSON 示例：同样每个分区将写入一个文件，而整个 DataFrame 将作为一个文件夹写入，每行将有一个 JSON 对象</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.write.format(<span class="string">&quot;json&quot;</span>).mode(<span class="string">&quot;overwrite&quot;</span>).save(path)</span><br></pre></td></tr></table></figure></div><h3 id="Parquet"><a href="#Parquet" class="headerlink" title="Parquet"></a>Parquet</h3><p>Parquet 是 Spark 的默认文件格式（默认数据源可以通过 <code>spark.sql.sources.default</code> 进行设置），Parquet 是面向列的开源数据存储，可提供各种存储优化。它提供了列压缩，从而节省了存储空间，并允许读取单个列而不是整个文件。Parquet 支持复杂类型，如果你的列是 <code>struct</code>、<code>array</code>、<code>map</code> 类型，仍然可以正常读写该文件。</p><ul><li>读取 Parquet 文件：Parquet 选项很少，因为它在存储数据时会强制执行自己的 Schema，你只需要设置格式就行了</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.read.format(<span class="string">&quot;parquet&quot;</span>).load(path)</span><br></pre></td></tr></table></figure></div><ul><li>写入 Parquet 文件：只需要指定文件位置即可</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.write.format(<span class="string">&quot;parquet&quot;</span>)</span><br><span class="line">    .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">    .save(path)</span><br></pre></td></tr></table></figure></div><h3 id="ORC"><a href="#ORC" class="headerlink" title="ORC"></a>ORC</h3><p>ORC 是一种专为 Hadoop workloads 设计的自我描述、有类型的列式文件格式。它针对大型数据流进行了优化，但是集成了对快速查找所需行的支持。ORC 实际上没有读取数据的选项，因为 Spark 非常了解这种文件格式，一个经常会被问到的问题是：ORC 和 Parquet 有什么区别？在大多数情况下，他们非常相似，根本的区别在于 Parquet 专门为 Spark 做了优化，而 ORC 专门为 Hive 做了优化。</p><ul><li>读取 ORC 示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.read.format(<span class="string">&quot;orc&quot;</span>).load(path)</span><br></pre></td></tr></table></figure></div><ul><li>写入 ORC 示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.write.format(<span class="string">&quot;orc&quot;</span>).mode(<span class="string">&quot;overwrite&quot;</span>).save(path)</span><br></pre></td></tr></table></figure></div><h3 id="Hive-数据源"><a href="#Hive-数据源" class="headerlink" title="Hive 数据源"></a>Hive 数据源</h3><p>Spark SQL 还支持读取和写入存储在Apache Hive中的数据。但是，由于Hive具有大量依赖项，因此这些依赖项不包含在默认的Spark发布包中。如果可以在类路径上找到Hive依赖项，Spark将自动加载它们。请注意，这些Hive依赖项也必须存在于所有工作节点(worker nodes)上，因为它们需要访问Hive序列化和反序列化库（SerDes）才能访问存储在Hive中的数据。</p><p>在使用Hive时，必须实例化一个支持Hive的SparkSession，包括连接到持久性Hive Metastore，支持Hive 的序列化、反序列化（serdes）和Hive用户定义函数。没有部署Hive的用户仍可以启用Hive支持。如果未配置hive-site.xml，则上下文(context)会在当前目录中自动创建metastore_db，并且会创建一个由spark.sql.warehouse.dir配置的目录，其默认目录为spark-warehouse，位于启动Spark应用程序的当前目录中。请注意，自Spark 2.0.0以来，该在hive-site.xml中的hive.metastore.warehouse.dir属性已被标记过时(deprecated)。使用spark.sql.warehouse.dir用于指定warehouse中的默认位置。可能需要向启动Spark应用程序的用户授予写入的权限。</p><p>下面的案例为在本地运行(为了方便查看打印的结果)，运行结束之后会发现在项目的目录下 <code>E:\IdeaProjects\myspark</code> 创建了 <code>spark-warehouse</code> 和 <code>metastore_db</code> 的文件夹。可以看出没有部署Hive的用户仍可以启用Hive支持，同时也可以将代码打包，放在集群上运行。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkHiveExample</span> </span>&#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Record</span>(<span class="params">key: <span class="type">Int</span>, value: <span class="type">String</span></span>)</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .appName(<span class="string">&quot;Spark Hive Example&quot;</span>)</span><br><span class="line">      .config(<span class="string">&quot;spark.sql.warehouse.dir&quot;</span>, <span class="string">&quot;e://warehouseLocation&quot;</span>)</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)<span class="comment">//设置为本地运行</span></span><br><span class="line">      .enableHiveSupport()</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="type">Logger</span>.getLogger(<span class="string">&quot;org.apache.spark&quot;</span>).setLevel(<span class="type">Level</span>.<span class="type">OFF</span>)</span><br><span class="line">    <span class="type">Logger</span>.getLogger(<span class="string">&quot;org.apache.hadoop&quot;</span>).setLevel(<span class="type">Level</span>.<span class="type">OFF</span>)</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="keyword">import</span> spark.sql</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//使用Spark SQL 的语法创建Hive中的表</span></span><br><span class="line">    sql(<span class="string">&quot;CREATE TABLE IF NOT EXISTS src (key INT, value STRING) USING hive&quot;</span>)</span><br><span class="line">    sql(<span class="string">&quot;LOAD DATA LOCAL INPATH &#x27;file:///e:/kv1.txt&#x27; INTO TABLE src&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用HiveQL查询</span></span><br><span class="line">    sql(<span class="string">&quot;SELECT * FROM src&quot;</span>).show()</span><br><span class="line">    <span class="comment">// +---+-------+</span></span><br><span class="line">    <span class="comment">// |key|  value|</span></span><br><span class="line">    <span class="comment">// +---+-------+</span></span><br><span class="line">    <span class="comment">// |238|val_238|</span></span><br><span class="line">    <span class="comment">// | 86| val_86|</span></span><br><span class="line">    <span class="comment">// |311|val_311|</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 支持使用聚合函数</span></span><br><span class="line">    sql(<span class="string">&quot;SELECT COUNT(*) FROM src&quot;</span>).show()</span><br><span class="line">    <span class="comment">// +--------+</span></span><br><span class="line">    <span class="comment">// |count(1)|</span></span><br><span class="line">    <span class="comment">// +--------+</span></span><br><span class="line">    <span class="comment">// |    500 |</span></span><br><span class="line">    <span class="comment">// +--------+</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// SQL查询的结果是一个DataFrame，支持使用所有的常规的函数</span></span><br><span class="line">    <span class="keyword">val</span> sqlDF = sql(<span class="string">&quot;SELECT key, value FROM src WHERE key &lt; 10 AND key &gt; 0 ORDER BY key&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// DataFrames是Row类型的, 允许你按顺序访问列.</span></span><br><span class="line">    <span class="keyword">val</span> stringsDS = sqlDF.map &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Row</span>(key: <span class="type">Int</span>, value: <span class="type">String</span>) =&gt; <span class="string">s&quot;Key: <span class="subst">$key</span>, Value: <span class="subst">$value</span>&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    stringsDS.show()</span><br><span class="line">    <span class="comment">// +--------------------+</span></span><br><span class="line">    <span class="comment">// |               value|</span></span><br><span class="line">    <span class="comment">// +--------------------+</span></span><br><span class="line">    <span class="comment">// |Key: 0, Value: val_0|</span></span><br><span class="line">    <span class="comment">// |Key: 0, Value: val_0|</span></span><br><span class="line">    <span class="comment">// |Key: 0, Value: val_0|</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//可以通过SparkSession使用DataFrame创建一个临时视图</span></span><br><span class="line">    <span class="keyword">val</span> recordsDF = spark.createDataFrame((<span class="number">1</span> to <span class="number">100</span>).map(i =&gt; <span class="type">Record</span>(i, <span class="string">s&quot;val_<span class="subst">$i</span>&quot;</span>)))</span><br><span class="line">    recordsDF.createOrReplaceTempView(<span class="string">&quot;records&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//可以用DataFrame与Hive中的表进行join查询</span></span><br><span class="line">    sql(<span class="string">&quot;SELECT * FROM records r JOIN src s ON r.key = s.key&quot;</span>).show()</span><br><span class="line">    <span class="comment">// +---+------+---+------+</span></span><br><span class="line">    <span class="comment">// |key| value|key| value|</span></span><br><span class="line">    <span class="comment">// +---+------+---+------+</span></span><br><span class="line">    <span class="comment">// |  2| val_2|  2| val_2|</span></span><br><span class="line">    <span class="comment">// |  4| val_4|  4| val_4|</span></span><br><span class="line">    <span class="comment">// |  5| val_5|  5| val_5|</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建一个Parquet格式的hive托管表，使用的是HQL语法，没有使用Spark SQL的语法(&quot;USING hive&quot;)</span></span><br><span class="line">    sql(<span class="string">&quot;CREATE TABLE IF NOT EXISTS hive_records(key int, value string) STORED AS PARQUET&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//读取Hive中的表，转换成了DataFrame</span></span><br><span class="line">    <span class="keyword">val</span> df = spark.table(<span class="string">&quot;src&quot;</span>)</span><br><span class="line">    <span class="comment">//将该DataFrame保存为Hive中的表，使用的模式(mode)为复写模式(Overwrite)</span></span><br><span class="line">    <span class="comment">//即如果保存的表已经存在，则会覆盖掉原来表中的内容</span></span><br><span class="line">    df.write.mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>).saveAsTable(<span class="string">&quot;hive_records&quot;</span>)</span><br><span class="line">    <span class="comment">// 查询表中的数据</span></span><br><span class="line">    sql(<span class="string">&quot;SELECT * FROM hive_records&quot;</span>).show()</span><br><span class="line">    <span class="comment">// +---+-------+</span></span><br><span class="line">    <span class="comment">// |key|  value|</span></span><br><span class="line">    <span class="comment">// +---+-------+</span></span><br><span class="line">    <span class="comment">// |238|val_238|</span></span><br><span class="line">    <span class="comment">// | 86| val_86|</span></span><br><span class="line">    <span class="comment">// |311|val_311|</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置Parquet数据文件路径</span></span><br><span class="line">    <span class="keyword">val</span> dataDir = <span class="string">&quot;/tmp/parquet_data&quot;</span></span><br><span class="line">    <span class="comment">//spark.range(10)返回的是DataSet[Long]</span></span><br><span class="line">    <span class="comment">//将该DataSet直接写入parquet文件</span></span><br><span class="line">    spark.range(<span class="number">10</span>).write.parquet(dataDir)</span><br><span class="line">    <span class="comment">// 在Hive中创建一个Parquet格式的外部表</span></span><br><span class="line">    sql(<span class="string">s&quot;CREATE EXTERNAL TABLE IF NOT EXISTS hive_ints(key int) STORED AS PARQUET LOCATION &#x27;<span class="subst">$dataDir</span>&#x27;&quot;</span>)</span><br><span class="line">    <span class="comment">// 查询上面创建的表</span></span><br><span class="line">    sql(<span class="string">&quot;SELECT * FROM hive_ints&quot;</span>).show()</span><br><span class="line">    <span class="comment">// +---+</span></span><br><span class="line">    <span class="comment">// |key|</span></span><br><span class="line">    <span class="comment">// +---+</span></span><br><span class="line">    <span class="comment">// |  0|</span></span><br><span class="line">    <span class="comment">// |  1|</span></span><br><span class="line">    <span class="comment">// |  2|</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 开启Hive动态分区</span></span><br><span class="line">    spark.sqlContext.setConf(<span class="string">&quot;hive.exec.dynamic.partition&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">    spark.sqlContext.setConf(<span class="string">&quot;hive.exec.dynamic.partition.mode&quot;</span>, <span class="string">&quot;nonstrict&quot;</span>)</span><br><span class="line">    <span class="comment">// 使用DataFrame API创建Hive的分区表</span></span><br><span class="line">    df.write.partitionBy(<span class="string">&quot;key&quot;</span>).format(<span class="string">&quot;hive&quot;</span>).saveAsTable(<span class="string">&quot;hive_part_tbl&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//分区键‘key’将会在最终的schema中被移除</span></span><br><span class="line">    sql(<span class="string">&quot;SELECT * FROM hive_part_tbl&quot;</span>).show()</span><br><span class="line">    <span class="comment">// +-------+---+</span></span><br><span class="line">    <span class="comment">// |  value|key|</span></span><br><span class="line">    <span class="comment">// +-------+---+</span></span><br><span class="line">    <span class="comment">// |val_238|238|</span></span><br><span class="line">    <span class="comment">// | val_86| 86|</span></span><br><span class="line">    <span class="comment">// |val_311|311|</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h3 id="JDBC-数据源"><a href="#JDBC-数据源" class="headerlink" title="JDBC 数据源"></a>JDBC 数据源</h3><p>Spark SQL 还包括一个可以使用 JDBC 从其他数据库读取数据的数据源。与使用 JdbcRDD 相比，应优先使用此功能。这是因为结果作为 DataFrame 返回，它们可以在 Spark SQL 中轻松处理或与其他数据源连接。JDBC 数据源也更易于使用 Java 或 Python，因为它不需要用户提供 ClassTag。</p><p>可以使用 Data Sources API 将远程数据库中的表加载为 DataFrame 或 Spark SQL 临时视图。用户可以在数据源选项中指定JDBC连接属性。user并且password通常作为用于登录数据源的连接属性提供。除连接属性外，Spark还支持以下不区分大小写的选项：</p><div class="table-container"><table><thead><tr><th>属性名称</th><th>含义</th></tr></thead><tbody><tr><td>url</td><td>要连接的JDBC URL，可以再URL中指定特定于源的连接属性</td></tr><tr><td>dbtable</td><td>应该读取或写入的JDBC表</td></tr><tr><td>query</td><td>将数据读入Spark的查询语句</td></tr><tr><td>driver</td><td>用于连接到此URL的JDBC驱动程序的类名</td></tr><tr><td>numPartitions</td><td>表读取和写入中可用于并行的最大分区数，同时确定了最大并发的JDBC连接数</td></tr><tr><td>partitionColumn,<br>lowerBound,<br>upperBound</td><td>如果指定了任一选项，则必须指定全部选项。此外，还必须指定numPartitions。<br>partitionColumn必须是表中的数字，日期或时间戳列。<br>注意：lowerBound和upperBound（仅用于决定分区步幅，而不是用于过滤表中的行。<br>因此，表中的所有行都将被分区并返回，这些选项仅用于读操作。）</td></tr><tr><td>queryTimeout</td><td>超时时间（单位：秒），零意味着没有限制</td></tr><tr><td>fetchsize</td><td>用于确定每次往返要获取的行数（例如Oracle是10行），<br>可以用于提升JDBC驱动程序的性能。此选项仅适用于读</td></tr><tr><td>batchsize</td><td>JDBC批处理大小，默认 1000，用于确定每次往返要插入的行数。 <br>这可以用于提升 JDBC 驱动程序的性能。此选项仅适用于写。</td></tr><tr><td>isolationLevel</td><td>事务隔离级别，适用于当前连接。它可以是 NONE，READ_COMMITTED，<br>READ_UNCOMMITTED，REPEATABLE_READ 或 SERIALIZABLE 之一，<br>对应于 JDBC的Connection 对象定义的标准事务隔离级别，<br>默认值为 READ_UNCOMMITTED。此选项仅适用于写。</td></tr><tr><td>sessionInitStatement</td><td>在向远程数据库打开每个数据库会话之后，在开始读取数据之前，<br>此选项将执行自定义SQL语句（或PL / SQL块）。 <br>使用它来实现会话初始化，例如：option(“sessionInitStatement”, <br>“”“BEGIN execute immediate ‘alter session set “_serial_direct_read”=true’; END;”””)</td></tr><tr><td>truncate</td><td>当启用SaveMode.Overwrite时，此选项会导致 Spark 截断现有表，<br>而不是删除并重新创建它。这样更高效，并且防止删除表元数据（例如，索引）。<br>但是，在某些情况下，例如新数据具有不同的 schema 时，它将无法工作。此选项仅适用于写。</td></tr><tr><td>cascadeTruncate</td><td>如果JDBC数据库（目前为 PostgreSQL和Oracle）启用并支持，<br>则此选项允许执行TRUNCATE TABLE t CASCADE（在PostgreSQL的情况下，<br>仅执行TRUNCATE TABLE t CASCADE以防止无意中截断表）。<br>这将影响其他表，因此应谨慎使用。此选项仅适用于写。</td></tr><tr><td>createTableOptions</td><td>此选项允许在创建表时设置特定于数据库的表和分区选项<br>（例如，CREATE TABLE t (name string) ENGINE=InnoDB）。此选项仅适用于写。</td></tr><tr><td>createTableColumnTypes</td><td>创建表时要使用的数据库列数据类型而不是默认值。<br>（例如：name CHAR（64），comments VARCHAR（1024））。<br>指定的类型应该是有效的 spark sql 数据类型。 此选项仅适用于写。</td></tr><tr><td>customSchema</td><td>用于从JDBC连接器读取数据的自定义 schema。<br>例如，id DECIMAL(38, 0), name STRING。<br>您还可以指定部分字段，其他字段使用默认类型映射。 <br>例如，id DECIMAL（38,0）。列名应与JDBC表的相应列名相同。<br>用户可以指定Spark SQL的相应数据类型，而不是使用默认值。 此选项仅适用于读。</td></tr><tr><td>pushDownPredicate</td><td>用于 启用或禁用 谓词下推 到 JDBC数据源的选项。<br>默认值为 true，在这种情况下，Spark会尽可能地将过滤器下推到JDBC数据源。<br>否则，如果设置为 false，则不会将过滤器下推到JDBC数据源，<br>此时所有过滤器都将由Spark处理。</td></tr></tbody></table></div><ul><li>读写 JDBC 示例：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">JdbcDatasetExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .appName(<span class="string">&quot;JdbcDatasetExample&quot;</span>)</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>) <span class="comment">//设置为本地运行</span></span><br><span class="line">      .getOrCreate()</span><br><span class="line">    <span class="type">Logger</span>.getLogger(<span class="string">&quot;org.apache.spark&quot;</span>).setLevel(<span class="type">Level</span>.<span class="type">OFF</span>)</span><br><span class="line">    <span class="type">Logger</span>.getLogger(<span class="string">&quot;org.apache.hadoop&quot;</span>).setLevel(<span class="type">Level</span>.<span class="type">OFF</span>)</span><br><span class="line">    runJdbcDatasetExample(spark)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">runJdbcDatasetExample</span></span>(spark: <span class="type">SparkSession</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//注意：从JDBC源加载数据</span></span><br><span class="line">    <span class="keyword">val</span> jdbcPersonDF = spark.read</span><br><span class="line">      .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;jdbc:mysql://localhost/mydb&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">&quot;person&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;root&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;123qwe&quot;</span>)</span><br><span class="line">      .load()</span><br><span class="line">    <span class="comment">//打印jdbcDF的schema</span></span><br><span class="line">    jdbcPersonDF.printSchema()</span><br><span class="line">    <span class="comment">//打印数据</span></span><br><span class="line">    jdbcPersonDF.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> connectionProperties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">    connectionProperties.put(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;root&quot;</span>)</span><br><span class="line">    connectionProperties.put(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;123qwe&quot;</span>)</span><br><span class="line">    <span class="comment">//通过.jdbc的方式加载数据</span></span><br><span class="line">    <span class="keyword">val</span> jdbcStudentDF = spark</span><br><span class="line">      .read</span><br><span class="line">      .jdbc(<span class="string">&quot;jdbc:mysql://localhost/mydb&quot;</span>, <span class="string">&quot;student&quot;</span>, connectionProperties)</span><br><span class="line">    <span class="comment">//打印jdbcDF的schema</span></span><br><span class="line">    jdbcStudentDF.printSchema()</span><br><span class="line">    <span class="comment">//打印数据</span></span><br><span class="line">    jdbcStudentDF.show()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 保存数据到JDBC源</span></span><br><span class="line">    jdbcStudentDF.write</span><br><span class="line">      .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;jdbc:mysql://localhost/mydb&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">&quot;student2&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;root&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;123qwe&quot;</span>)</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Append</span>)</span><br><span class="line">      .save()</span><br><span class="line"></span><br><span class="line">    jdbcStudentDF</span><br><span class="line">      .write</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Append</span>)</span><br><span class="line">      .jdbc(<span class="string">&quot;jdbc:mysql://localhost/mydb&quot;</span>, <span class="string">&quot;student2&quot;</span>, connectionProperties)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://blog.csdn.net/An1090239782/article/details/101466076">Spark DataSource Option 参数</a></li><li><a href="https://snaildove.github.io/2019/10/20/Chapter9_DataSources(SparkTheDefinitiveGuide">《Spark 权威指南》</a>_online/)</li></ul><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;SparkSession 是 Dataset 与 DataFrame API 的编程入口，从 Spark2.0 开始支持，用于统一原来的 HiveContext 和 SQLContext，统一入口提高了 Spark 的易用性，但为了兼容向后兼容，新版本仍然保留了这两个入口。
      
    
    </summary>
    
      <category term="Spark" scheme="http://liketea.xyz/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://liketea.xyz/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark 指南：Spark SQL（〇）—— 结构化 API</title>
    <link href="http://liketea.xyz/Spark/Spark/Spark%20%E6%8C%87%E5%8D%97%EF%BC%9ASpark%20SQL%EF%BC%88%E3%80%87%EF%BC%89%E2%80%94%E2%80%94%20%E7%BB%93%E6%9E%84%E5%8C%96%20API/"/>
    <id>http://liketea.xyz/Spark/Spark/Spark 指南：Spark SQL（〇）—— 结构化 API/</id>
    <published>2020-11-03T10:51:22.000Z</published>
    <updated>2021-07-11T08:49:39.990Z</updated>
    
    <content type="html"><![CDATA[<p>Spark SQL 是 Spark 用于处理结构化数据的一个模块，不同于 Spark RDD，Spark SQL 接口提供了更多关于数据的结构化信息，Spark SQL 会通过这些信息执行一些额外的优化操作。Spark SQL 提供了 SQL 和 DataSet 两种 API，二者底层使用的执行引擎相同，效率也一样，开发人员可以很容易地的在不同 API 之间切换，选择何种 API 要看哪种方式可以更自然地来表达给定的变换。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/16041255796022.jpg" width="80%" heigh="80%"></img></div><h2 id="结构化-API"><a href="#结构化-API" class="headerlink" title="结构化 API"></a>结构化 API</h2><p>Spark SQL API 可以在模块 <a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/expressions/index.html"><code>org.apache.spark.sql</code></a>下查看：</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201103184649.png" width="80%" heigh="80%"></img></div><p>常用的 API 模块：</p><ol><li>Spark SQL 数据类型：<a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/types/index.html">org.apache.spark.sql.types</a></li><li>Spark SQL 函数：<a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/functions$.html">org.apache.spark.sql.functions</a></li><li>Spark SQL DataFrame:<a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Dataset.html"></a>，Dataset 的大部分 API 同样适用于 DataFrame</li><li>Spark SQL Column:<a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Column.html">org.apache.spark.sql.Column</a></li><li>Spark SQL Row：<a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Row.html">org.apache.spark.sql.Row</a></li><li>Spark SQL Window：<a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/expressions/Window.html">org.apache.spark.sql.Window</a></li></ol><h3 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h3><p>Spark SQL 的用法之一是执行 SQL 查询，它也可以从现有的 Hive 中读取数据，如果从其它编程语言内部运行 SQL，查询结果将作为一个 Dataset/DataFrame 返回。</p><p>表和视图与 DataFrame 基本相同，为我们只是针对它们执行 SQL 而不是 DataFrame 代码。</p><h3 id="DataSet"><a href="#DataSet" class="headerlink" title="DataSet"></a>DataSet</h3><p>Spark 结构化 API 可以细分为两个 API：有类型的 Dataset 和无类型的 DataFrame。说 DataFrame 是无类型的并不准确，它们具有类型，但是 Spark 会完全维护它们，并且仅在运行时检查那些类型是否与模式中指定的类型一致。而 DataSet 在编译时检查类型是否符合规范，DataSet 仅适用于基于 Java 虚拟机（JVM）的语言（Scala 和 Java）。</p><ul><li><p>Dataset 是一个分布式数据集，它是 Spark 1.6 版本中新增的一个接口, 它结合了 RDD（强类型，可以使用强大的 lambda 表达式函数） 和 Spark SQL 的优化执行引擎的好处。Dataset 可以从 JVM 对象构造得到，随后可以使用函数式的变换（map，flatMap，filter 等）进行操作。Dataset API 目前支持 Scala 和 Java 语言，还不支持 Python, 不过由于 Python 语言的动态性, Dataset API 的许多好处早就已经可用了，例如，你可以使用 row.columnName 来访问数据行的某个字段。</p></li><li><p>DataFrame 是按命名列方式组织的一个 Dataset。从概念上来讲，它等同于关系型数据库中的一张表或者 R 和 Python 中的一个 dataframe， 只不过在底层进行了更多的优化。DataFrame 可以从很多数据源构造得到，比如：结构化的数据文件，Hive 表，外部数据库或现有的 RDD。 DataFrame API 支持 Scala, Java, Python 以及 R 语言。在 Scala 和 Java 语言中, DataFrame 由 Row 的 Dataset 来 表示的。在 Scala API 中, DataFrame 仅仅只是 <strong>Dataset[Row]</strong> 的一个类型别名，而在 Java API 中, 开发人员需要使用 Dataset<Row> 来表示一个 DataFrame。</p></li></ul><p>下图对比了 SQL、DataFrame 和 DataSet 三种 Spark SQL 编程方式错误检查机制：</p><ol><li>对于 SQL 来说，编译的时候并不知道你写的对不对，只有到运行的时候才知道；</li><li>对于 DataFrame，语法错误可以在编译时发现（比如将 select 写错），但分析错误只有到运行时才能知道（比如将字段名写错）；</li><li>对于 DataSet，在编译阶段就可以发现语法和分析错误，即静态类型和运行时类型安全。</li></ol><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/v2-a.jpg" width="80%" heigh="80%"></img></div><p>在大多数情况下，您可能会使用 DataFrame。对于 Scala-Spark，DataFrame 只是类型为 Row 的数据集，Row 类型是 Spark 内部优化表示的内部表示形式，这种格式可以进行高度专业化和高效的计算，而不是使用 JVM（可能导致高昂的垃圾处理和对象实例化成本）。对于 PySpark，一切都是 DataFrame。</p><h3 id="DataFrame-VS-RDD"><a href="#DataFrame-VS-RDD" class="headerlink" title="DataFrame VS RDD"></a>DataFrame VS RDD</h3><p>DataFrame 和 RDD 都是可以并行处理的集合，但 DataFrame 更像是一个传统数据库里的表，除了数据之外还可以知道更多信息，比如列名、值、类型。从 API 角度来看 DataFrame 提供了更高级的 API，比 RDD 编程要方便很多，由于 R 语言和 Pandas 也有 DataFrame，这就降低了 Spark 的学习门槛，在编写 Spark 程序时根本不需要关心最后是运行在单机上还是分布式集群上，因为代码都是一样的。</p><p>假设 RDD 里面支持的是一个 Person 类型，那么每一条记录都相当于一个 Person，但是 Person 里面到底有什么我们并不知道。DataFrame 存储了各字段的列名、数据类型以及值，有了这些信息，Spark SQL 的查询优化器（Catalyst）在编译的时候就能够做更多的优化。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201113110151.png" width="60%" heigh="60%"></img></div><p>SQL、DataFrame 和 RDD 运行时<a href="https://www.youtube.com/watch?v=GDeePbbCz2g&amp;feature=youtu.be">性能对比</a>：在大多数情况下 SQL 和 DataFrame 性能要好于 RDD</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201031144631.png" width="80%" heigh="80%"></img></div><h2 id="优化器-Catalyst"><a href="#优化器-Catalyst" class="headerlink" title="优化器 Catalyst"></a>优化器 Catalyst</h2><p>Spark SQL 的核心是 Catalyst 优化器，一种函数式的可扩展的查询优化器：</p><ol><li>优化：Catalyst 使查询以更少的资源获取更快的效率；</li><li>函数式：Catalyst 基于 Scala 的模式匹配和 quasiquotes 机制；</li><li>可扩展：Catalyst 允许用户扩展优化器；</li></ol><h3 id="Catalyst-优化策略"><a href="#Catalyst-优化策略" class="headerlink" title="Catalyst 优化策略"></a>Catalyst 优化策略</h3><p>Catalyst 支持两种优化策略：</p><ol><li>基于规则的优化(Rule-Based Optimization, RBO)：使用一组规则来确定如何执行查询；RBO 是一种经验式、启发式优化思路，对于核心优化算子 join 有点力不从心，如两张表执行join 到底使用 BroadcaseHashJoin 还是 sortMergeJoin，目前 Spark SQL 是通过手工设定参数来确定的，如果一个表的数据量小于某个阈值（默认10M）就使用BroadcastHashJoin；</li><li>基于代价的优化(Cost-Based Optimization, CBO)：使用规则生成多个计划，然后选取代价最小的计划执行查询；不同 Physical Plans 输入到代价模型，调整 Join 顺序，减少中间Shuffle 数据集大小，达到最优输出；</li></ol><h3 id="Catalyst-工作流程"><a href="#Catalyst-工作流程" class="headerlink" title="Catalyst 工作流程"></a>Catalyst 工作流程</h3><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20200507143337.png" width="80%" heigh="80%"></img></div><p>无论是直接使用 SQL 语句还是使用 DataFrame，都会经过如下环节转换成 DAG 对 RDD 的操作：</p><ol><li>Parser：通过 <a href="https://zh.wikipedia.org/wiki/ANTLR">ANTLR</a> 将 Spark SQL 字符串解析为抽象语法树(Abstract Syntax Tree，AST)，即未解析的逻辑计划(Unresolved Logical Plan, ULP)；</li><li>Analyzer：通过元数据信息 Catalog 将 ULP 解析为携带 Schema 信息的逻辑计划(Logical Plan, LP)；</li><li>RBO：通过 RBO 对 Logical Plan 进行谓词下推、列值裁剪、常量累加等操作，得到优化后的逻辑计划(Optimized logical plan, OLP)；</li><li>Planner：将 OLP 转换成多个物理计划(Physical Plan)；</li><li>CBO：根据 Cost Model 算出每个 Physical Plan 的代价并选取代价最小的 Physical Plan 作为最终的 Physical Plan；</li><li>WholeStageCodegen：生成 Java bytecode 然后在每一台机器上执行，形成 RDD graph/DAG；</li></ol><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/Spark-SQL.png" width="80%" heigh="80%"></img></div><h4 id="Parser-阶段"><a href="#Parser-阶段" class="headerlink" title="Parser 阶段"></a>Parser 阶段</h4><p>Spark2.x SQL 语句的解析采用的是 ANTLR4，ANTLR4 根据语法文件 <a href="https://github.com/apache/spark/blob/master/sql/catalyst/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBase.g4">SqlBase.g4</a> 自动解析生成两个Java类：词法解析器 SqlBaseLexer 和语法解析器 SqlBaseParser。使用这两个解析器将SQL字符串语句解析成了ANTLR4 的 ParseTree 语法树结构。然后在 parsePlan 过程中，使用 <a href="https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/parser/AstBuilder.scala">AstBuilder.scala</a> 将 ParseTree 转换成catalyst 表达式逻辑计划 Unresolved Logical Plan，ULP。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20200507185403.png" width="80%" heigh="80%"></img></div><h4 id="Analyzer-阶段"><a href="#Analyzer-阶段" class="headerlink" title="Analyzer 阶段"></a>Analyzer 阶段</h4><p>ULP 还只是一个语法树，系统需要通过元数据信息 Calalog 来获取表的 schema 信息（表名、列名、数据类型）和函数信息（类信息）。Analyzer 会再次遍历整个 AST，对树上的每个节点进行<strong>数据类型绑定</strong>以及<strong>函数绑定</strong>，比如people 词素会根据元数据表信息解析为包含 age、id 以及 name 三列的表，people.age会被解析为数据类型为 int 的变量，sum 会被解析为特定的聚合函数，解析后得到 Logical Plan，LP。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20200507200440.png" width="80%" heigh="80%"></img></div><h4 id="RBO-阶段"><a href="#RBO-阶段" class="headerlink" title="RBO 阶段"></a>RBO 阶段</h4><p>RBO 的优化策略就是对语法树进行一次遍历，模式匹配能够满足特定规则的节点，再进行相应的等价转换，即将一棵树等价地转换为另一棵树，最终得到优化后的逻辑计划 Optimized logical plan, OLP。</p><p>SQL 中经典的常见优化规则有：</p><ul><li>谓词下推（predicate pushdown）：将 Filter 算子尽可能下推，尽可能早地对数据源进行过滤，以减少参与计算的数据量（语法树是从下往上看的）</li></ul><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20200507200627.png" width="80%" heigh="80%"></img></div><ul><li>列值裁剪（column pruning）：剪裁不需要的字段，特别是嵌套里面的不需要字段。如只需people.age，不需要 people.address，那么可以将 address 字段丢弃</li></ul><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20200507201159.png" width="80%" heigh="80%"></img></div><ul><li>常量合并（constant folding）：从<code>100+80</code>优化为<code>180</code>，避免每一条 record 都需要执行一次<code>100+80</code>的操作</li></ul><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20200507201220.png" width="80%" heigh="80%"></img></div><h4 id="Planner-阶段"><a href="#Planner-阶段" class="headerlink" title="Planner 阶段"></a>Planner 阶段</h4><p>OLP 只是逻辑上可行，实际上 spark 并不知道如何去执行这个OLP。一个逻辑计划（Logical Plan）经过一系列的策略（Strategy）处理之后，得到多个物理计划（Physical Plans），物理计划在 Spark 是由 SparkPlan 实现的。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20200507203422.png" width="80%" heigh="80%"></img></div><h4 id="CBO-阶段"><a href="#CBO-阶段" class="headerlink" title="CBO 阶段"></a>CBO 阶段</h4><p>RBO 属于 LogicalPlan 的优化，所有优化均基于 LogicalPlan 本身的特点，未考虑数据本身的特点，也未考虑算子本身的代价。CBO 充分考虑了数据本身的特点（如大小、分布）以及操作算子的特点（中间结果集的分布及大小）及代价，从而更好的选择执行代价最小的物理执行计划，即 SparkPlan。</p><p>比如 join 算子，Spark 根据不同场景为该算子制定了不同的算法策略，有 broadcastHashJoin、shuffleHashJoin 以及 sortMergeJoin。CBO 中常见的优化是 join 换位，以便尽量减少中间shuffle 数据集大小，达到最优输出。</p><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20200507203837.png" width="80%" heigh="80%"></img></div><div align=center>    <img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20200507203845.png" width="80%" heigh="80%"></img></div><h4 id="Code-Generation-阶段"><a href="#Code-Generation-阶段" class="headerlink" title="Code Generation 阶段"></a>Code Generation 阶段</h4><p>选出的物理计划还是不能直接交给 Spark 执行，Spark 最后仍然会用一些 Rule 对 SparkPlan 进行处理：</p><ul><li>全阶段代码生成（Whole-stage Code Generation）：用来将多个处理逻辑整合到单个代码模块中。通过引入全阶段代码生成，大大减少了虚函数的调用，减少了 CPU 的调用，使得 SQL 的执行速度有很大提升。</li><li>代码编译：生成代码之后需要解决的另一个问题是如何将生成的代码进行编译然后加载到同一个 JVM 中去，Spark 引入了 Janino 项目，参见 <a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9TUEFSSy03OTU2&amp;article=true">SPARK-7956</a>。Janino 是一个超级小但又超级快的 Java™ 编译器. 它不仅能像 javac 工具那样将一组源文件编译成字节码文件，还可以对一些 Java 表达式，代码块，类中的文本(class body)或者内存中源文件进行编译，并把编译后的字节码直接加载到同一个 JVM 中运行。Janino 不是一个开发工具, 而是作为运行时的嵌入式编译器，比如作为表达式求值的翻译器或类似于 JSP 的服务端页面引擎，关于 Janino 的更多知识请参见<a href="https://janino-compiler.github.io/janino/">这里</a>。通过引入了 Janino 来编译生成的代码，结果显示 SQL 表达式的编译时间减少到 5ms。需要注意的是，代码生成是在 Driver 端进行的，而代码编译是在 Executor 端进行的。</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://snaildove.github.io/2020/02/10/summary_of_Translation(SparkTheDefinitiveGuide">《Spark 权威指南》</a>_online/)：正如书名所言，对Spark 各个方面做了权威的介绍，中文版现已出版，网上也有牛人博客的翻译</li><li><a href="https://spark-reference-doc-cn.readthedocs.io/zh_CN/latest/programming-guide/sql-guide.html">Spark 2.2.x 中文文档</a>：官方文档中文版翻译，每一块内容都蜻蜓点水</li><li><a href="https://sparkbyexamples.com/apache-spark-tutorial-with-scala-examples/">Spark By Examples</a>：通过实际例子学习 Spark 的绝佳去处</li><li><a href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Dataset.html">org.apache.spark.sql.Dataset</a>：Dataset 对象方法</li><li><a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Column.html">org.apache.spark.sql.Dataset.Column</a>：Column 对象方法</li><li><a href="https://www.jianshu.com/p/410c23efb565">Spark SQL Catalyst优化器</a></li><li><a href="https://www.iteblog.com/archives/2561.html">一条 SQL 在 Apache Spark 之旅（上）</a></li><li><a href="https://www.iteblog.com/archives/2562.html">一条 SQL 在 Apache Spark 之旅（中）</a></li><li><a href="https://www.iteblog.com/archives/2563.html">一条 SQL 在 Apache Spark 之旅（下）</a></li><li><a href="https://cloud.tencent.com/developer/article/1032529">SparkSql的优化器-Catalyst</a></li><li><a href="http://www.jasongj.com/spark/rbo/">Spark SQL / Catalyst 内部原理 与 RBO</a></li><li><a href="http://www.jasongj.com/spark/cbo/">Spark SQL 性能优化再进一步 CBO 基于代价的优化</a></li><li><a href="https://data-flair.training/blogs/spark-sql-optimization/">Spark SQL Optimization – Understanding the Catalyst Optimizer</a></li></ul><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Spark SQL 是 Spark 用于处理结构化数据的一个模块，不同于 Spark RDD，Spark SQL 接口提供了更多关于数据的结构化信息，Spark SQL 会通过这些信息执行一些额外的优化操作。Spark SQL 提供了 SQL 和 DataSet 两种 AP
      
    
    </summary>
    
      <category term="Spark" scheme="http://liketea.xyz/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://liketea.xyz/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>数据科学：工具篇（一）—— Jupyter Lab 配置环境</title>
    <link href="http://liketea.xyz/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%EF%BC%9A%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%20Jupyter%20Lab%20%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83/"/>
    <id>http://liketea.xyz/数据科学/数据科学/数据科学：工具使用（一）—— Jupyter Lab 配置环境/</id>
    <published>2020-10-23T06:16:46.000Z</published>
    <updated>2021-06-21T11:32:46.269Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201023183040.png" alt=""></p><p><a href="https://jupyter.org/">JupyterLab</a> 是 Jupyter 团队为 Jupyter 项目开发的下一代基于 Web 的交互式开发环境。相对于 Jupyter Notebook，它的集成性更强、更灵活并且更易扩展。它支持 100 种多种语言，支持多种文档相互集成，实现了交互式计算的新工作流程。如果说 Jupyter Notebook 像是一个交互式的笔记本，那么 Jupyter Lab 更像是一个交互式的 VSCode。另外，JupyterLab 非常强大的一点是，你可以将它部署在云服务器，不管是电脑、平板还是手机，都只需一个浏览器，即可远程访问使用。使用 JupyterLab，你可以进行数据分析相关的工作，可以进行交互式编程，可以学习社区中丰富的 Notebook 资料。</p><blockquote><p>本文只是提供一个 Jupyter lab 的基本配置思路和索引，Jupyter lab 还在快速发展，文中提到的很多内容可能已经不再适用了，大家在配置时不要拘泥于文中细节，还是要去官网上查看具体安装细节，否则可能导致版本兼容的各种问题</p></blockquote><h2 id="安装-Jupyter"><a href="#安装-Jupyter" class="headerlink" title="安装 Jupyter"></a>安装 Jupyter</h2><p>建议先安装 <a href="https://www.anaconda.com/">Anaconda</a>，Anaconda 自带 Jupyter 和常用的科学计算包，且方便通过 conda 进行环境管理。为了不污染本地 Python 环境，建议单独为 Jupyter lab 创建一个虚拟环境（在 base 环境下可能遇到各种奇怪的错误）:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="ZSH"><figure class="iseeu highlight /zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建虚拟环境，同时安装完整anaconda集合包（假设已经成功安装了 Anaconda）</span></span><br><span class="line">$ conda create -n mylab python=3.7 anaconda</span><br><span class="line"></span><br><span class="line"><span class="comment"># 激活虚拟环境</span></span><br><span class="line">$ conda activate mylab</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 Jupyter 版本</span></span><br><span class="line">$ jupyter --version</span><br><span class="line">jupyter core     : 4.6.3</span><br><span class="line">jupyter-notebook : 6.0.3</span><br><span class="line">qtconsole        : 4.7.5</span><br><span class="line">ipython          : 7.16.1</span><br><span class="line">ipykernel        : 5.3.2</span><br><span class="line">jupyter client   : 6.1.6</span><br><span class="line">jupyter lab      : 2.1.5</span><br><span class="line">nbconvert        : 5.6.1</span><br><span class="line">ipywidgets       : 7.5.1</span><br><span class="line">nbformat         : 5.0.7</span><br><span class="line">traitlets        : 4.3.3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看相关路径</span></span><br><span class="line">$ jupyter lab paths</span><br><span class="line">Application directory: /Users/likewang/opt/anaconda3/share/jupyter/lab</span><br><span class="line">User Settings directory: /Users/likewang/.jupyter/lab/user-settings</span><br><span class="line">Workspaces directory: /Users/likewang/.jupyter/lab/workspaces</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看配置文件路径</span></span><br><span class="line">$ jupyter notebook --generate-config</span><br><span class="line">Overwrite /Users/likewang/.jupyter/jupyter_notebook_config.py with default config? [y/N]n</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改配置文件，设置 jupyter 默认打开的目录</span></span><br><span class="line">$ vim .jupyter/jupyter_notebook_config.py</span><br><span class="line">c.NotebookApp.notebook_dir = <span class="string">&#x27;/Users/likewang/ilab&#x27;</span></span><br></pre></td></tr></table></figure></div><h2 id="插件管理"><a href="#插件管理" class="headerlink" title="插件管理"></a>插件管理</h2><p>jupyter-lab 提供了两种方式来管理 Jupyter-lab 的插件：</p><ul><li>命令行：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="ZSH"><figure class="iseeu highlight /zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># jupyter-lab 运行插件需要先安装 nodejs</span></span><br><span class="line">$ conda install nodejs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询安装的插件</span></span><br><span class="line">$ jupyter labextension list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装插件</span></span><br><span class="line">$ jupyter labextension install xxx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除插件</span></span><br><span class="line">$ jupyter labextension uninstall xxx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新所有插件（当插件版本过低或与当前jupyter版本不兼容的时候很好用）</span></span><br><span class="line">$ jupyter labextension update --all</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建插件</span></span><br><span class="line">$ jupyter lab build</span><br></pre></td></tr></table></figure></div><ul><li>通过 juputer-lab 插件图形化管理：进入jupyter界面，点击插件图标，在搜索栏中搜索对应插件名，如jupytext，可直接管理对应的插件</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201023182853.png" alt=""></p><p>安装插件时，通常需要先通过 <code>pip/conda</code> 安装相关依赖，再通过 <code>jupyter labextension</code> 来安装对应插件，部分插件在成功安装之后需要重启 jupyter-lab 才能生效。建议只安装必要的插件，插件过多会拖慢 jupyter-lab 的打开速度。</p><h3 id="kite-——-代码补全"><a href="#kite-——-代码补全" class="headerlink" title="kite —— 代码补全"></a>kite —— 代码补全</h3><p><a href="https://kite.com/">kite</a> 是一个功能非常强大的代码补全工具，目前可用于 Python 与 javascript，为许多知名的编辑器譬如 Vs Code、Pycharm 提供对应的插件，详细的安装过程可以参考<a href="https://www.cnblogs.com/feffery/p/13199472.html">Jupyter lab 最强代码补全插件</a>。</p><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>安装 kite 的一般步骤：</p><ol><li>下载安装 <a href="https://kite.com/">kite 客户端</a>：安装后登陆 kite 客户端，并保持 kite 客户端开启；</li><li>配置 <code>jupyter-lab</code>：需要注意的是 kite 只支持 2.2.0 以上版本的jupyter lab，但是目前jupyter lab的最新正式版本为2.1.5，因此我们需要使用pip来安装其提前发行版本，这里我选择2.2.0a1；</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="ZSH"><figure class="iseeu highlight /zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 升级 jupyterlab 到 2.2.0</span></span><br><span class="line">$ pip install --pre jupyterlab==2.2.0a1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 jupyter-kite 依赖</span></span><br><span class="line">$ pip install jupyter-kite</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 @kiteco/jupyterlab-kite 插件</span></span><br><span class="line">$ jupyter labextension install @kiteco/jupyterlab-kite</span><br></pre></td></tr></table></figure></div><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p>成功安装 kite 后，会自动跳转到 kite 使用说明文档 kite_tutorial.ipynb，这里简单介绍 kite 的几项核心功能：</p><ul><li>自动补全：写代码的时候不需要按 <Tab> 健，也会弹出代码补全提示，可以在命令面板中通过 <code>Kite: Toggle Docs Panel</code> 来关闭或打开完整说明文档</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/16031814006335.gif" alt=""></p><ul><li>手动补全：仍然可以继续使用 jupyter-lab 本身的 <Tab> 补全功能</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/16031815825233.gif" alt=""></p><ul><li>实时文档：如果在 Kite 中打开了 Copilot，Copilot 会自动地根据光标在 Jupyter-lab 中的位置更新说明文档</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/16031816905266.gif" alt=""></p><h3 id="jupyterlab-code-formatter-——-代码格式化"><a href="#jupyterlab-code-formatter-——-代码格式化" class="headerlink" title="jupyterlab_code_formatter —— 代码格式化"></a>jupyterlab_code_formatter —— 代码格式化</h3><p><a href="https://github.com/ryantam626/jupyterlab_code_formatter">jupyterlab_code_formatter</a> 用于代码一键格式化。</p><h4 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 安装依赖</span><br><span class="line">$ conda install -c conda-forge jupyterlab_code_formatter</span><br><span class="line">$ jupyter labextension install @ryantam626/jupyterlab_code_formatter</span><br><span class="line"># 安装插件</span><br><span class="line">$ jupyter serverextension enable --py jupyterlab_code_formatter</span><br><span class="line"># 安装支持的代码格式</span><br><span class="line">$ conda install black isort</span><br></pre></td></tr></table></figure></div><h4 id="使用-1"><a href="#使用-1" class="headerlink" title="使用"></a>使用</h4><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/formatter.gif" alt="formatte"></p><h3 id="jupyterlab-go-to-definition-——-代码跳转"><a href="#jupyterlab-go-to-definition-——-代码跳转" class="headerlink" title="jupyterlab-go-to-definition —— 代码跳转"></a>jupyterlab-go-to-definition —— 代码跳转</h3><p><a href="">jupyterlab-go-to-definition</a> 用于Lab笔记本和文件编辑器中跳转到变量或函数的定义</p><h4 id="安装-2"><a href="#安装-2" class="headerlink" title="安装"></a>安装</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="ZSH"><figure class="iseeu highlight /zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># JuupyterLab 2.x</span></span><br><span class="line">$ jupyter labextension install @krassowski/jupyterlab_go_to_definition   </span><br><span class="line"><span class="comment"># JupyterLab 1.x</span></span><br><span class="line">$ jupyter labextension install @krassowski/jupyterlab_go_to_definition@0.7.1   </span><br></pre></td></tr></table></figure></div><h4 id="使用-2"><a href="#使用-2" class="headerlink" title="使用"></a>使用</h4><p>默认快捷键 <code>alt+click</code>：</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/click.gif" alt="click"></p><h3 id="jupyterlab-git-——-版本管理"><a href="#jupyterlab-git-——-版本管理" class="headerlink" title="jupyterlab-git —— 版本管理"></a>jupyterlab-git —— 版本管理</h3><p><a href="https://github.com/jupyterlab/jupyterlab-git">jupyterlab-git</a> 是 jupyter-lab 的 git 插件，可以方便地进行版本管理。</p><h4 id="安装-3"><a href="#安装-3" class="headerlink" title="安装"></a>安装</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ conda install -c conda-forge jupyterlab jupyterlab-git</span><br><span class="line">jupyter lab build</span><br></pre></td></tr></table></figure></div><h4 id="使用-3"><a href="#使用-3" class="headerlink" title="使用"></a>使用</h4><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/preview.gif" alt="previe"></p><h3 id="qgrid-——-DataFrame-交互"><a href="#qgrid-——-DataFrame-交互" class="headerlink" title="qgrid —— DataFrame 交互"></a>qgrid —— DataFrame 交互</h3><p><a href="https://github.com/quantopian/qgrid">qgrid</a> 是一个可以用交互的方式操作 Pandas DataFrame 的插件，主要优点有：</p><ol><li>直接用点选的方式进行选择、排序甚至是修改单元格中的值；</li><li>做 EDA 时可以看到整个 DataFrame 的全貌，而不是用 … 的方式来显示，而且读取速度很快；</li></ol><h4 id="安装-4"><a href="#安装-4" class="headerlink" title="安装"></a>安装</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ conda install qgrid</span><br><span class="line">$ jupyter labextension install @jupyter-widgets/jupyterlab-manager</span><br><span class="line">$ jupyter labextension install qgrid2</span><br></pre></td></tr></table></figure></div><h4 id="使用-4"><a href="#使用-4" class="headerlink" title="使用"></a>使用</h4><ul><li>以交互的方式显示 Pandas DataFrame：可以显示完整数据</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 載入所需套件</span><br><span class="line">import qgrid</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 為了讓結果相同，設定種子以及資料數量</span><br><span class="line">np.random.seed(1)</span><br><span class="line">nrow = 1000000</span><br><span class="line"></span><br><span class="line"># 建立 Dataframe</span><br><span class="line">df = pd.DataFrame(&#123;&#x27;Index&#x27;: range(nrow), </span><br><span class="line">                   &#x27;Sex&#x27;: np.random.choice([&#x27;M&#x27;, &#x27;F&#x27;], nrow), </span><br><span class="line">                   &#x27;Age&#x27;: np.random.randint(12, 56, nrow),</span><br><span class="line">                   &#x27;Height&#x27;: np.round(np.random.random(nrow),3)*30+160,</span><br><span class="line">                   &#x27;Weight&#x27;: np.round(np.random.random(nrow),3)*30+55,</span><br><span class="line">                   &#x27;Tag&#x27;: np.random.choice([True, False], nrow)&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">qgrid_widget = qgrid.show_grid(df, show_toolbar=True)</span><br><span class="line">qgrid_widget</span><br></pre></td></tr></table></figure></div><ul><li>在 DataFrame 上排序、筛选数据：</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/Qgrid_basic.gif" alt="Qgrid_basi"></p><ul><li>甚至可以直接更改 Dataframe 的值：</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/Qgrid_tweakData.gif" alt="Qgrid_tweakData"></p><ul><li>还可以获取改动过的数据：qgrid_widget.get_changed_df() 可以获取经过筛选、排序、修改后的 DataFrame 数据：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qgrid_widget.get_changed_df()</span><br></pre></td></tr></table></figure></div><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/filtering_demo.gif" alt="filtering_demo"></p><h3 id="jupyter-bokeh-——-可视化效果"><a href="#jupyter-bokeh-——-可视化效果" class="headerlink" title="jupyter_bokeh —— 可视化效果"></a>jupyter_bokeh —— 可视化效果</h3><p><a href="https://github.com/bokeh/jupyter_bokeh">jupyter_bokeh</a> 该插件可以在 Lab 中展示bokeh 可视化效果。</p><h4 id="安装-5"><a href="#安装-5" class="headerlink" title="安装"></a>安装</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda install -c bokeh jupyter_bokeh</span><br><span class="line">jupyter labextension install @jupyter-widgets/jupyterlab-manager</span><br><span class="line">jupyter labextension install @bokeh/jupyter_bokeh</span><br></pre></td></tr></table></figure></div><h4 id="使用-5"><a href="#使用-5" class="headerlink" title="使用"></a>使用</h4><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/boek.gif" alt="boek"></p><h3 id="jupyterlab-dash-——-单独面板"><a href="#jupyterlab-dash-——-单独面板" class="headerlink" title="jupyterlab-dash —— 单独面板"></a>jupyterlab-dash —— 单独面板</h3><p><a href="https://github.com/plotly/jupyterlab-dash">jupyterlab-dash</a> 该插件可以在Lab中展示 plotly dash 交互式面板。</p><h4 id="安装-6"><a href="#安装-6" class="headerlink" title="安装"></a>安装</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ conda install -c plotly -c defaults -c conda-forge &quot;jupyterlab&gt;=1.0&quot; jupyterlab-dash=0.1.0a3</span><br><span class="line">$ jupyter labextension install jupyterlab-dash@0.1.0-alpha.3</span><br></pre></td></tr></table></figure></div><h4 id="使用-6"><a href="#使用-6" class="headerlink" title="使用"></a>使用</h4><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/dash.gif" alt="dash"></p><h3 id="jupyterlab-variableinspector-——-变量显示"><a href="#jupyterlab-variableinspector-——-变量显示" class="headerlink" title="jupyterlab_variableinspector —— 变量显示"></a>jupyterlab_variableinspector —— 变量显示</h3><p><a href="https://github.com/lckr/jupyterlab-variableInspector">jupyterlab_variableinspector</a> 可以在 Lab 中展示代码中的变量及其属性，类似RStudio中的变量检查器。你可以一边撸代码，一边看有哪些变量。对 Spark 和 Tensorflow 的支持需要解决依赖。</p><h4 id="安装-7"><a href="#安装-7" class="headerlink" title="安装"></a>安装</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jupyter labextension install @lckr/jupyterlab_variableinspector</span><br></pre></td></tr></table></figure></div><h4 id="使用-7"><a href="#使用-7" class="headerlink" title="使用"></a>使用</h4><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/early_demo.gif" alt="early_demo"></p><h3 id="jupyterlab-system-monitor-——-资源监控"><a href="#jupyterlab-system-monitor-——-资源监控" class="headerlink" title="jupyterlab-system-monitor —— 资源监控"></a>jupyterlab-system-monitor —— 资源监控</h3><p><a href="https://github.com/jtpio/jupyterlab-system-monitor">jupyterlab-system-monitor</a> 用于监控 jupyter-lab 的资源使用情况。</p><h4 id="安装-8"><a href="#安装-8" class="headerlink" title="安装"></a>安装</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ conda install -c conda-forge nbresuse</span><br><span class="line">$ jupyter labextension install jupyterlab-topbar-extension jupyterlab-system-monitor</span><br></pre></td></tr></table></figure></div><h4 id="使用-8"><a href="#使用-8" class="headerlink" title="使用"></a>使用</h4><p>默认只显示内存使用情况：</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/16031950705517.jpg" alt=""></p><p>编辑配置文件 <code>~/.jupyter/jupyter_notebook_config.py</code>：添加一下内容，重启 jupyter-lab 就可以显示 CPU 利用率以及内存使用情况了。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">c = get_config()</span><br><span class="line"></span><br><span class="line"># memory</span><br><span class="line">c.NotebookApp.ResourceUseDisplay.mem_limit = &lt;size_in_GB&gt; *1024*1024*1024</span><br><span class="line"></span><br><span class="line"># cpu</span><br><span class="line">c.NotebookApp.ResourceUseDisplay.track_cpu_percent = True</span><br><span class="line">c.NotebookApp.ResourceUseDisplay.cpu_limit = &lt;number_of_cpus&gt;</span><br></pre></td></tr></table></figure></div><p>示例：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 示例：限制最大内存 4G，2 个 CPU，显示 CPU 利用率</span><br><span class="line">c.NotebookApp.ResourceUseDisplay.mem_limit = 4294967296</span><br><span class="line">c.NotebookApp.ResourceUseDisplay.track_cpu_percent = True</span><br><span class="line">c.NotebookApp.ResourceUseDisplay.cpu_limit = 2</span><br></pre></td></tr></table></figure></div><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/screencast.gif" alt="screencast"></p><h3 id="jupyterlab-toc-——-显示目录"><a href="#jupyterlab-toc-——-显示目录" class="headerlink" title="jupyterlab-toc —— 显示目录"></a>jupyterlab-toc —— 显示目录</h3><p><a href="https://github.com/jupyterlab/jupyterlab-toc">jupyterlab-toc</a> 用于在 jupyter-lab 中显示文档的目录。</p><h4 id="安装-9"><a href="#安装-9" class="headerlink" title="安装"></a>安装</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jupyter labextension install @jupyterlab/toc</span><br></pre></td></tr></table></figure></div><h4 id="使用-9"><a href="#使用-9" class="headerlink" title="使用"></a>使用</h4><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/toc.gif" alt="to"></p><h3 id="Collapsible-Headings-——-折叠标题"><a href="#Collapsible-Headings-——-折叠标题" class="headerlink" title="Collapsible_Headings —— 折叠标题"></a>Collapsible_Headings —— 折叠标题</h3><p><a href="https://github.com/aquirdTurtle/Collapsible_Headings">Collapsible_Headings</a> 可实现标题的折叠。</p><h4 id="安装-10"><a href="#安装-10" class="headerlink" title="安装"></a>安装</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jupyter labextension install @aquirdturtle/collapsible_headings</span><br></pre></td></tr></table></figure></div><h4 id="使用-10"><a href="#使用-10" class="headerlink" title="使用"></a>使用</h4><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/Demo2.gif" alt="Demo2"></p><h3 id="jupyterlab-html-——-显示-HTML"><a href="#jupyterlab-html-——-显示-HTML" class="headerlink" title="jupyterlab_html —— 显示 HTML"></a>jupyterlab_html —— 显示 HTML</h3><p>该插件允许你在Jupyter Lab内部呈现HTML文件，这在打开例如d3可视化效果时非常有用</p><h4 id="安装-11"><a href="#安装-11" class="headerlink" title="安装"></a>安装</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jupyter labextension install @mflevine/jupyterlab_html</span><br></pre></td></tr></table></figure></div><h4 id="使用-11"><a href="#使用-11" class="headerlink" title="使用"></a>使用</h4><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/example1.gif" alt="example1"></p><h3 id="jupyterlab-drawio-——-绘制流程图"><a href="#jupyterlab-drawio-——-绘制流程图" class="headerlink" title="jupyterlab-drawio —— 绘制流程图"></a>jupyterlab-drawio —— 绘制流程图</h3><p><a href="https://github.com/QuantStack/jupyterlab-drawio">jupyterlab-drawio</a> 可以在Lab中启用 drawio 绘图工具，drawio是一款非常棒的流程图工具。</p><h4 id="安装-12"><a href="#安装-12" class="headerlink" title="安装"></a>安装</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jupyter labextension install jupyterlab-drawio</span><br></pre></td></tr></table></figure></div><h4 id="使用-12"><a href="#使用-12" class="headerlink" title="使用"></a>使用</h4><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/drawio.gif" alt="drawio"></p><h3 id="jupyterlab-tabular-data-editor-——-CSV-编辑"><a href="#jupyterlab-tabular-data-editor-——-CSV-编辑" class="headerlink" title="jupyterlab-tabular-data-editor —— CSV 编辑"></a>jupyterlab-tabular-data-editor —— CSV 编辑</h3><p><a href="https://www.cnblogs.com/feffery/p/13647422.html">jupyterlab-tabular-data-editor</a> 插件赋予我们高度的交互式操纵 csv 文件的自由，无需excel，就可以实现对csv表格数据的增删改查。</p><h4 id="安装-13"><a href="#安装-13" class="headerlink" title="安装"></a>安装</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jupyter labextension install jupyterlab-tabular-data-editor</span><br></pre></td></tr></table></figure></div><h4 id="使用-13"><a href="#使用-13" class="headerlink" title="使用"></a>使用</h4><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/showcase.gif" alt="showcase"></p><h3 id="jupyter-themes-——-切换主题"><a href="#jupyter-themes-——-切换主题" class="headerlink" title="jupyter-themes —— 切换主题"></a>jupyter-themes —— 切换主题</h3><p><a href="https://github.com/arbennett/jupyterlab-themes">jupyterlab-themes</a> 用于切换 jupyter 的主题。</p><h4 id="安装-14"><a href="#安装-14" class="headerlink" title="安装"></a>安装</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 目前还只能一个一个安装</span><br><span class="line">$ jupyter labextension install @arbennett/base16-&#123;$themename&#125;</span><br></pre></td></tr></table></figure></div><h4 id="使用-14"><a href="#使用-14" class="headerlink" title="使用"></a>使用</h4><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/16032502274677.jpg" alt=""></p><h3 id="更多插件"><a href="#更多插件" class="headerlink" title="更多插件"></a>更多插件</h3><p>更多插件可以参考以下网站：</p><ol><li><a href="https://github.com/mauhai/awesome-jupyterlab">Awesome JupyterLab</a></li><li><a href="https://zhuanlan.zhihu.com/p/101070029">15个好用到爆炸的Jupyter Lab插件</a></li></ol><h2 id="kernel-管理"><a href="#kernel-管理" class="headerlink" title="kernel 管理"></a>kernel 管理</h2><p>Jupyter kernel 可以用任何语言实现，只要它们遵循基于 ZeroMQ 的 Jupyter 通信协议。IPython 是最流行的内核，默认情况下包括在内。这并不奇怪，因为 Jupyter（Jupyter，Jupyter，Python，R）来自IPython项目。它是将独立于语言的部分从IPython内核中分离出来，使其能够与其他语言一起工作的结果，现在有超过100种编程语言的内核可用。</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/16032660834478.jpg" alt=""></p><p>除了内核和前端之外，Jupyter 还包括与语言无关的后端部分，它管理内核、笔记本和与前端的通信。这个组件称为Jupyter服务器。笔记本存储在.ipynb文件中，在服务器上以Json格式编码。基于Json的格式允许以结构化的方式存储单元输入、输出和元数据。二进制输出数据采用base64编码。缺点是，与基于行的文本格式相比，json使diff和merge更困难。您可以将笔记本导出为其他格式，如Markdown、Scala（仅包含代码输入单元格）或类似本文的HTML。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 查看 kernel 列表</span><br><span class="line">jupyter kernelspec list</span><br><span class="line"># 卸载指定 kernel </span><br><span class="line">jupyter kernelspec remove kernel_name</span><br></pre></td></tr></table></figure></div><h3 id="安装-Scala-kernel"><a href="#安装-Scala-kernel" class="headerlink" title="安装 Scala kernel"></a>安装 Scala kernel</h3><p>在Scala中对Jupyter的支持是怎样的？实际上有很多不同的内核。但是，如果仔细观察，它们中的许多在功能上有一定的局限性，存在可伸缩性问题，甚至已经被放弃。其他人只关注Spark而不是Scala和其他框架。</p><p>其中一个原因是，几乎所有现有内核都构建在默认REPL之上。由于其局限性，他们对其进行定制和扩展，以添加自己的特性，如依赖关系管理或框架支持。一些内核还使用sparkshell，它基本上是scalarepl的一个分支，专门为Spark支持而定制。这一切都会导致碎片化、重用困难和重复工作，使得创建一个与其他语言相当的内核变得更加困难。</p><p>关于一些原因的更详细讨论，请查看 Alexandre Archambault 在2017年 JupyterCon 上的演讲 <a href="https://www.youtube.com/watch?v=pgVtdveelAQ">Scala: Why hasn’t an Official Scala Kernel for Jupyter emerged yet?</a>。</p><h4 id="almond（推荐）"><a href="#almond（推荐）" class="headerlink" title="almond（推荐）"></a>almond（推荐）</h4><blockquote><p><a href="https://github.com/almond-sh/almond">almond（之前叫jupyter-scala）</a> 使得 jupyter 强大的功能向 Scala 开放，包括 <a href="http://ammonite.io/#Ammonite-REPL">Ammonite</a> 的所有细节，尽管它还需要一些更多的集成和文档，但是它已经非常有用，并且非常有趣。<br>——<a href="https://brunk.io/interactive-computing-in-scala-with-jupyter-and-almond.html">Interactive Computing in Scala with Jupyter and almond</a></p></blockquote><p>安装 almond 需要特别注意 almond 版本、Scala 版本以及 Spark版本之间的兼容性（almond 0.10.0 支持 scala 2.12.11 and 2.13.2 支持 park 2.4.x），almond 详细安装过程及版本对应关系请参考 <a href="https://almond.sh/docs/install-versions">almond 官方文档</a>。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 查看可用的 Scala 版本</span><br><span class="line">$ brew search scala</span><br><span class="line">==&gt; Formulae</span><br><span class="line">scala         scala@2.11    scala@2.12    scalaenv      scalapack     scalariform   scalastyle</span><br><span class="line"></span><br><span class="line"># 安装 scala 2.12.x</span><br><span class="line">$ brew install scala@2.12</span><br><span class="line"></span><br><span class="line"># 查看实际安装的 scala 版本</span><br><span class="line">$ scala -version</span><br><span class="line">Scala code runner version 2.12.11 -- Copyright 2002-2020, LAMP/EPFL and Lightbend, Inc.</span><br><span class="line"></span><br><span class="line"># 安装 coursier，scala 的依赖解析器</span><br><span class="line">$ brew install coursier/formulas/coursier</span><br><span class="line"></span><br><span class="line"># 通过 coursier 安装 almond，指定 almond 版本=0.10.0，scala版本=2.12.11，重复安装需要加--force</span><br><span class="line">$ coursier launch --fork almond:0.10.0 --scala 2.12.11 -- --install --force</span><br><span class="line"></span><br><span class="line"># 成功安装后，可以看到 jupyter kernelspec 多了一个 Scala 的核</span><br><span class="line">$ jupyter kernelspec list</span><br><span class="line">Available kernels:</span><br><span class="line">  scala            /Users/likewang/Library/Jupyter/kernels/scala</span><br><span class="line">  python3          /Users/likewang/opt/anaconda3/envs/mylab/share/jupyter/kernels/python3</span><br><span class="line">  python2          /usr/local/share/jupyter/kernels/python2</span><br><span class="line">  spylon-kernel    /usr/local/share/jupyter/kernels/spylon-kernel</span><br><span class="line"></span><br><span class="line"># 安装 Spark 依赖</span><br></pre></td></tr></table></figure></div><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/16032700843174.jpg" alt=""></p><p>配置 Spark：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Or use any other 2.x version here</span></span><br><span class="line"><span class="keyword">import</span> $ivy.`org.apache.spark::spark-sql:<span class="number">2.4</span><span class="number">.0</span>`</span><br><span class="line"></span><br><span class="line"><span class="comment"># Not required since almond 0.7.0 (will be automatically added when importing spark)</span></span><br><span class="line"><span class="keyword">import</span> $ivy.`sh.almond::almond-spark:<span class="number">0.10</span><span class="number">.9</span>` </span><br><span class="line"><span class="comment"># 通常，为了避免污染单元输出，您需要禁用日志记录</span></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.&#123;Level, Logger&#125;</span><br><span class="line">Logger.getLogger(<span class="string">&quot;org&quot;</span>).setLevel(Level.OFF)</span><br><span class="line"><span class="comment"># 引入 NotebookSparkSession</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql._</span><br><span class="line"></span><br><span class="line">val spark = &#123;</span><br><span class="line">  NotebookSparkSession.builder()</span><br><span class="line">    .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    .getOrCreate()</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 引入隐式转换</span></span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br></pre></td></tr></table></figure></div><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/16032798130948.jpg" alt=""></p><h4 id="其他-Scala-kernel"><a href="#其他-Scala-kernel" class="headerlink" title="其他 Scala kernel"></a>其他 Scala kernel</h4><ul><li><a href="https://github.com/Valassis-Digital-Media/spylon-kernel">spylon-kernel</a> 是一个 Scala Jupyter Kernel。</li><li><a href="https://github.com/jegonzal/jupyter-scala">jupyter-scala</a> 依赖于 scala 2.11.x，还不支持 2.12；jupyter-scala 只能用于 jupyter notebook 无法用于 jupyter lab：</li></ul><h3 id="安装-python-kernel"><a href="#安装-python-kernel" class="headerlink" title="安装 python kernel"></a>安装 python kernel</h3><p>由于我们是在 python 3 虚拟环境下安装了 jupyter lab，自带的是 python 3 kernel，现在需要添加 python 2 的 kernel：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 假设已经安装了名为 python2 的虚拟环境，切换到 python 2 环境</span><br><span class="line">$ conda activate python2</span><br><span class="line"># 安装 python 2 kernel  </span><br><span class="line">$ python2 -m ipykernel install --name python2</span><br></pre></td></tr></table></figure></div><p>安装成功后，在 jupyter lab 新建文件页面会出现 python 2 的图标：</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/16032572845419.jpg" alt=""></p><h2 id="各种奇怪的问题"><a href="#各种奇怪的问题" class="headerlink" title="各种奇怪的问题"></a>各种奇怪的问题</h2><h4 id="插件同时出现在已安装和未安装列表中"><a href="#插件同时出现在已安装和未安装列表中" class="headerlink" title="插件同时出现在已安装和未安装列表中"></a>插件同时出现在已安装和未安装列表中</h4><ul><li>问题描述：在uninstall 插件后，插件同时出现在 Known labextensions 和 Uninstalled core extensions。</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="ZSH"><figure class="iseeu highlight /zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  ~ jupyter labextension list</span><br><span class="line">JupyterLab v1.2.6</span><br><span class="line">Known labextensions:</span><br><span class="line">   app dir: /Users/likewang/opt/anaconda3/share/jupyter/lab</span><br><span class="line">        @bokeh/jupyter_bokeh v1.2.0  enabled  OK</span><br><span class="line">        @jupyterlab/github v1.0.1  enabled  OK</span><br><span class="line">        @jupyterlab/toc v2.0.0  enabled  OK</span><br><span class="line">        @mflevine/jupyterlab_html v0.1.4  enabled  OK</span><br><span class="line">        @pyviz/jupyterlab_pyviz v0.8.0  enabled  OK</span><br><span class="line">        @ryantam626/jupyterlab_code_formatter v1.1.0  enabled  OK</span><br><span class="line">        jupyterlab-dash v0.1.0-alpha.3  enabled  OK</span><br><span class="line">        jupyterlab-drawio v0.6.0  enabled  OK</span><br><span class="line"></span><br><span class="line">Uninstalled core extensions:</span><br><span class="line">    @ryantam626/jupyterlab_code_formatter</span><br></pre></td></tr></table></figure></div><ul><li>解决办法：删除 <code>jupyter\lab\settings\build_config.json，https://github.com/jupyterlab/jupyterlab/issues/8122</code></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  ~ jupyter lab build</span><br><span class="line">[LabBuildApp] JupyterLab 1.2.6</span><br><span class="line">[LabBuildApp] Building in /Users/likewang/opt/anaconda3/share/jupyter/lab</span><br><span class="line">[LabBuildApp] Building jupyterlab assets (build:prod:minimize)</span><br><span class="line">(base) ➜  ~ jupyter labextension list</span><br><span class="line">JupyterLab v1.2.6</span><br><span class="line">Known labextensions:</span><br><span class="line">   app dir: /Users/likewang/opt/anaconda3/share/jupyter/lab</span><br><span class="line">        @bokeh/jupyter_bokeh v1.2.0  enabled  OK</span><br><span class="line">        @jupyterlab/github v1.0.1  enabled  OK</span><br><span class="line">        @jupyterlab/toc v2.0.0  enabled  OK</span><br><span class="line">        @mflevine/jupyterlab_html v0.1.4  enabled  OK</span><br><span class="line">        @pyviz/jupyterlab_pyviz v0.8.0  enabled  OK</span><br><span class="line">        @ryantam626/jupyterlab_code_formatter v1.1.0  enabled  OK</span><br><span class="line">        jupyterlab-dash v0.1.0-alpha.3  enabled  OK</span><br><span class="line">        jupyterlab-drawio v0.6.0  enabled  OK</span><br></pre></td></tr></table></figure></div><h4 id="No-module-named-‘jupyter-nbextensions-configurator’"><a href="#No-module-named-‘jupyter-nbextensions-configurator’" class="headerlink" title="No module named ‘jupyter_nbextensions_configurator’"></a>No module named ‘jupyter_nbextensions_configurator’</h4><ul><li>问题描述：启动 jupyter-lab 时报错 <code>ModuleNotFoundError: No module named &#39;jupyter_nbextensions_configurator&#39;</code></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">(mylab) ➜  ilab jupyter-lab</span><br><span class="line">[W 19:37:20.086 LabApp] Error loading server extension jupyter_nbextensions_configurator</span><br><span class="line">    Traceback (most recent call last):</span><br><span class="line">      File &quot;/Users/likewang/opt/anaconda3/envs/mylab/lib/python3.7/site-packages/notebook/notebookapp.py&quot;, line 1670, in init_server_extensions</span><br><span class="line">        mod = importlib.import_module(modulename)</span><br><span class="line">      File &quot;/Users/likewang/opt/anaconda3/envs/mylab/lib/python3.7/importlib/__init__.py&quot;, line 127, in import_module</span><br><span class="line">        return _bootstrap._gcd_import(name[level:], package, level)</span><br><span class="line">      File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1006, in _gcd_import</span><br><span class="line">      File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 983, in _find_and_load</span><br><span class="line">      File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 965, in _find_and_load_unlocked</span><br><span class="line">    ModuleNotFoundError: No module named &#x27;jupyter_nbextensions_configurator&#x27;</span><br></pre></td></tr></table></figure></div><ul><li>解决办法：以上问题出现在虚拟环境中启动 jupyter-lab，jupyter-nbextensions_configurator 和 python pip 不在同一个环境，解决办法是在对应的虚拟环境中安装 jupyter_nbextensions_configurator</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">(mylab) ➜  ~ which jupyter-nbextensions_configurator</span><br><span class="line">/Users/likewang/opt/anaconda3/bin/jupyter-nbextensions_configurator</span><br><span class="line">(mylab) ➜  ~ which python</span><br><span class="line">/Users/likewang/opt/anaconda3/envs/mylab/bin/python</span><br><span class="line">(mylab) ➜  ~ which jupyter</span><br><span class="line">/Users/likewang/opt/anaconda3/envs/mylab/bin/jupyter</span><br><span class="line">(mylab) ➜  ~ which jupyter-notebook</span><br><span class="line">/Users/likewang/opt/anaconda3/envs/mylab/bin/jupyter-notebook</span><br><span class="line"># 重新在虚拟环境安装 jupyter_nbextensions_configurator</span><br><span class="line">conda install -c conda-forge jupyter_nbextensions_configurator</span><br><span class="line">(mylab) ➜  .jupyter which jupyter-nbextensions_configurator</span><br><span class="line">/Users/likewang/opt/anaconda3/envs/mylab/bin/jupyter-nbextensions_configurator</span><br></pre></td></tr></table></figure></div><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://towardsdatascience.com/getting-the-most-out-of-jupyter-lab-9b3198f88f2d">Getting the most out of Jupyter Lab</a></li></ul><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20201023183040.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://jupy
      
    
    </summary>
    
      <category term="数据科学" scheme="http://liketea.xyz/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
    
      <category term="数据科学" scheme="http://liketea.xyz/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Scala 教程：Basics（二）—— 核心类型</title>
    <link href="http://liketea.xyz/Scala/Scala/Scala%20%E6%95%99%E7%A8%8B%EF%BC%9ABasics%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%20%E6%A0%B8%E5%BF%83%E7%B1%BB%E5%9E%8B/"/>
    <id>http://liketea.xyz/Scala/Scala/Scala 教程：Basics（二）—— 核心类型/</id>
    <published>2020-08-10T08:00:00.000Z</published>
    <updated>2021-06-02T10:44:40.904Z</updated>
    
    <content type="html"><![CDATA[<p>Scala的核心类型，包括String，以及数值类型 Byte、Short、Int、Long、Float、Double、Char 和 Boolean。</p><h2 id="数值类型"><a href="#数值类型" class="headerlink" title="数值类型"></a>数值类型</h2><p>Byte、Short、Int、Long和Char类型统称整数类型，加上Float和Double称作数值类型。</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20200811152743.png" alt=""></p><p>以上列出的基本类型除了Java.lang.String外都是scala包的成员，Int的完整名称是scala.Int，不过scala包的所有成员在scala源文件中都已经自动引入，可以在任何地方使用简单名称。</p><p>以上列出的所有基础类型都可以使用字面值(literal)来书写，下图是指定字面值类型的记法：</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20200811162049.png" alt=""></p><p>示例：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> f = <span class="number">1.234</span></span><br><span class="line">f: <span class="type">Double</span> = <span class="number">1.234</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> ff = <span class="number">1.234</span>f</span><br><span class="line">ff: <span class="type">Float</span> = <span class="number">1.234</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> fff: <span class="type">Float</span> = <span class="number">1.234</span></span><br><span class="line">&lt;console&gt;:<span class="number">11</span>: error: <span class="class"><span class="keyword">type</span> <span class="title">mismatch</span></span>;</span><br><span class="line"> found   : <span class="type">Double</span>(<span class="number">1.234</span>)</span><br><span class="line"> required: <span class="type">Float</span></span><br><span class="line">       <span class="keyword">val</span> fff: <span class="type">Float</span> = <span class="number">1.234</span></span><br><span class="line">                        ^</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> fff: <span class="type">Float</span> = <span class="number">1.234</span>f</span><br><span class="line">fff: <span class="type">Float</span> = <span class="number">1.234</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div><h3 id="整数类型"><a href="#整数类型" class="headerlink" title="整数类型"></a>整数类型</h3><p>一些常见的整数字面值：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如果整数以非0开头，默认被视为十进制数</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> a = <span class="number">10</span></span><br><span class="line">a: <span class="type">Int</span> = <span class="number">10</span></span><br><span class="line"><span class="comment">// 十六进制数以0x开头，shell默认打印其十进制整数值</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> b = <span class="number">0xF</span></span><br><span class="line">b: <span class="type">Int</span> = <span class="number">15</span></span><br><span class="line"><span class="comment">// 将Int类型整数赋值给Long型，发生隐式类型转化</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> long: <span class="type">Long</span> = <span class="number">10</span></span><br><span class="line">long: <span class="type">Long</span> = <span class="number">10</span></span><br><span class="line"><span class="comment">// 也可以在字面值末尾加上`l`或`L`，指明整数位Long型</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> c = <span class="number">35</span>l</span><br><span class="line">c: <span class="type">Long</span> = <span class="number">35</span></span><br><span class="line"><span class="comment">// 将 Int 型赋值给Short或Byte，如果在范围内就会自动转化，否则报错</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> d: <span class="type">Short</span> = <span class="number">3</span></span><br><span class="line">d: <span class="type">Short</span> = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> e: <span class="type">Byte</span> = <span class="number">129</span></span><br><span class="line">&lt;console&gt;:<span class="number">11</span>: error: <span class="class"><span class="keyword">type</span> <span class="title">mismatch</span></span>;</span><br><span class="line"> found   : <span class="type">Int</span>(<span class="number">129</span>)</span><br><span class="line"> required: <span class="type">Byte</span></span><br><span class="line">       <span class="keyword">val</span> e: <span class="type">Byte</span> = <span class="number">129</span></span><br><span class="line">                     ^</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> e: <span class="type">Byte</span> = <span class="number">127</span></span><br><span class="line">e: <span class="type">Byte</span> = <span class="number">127</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div><h3 id="浮点类型"><a href="#浮点类型" class="headerlink" title="浮点类型"></a>浮点类型</h3><p>浮点数以十进制数字+可选的小数点+可选的E或e打头的指数组成：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 浮点数字面值默认为Double型</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> double = <span class="number">3.14</span></span><br><span class="line">double: <span class="type">Double</span> = <span class="number">3.14</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> float = <span class="number">3.14</span></span><br><span class="line">float: <span class="type">Double</span> = <span class="number">3.14</span></span><br><span class="line"><span class="comment">// 如需使用Float类型字面值，必须在数字后面加上f或F</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> float = <span class="number">3.14</span>f</span><br><span class="line">float: <span class="type">Float</span> = <span class="number">3.14</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> float: <span class="type">Float</span> = <span class="number">3.14</span></span><br><span class="line">&lt;console&gt;:<span class="number">11</span>: error: <span class="class"><span class="keyword">type</span> <span class="title">mismatch</span></span>;</span><br><span class="line"> found   : <span class="type">Double</span>(<span class="number">3.14</span>)</span><br><span class="line"> required: <span class="type">Float</span></span><br><span class="line">       <span class="keyword">val</span> float: <span class="type">Float</span> = <span class="number">3.14</span></span><br><span class="line">                          ^</span><br><span class="line"><span class="comment">// e前面部分 ✖️ 10的后面部分次幂</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> e = <span class="number">3.14e2</span></span><br><span class="line">e: <span class="type">Double</span> = <span class="number">314.0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div><h3 id="字符类型"><a href="#字符类型" class="headerlink" title="字符类型"></a>字符类型</h3><ul><li>原字符表示法：使用一对单引号和中间的任意单个Unicode字符组成</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> c = <span class="symbol">&#x27;w</span>e&#x27;</span><br><span class="line">&lt;console&gt;:<span class="number">1</span>: error: unclosed character literal (or use <span class="string">&quot; for string literal &quot;</span><span class="string">we&quot;)</span></span><br><span class="line"><span class="string">       val c = &#x27;we&#x27;</span></span><br><span class="line"><span class="string">                  ^</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; val c = &#x27;w&#x27;</span></span><br><span class="line"><span class="string">c: Char = w</span></span><br></pre></td></tr></table></figure></div><ul><li>Unicode字符表示法：<code>\u</code>加上字符对应的四位十六进制数字，Unicode字符可以出现在Scala程序的任何位置</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 出现在字面值字符中</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> d = &#x27;\u0041&#x27;</span><br><span class="line">d: <span class="type">Char</span> = <span class="type">A</span></span><br><span class="line"><span class="comment">// 出现在变量中</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> d\u0041 = &#x27;x&#x27;</span><br><span class="line">dA: <span class="type">Char</span> = x</span><br></pre></td></tr></table></figure></div><ul><li>转义字符：</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20200811162107.png" alt=""></p><h2 id="String类型"><a href="#String类型" class="headerlink" title="String类型"></a>String类型</h2><p>Scala 本身没有 String 类，字符串的类型实际上是 <code>java.lang.String</code>，String 是一个不可变对象，对字符串的修改会生成一个新的字符串对象。</p><h3 id="String字面值"><a href="#String字面值" class="headerlink" title="String字面值"></a>String字面值</h3><ul><li>普通字符串字面值：普通字符串字面值由用双引号括起来的字符组成，普通字符串中的<code>\</code>会被解析为转义符：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> c1 = <span class="string">&quot;hello world&quot;</span></span><br><span class="line">c1: <span class="type">String</span> = hello world</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> c2 = <span class="string">&quot;\\\&quot;\&#x27;&quot;</span></span><br><span class="line">c2: <span class="type">String</span> = \<span class="string">&quot;&#x27;</span></span><br></pre></td></tr></table></figure></div><ul><li>原生字符串字面值：原生字符串由三重引号括起来的字符组成，原生字符串中每个字符都会被当做该字符本身进行原样输出：</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 转义符会被当做普通字符</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> c4 = <span class="string">&quot;&quot;&quot;\\\&quot;\&#x27;&quot;&quot;&quot;</span></span><br><span class="line">c4: <span class="type">String</span> = \\\<span class="string">&quot;\&#x27;</span></span><br><span class="line"><span class="string">// 空格 换行都会被原样输出</span></span><br><span class="line"><span class="string">scala&gt; val mutiLine = &quot;</span><span class="string">&quot;&quot;</span>hello \t world</span><br><span class="line">     | \n nihao</span><br><span class="line">     | <span class="string">china&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">mutiLine: String =</span></span><br><span class="line"><span class="string">hello \t world</span></span><br><span class="line"><span class="string">\n nihao</span></span><br><span class="line"><span class="string">china</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">// 管道符 `|` 的作用是标识每一行字符串字面值的开始位置：</span></span><br><span class="line"><span class="string">scala&gt; println(&quot;</span><span class="string">&quot;&quot;</span>welcome to china</span><br><span class="line">     |            you are <span class="string">great&quot;&quot;</span><span class="string">&quot;)</span></span><br><span class="line"><span class="string">welcome to china</span></span><br><span class="line"><span class="string">           you are great</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; println(&quot;</span><span class="string">&quot;&quot;</span>welcome to china</span><br><span class="line">     |           |you are <span class="string">great&quot;&quot;</span><span class="string">&quot;)</span></span><br><span class="line"><span class="string">welcome to china</span></span><br><span class="line"><span class="string">you are great</span></span><br></pre></td></tr></table></figure></div><h3 id="字符串插值"><a href="#字符串插值" class="headerlink" title="字符串插值"></a>字符串插值</h3><p>Scala默认提供了三种插值器来实现在字符串字面值中嵌入表达式，你也可以定义自己的插值器来满足不同的需求。</p><ol><li>s插值器：<ol><li>语法： <code>s&quot;$&#123;expression&#125;&quot;</code> </li><li>解析：<code>定位表达式 -&gt; 表达式求值 -&gt; 对值调用toString方法</code></li></ol></li><li>raw插值器：<ol><li>语法：<code>raw&quot;$&#123;expression&#125;&quot;</code></li><li>解析：和s插值器相似，但是会把其他字符作为原义字符对待</li></ol></li><li>f插值器：<ol><li>语法：<code>f&quot;$&#123;expression&#125;%.2f&quot;</code></li><li>解析：和s插值器相似，多个格式化输出</li></ol></li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> x = <span class="number">314</span></span><br><span class="line">x: <span class="type">Int</span> = <span class="number">314</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="string">&quot;hell &quot;</span> + x</span><br><span class="line">res22: <span class="type">String</span> = hell <span class="number">314</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="string">s&quot;hell <span class="subst">$x</span> world <span class="subst">$&#123;math.Pi&#125;</span>&quot;</span></span><br><span class="line">res23: <span class="type">String</span> = hell <span class="number">314</span> world <span class="number">3.141592653589793</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="string">s&quot;hello\t<span class="subst">$x</span> world <span class="subst">$&#123;math.Pi&#125;</span>&quot;</span></span><br><span class="line">res24: <span class="type">String</span> = hello<span class="number">314</span> world <span class="number">3.141592653589793</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="string">raw&quot;hello\t<span class="subst">$x</span> world <span class="subst">$&#123;math.Pi&#125;</span>&quot;</span></span><br><span class="line">res26: <span class="type">String</span> = hello\t314 world <span class="number">3.141592653589793</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="string">f&quot;hello\t<span class="subst">$x</span> world <span class="subst">$&#123;math.Pi&#125;</span>%.2f&quot;</span></span><br><span class="line">res27: <span class="type">String</span> = hello<span class="number">314</span> world <span class="number">3.14</span></span><br></pre></td></tr></table></figure></div><h3 id="字符串的常用方法"><a href="#字符串的常用方法" class="headerlink" title="字符串的常用方法"></a>字符串的常用方法</h3><p>下表列出了 java.lang.String 中常用的方法，你可以在 Scala 中使用：</p><div class="table-container"><table><thead><tr><th>序号</th><th>方法</th><th>描述</th></tr></thead><tbody><tr><td>1</td><td>char charAt(int index)</td><td>返回指定位置的字符</td></tr><tr><td>2</td><td>int compareTo(Object o)</td><td>比较字符串与对象</td></tr><tr><td>3</td><td>int compareTo(String anotherString)</td><td>按字典顺序比较两个字符串</td></tr><tr><td>4</td><td>int compareToIgnoreCase(String str)</td><td>按字典顺序比较两个字符串，不考虑大小写</td></tr><tr><td>5</td><td>String concat(String str)</td><td>将指定字符串连接到此字符串的结尾，等价于 <code>+</code></td></tr><tr><td>6</td><td>boolean contentEquals(StringBuffer sb)</td><td>将此字符串与指定的 StringBuffer 比较。</td></tr><tr><td>7</td><td>static String copyValueOf(char[] data)</td><td>返回指定数组中表示该字符序列的 String</td></tr><tr><td>8</td><td>static String copyValueOf(char[] data, int offset, int count)</td><td>返回指定数组中表示该字符序列的 String</td></tr><tr><td>9</td><td>boolean endsWith(String suffix)</td><td>测试此字符串是否以指定的后缀结束</td></tr><tr><td>10</td><td>boolean equals(Object anObject)</td><td>将此字符串与指定的对象比较</td></tr><tr><td>11</td><td>boolean equalsIgnoreCase(String anotherString)</td><td>将此 String 与另一个 String 比较，不考虑大小写</td></tr><tr><td>12</td><td>byte getBytes()</td><td>使用平台的默认字符集将此 String 编码为 byte 序列，并将结果存储到一个新的 byte 数组中</td></tr><tr><td>13</td><td>byte[] getBytes(String charsetName</td><td>使用指定的字符集将此 String 编码为 byte 序列，并将结果存储到一个新的 byte 数组中</td></tr><tr><td>14</td><td>void getChars(int srcBegin, int srcEnd, char[] dst, int dstBegin)</td><td>将字符从此字符串复制到目标字符数组</td></tr><tr><td>15</td><td>int hashCode()</td><td>返回此字符串的哈希码</td></tr><tr><td>16</td><td>int indexOf(int ch)</td><td>返回指定字符在此字符串中第一次出现处的索引</td></tr><tr><td>17</td><td>int indexOf(int ch, int fromIndex)</td><td>返回在此字符串中第一次出现指定字符处的索引，从指定的索引开始搜索</td></tr><tr><td>18</td><td>int indexOf(String str)</td><td>返回指定子字符串在此字符串中第一次出现处的索引</td></tr><tr><td>19</td><td>int indexOf(String str, int fromIndex)</td><td>返回指定子字符串在此字符串中第一次出现处的索引，从指定的索引开始</td></tr><tr><td>20</td><td>String intern()</td><td>返回字符串对象的规范化表示形式</td></tr><tr><td>21</td><td>int lastIndexOf(int ch)</td><td>返回指定字符在此字符串中最后一次出现处的索引</td></tr><tr><td>22</td><td>int lastIndexOf(int ch, int fromIndex)</td><td>返回指定字符在此字符串中最后一次出现处的索引，从指定的索引处开始进行反向搜索</td></tr><tr><td>23</td><td>int lastIndexOf(String str)</td><td>返回指定子字符串在此字符串中最右边出现处的索引</td></tr><tr><td>24</td><td>int lastIndexOf(String str, int fromIndex)</td><td>返回指定子字符串在此字符串中最后一次出现处的索引，从指定的索引开始反向搜索</td></tr><tr><td>25</td><td>int length()</td><td>返回此字符串的长度</td></tr><tr><td>26</td><td>boolean matches(String regex)</td><td>告知此字符串是否匹配给定的正则表达式</td></tr><tr><td>27</td><td>boolean regionMatches(boolean ignoreCase, int toffset, String other, int ooffset, int len)</td><td>测试两个字符串区域是否相等</td></tr><tr><td>28</td><td>boolean regionMatches(int toffset, String other, int ooffset, int len)</td><td>测试两个字符串区域是否相等</td></tr><tr><td>29</td><td>String replace(char oldChar, char newChar)</td><td>返回一个新的字符串，它是通过用 newChar 替换此字符串中出现的所有 oldChar 得到的</td></tr><tr><td>30</td><td>String replaceAll(String regex, String replacement</td><td>使用给定的 replacement 替换此字符串所有匹配给定的正则表达式的子字符串</td></tr><tr><td>31</td><td>String replaceFirst(String regex, String replacement)</td><td>使用给定的 replacement 替换此字符串匹配给定的正则表达式的第一个子字符串</td></tr><tr><td>32</td><td>String[] split(String regex)</td><td>根据给定正则表达式的匹配拆分此字符串</td></tr><tr><td>33</td><td>String[] split(String regex, int limit)</td><td>根据匹配给定的正则表达式来拆分此字符串</td></tr><tr><td>34</td><td>boolean startsWith(String prefix)</td><td>测试此字符串是否以指定的前缀开始</td></tr><tr><td>35</td><td>boolean startsWith(String prefix, int toffset)</td><td>测试此字符串从指定索引开始的子字符串是否以指定前缀开始。</td></tr><tr><td>36</td><td>CharSequence subSequence(int beginIndex, int endIndex)</td><td>返回一个新的字符序列，它是此序列的一个子序列</td></tr><tr><td>37</td><td>String substring(int beginIndex)</td><td>返回一个新的字符串，它是此字符串的一个子字符串</td></tr><tr><td>38</td><td>String substring(int beginIndex, int endIndex)</td><td>返回一个新字符串，它是此字符串的一个子字符串</td></tr><tr><td>39</td><td>char[] toCharArray()</td><td>将此字符串转换为一个新的字符数组</td></tr><tr><td>40</td><td>String toLowerCase()</td><td>使用默认语言环境的规则将此 String 中的所有字符都转换为小写</td></tr><tr><td>41</td><td>String toLowerCase(Locale locale)</td><td>使用给定 Locale 的规则将此 String 中的所有字符都转换为小写</td></tr><tr><td>42</td><td>String toString()</td><td>返回此对象本身（它已经是一个字符串！）</td></tr><tr><td>43</td><td>String toUpperCase()</td><td>使用默认语言环境的规则将此 String 中的所有字符都转换为大写</td></tr><tr><td>44</td><td>String toUpperCase(Locale locale)</td><td>使用给定 Locale 的规则将此 String 中的所有字符都转换为大写</td></tr><tr><td>45</td><td>String trim()</td><td>删除指定字符串的首尾空白符</td></tr><tr><td>46</td><td>static String valueOf(primitive data type x)</td><td>返回指定类型参数的字符串表示形式</td></tr></tbody></table></div><h2 id="Boolean类型"><a href="#Boolean类型" class="headerlink" title="Boolean类型"></a>Boolean类型</h2><p>Boolean类型有两个字面量，<code>true</code>和<code>false</code>：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> t = <span class="literal">true</span></span><br><span class="line">t: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> f = <span class="literal">false</span></span><br><span class="line">f: <span class="type">Boolean</span> = <span class="literal">false</span></span><br></pre></td></tr></table></figure></div><p>和很多动态语言不同， Scala不支持其他类型到Boolean类型的隐式转换：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">if</span>(<span class="number">4</span>&gt;<span class="number">3</span>) print(<span class="string">&quot;4&gt;3&quot;</span>)</span><br><span class="line"><span class="number">4</span>&gt;<span class="number">3</span></span><br><span class="line">scala&gt; <span class="keyword">if</span>(<span class="number">1</span>) print(<span class="string">&quot;1&quot;</span>)</span><br><span class="line">&lt;console&gt;:<span class="number">12</span>: error: <span class="class"><span class="keyword">type</span> <span class="title">mismatch</span></span>;</span><br><span class="line"> found   : <span class="type">Int</span>(<span class="number">1</span>)</span><br><span class="line"> required: <span class="type">Boolean</span></span><br><span class="line">       <span class="keyword">if</span>(<span class="number">1</span>) print(<span class="string">&quot;1&quot;</span>)</span><br><span class="line">          ^</span><br></pre></td></tr></table></figure></div><h2 id="核心类型间的转换"><a href="#核心类型间的转换" class="headerlink" title="核心类型间的转换"></a>核心类型间的转换</h2><h3 id="隐式转换"><a href="#隐式转换" class="headerlink" title="隐式转换"></a>隐式转换</h3><ul><li>数值类型的隐式准换：当Scala在进行赋值或者运算时，精度小的数值类型会自动转换为精度高的数值类型：</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20200811162124.png" alt=""></p><p>举例：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> a = &#x27;a&#x27;</span><br><span class="line">a: <span class="type">Char</span> = a</span><br><span class="line"></span><br><span class="line">scala&gt; a + <span class="number">1</span></span><br><span class="line">res36: <span class="type">Int</span> = <span class="number">98</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> x = <span class="number">1</span></span><br><span class="line">x: <span class="type">Int</span> = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> y: <span class="type">Short</span> = <span class="number">2</span></span><br><span class="line">y: <span class="type">Short</span> = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">scala&gt; x + y</span><br><span class="line">res37: <span class="type">Int</span> = <span class="number">3</span></span><br></pre></td></tr></table></figure></div><ul><li>String的隐式转换：s + <data> 会自动调用<data>的toString方法进行字符串拼接</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="string">&quot;hello&quot;</span> + <span class="number">2019</span></span><br><span class="line">res38: <span class="type">String</span> = hello2019</span><br></pre></td></tr></table></figure></div><h3 id="显式转换"><a href="#显式转换" class="headerlink" title="显式转换"></a>显式转换</h3><p>有几种方式：</p><ul><li>to.类型名</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> a = <span class="number">97</span></span><br><span class="line">a: <span class="type">Int</span> = <span class="number">97</span></span><br><span class="line"></span><br><span class="line">scala&gt; a.toByte</span><br><span class="line">res48: <span class="type">Byte</span> = <span class="number">97</span></span><br><span class="line"></span><br><span class="line">scala&gt; a.toShort</span><br><span class="line">res49: <span class="type">Short</span> = <span class="number">97</span></span><br><span class="line"></span><br><span class="line">scala&gt; a.toChar</span><br><span class="line">res50: <span class="type">Char</span> = a</span><br><span class="line"></span><br><span class="line">scala&gt; a.toLong</span><br><span class="line">res51: <span class="type">Long</span> = <span class="number">97</span></span><br><span class="line"></span><br><span class="line">scala&gt; a.toFloat</span><br><span class="line">res52: <span class="type">Float</span> = <span class="number">97.0</span></span><br><span class="line"></span><br><span class="line">scala&gt; a.toDouble</span><br><span class="line">res53: <span class="type">Double</span> = <span class="number">97.0</span></span><br><span class="line"></span><br><span class="line">scala&gt; a.toString</span><br><span class="line">res54: <span class="type">String</span> = <span class="number">97</span></span><br><span class="line"></span><br><span class="line">scala&gt; &#x27;a&#x27;.toInt</span><br><span class="line">res55: <span class="type">Int</span> = <span class="number">97</span></span><br></pre></td></tr></table></figure></div><ul><li>asInstanceOf[type]：测定某个对象是否属于给定的类，用isInstanceOf方法，如果测试成功，可以用asInstanceOf方法转换</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; a.asInstanceOf[<span class="type">Int</span>]</span><br><span class="line">res65: <span class="type">Int</span> = <span class="number">97</span></span><br><span class="line"></span><br><span class="line">scala&gt; a.asInstanceOf[<span class="type">Long</span>]</span><br><span class="line">res66: <span class="type">Long</span> = <span class="number">97</span></span><br><span class="line"></span><br><span class="line">scala&gt; a.asInstanceOf[<span class="type">Short</span>]</span><br><span class="line">res67: <span class="type">Short</span> = <span class="number">97</span></span><br><span class="line"></span><br><span class="line">scala&gt; a.asInstanceOf[<span class="type">String</span>]</span><br><span class="line">java.lang.<span class="type">ClassCastException</span>: java.lang.<span class="type">Integer</span> cannot be cast to java.lang.<span class="type">String</span></span><br><span class="line">  ... <span class="number">28</span> elided</span><br></pre></td></tr></table></figure></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Scala的核心类型，包括String，以及数值类型 Byte、Short、Int、Long、Float、Double、Char 和 Boolean。&lt;/p&gt;
&lt;h2 id=&quot;数值类型&quot;&gt;&lt;a href=&quot;#数值类型&quot; class=&quot;headerlink&quot; title=&quot;数
      
    
    </summary>
    
      <category term="Scala" scheme="http://liketea.xyz/categories/Scala/"/>
    
    
      <category term="教程" scheme="http://liketea.xyz/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="Scala" scheme="http://liketea.xyz/tags/Scala/"/>
    
  </entry>
  
  <entry>
    <title>Scala 教程：Basics（三）—— 操作符&amp;表达式</title>
    <link href="http://liketea.xyz/Scala/Scala/Scala%20%E6%95%99%E7%A8%8B%EF%BC%9ABasics%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94%20%E6%93%8D%E4%BD%9C%E7%AC%A6&amp;%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    <id>http://liketea.xyz/Scala/Scala/Scala 教程：Basics（三）—— 操作符&amp;表达式/</id>
    <published>2020-08-09T08:00:00.000Z</published>
    <updated>2021-06-02T10:44:40.903Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>操作符即方法：操作符和方法只不过是操作的两种语法形式</p><blockquote><p>一切操作符都只不过是方法调用的漂亮语法<br>一切方法都可以写作操作符表示法</p></blockquote></blockquote><h2 id="操作符"><a href="#操作符" class="headerlink" title="操作符"></a>操作符</h2><h3 id="Scala中的操作符"><a href="#Scala中的操作符" class="headerlink" title="Scala中的操作符"></a>Scala中的操作符</h3><ul><li>算术操作符: A 为 10，B 为 20</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20191203101215.png" alt=""></p><ul><li>关系操作符: A 为 10，B 为 20，<code>==</code>的实现很用心，大部分场合都能返回给你需要的相等性比较的结果，其背后的规则是：首先检查左侧是否为null，如果不为Null，调用equals方法</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20191203101255.png" alt=""></p><ul><li>逻辑操作符：A 为 true，B 为 false；&amp;&amp; 和 || 遵循短路原则，对应的非短路版本为 &amp; 和 |；</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20191203101319.png" alt=""></p><ul><li>位操作符：A = 60; 及 B = 13;</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20191203101351.png" alt=""></p><ul><li>赋值运算符：注意，在Java中赋值语句的返回值是被赋上的值，而在Scala中赋值语句的返回值永远是 Unit类型的单元值<code>()</code></li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20191203101416.png" alt=""></p><h3 id="操作符的优先级和结合性"><a href="#操作符的优先级和结合性" class="headerlink" title="操作符的优先级和结合性"></a>操作符的优先级和结合性</h3><p>由于Scala并不是真的有操作符，操作符仅仅是用操作符表示法使用方法的一种方式，Scala通过操作符的首字符来决定操作符的优先级，通过操作符的尾字符决定操作符的结合性。</p><p>尽管你能够记住这些操作符的优先级，为了使得代码更加易于理解，你只应该在算术操作符合赋值操作符上利用操作符的优先级，其他情形还是老老实实加上括号吧。</p><h4 id="操作符的优先级"><a href="#操作符的优先级" class="headerlink" title="操作符的优先级"></a>操作符的优先级</h4><p>Scala中操作符的优先级由操作符的<strong>首字符</strong>决定：举例来说，以*开始的操作符优先级比以+开始的操作符优先级更高，下图列出了Scala中不同首字母的操作度的优先级（自上而下，依次递减；同一行具有相同优先级）：</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20191203101638.png" alt=""></p><p>上面红框分类不是很严谨，只是为了方便记忆，比较两个操作符的优先级的时候这样做：</p><ol><li>得到两个操作符的首字符A和B;</li><li>看看首字母是属于<strong>算术-&gt;关系-&gt;逻辑</strong>-&gt;字母-&gt;赋值中的哪一类；</li><li>在以上顺序中，位于前面的优先级高；</li><li>记住两个特例：<code>:</code>在算术和关系之间，<code>^</code>在 <code>&amp;</code> 和 <code>|</code> 之间；</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// + 的优先级在 &lt; 之上，因而 + 先执行</span></span><br><span class="line">scala&gt; <span class="number">2</span> &lt;&lt; <span class="number">2</span> + <span class="number">2</span></span><br><span class="line">res107: <span class="type">Int</span> = <span class="number">32</span></span><br><span class="line"><span class="comment">// + 的优先级在赋值操作之上，因而 + 先执行</span></span><br><span class="line">x *= y + <span class="number">1</span> 等价于 x *= (y+<span class="number">1</span>)</span><br></pre></td></tr></table></figure></div><h4 id="操作符的结合性"><a href="#操作符的结合性" class="headerlink" title="操作符的结合性"></a>操作符的结合性</h4><p>当多个同等优先级的操作符并排在一起的时候，操作符的结合性由操作符的尾字符决定：任何以 <code>:</code> 结尾的操作符都是在它右侧的操作元调用，传入左侧操作元，以任何其他字符结尾的方法则相反。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a ::: b ::: c 等价于 a ::: (b:::c)</span><br></pre></td></tr></table></figure></div><h3 id="任何操作符都是方法调用"><a href="#任何操作符都是方法调用" class="headerlink" title="任何操作符都是方法调用"></a>任何操作符都是方法调用</h3><p>Scala中的操作符只是方法调用的漂亮语法，换句话说Scala中所有操作符都可以写作方法调用的形式。</p><ul><li>中缀操作符：<code>&lt;operator1&gt; &lt;operate&gt; &lt;operator2&gt;</code> ，如果是左结合性可以写作 <code>&lt;operator1&gt;.&lt;operate&gt;(&lt;operator2)</code>，如果是右结合性可以写作<code>&lt;operator2&gt;.&lt;operate&gt;(&lt;operator1)</code>；</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1 + 2</span></span><br><span class="line">scala&gt; <span class="number">1.</span>+(<span class="number">2</span>)</span><br><span class="line">res108: <span class="type">Int</span> = <span class="number">3</span></span><br><span class="line"><span class="comment">// 2 &lt;&lt; 1</span></span><br><span class="line">scala&gt; <span class="number">2.</span>&lt;&lt;(<span class="number">1</span>)</span><br><span class="line">res113: <span class="type">Int</span> = <span class="number">4</span></span><br></pre></td></tr></table></figure></div><ul><li>前缀操作符：只有一元操作符(unary)<code>+</code>、<code>-</code>、<code>!</code>、<code>~</code>可以被用作前缀操作符，<code>&lt;operate&gt; &lt;operator1&gt;</code> 可以写作 <code>&lt;operator1&gt;.unary_&lt;operate&gt;</code></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// -2.0</span></span><br><span class="line">scala&gt; (<span class="number">2.0</span>).unary_-</span><br><span class="line">res111: <span class="type">Double</span> = <span class="number">-2.0</span></span><br><span class="line"><span class="comment">//  ! true</span></span><br><span class="line">scala&gt; <span class="literal">true</span>.unary_!</span><br><span class="line">res115: <span class="type">Boolean</span> = <span class="literal">false</span></span><br></pre></td></tr></table></figure></div><h3 id="任何方法都可以是操作符"><a href="#任何方法都可以是操作符" class="headerlink" title="任何方法都可以是操作符"></a>任何方法都可以是操作符</h3><p>Scala中操作符并不是特殊的语法，任何方法都可以是操作符。</p><ul><li>中缀操作符表示法：<code>&lt;operator1&gt;.&lt;operate&gt;(&lt;operator2&gt;)</code> 可以写作 <code>&lt;operator1&gt; &lt;operate&gt; &lt;operator2&gt;</code> </li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="string">&quot;hello world&quot;</span>.indexOf(<span class="string">&quot;w&quot;</span>)</span><br><span class="line">res122: <span class="type">Int</span> = <span class="number">6</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="string">&quot;hello world&quot;</span> indexOf <span class="string">&quot;w&quot;</span></span><br><span class="line">res123: <span class="type">Int</span> = <span class="number">6</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="string">&quot;hello world&quot;</span> indexOf (<span class="string">&quot;o&quot;</span>,<span class="number">5</span>)</span><br><span class="line">res125: <span class="type">Int</span> = <span class="number">7</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="string">&quot;hello world&quot;</span>.indexOf(<span class="string">&quot;o&quot;</span>,<span class="number">5</span>)</span><br><span class="line">res126: <span class="type">Int</span> = <span class="number">7</span></span><br></pre></td></tr></table></figure></div><ul><li>后缀操作符表示法：后缀操作符是那些不接受任何参数的方法，在Scala中可以在方法调用时省略空的圆括号，除非方法有副作用，比如println()</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">import</span> scala.language.postfixOps</span><br><span class="line"><span class="keyword">import</span> scala.language.postfixOps</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="string">&quot;Hello WOrld&quot;</span> toLowerCase</span><br><span class="line">res130: <span class="type">String</span> = hello world</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="string">&quot;Hello WOrld&quot;</span>.toLowerCase</span><br><span class="line">res131: <span class="type">String</span> = hello world</span><br></pre></td></tr></table></figure></div><h2 id="表达式"><a href="#表达式" class="headerlink" title="表达式"></a>表达式</h2><ul><li>表达式：表达式是执行后会返回一个值的代码单元</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 一个最简单的表达式</span></span><br><span class="line">scala&gt; <span class="number">1</span></span><br><span class="line">res132: <span class="type">Int</span> = <span class="number">1</span></span><br></pre></td></tr></table></figure></div><ul><li>表达式块：可以用大括号结合多个表达式创建一个表达式块，块中最后一个表达式将作为整个表达式块的返回值，表达式块可以进行嵌套，每个表达式块拥有自己的变量和作用域</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 表达式块</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> amount = &#123;</span><br><span class="line">     | <span class="keyword">val</span> x = <span class="number">5</span> * <span class="number">20</span></span><br><span class="line">     | x + <span class="number">10</span></span><br><span class="line">     | &#125;</span><br><span class="line">amount: <span class="type">Int</span> = <span class="number">110</span></span><br></pre></td></tr></table></figure></div><ul><li>语句：语句就是不返回值的表达式，语句的返回类型为Unit；由于不返回值，语句通常用来修改现有的数据或者完成应用之外的修改；Scala中常见的语句包括 println()调用、变量声明语句、while控制语句</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; println(<span class="string">&quot;hello world&quot;</span>)</span><br><span class="line">hello world</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> a = <span class="number">1</span></span><br><span class="line">a: <span class="type">Int</span> = <span class="number">1</span></span><br></pre></td></tr></table></figure></div><p>表达式为函数式编程提供了基础：表达式可以返回数据而不修改现有数据，这就允许使用不可变数据，函数也可以用来返回新的数据，在某种意义上这种函数是另一种类型的表达式。</p><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;操作符即方法：操作符和方法只不过是操作的两种语法形式&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一切操作符都只不过是方法调用的漂亮语法&lt;br&gt;一切方法都可以写作操作符表示法&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;h2 id
      
    
    </summary>
    
      <category term="Scala" scheme="http://liketea.xyz/categories/Scala/"/>
    
    
      <category term="教程" scheme="http://liketea.xyz/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="Scala" scheme="http://liketea.xyz/tags/Scala/"/>
    
  </entry>
  
  <entry>
    <title>Scala 教程：Basics（四）—— 控制结构</title>
    <link href="http://liketea.xyz/Scala/Scala/Scala%20%E6%95%99%E7%A8%8B%EF%BC%9ABasics%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94%20%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84/"/>
    <id>http://liketea.xyz/Scala/Scala/Scala 教程：Basics（四）—— 控制结构/</id>
    <published>2020-08-08T08:00:00.000Z</published>
    <updated>2021-06-02T10:44:40.905Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Scala中大多数控制结构都是表达式，有返回值</p></blockquote><p>Scala 只有为数不多的几个内建的控制结构：if、match、for、while、try和函数调用，由于它们有返回值，可以很好地支持函数式编程。</p><h2 id="条件控制结构"><a href="#条件控制结构" class="headerlink" title="条件控制结构"></a>条件控制结构</h2><h3 id="if表达式"><a href="#if表达式" class="headerlink" title="if表达式"></a>if表达式</h3><p>语法：</p><ul><li><code>if (&lt;Boolean expression&gt;) &lt;expression&gt;</code>：返回值是 Any 类型；</li><li><code>if (&lt;Boolean expression&gt;) &lt;expression&gt; else &lt;expression&gt;</code>：返回值的类型是两种结果类型的最近公共父类型；</li><li><code>if (&lt;Boolean expression&gt;) &lt;expression&gt; else if (&lt;Boolean expression&gt;) ... else &lt;expression&gt;</code>：本质上是 <code>if ... else</code> 表达式的嵌套，返回值的类型是所有可能返回结果类型的最近公共父类型；</li></ul><p>执行：如果布尔表达式成立则执行第一个表达式，否则执行另外一个表达式</p><p>示例：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// if ... 返回值类型必为 Any</span></span><br><span class="line">scala&gt; <span class="keyword">if</span> (<span class="number">3</span>&lt;<span class="number">4</span>) <span class="number">4</span></span><br><span class="line">res0: <span class="type">AnyVal</span> = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// if ... else ... ，返回值的类型是所有可能返回结果类型的最近公共父类型</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> x = <span class="number">1</span></span><br><span class="line">x: <span class="type">Int</span> = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> y = <span class="number">2</span></span><br><span class="line">y: <span class="type">Int</span> = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">if</span> (x &gt; y) x</span><br><span class="line">res1: <span class="type">AnyVal</span> = ()</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">if</span> (x &gt; y) x <span class="keyword">else</span> y</span><br><span class="line">res2: <span class="type">Int</span> = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// if ... else if ... else ...，本质上是嵌套的 if ... else 表达式</span></span><br><span class="line">scala&gt; <span class="keyword">if</span> (<span class="number">2</span> == <span class="number">3</span>)&#123;</span><br><span class="line">     | <span class="number">0</span></span><br><span class="line">     | &#125; <span class="keyword">else</span></span><br><span class="line">     | <span class="keyword">if</span> (<span class="number">2</span> &gt; <span class="number">3</span>)&#123;</span><br><span class="line">     | <span class="number">1</span></span><br><span class="line">     | &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     | <span class="number">-1</span></span><br><span class="line">     | &#125;</span><br><span class="line">res23: <span class="type">Int</span> = <span class="number">-1</span></span><br></pre></td></tr></table></figure></div><h3 id="match表达式"><a href="#match表达式" class="headerlink" title="match表达式"></a>match表达式</h3><p>模式匹配是检查某个值（value）是否匹配某一个模式的机制，它是Java中的switch语句的升级版，同样可以用于替代一系列的 if/else 语句。</p><p>语法：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;expression&gt; <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> &lt;pattern&gt; =&gt; &lt;expression&gt;</span><br><span class="line">    [<span class="keyword">case</span> ...]</span><br></pre></td></tr></table></figure></div><p>执行：获取输入表达式的<strong>值</strong>，逐一匹配备选模式，匹配成功则执行并返回对应模式后的表达式，匹配不成功则触发MatchError，返回值类型是各个备选结果表达式类型的最近公共父类型。</p><p>示例：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 对 if (x &gt; y) x else y 的改写</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> x = <span class="number">1</span>; <span class="keyword">val</span> y = <span class="number">2</span></span><br><span class="line">x: <span class="type">Int</span> = <span class="number">1</span></span><br><span class="line">y: <span class="type">Int</span> = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> max = x &gt; y <span class="keyword">match</span> &#123;</span><br><span class="line">     | <span class="keyword">case</span> <span class="literal">true</span> =&gt; x</span><br><span class="line">     | <span class="keyword">case</span> <span class="literal">false</span> =&gt; y</span><br><span class="line">     | &#125;</span><br><span class="line">max: <span class="type">Int</span> = <span class="number">2</span></span><br></pre></td></tr></table></figure></div><p>变形：match 表达式的变形主要发生在 <pattern></p><ul><li>复合模式：使用 <code>&lt;pattern1&gt; | &lt;pattern2&gt; ...</code> 可以对多个模式重用 case 块</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="string">&quot;MON&quot;</span> <span class="keyword">match</span> &#123;</span><br><span class="line">     | <span class="keyword">case</span> <span class="string">&quot;SAT&quot;</span> | <span class="string">&quot;SUN&quot;</span> =&gt; <span class="string">&quot;weekend&quot;</span></span><br><span class="line">     | <span class="keyword">case</span> <span class="string">&quot;MON&quot;</span> | <span class="string">&quot;TUE&quot;</span> | <span class="string">&quot;WED&quot;</span> | <span class="string">&quot;THU&quot;</span> | <span class="string">&quot;FRI&quot;</span> =&gt;</span><br><span class="line">     | <span class="string">&quot;weekday&quot;</span></span><br><span class="line">     | &#125;</span><br><span class="line">res9: <span class="type">String</span> = weekday</span><br></pre></td></tr></table></figure></div><ul><li>通配模式：使用通配符 <code>_</code> 可以匹配任意模式，但是不能在 =&gt; 右侧访问通配符</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="string">&quot;MON&quot;</span> <span class="keyword">match</span> &#123;</span><br><span class="line">     | <span class="keyword">case</span> <span class="string">&quot;SAT&quot;</span> | <span class="string">&quot;SUN&quot;</span> =&gt; <span class="string">&quot;weekend&quot;</span></span><br><span class="line">     | <span class="keyword">case</span> _ =&gt; <span class="string">&quot;weekday&quot;</span></span><br><span class="line">     | &#125;</span><br><span class="line">res8: <span class="type">String</span> = weekday</span><br></pre></td></tr></table></figure></div><ul><li>变量模式：使用一个<strong>模式变量</strong>可以将输入表达式的值绑定到该变量，变量可以在 =&gt; 右侧访问</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="string">&quot;MON&quot;</span> <span class="keyword">match</span> &#123;</span><br><span class="line">     | <span class="keyword">case</span> <span class="string">&quot;SAT&quot;</span> | <span class="string">&quot;SUN&quot;</span> =&gt; <span class="string">&quot;weekend&quot;</span></span><br><span class="line">     | <span class="keyword">case</span> x =&gt; <span class="string">&quot;weekday&quot;</span> + x</span><br><span class="line">     | &#125;</span><br><span class="line">res10: <span class="type">String</span> = weekdayMON</span><br></pre></td></tr></table></figure></div><ul><li>类型模式：使用 <code>模式变量: 类型</code> 可以匹配输入表达式返回值的具体类型，需要注意的是备选模式的类型必须是输入表达式返回值类型的子类，否则会触发异常：<code>error: scrutinee is incompatible with pattern type</code></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> x: <span class="type">Int</span> = <span class="number">1</span></span><br><span class="line">x: <span class="type">Int</span> = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> y: <span class="type">Any</span> = x</span><br><span class="line">y: <span class="type">Any</span> = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">scala&gt; y</span><br><span class="line">res25: <span class="type">Any</span> = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">scala&gt; y <span class="keyword">match</span> &#123;</span><br><span class="line">     | <span class="keyword">case</span> t: <span class="type">Float</span> =&gt; <span class="string">&quot;Float&quot;</span></span><br><span class="line">     | <span class="keyword">case</span> t: <span class="type">Long</span> =&gt; <span class="string">&quot;Long&quot;</span></span><br><span class="line">     | <span class="keyword">case</span> t: <span class="type">Int</span> =&gt; <span class="string">&quot;Int&quot;</span></span><br><span class="line">     | <span class="keyword">case</span> _ =&gt; <span class="string">&quot;_&quot;</span></span><br><span class="line">     | &#125;</span><br><span class="line">res26: <span class="type">String</span> = <span class="type">Int</span></span><br></pre></td></tr></table></figure></div><ul><li>哨兵模式：在模式变量后面加上 <code>if &lt;boolean expression&gt;</code>，可以为匹配表达式添加匹配条件，只有条件满足时才算匹配成功</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">showImportantNotification</span></span>(notification: <span class="type">Notification</span>, importantPeopleInfo: <span class="type">Seq</span>[<span class="type">String</span>]): <span class="type">String</span> = &#123;</span><br><span class="line">  notification <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Email</span>(sender, _, _) <span class="keyword">if</span> importantPeopleInfo.contains(sender) =&gt;</span><br><span class="line">      <span class="string">&quot;You got an email from special someone!&quot;</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">SMS</span>(number, _) <span class="keyword">if</span> importantPeopleInfo.contains(number) =&gt;</span><br><span class="line">      <span class="string">&quot;You got an SMS from special someone!&quot;</span></span><br><span class="line">    <span class="keyword">case</span> other =&gt;</span><br><span class="line">      showNotification(other) <span class="comment">// nothing special, delegate to our original showNotification function</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> importantPeopleInfo = <span class="type">Seq</span>(<span class="string">&quot;867-5309&quot;</span>, <span class="string">&quot;jenny@gmail.com&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> someSms = <span class="type">SMS</span>(<span class="string">&quot;867-5309&quot;</span>, <span class="string">&quot;Are you there?&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> someVoiceRecording = <span class="type">VoiceRecording</span>(<span class="string">&quot;Tom&quot;</span>, <span class="string">&quot;voicerecording.org/id/123&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> importantEmail = <span class="type">Email</span>(<span class="string">&quot;jenny@gmail.com&quot;</span>, <span class="string">&quot;Drinks tonight?&quot;</span>, <span class="string">&quot;I&#x27;m free after 5!&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> importantSms = <span class="type">SMS</span>(<span class="string">&quot;867-5309&quot;</span>, <span class="string">&quot;I&#x27;m here! Where are you?&quot;</span>)</span><br><span class="line"></span><br><span class="line">println(showImportantNotification(someSms, importantPeopleInfo))</span><br><span class="line">println(showImportantNotification(someVoiceRecording, importantPeopleInfo))</span><br><span class="line">println(showImportantNotification(importantEmail, importantPeopleInfo))</span><br><span class="line">println(showImportantNotification(importantSms, importantPeopleInfo))</span><br></pre></td></tr></table></figure></div><h2 id="循环表达式-语句"><a href="#循环表达式-语句" class="headerlink" title="循环表达式/语句"></a>循环表达式/语句</h2><h3 id="for表达式"><a href="#for表达式" class="headerlink" title="for表达式"></a>for表达式</h3><p>Scala 的for表达式是用于迭代的瑞士军刀，每次迭代会执行一个表达式，并返回所有表达式返回值的一个集合（可选）。</p><p>语法：enumerators 是一个枚举器，可以包含多个生成器（items &lt;- items）和过滤器（if <expression>）；</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAINTEXT"><figure class="iseeu highlight /plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for (enumerators) [yield] &lt;expression&gt;</span><br></pre></td></tr></table></figure></div><p>执行：每次从枚举器中取出一个元素，执行表达式，返回所有返回值构成的一个集合（如果加了 yield 的话）。</p><p>示例：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 不带 yield，没有返回值</span></span><br><span class="line">scala&gt; <span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span>) &#123;<span class="number">2</span> * i&#125;</span><br><span class="line"><span class="comment">// 带了yeild，返回所有返回值构成的一个集合</span></span><br><span class="line">scala&gt; <span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span>) <span class="keyword">yield</span> &#123;<span class="number">2</span> * i&#125;</span><br><span class="line">res30: scala.collection.immutable.<span class="type">IndexedSeq</span>[<span class="type">Int</span>] = <span class="type">Vector</span>(<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">14</span>, <span class="number">16</span>, <span class="number">18</span>, <span class="number">20</span>)</span><br></pre></td></tr></table></figure></div><p>变形：</p><ul><li>迭代器哨兵：枚举器中可以包含多个过滤器</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span> <span class="keyword">if</span> i % <span class="number">2</span> == <span class="number">0</span>) <span class="keyword">yield</span> &#123;<span class="number">2</span> * i&#125;</span><br><span class="line">res32: scala.collection.immutable.<span class="type">IndexedSeq</span>[<span class="type">Int</span>] = <span class="type">Vector</span>(<span class="number">4</span>, <span class="number">8</span>, <span class="number">12</span>, <span class="number">16</span>, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span> <span class="keyword">if</span> i % <span class="number">2</span> == <span class="number">0</span> <span class="keyword">if</span> i &gt; <span class="number">5</span>) <span class="keyword">yield</span> &#123;<span class="number">2</span> * i&#125;</span><br><span class="line">res33: scala.collection.immutable.<span class="type">IndexedSeq</span>[<span class="type">Int</span>] = <span class="type">Vector</span>(<span class="number">12</span>, <span class="number">16</span>, <span class="number">20</span>)</span><br></pre></td></tr></table></figure></div><ul><li>迭代器嵌套：枚举器中可以包含多个迭代器</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;  <span class="keyword">for</span> &#123;i &lt;- <span class="number">1</span> to <span class="number">10</span></span><br><span class="line">     |       j &lt;- <span class="number">1</span> until <span class="number">3</span></span><br><span class="line">     |      <span class="keyword">if</span> i &gt; j</span><br><span class="line">     |      <span class="keyword">if</span> i % <span class="number">2</span> == <span class="number">0</span></span><br><span class="line">     |  &#125; <span class="keyword">yield</span> &#123;</span><br><span class="line">     |      i + j</span><br><span class="line">     |  &#125;</span><br><span class="line">res37: scala.collection.immutable.<span class="type">IndexedSeq</span>[<span class="type">Int</span>] = <span class="type">Vector</span>(<span class="number">3</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>)</span><br></pre></td></tr></table></figure></div><ul><li>值绑定：在for循环中使用值绑定，可以把循环的大部分逻辑都集中在定义中，可以得到一个更为简洁的 yield 表达式</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">for</span> &#123;</span><br><span class="line">     |     i &lt;- <span class="number">1</span> to <span class="number">8</span></span><br><span class="line">     |     pow = <span class="number">1</span> &lt;&lt; i</span><br><span class="line">     | &#125; <span class="keyword">yield</span> &#123;</span><br><span class="line">     |     pow</span><br><span class="line">     | &#125;</span><br><span class="line">res38: scala.collection.immutable.<span class="type">IndexedSeq</span>[<span class="type">Int</span>] = <span class="type">Vector</span>(<span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>)</span><br></pre></td></tr></table></figure></div><h3 id="while语句"><a href="#while语句" class="headerlink" title="while语句"></a>while语句</h3><p>Scala 同样支持 while 和 do/while 循环语句，不过没有 for 表达式那么常用，因为它不是表达式，不能用来返回值。事实上，while 循环和 var通常是一起使用的，要想对程序产生任何效果，while循环通常要么更新一个var要么执行I/O。Scala 没有内建的 break 和 continue 语句，但可以通过 if 表达式来改写。</p><p>语法：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// while</span></span><br><span class="line"><span class="keyword">while</span> (<span class="type">Boolean</span> expression) statement</span><br><span class="line"><span class="comment">// do ... while</span></span><br><span class="line">do statement <span class="keyword">while</span> (<span class="type">Boolean</span> expression)</span><br></pre></td></tr></table></figure></div><p>执行：</p><ul><li>while 只要条件为true，循环体就会一遍接着一遍执行；</li><li>do/while：一遍接着一遍执行循环体，直至条件为false</li></ul><p>while 和 do/while语句也有自己的用途，比如需要不断读取外部输入知道没有可读的内容为止，不过Scala提供了很多更有表述性且功能更强的方法来处理循环。</p><h2 id="try-表达式"><a href="#try-表达式" class="headerlink" title="try 表达式"></a>try 表达式</h2><p>异常传播机制：方法除了正常返回某个值外，也可以通过抛出异常终止执行，方法调用方要么捕获并处理这个异常，要么自我终止，让异常传播到更上层的方法调用方，异常通过这种方式传播，逐个展开调用栈，直至某个方法处理该异常或再没有更多方法为止。</p><h3 id="抛出异常"><a href="#抛出异常" class="headerlink" title="抛出异常"></a>抛出异常</h3><p>语法：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> classException(<span class="string">&quot;something&quot;</span>)</span><br></pre></td></tr></table></figure></div><p>执行：抛出对应类型的异常，返回值类型为Nothing</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">&quot;ddfs&quot;</span>)</span><br><span class="line">java.lang.<span class="type">IllegalArgumentException</span>: ddfs</span><br><span class="line">  ... <span class="number">28</span> elided</span><br></pre></td></tr></table></figure></div><h3 id="捕获异常"><a href="#捕获异常" class="headerlink" title="捕获异常"></a>捕获异常</h3><p>语法：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    &lt;expression1&gt;</span><br><span class="line">&#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> &lt;pattern1&gt; =&gt; &lt;expression2&gt;</span><br><span class="line">    <span class="keyword">case</span> &lt;pattern2&gt; =&gt; &lt;expression3&gt;</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    &lt;expression4&gt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>执行：</p><ul><li>try子句：首先执行代码体 <expression1>，如果出现异常则先执行 catch 子句后再执行finally 子句，如果没有异常，则直接执行finally子句</li><li>catch子句：根据try子句抛出的异常，依次尝试匹配每个模式，匹配成功则执行模式后面对应的表达式（使用方式和match表达式一致）</li><li>finally子句：将那些无论是否抛出异常都想执行的代码以表达式的形式包在finally子句里，finally子句一般都是执行清理工作，这是正确关闭非内存资源的惯用做法，比如关闭文件、套接字、数据库连接</li></ul><p>返回值：</p><ul><li>如果没有抛出异常，返回try表达式子句的结果；</li><li>如果抛出异常且被捕获，则返回对应catch子句的结果；</li><li>如果抛出异常但没有被捕获，则整个表达式没有结果；</li><li>如果finally子句包含一个显式地返回语句，则整个表达式会返回finally子句的结果，否则按前三个规则</li></ul><p>示例:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.<span class="type">FileReader</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">val</span> file = <span class="keyword">new</span> <span class="type">FileReader</span>(<span class="string">&quot;input.txt&quot;</span>)</span><br><span class="line">    <span class="comment">// 使用文件</span></span><br><span class="line">&#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="comment">// 捕获并处理异常</span></span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">FileNotFoundException</span> =&gt; <span class="string">&quot;未找到对应文件&quot;</span></span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">IOException</span> =&gt; <span class="string">&quot;处理其他I/O错误&quot;</span> </span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="comment">// 关闭文件</span></span><br><span class="line">    file.close()</span><br><span class="line">    <span class="comment">// 显式返回一个值</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;Scala中大多数控制结构都是表达式，有返回值&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Scala 只有为数不多的几个内建的控制结构：if、match、for、while、try和函数调用，由于它们有返回值，可以很好地支持函数式编程。&lt;/p&gt;
&lt;
      
    
    </summary>
    
      <category term="Scala" scheme="http://liketea.xyz/categories/Scala/"/>
    
    
      <category term="教程" scheme="http://liketea.xyz/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="Scala" scheme="http://liketea.xyz/tags/Scala/"/>
    
  </entry>
  
  <entry>
    <title>Scala 教程：Basics（五）—— 函数</title>
    <link href="http://liketea.xyz/Scala/Scala/Scala%20%E6%95%99%E7%A8%8B%EF%BC%9ABasics%EF%BC%88%E4%BA%94%EF%BC%89%E2%80%94%E2%80%94%20%E5%87%BD%E6%95%B0/"/>
    <id>http://liketea.xyz/Scala/Scala/Scala 教程：Basics（五）—— 函数/</id>
    <published>2020-08-07T08:00:00.000Z</published>
    <updated>2021-06-02T10:44:40.904Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>在Scala中，函数是命名的<strong>参数化表达式</strong>，而匿名函数实际上就是参数化表达式，函数可以出现在任何表达式可以出现的地方<br>在Scala中，函数是首类的，不仅可以得到声明和调用，还具有类型和值，函数类型和函数值可以出现在任何类型和值可以出现的地方</p></blockquote><p>对于 Scala 和其他函数式编程语言来说，函数尤其重要。标准函数式编程方法论建议我们尽可能地构建纯（pure）函数，纯函数相对于非纯函数更加稳定，他们没有状态，且与外部数据正交，事实上它们是不可破坏的纯逻辑表达式：</p><ol><li>有一个或多个输入参数，只使用输入参数完成计算，返回一个值；</li><li>对相同输入总是返回相同的值；</li><li>不使用或影响函数之外的任何数据，也不受函数之外的任何数据的影响；</li></ol><h2 id="作为传统函数"><a href="#作为传统函数" class="headerlink" title="作为传统函数"></a>作为传统函数</h2><p>Scala 函数可以像传统函数那样进行声明和调用，还可以进行嵌套和递归。</p><h3 id="函数声明"><a href="#函数声明" class="headerlink" title="函数声明"></a>函数声明</h3><p>函数声明的一般格式：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">&lt;function_name&gt;</span></span>[[type_param]](&lt;param1&gt;: &lt;param1_type&gt; [,...]): &lt;function_type&gt; = &lt;expression&gt;</span><br></pre></td></tr></table></figure></div><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20200811162237.png" alt=""></p><ul><li><code>def</code>：函数声明的关键字</li><li><code>function_name</code>：函数名</li><li><code>type_param</code>：类型参数，如果传入了类型参数，类型参数在函数定义的后续代码中就可以像普通类型一样使用</li><li><code>param1</code>：值参数</li><li><code>:</code>：每个参数后面都必须加上以冒号开始的类型标注，因为Scala并不会推断函数参数的类型</li><li><code>param1_type</code>：值参数类型</li><li><code>function_type</code>：函数的返回值类型是可选的，Scalade的<strong>类型推断</strong>会根据函数的实际返回值来推断函数的返回值类型，但在无法推断出函数返回值类型时必须显式提供函数返回值类型，比如递归函数必须显式给出函数的结果类型</li><li><code>=</code>：等号也有特别的含义，表示在函数式的世界观里，函数定义的是一个可以获取到结果值的表达式</li><li><code>expression</code>：函数体，由表达式或表达式块组成，最后一行将成为函数的返回值，如果需要在函数的表达式块结束前退出并返回一个值，可以使用return关键字显式指定函数的返回值，然后退出函数；如果函数只有一条语句，也可以选择不使用花括号</li></ul><p>没有参数的函数只是表达式的一个<strong>命名包装器</strong>：适用于通过一个函数来格式化当前数据或者返回一个固定的值</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">hi</span></span>() = <span class="string">&quot;hi&quot;</span></span><br><span class="line">hi: ()<span class="type">String</span></span><br><span class="line"></span><br><span class="line">scala&gt; hi</span><br><span class="line">res11: <span class="type">String</span> = hi</span><br><span class="line"></span><br><span class="line">scala&gt; hi()</span><br><span class="line">res12: <span class="type">String</span> = hi</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">hi</span> </span>= <span class="string">&quot;hi&quot;</span></span><br><span class="line">hi: <span class="type">String</span></span><br><span class="line"></span><br><span class="line">scala&gt; hi</span><br><span class="line">res13: <span class="type">String</span> = hi</span><br><span class="line"></span><br></pre></td></tr></table></figure></div><p>没有返回值的函数被称作<strong>过程</strong>：以一个语句结尾的函数，如果函数没有显式的返回类型，且最后是一个语句，则Scala会推导出这个函数的返回类型为Unit</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">log</span></span>(d: <span class="type">Double</span>) = println(<span class="string">f&quot;Got Value <span class="subst">$d</span>%.2f&quot;</span>)</span><br><span class="line">log: (d: <span class="type">Double</span>)<span class="type">Unit</span></span><br></pre></td></tr></table></figure></div><h3 id="函数调用"><a href="#函数调用" class="headerlink" title="函数调用"></a>函数调用</h3><p>函数调用的通用语法：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;function identifier&gt;(&lt;params&gt;)</span><br></pre></td></tr></table></figure></div><p>调用无参函数时，空括号是可选的：如果在定义时加了空括号，在调用时可加可不加，但如果在定义时没有加，在调用时也不能加，这可以避免混淆调用无括号函数与调用函数返回值。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">hi</span></span>() = <span class="string">&quot;hi&quot;</span></span><br><span class="line">hi: ()<span class="type">String</span></span><br><span class="line"></span><br><span class="line">scala&gt; hi</span><br><span class="line">res11: <span class="type">String</span> = hi</span><br><span class="line"></span><br><span class="line">scala&gt; hi()</span><br><span class="line">res12: <span class="type">String</span> = hi</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">hi</span> </span>= <span class="string">&quot;hi&quot;</span></span><br><span class="line">hi: <span class="type">String</span></span><br><span class="line"></span><br><span class="line">scala&gt; hi</span><br><span class="line">res13: <span class="type">String</span> = hi</span><br><span class="line"></span><br><span class="line">scala&gt; hi()</span><br><span class="line">&lt;console&gt;:<span class="number">13</span>: error: not enough arguments <span class="keyword">for</span> method apply: (index: <span class="type">Int</span>)<span class="type">Char</span> in <span class="class"><span class="keyword">class</span> <span class="title">StringOps</span>.</span></span><br><span class="line"><span class="type">Unspecified</span> value parameter index.</span><br><span class="line">       hi()</span><br><span class="line">         ^</span><br></pre></td></tr></table></figure></div><p>当函数只有一个参数时，可以使用表达式块来发送参数：不必先计算一个量，然后把它保存在局部值中再传递给函数，完全可以在表达式块中完成计算，表达式块会在调用函数之前计算，将表达式块的返回值用作函数的参数</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">len</span></span>(s: <span class="type">String</span>) = &#123;</span><br><span class="line">     |     s.length()</span><br><span class="line">     | &#125;</span><br><span class="line">len: (s: <span class="type">String</span>)<span class="type">Int</span></span><br><span class="line"></span><br><span class="line">scala&gt; len&#123;</span><br><span class="line">     |    <span class="keyword">val</span> x = <span class="string">&quot;Hello&quot;</span></span><br><span class="line">     |    <span class="keyword">val</span> y = <span class="string">&quot;World&quot;</span></span><br><span class="line">     |    x + <span class="string">&quot; &quot;</span> + y</span><br><span class="line">     | &#125;</span><br><span class="line">res6: <span class="type">Int</span> = <span class="number">11</span></span><br></pre></td></tr></table></figure></div><h3 id="参数传递"><a href="#参数传递" class="headerlink" title="参数传递"></a>参数传递</h3><h4 id="按顺序传参-amp-按关键字传参"><a href="#按顺序传参-amp-按关键字传参" class="headerlink" title="按顺序传参&amp;按关键字传参"></a>按顺序传参&amp;按关键字传参</h4><p>Scala 中的参数默认按照参数顺序传递，也可以按照关键字传递：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">greet</span></span>(prefix: <span class="type">String</span>, name: <span class="type">String</span>) = <span class="string">s&quot;<span class="subst">$prefix</span> <span class="subst">$name</span>&quot;</span></span><br><span class="line">greet: (prefix: <span class="type">String</span>, name: <span class="type">String</span>)<span class="type">String</span></span><br><span class="line"></span><br><span class="line">scala&gt; greet(<span class="string">&quot;Mr&quot;</span>, <span class="string">&quot;Bob&quot;</span>)</span><br><span class="line">res0: <span class="type">String</span> = <span class="type">Mr</span> <span class="type">Bob</span></span><br><span class="line"></span><br><span class="line">scala&gt; greet(name = <span class="string">&quot;Bob&quot;</span>, prefix = <span class="string">&quot;Mr&quot;</span>)</span><br><span class="line">res1: <span class="type">String</span> = <span class="type">Mr</span> <span class="type">Bob</span></span><br></pre></td></tr></table></figure></div><h4 id="默认参数"><a href="#默认参数" class="headerlink" title="默认参数"></a>默认参数</h4><p>Scala 可以为函数的任意参数指定默认值，使得调用者可以忽略这个参数：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">&lt;identifier&gt;</span></span>(&lt;identifier&gt;: &lt;<span class="class"><span class="keyword">type</span><span class="title">&gt;</span> </span>= &lt;value&gt; [,...]): &lt;<span class="class"><span class="keyword">type</span><span class="title">&gt;</span> </span>= &lt;expression&gt;</span><br></pre></td></tr></table></figure></div><p>如果默认参数后面还有非默认参数，那只能按照关键字传参，因为无法利用参数的顺序了；如果默认参数后面没有非默认参数，则可以按照顺序来传递前面的参数。</p><h4 id="变长参数"><a href="#变长参数" class="headerlink" title="变长参数"></a>变长参数</h4><p>Scala 支持vararg参数，可以定义输入参数个数可变的函数，可变参数后面不可以有非可变参数，因为无法加以区分。</p><p>语法：在参数类型后面加上 <code>*</code> 来标识这是一个可变参数</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>(items: <span class="type">Int</span>*): <span class="type">Int</span> = &#123;</span><br><span class="line">     |     <span class="keyword">var</span> total = <span class="number">0</span></span><br><span class="line">     |     <span class="keyword">for</span> (i &lt;- items) total += i</span><br><span class="line">     |     total</span><br><span class="line">     | &#125;</span><br><span class="line">sum: (items: <span class="type">Int</span>*)<span class="type">Int</span></span><br><span class="line"></span><br><span class="line">scala&gt; sum(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">res8: <span class="type">Int</span> = <span class="number">6</span></span><br></pre></td></tr></table></figure></div><h4 id="类型参数"><a href="#类型参数" class="headerlink" title="类型参数"></a>类型参数</h4><p>Scala 函数不仅可以传入“值”参数，还可以传入“类型”参数，这可以提高函数的灵活性和可重用性，这样函数参数或返回值的类型不再是固定的，而是可以由函数调用者控制。</p><p>语法：在函数名后的<code>[]</code>传入类型参数R之后，R就可以像一个具体的类型一样在后面使用了</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">&lt;identifier&gt;</span></span>[<span class="class"><span class="keyword">type</span><span class="title">-param</span>](<span class="params">&lt;value-param&gt;: &lt;type-param&gt;</span>)</span>: &lt;<span class="class"><span class="keyword">type</span><span class="title">&gt;</span> </span>= &lt;expression&gt;</span><br></pre></td></tr></table></figure></div><p>示例：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">identity</span></span>[<span class="type">R</span>](r: <span class="type">R</span>): <span class="type">R</span> = r</span><br><span class="line">identity: [<span class="type">R</span>](r: <span class="type">R</span>)<span class="type">R</span></span><br><span class="line"></span><br><span class="line">scala&gt; identity[<span class="type">String</span>](<span class="string">&quot;sds&quot;</span>)</span><br><span class="line">res9: <span class="type">String</span> = sds</span><br><span class="line"></span><br><span class="line">scala&gt; identity[<span class="type">Int</span>](<span class="number">23</span>)</span><br><span class="line">res10: <span class="type">Int</span> = <span class="number">23</span></span><br><span class="line"></span><br><span class="line">scala&gt; identity[<span class="type">Int</span>](<span class="string">&quot;fs&quot;</span>)</span><br><span class="line">&lt;console&gt;:<span class="number">13</span>: error: <span class="class"><span class="keyword">type</span> <span class="title">mismatch</span></span>;</span><br><span class="line"> found   : <span class="type">String</span>(<span class="string">&quot;fs&quot;</span>)</span><br><span class="line"> required: <span class="type">Int</span></span><br><span class="line">       identity[<span class="type">Int</span>](<span class="string">&quot;fs&quot;</span>)</span><br><span class="line">                     ^</span><br></pre></td></tr></table></figure></div><p>函数调用时，类型参数的类型推断：在调用包含类型参数的函数时，如果未明确指定类型参数的具体类型，scala会根据<strong>第一个</strong>参数列表的类型来推断类型参数的类型，如果第一个参数列表的类型也未知则会抛出异常。因此在设计柯里化函数时，往往将非函数参数放在第一个参数列表，将函数参数放在最后一个参数列表，这样函数的类型参数的具体类型可以通过第一个非函数入参的类型推断出来，而这个类型又能被继续用于对函数参数列表类型进行检查，使用者需要给出的类型信息更少，在编写函数字面量时可以更精简；</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 类型参数未指定，且第一个参数函数字面值类型未指定，抛出异常</span></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">curry</span></span>[<span class="type">T</span>](f: <span class="type">T</span> =&gt; <span class="type">T</span>)(x:<span class="type">T</span>) = f(x)</span><br><span class="line">curry: [<span class="type">T</span>](f: <span class="type">T</span> =&gt; <span class="type">T</span>)(x: <span class="type">T</span>)<span class="type">T</span></span><br><span class="line"></span><br><span class="line">scala&gt; curry(_ * <span class="number">2</span>)(<span class="number">3</span>)</span><br><span class="line">&lt;console&gt;:<span class="number">13</span>: error: missing parameter <span class="class"><span class="keyword">type</span> <span class="title">for</span> <span class="title">expanded</span> <span class="title">function</span> (<span class="params">(x$1: &lt;error&gt;</span>) <span class="title">=&gt;</span> <span class="title">x$1</span>.<span class="title">$times</span>(<span class="params">2</span>))</span></span><br><span class="line">       curry(_ * <span class="number">2</span>)(<span class="number">3</span>)</span><br><span class="line">             ^</span><br><span class="line"><span class="comment">// 类型参数的具体类型可以通过第一个参数列表的类型推断出来，继而推断出第二个参数列表的类型</span></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">curry</span></span>[<span class="type">T</span>](x: <span class="type">T</span>)(f: <span class="type">T</span> =&gt; <span class="type">T</span>) = f(x)</span><br><span class="line">curry: [<span class="type">T</span>](x: <span class="type">T</span>)(f: <span class="type">T</span> =&gt; <span class="type">T</span>)<span class="type">T</span></span><br><span class="line"></span><br><span class="line">scala&gt; curry(<span class="number">3</span>)(_ * <span class="number">2</span>)</span><br><span class="line">res97: <span class="type">Int</span> = <span class="number">6</span></span><br></pre></td></tr></table></figure></div><h3 id="递归函数"><a href="#递归函数" class="headerlink" title="递归函数"></a>递归函数</h3><p>递归函数在函数式编程中很普遍，因为他们为迭代处理数据结构或计算提供了一种很好的方法，而且不必使用可变的数据，因为每个函数调用自己的栈来存储参数。</p><p>示例：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 计算正数次幂</span></span><br><span class="line">scala&gt; greet(name = <span class="string">&quot;Bob&quot;</span>, prefix = <span class="string">&quot;Mr&quot;</span>)</span><br><span class="line">res1: <span class="type">String</span> = <span class="type">Mr</span> <span class="type">Bob</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">power</span></span>(x:<span class="type">Int</span>,n:<span class="type">Int</span>):<span class="type">Long</span> = &#123;</span><br><span class="line">     |     <span class="keyword">if</span> (n &gt; <span class="number">1</span>) x * power(x, n<span class="number">-1</span>)</span><br><span class="line">     |     <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">     | &#125;</span><br><span class="line">power: (x: <span class="type">Int</span>, n: <span class="type">Int</span>)<span class="type">Long</span></span><br><span class="line"></span><br><span class="line">scala&gt; power(<span class="number">2</span>,<span class="number">8</span>)</span><br><span class="line">res2: <span class="type">Long</span> = <span class="number">128</span></span><br></pre></td></tr></table></figure></div><p>使用递归函数可能会遇到”栈溢出“错误，为了避免这种情况，Scala编译器可以使用尾递归（tail-recursion）优化一些递归函数，使得递归调用不使用额外的栈空间，而只使用当前函数的栈空间。但是只有最后一个语句是递归调用的函数时（调用函数本身的结果作为直接返回值），Scala编译器才能完成尾递归优化。</p><p>示例：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 用尾递归的方式重写power</span></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">power</span></span>(x: <span class="type">Int</span>, n: <span class="type">Int</span>, t: <span class="type">Int</span> = <span class="number">1</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">     |     <span class="keyword">if</span> (n &lt; <span class="number">1</span>) t</span><br><span class="line">     |     <span class="keyword">else</span> power(x, n - <span class="number">1</span>, x * t)</span><br><span class="line">     | &#125;</span><br><span class="line">power: (x: <span class="type">Int</span>, n: <span class="type">Int</span>, t: <span class="type">Int</span>)<span class="type">Int</span></span><br><span class="line"></span><br><span class="line">scala&gt; power(<span class="number">2</span>, <span class="number">8</span>)</span><br><span class="line">res4: <span class="type">Int</span> = <span class="number">256</span></span><br></pre></td></tr></table></figure></div><h3 id="嵌套函数"><a href="#嵌套函数" class="headerlink" title="嵌套函数"></a>嵌套函数</h3><p>函数是命名的参数化表达式，而表达式是可以嵌套的，所以函数本身也是可以嵌套的。当需要在一个方法中重复某个逻辑，但是把它作为外部方法有没有太大意义时，可以在函数中定义一个内部函数，这个内部函数只能在该函数内部使用。</p><p>示例：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">max</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>, c: <span class="type">Int</span>) = &#123;</span><br><span class="line">     |     <span class="function"><span class="keyword">def</span> <span class="title">max</span></span>(x: <span class="type">Int</span>, y: <span class="type">Int</span>) = <span class="keyword">if</span> (x &gt; y) x <span class="keyword">else</span> y</span><br><span class="line">     |     max(a,max(b,c))</span><br><span class="line">     | &#125;</span><br><span class="line">max: (a: <span class="type">Int</span>, b: <span class="type">Int</span>, c: <span class="type">Int</span>)<span class="type">Int</span></span><br><span class="line"></span><br><span class="line">scala&gt; max(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">res7: <span class="type">Int</span> = <span class="number">3</span></span><br></pre></td></tr></table></figure></div><h2 id="作为首类函数"><a href="#作为首类函数" class="headerlink" title="作为首类函数"></a>作为首类函数</h2><blockquote><p>函数式编程的一个关键是函数应当是首类的（first-class）：函数不仅能得到声明和调用，还具有类型和值，函数类型和函数值可以出现在任何类型和值可以出现的地方</p></blockquote><h3 id="函数类型"><a href="#函数类型" class="headerlink" title="函数类型"></a>函数类型</h3><p>与函数返回值类型不同，函数类型是函数本身的类型，函数类型可以用 <code>参数类型 =&gt; 返回值类型</code> 来表示：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">([&lt;<span class="class"><span class="keyword">type</span><span class="title">&gt;</span>, ...]) <span class="title">=&gt;</span> <span class="title">&lt;type&gt;</span></span></span><br></pre></td></tr></table></figure></div><p>函数类型可以出现在任何类型可以出现的地方：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">func</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> = <span class="keyword">if</span> (a &gt; b) a <span class="keyword">else</span> b</span><br><span class="line">func: (a: <span class="type">Int</span>, b: <span class="type">Int</span>)<span class="type">Int</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 出现在变量/值声明语句中</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> x: (<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span> = func</span><br><span class="line">x: (<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span> = $$<span class="type">Lambda</span>$<span class="number">1096</span>/<span class="number">23426726</span>@<span class="number">70</span>b037ac</span><br><span class="line"></span><br><span class="line">scala&gt; x(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">res9: <span class="type">Int</span> = <span class="number">2</span></span><br><span class="line"><span class="comment">// 2. 出现在函数参数类型中</span></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">max</span></span>(a: <span class="type">Int</span>, b: (<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span>): <span class="type">Int</span> = b(a, <span class="number">3</span>)</span><br><span class="line">max: (a: <span class="type">Int</span>, b: (<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span>)<span class="type">Int</span></span><br><span class="line"></span><br><span class="line">scala&gt; max(<span class="number">1</span>, func)</span><br><span class="line">res10: <span class="type">Int</span> = <span class="number">3</span></span><br><span class="line"><span class="comment">// 3. 出现在函数返回值类型中</span></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">dummy</span></span>(): (<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span> = func</span><br><span class="line">dummy: ()(<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span></span><br><span class="line"></span><br><span class="line">scala&gt; dummy()(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">res11: <span class="type">Int</span> = <span class="number">2</span></span><br></pre></td></tr></table></figure></div><h3 id="函数值"><a href="#函数值" class="headerlink" title="函数值"></a>函数值</h3><p>与函数返回值不同，函数值是函数本身的值，每个函数值都是某个扩展自scala包的FunctionN系列当中的一个特质的类的<strong>实例</strong>，比如Function0表示不带参数的函数，Function1表示带一个参数的函数，等等。每一个FunctionN特质都有一个apply方法用来调用该函数。</p><p>函数值可以出现在任何值可以出现的地方：</p><ol><li>可以用字面值形式创建，而不必指定标识符；</li><li>可以存储在某个容器，比如值、变量或数据结构；</li><li>作为另一个函数的参数或返回值；</li></ol><p>Scala 中有一些特殊的方法来创建或返回函数值，包括：</p><ol><li>创建函数字面值/匿名函数；</li><li>当通过函数名为一个显式声明为函数类型的变量赋值时，函数名会被推断为一个函数值，而不是函数调用；</li><li>使用通配符替换部分参数来<strong>部分调用函数</strong>，将返回一个能够接收剩余参数的函数值；</li><li>函数柯里化提供了一种更加简洁的方式来实现部分调用函数；</li></ol><h4 id="匿名函数（Anonymous-function）"><a href="#匿名函数（Anonymous-function）" class="headerlink" title="匿名函数（Anonymous function）"></a>匿名函数（Anonymous function）</h4><p>匿名函数是一个没有名字的函数值，匿名函数可以用 <code>输入参数 =&gt; 返回值</code> 来表示：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">([&lt;param1&gt;: &lt;<span class="class"><span class="keyword">type</span><span class="title">&gt;</span>...]) <span class="title">=&gt;</span> <span class="title">&lt;expression&gt;</span></span></span><br></pre></td></tr></table></figure></div><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20200811162254.png" alt=""></p><p>示例：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 一个没有输入的函数字面值</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> func = () =&gt; <span class="string">&quot;hi&quot;</span></span><br><span class="line">func: () =&gt; <span class="type">String</span> = $$<span class="type">Lambda</span>$<span class="number">1182</span>/<span class="number">355159860</span>@<span class="number">42e71</span>f6c</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> doubler = (x: <span class="type">Int</span>) =&gt; x * <span class="number">2</span></span><br><span class="line">doubler: <span class="type">Int</span> =&gt; <span class="type">Int</span> = $$<span class="type">Lambda</span>$<span class="number">1181</span>/<span class="number">1140744858</span>@<span class="number">40</span>fd8aa1</span><br></pre></td></tr></table></figure></div><p>匿名函数有很多名字：</p><blockquote><p>函数字面量(function literal)：由于匿名函数的创建不必指定标识符，且可以出现在一切函数值可以出现的地方，和一般类型中的字面值作用类似；<br>Lambda表达式：C#和Java8都采用这种说法，这是从原先数学中的lambda演算语法得来的；<br>functionN：Scala编译器对函数字面量的叫法，根据输入参数的个数而定；</p></blockquote><p>当函数字面值满足以下两个条件时，甚至可以使用通配符语法把参数和箭头也给匿了：</p><ol><li>函数的显式类型在字面量之外指定，Scala可以通过类型推断推断出参数类型；</li><li>参数最多被使用一次；</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 一个参数的情形</span></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">x</span></span>(s: <span class="type">String</span>, f: <span class="type">String</span> =&gt; <span class="type">String</span>) = &#123;</span><br><span class="line">     |     <span class="keyword">if</span> (s != <span class="literal">null</span>) f(s) <span class="keyword">else</span> s</span><br><span class="line">     | &#125;</span><br><span class="line">x: (s: <span class="type">String</span>, f: <span class="type">String</span> =&gt; <span class="type">String</span>)<span class="type">String</span></span><br><span class="line"></span><br><span class="line">scala&gt; x(<span class="string">&quot;Ready&quot;</span>, _.reverse)</span><br><span class="line">res14: <span class="type">String</span> = ydaeR</span><br><span class="line"></span><br><span class="line"><span class="comment">// 多个参数的情形：通配符会按照顺序替换输入参数，通配符必须与输入参数个数一致</span></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">com</span></span>(x: <span class="type">Int</span>, y:<span class="type">Int</span>, f:(<span class="type">Int</span>, <span class="type">Int</span>)=&gt; <span class="type">Int</span>) = f(x, y)</span><br><span class="line">com: (x: <span class="type">Int</span>, y: <span class="type">Int</span>, f: (<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span>)<span class="type">Int</span></span><br><span class="line"></span><br><span class="line">scala&gt; com(<span class="number">23</span>, <span class="number">12</span>, _ * _)</span><br><span class="line">res15: <span class="type">Int</span> = <span class="number">276</span></span><br><span class="line"><span class="comment">// 使用类型参数的情形</span></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">x</span></span>[<span class="type">A</span>, <span class="type">B</span>](a: <span class="type">A</span>, b: <span class="type">A</span>, c: <span class="type">A</span>, f:(<span class="type">A</span>, <span class="type">A</span>, <span class="type">A</span>)=&gt;<span class="type">B</span>) = f(a,b,c)</span><br><span class="line">x: [<span class="type">A</span>, <span class="type">B</span>](a: <span class="type">A</span>, b: <span class="type">A</span>, c: <span class="type">A</span>, f: (<span class="type">A</span>, <span class="type">A</span>, <span class="type">A</span>) =&gt; <span class="type">B</span>)<span class="type">B</span></span><br><span class="line"></span><br><span class="line">scala&gt; x[<span class="type">Int</span>, <span class="type">Int</span>](<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,_*_+_)</span><br><span class="line">res18: <span class="type">Int</span> = <span class="number">5</span></span><br></pre></td></tr></table></figure></div><p>通配符语法在处理数据结构和集合事尤其有帮助，很多核心的排序、过滤和其他数据结构方法都会使用首类函数和占位符语法来减少调用这些方法所需的额外代码。</p><h4 id="偏函数（partial-function）"><a href="#偏函数（partial-function）" class="headerlink" title="偏函数（partial function）"></a>偏函数（partial function）</h4><p>偏函数是只对满足某些特定模式的输入进行输出的函数字面值，如果输入匹配不到任何给定模式则会导致一个Scala错误（如果要避免这样的错误可以在末尾使用一个通配符）：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> statusHandler: <span class="type">Int</span> =&gt; <span class="type">String</span> = &#123;</span><br><span class="line">     |     <span class="keyword">case</span> <span class="number">200</span> =&gt; <span class="string">&quot;Okay&quot;</span></span><br><span class="line">     |     <span class="keyword">case</span> <span class="number">400</span> =&gt; <span class="string">&quot;Your Error&quot;</span></span><br><span class="line">     |     <span class="keyword">case</span> <span class="number">500</span> =&gt; <span class="string">&quot;Our Error&quot;</span></span><br><span class="line">     | &#125;</span><br><span class="line">statusHandler: <span class="type">Int</span> =&gt; <span class="type">String</span> = $$<span class="type">Lambda</span>$<span class="number">1196</span>/<span class="number">551773385</span>@<span class="number">24</span>efdd16</span><br><span class="line"></span><br><span class="line">scala&gt; statusHandler(<span class="number">200</span>)</span><br><span class="line">res22: <span class="type">String</span> = <span class="type">Okay</span></span><br><span class="line"></span><br><span class="line">scala&gt; statusHandler(<span class="number">20</span>)</span><br><span class="line">scala.<span class="type">MatchError</span>: <span class="number">20</span> (of <span class="class"><span class="keyword">class</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Integer</span>)</span></span><br><span class="line">  at .$anonfun$statusHandler$<span class="number">1</span>(&lt;console&gt;:<span class="number">11</span>)</span><br><span class="line">  at .$anonfun$statusHandler$<span class="number">1</span>$adapted(&lt;console&gt;:<span class="number">11</span>)</span><br><span class="line">  ... <span class="number">28</span> elided</span><br></pre></td></tr></table></figure></div><p>偏函数无法单独存在，必须要赋值给变量/参数。偏函数有点像 Sql 中的 <code>case when</code> 语句，在处理集合和模式匹配时更为有用。</p><h4 id="函数名用作函数值"><a href="#函数名用作函数值" class="headerlink" title="函数名用作函数值"></a>函数名用作函数值</h4><p>函数名出现的时候会被默认视作一次函数调用，但是当将函数名赋值/传递给一个显式声明的变量/参数时，Scala会将其推断为一个函数值：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">double</span></span>(x: <span class="type">Int</span>): <span class="type">Int</span> = x * <span class="number">2</span></span><br><span class="line">double: (x: <span class="type">Int</span>)<span class="type">Int</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> myDouble: (<span class="type">Int</span>) =&gt; <span class="type">Int</span> = double</span><br><span class="line">myDouble: <span class="type">Int</span> =&gt; <span class="type">Int</span> = $$<span class="type">Lambda</span>$<span class="number">1135</span>/<span class="number">1858051117</span>@<span class="number">753</span>c7411</span><br><span class="line"></span><br><span class="line">scala&gt; myDouble(<span class="number">5</span>)</span><br><span class="line">res6: <span class="type">Int</span> = <span class="number">10</span></span><br><span class="line"><span class="comment">// 没有参数的函数不建议这样使用</span></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">func</span></span>() = <span class="string">&quot;hi&quot;</span></span><br><span class="line">func: ()<span class="type">String</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> x = func</span><br><span class="line">x: <span class="type">String</span> = hi</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> x: () =&gt; <span class="type">String</span> = func</span><br><span class="line">&lt;console&gt;:<span class="number">12</span>: warning: <span class="type">Eta</span>-expansion of zero-argument methods is deprecated. <span class="type">To</span> avoid <span class="keyword">this</span> warning, write (() =&gt; func()).</span><br><span class="line">       <span class="keyword">val</span> x: () =&gt; <span class="type">String</span> = func</span><br><span class="line">                             ^</span><br><span class="line">x: () =&gt; <span class="type">String</span> = $$<span class="type">Lambda</span>$<span class="number">1177</span>/<span class="number">572488693</span>@<span class="number">2986</span>db02</span><br></pre></td></tr></table></figure></div><h4 id="部分调用函数（partially-apply）"><a href="#部分调用函数（partially-apply）" class="headerlink" title="部分调用函数（partially apply）"></a>部分调用函数（partially apply）</h4><p>对于多参数函数，如果固定其中某些参数，剩余参数用通配符替换，将返回一个只接收剩余参数的函数值：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>, c: <span class="type">Int</span>) = a + b + c</span><br><span class="line"><span class="comment">// 返回保留一个参数的函数值</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> left1 = sum(<span class="number">1</span>, _, <span class="number">3</span>)</span><br><span class="line">left1: <span class="type">Int</span> =&gt; <span class="type">Int</span> = $$<span class="type">Lambda</span>$<span class="number">1090</span>/<span class="number">466959452</span>@<span class="number">38</span>affd02</span><br><span class="line">scala&gt; left1(<span class="number">2</span>)</span><br><span class="line">res8: <span class="type">Int</span> = <span class="number">6</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回保留两个参数的函数值</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> left2 = sum(<span class="number">1</span>, _, _)</span><br><span class="line">left2: (<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span> = $$<span class="type">Lambda</span>$<span class="number">1088</span>/<span class="number">1147105139</span>@<span class="number">27</span>f31d91</span><br><span class="line">scala&gt; left2(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">res7: <span class="type">Int</span> = <span class="number">6</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回保留三个参数，等价于 sum _</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> left3 = sum(_, _, _)</span><br><span class="line">left3: (<span class="type">Int</span>, <span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span> = $$<span class="type">Lambda</span>$<span class="number">1087</span>/<span class="number">417004859</span>@<span class="number">2954</span>c429</span><br><span class="line">scala&gt; left3(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">res6: <span class="type">Int</span> = <span class="number">6</span></span><br><span class="line"><span class="comment">// 返回保留所有参数的函数值</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> leftAll = sum _</span><br><span class="line">leftAll: (<span class="type">Int</span>, <span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span> = $$<span class="type">Lambda</span>$<span class="number">1103</span>/<span class="number">118175968</span>@<span class="number">79414283</span></span><br><span class="line"></span><br><span class="line">scala&gt; leftAll(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">res12: <span class="type">Int</span> = <span class="number">6</span></span><br></pre></td></tr></table></figure></div><h4 id="函数柯里化（function-Currying）"><a href="#函数柯里化（function-Currying）" class="headerlink" title="函数柯里化（function Currying）"></a>函数柯里化（function Currying）</h4><blockquote><p>柯里化（Currying）是以逻辑学家 Haskell Curry 命名的一种将多参数函数转化为<strong>单参数函数链</strong>的技术。某些分析技术只能应用于具有单个参数的函数，在处理多参数函数时，柯里化通过逐一固定参数来得到关于剩余参数的新的函数，这样每次只需要处理单参数函数。</p></blockquote><p>函数柯里化可以看做是部分调用函数的一种简洁语法：使用有多个参数表的函数，而不是将一个参数表分解为调用参数和非调用参数，每次调用一个函数表将返回一个函数而非函数值：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义一个多参数表的函数</span></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>(x: <span class="type">Int</span>)(y: <span class="type">Int</span>)(z: <span class="type">Int</span>): <span class="type">Int</span> = x + y + z</span><br><span class="line">sum: (x: <span class="type">Int</span>)(y: <span class="type">Int</span>)(z: <span class="type">Int</span>)<span class="type">Int</span></span><br><span class="line"><span class="comment">// 调用一个参数表将返回一个函数，这个函数默认被视为函数调用，因此报错</span></span><br><span class="line">scala&gt; sum(<span class="number">1</span>)</span><br><span class="line">&lt;console&gt;:<span class="number">13</span>: error: missing argument list <span class="keyword">for</span> method sum</span><br><span class="line"><span class="type">Unapplied</span> methods are only converted to functions when a function <span class="class"><span class="keyword">type</span> <span class="title">is</span> <span class="title">expected</span>.</span></span><br><span class="line"><span class="type">You</span> can make <span class="keyword">this</span> conversion explicit by writing `sum _` or `sum(_)(_)(_)` instead of `sum`.</span><br><span class="line">       sum(<span class="number">1</span>)</span><br><span class="line">          ^</span><br><span class="line"><span class="comment">// 使用部分调用函数语法返回一个函数值</span></span><br><span class="line">scala&gt; sum(<span class="number">1</span>) _</span><br><span class="line">res17: <span class="type">Int</span> =&gt; (<span class="type">Int</span> =&gt; <span class="type">Int</span>) = $$<span class="type">Lambda</span>$<span class="number">1143</span>/<span class="number">106305065</span>@<span class="number">26156929</span></span><br><span class="line"></span><br><span class="line">scala&gt; sum(<span class="number">1</span>)(<span class="number">2</span>) _</span><br><span class="line">res18: <span class="type">Int</span> =&gt; <span class="type">Int</span> = $$<span class="type">Lambda</span>$<span class="number">1144</span>/<span class="number">141828288</span>@<span class="number">1</span>cdb0d7b</span><br><span class="line"><span class="comment">// 函数完全调用后得到函数最终的返回值</span></span><br><span class="line">scala&gt; sum(<span class="number">1</span>)(<span class="number">2</span>)(<span class="number">3</span>)</span><br><span class="line">res19: <span class="type">Int</span> = <span class="number">6</span></span><br></pre></td></tr></table></figure></div><h3 id="高阶函数（high-order-function）"><a href="#高阶函数（high-order-function）" class="headerlink" title="高阶函数（high-order function）"></a>高阶函数（high-order function）</h3><p>如果一个函数不接收任何函数作为入参，就被称为初阶（first-order）函数，<br>高阶（high-order）函数则是包含了函数类型的参数或返回值的函数。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">safeStringOp</span></span>(s: <span class="type">String</span>, f: <span class="type">String</span> =&gt; <span class="type">String</span>) = &#123;</span><br><span class="line">     |     <span class="keyword">if</span> (s != <span class="literal">null</span>) f(s) <span class="keyword">else</span> s</span><br><span class="line">     | &#125;</span><br><span class="line">safeStringOp: (s: <span class="type">String</span>, f: <span class="type">String</span> =&gt; <span class="type">String</span>)<span class="type">String</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">reverser</span></span>(s: <span class="type">String</span>) = s.reverse</span><br><span class="line">reverser: (s: <span class="type">String</span>)<span class="type">String</span></span><br><span class="line"></span><br><span class="line">scala&gt; safeStringOp(<span class="string">&quot;Hello&quot;</span>, reverser)</span><br><span class="line">res20: <span class="type">String</span> = olleH</span><br></pre></td></tr></table></figure></div><h3 id="传名参数（by-name）"><a href="#传名参数（by-name）" class="headerlink" title="传名参数（by-name）"></a>传名参数（by-name）</h3><p>对于普通的传值参数（by-value）来说，如果向其传递一个函数调用，那么只会在参数传递的时候调用这个函数并将其<strong>返回值</strong>传递给传值参数，后面在使用这个参数的时候使用的都是它的值。而传名参数（by-name）不同，可以获取一个值，也可以获取最终返回一个值的函数，如果向这个函数传入一个值，和传值参数效果相同，但如果向它传入一个函数调用，那么每次使用这个参数时都会调用这个函数，整体上起到了“延迟调用”的效果。</p><p>传名参数的声明语法：仅仅是在参数和参数类型中间加了一个 <code>=&gt;</code>：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;identifier&gt;: =&gt; &lt;<span class="class"><span class="keyword">type</span><span class="title">&gt;</span></span></span><br></pre></td></tr></table></figure></div><p>示例：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">f</span></span>(i: <span class="type">Int</span>) = &#123;</span><br><span class="line">     |     println(<span class="string">s&quot;Hello from f(<span class="subst">$i</span>)&quot;</span>)</span><br><span class="line">     |     i</span><br><span class="line">     | &#125;</span><br><span class="line">f: (i: <span class="type">Int</span>)<span class="type">Int</span></span><br><span class="line"><span class="comment">// 传值参数</span></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">doubles</span></span>(x: <span class="type">Int</span>) = &#123;</span><br><span class="line">     |     println(<span class="string">&quot;Now doubling&quot;</span> + x)</span><br><span class="line">     |     x * <span class="number">2</span></span><br><span class="line">     | &#125;</span><br><span class="line"></span><br><span class="line">scala&gt; doubles(f(<span class="number">3</span>))</span><br><span class="line"><span class="type">Hello</span> from f(<span class="number">3</span>)</span><br><span class="line"><span class="type">Now</span> doubling3</span><br><span class="line">res5: <span class="type">Int</span> = <span class="number">6</span></span><br><span class="line"><span class="comment">// 传名参数</span></span><br><span class="line">scala&gt; <span class="function"><span class="keyword">def</span> <span class="title">doubles</span></span>(x: =&gt; <span class="type">Int</span>) = &#123;</span><br><span class="line">     |     println(<span class="string">&quot;Now doubling&quot;</span> + x)</span><br><span class="line">     |     x * <span class="number">2</span></span><br><span class="line">     | &#125;</span><br><span class="line">     </span><br><span class="line">scala&gt; doubles(f(<span class="number">3</span>))</span><br><span class="line"><span class="type">Hello</span> from f(<span class="number">3</span>)</span><br><span class="line"><span class="type">Now</span> doubling3</span><br><span class="line"><span class="type">Hello</span> from f(<span class="number">3</span>)</span><br><span class="line">res4: <span class="type">Int</span> = <span class="number">6</span></span><br><span class="line">scala&gt; doubles(<span class="number">3</span>)</span><br><span class="line"><span class="type">Now</span> doubling3</span><br><span class="line">res0: <span class="type">Int</span> = <span class="number">6</span></span><br></pre></td></tr></table></figure></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;在Scala中，函数是命名的&lt;strong&gt;参数化表达式&lt;/strong&gt;，而匿名函数实际上就是参数化表达式，函数可以出现在任何表达式可以出现的地方&lt;br&gt;在Scala中，函数是首类的，不仅可以得到声明和调用，还具有类型和值，函数类型和函数值可以出
      
    
    </summary>
    
      <category term="Scala" scheme="http://liketea.xyz/categories/Scala/"/>
    
    
      <category term="教程" scheme="http://liketea.xyz/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="Scala" scheme="http://liketea.xyz/tags/Scala/"/>
    
  </entry>
  
  <entry>
    <title>Scala 教程：Collections（〇）—— 集合框架</title>
    <link href="http://liketea.xyz/Scala/Scala/Scala%20%E6%95%99%E7%A8%8B%EF%BC%9ACollections%EF%BC%88%E3%80%87%EF%BC%89%E2%80%94%E2%80%94%20%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/"/>
    <id>http://liketea.xyz/Scala/Scala/Scala 教程：Collections（〇）—— 集合框架/</id>
    <published>2020-08-06T08:00:00.000Z</published>
    <updated>2021-06-02T10:44:40.905Z</updated>
    
    <content type="html"><![CDATA[<p>Scala 2.8 的集合框架有以下特点：</p><ol><li>易用：使用 20~50 个方法的词汇量就足以解决大部分的集合问题；</li><li>简洁：可以通过单独的一个词来执行一个或多个循环；</li><li>安全：Scala 集合的静态类型和函数性质意味着在编译时就可以捕获绝大多数错误；</li><li>快速：集合操作已经在类库中优化过；</li><li>通用：集合类提供了在一些类型上的相同操作；</li></ol><p>Seq、Map、Set 是 Scala 最重要的三种集合类（容器），此外还有 Tuple、Option 等，这些会在后面小节逐一讲解，本节将按照自顶向下的层级结构来学习不同集合类的通用特性。</p><h2 id="可变-不可变类型（Mutable-Immutable）"><a href="#可变-不可变类型（Mutable-Immutable）" class="headerlink" title="可变/不可变类型（Mutable/Immutable）"></a>可变/不可变类型（Mutable/Immutable）</h2><p>Scala 集合框架系统地区分了可变的(mutable)和不可变的(immutable)集合，并且可以很方便地在两者之间进行转换。你可以对可变集合中的元素进行增、删、改操作，你也可以对不可变类型模拟这些操作，但每个操作都会返回一个新的集合，原来的集合不会发生改变。</p><h3 id="集合类的继承树"><a href="#集合类的继承树" class="headerlink" title="集合类的继承树"></a>集合类的继承树</h3><p>Scala 所有集合类都可以在以下包中找到：</p><ul><li><code>scala.collection</code>：包中的集合既可以是可变的也可以是不可变的，下图展示了这个包中所有的集合类，这些都是高级抽象类或特质，它们通常有可变和不可变两种实现方式</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20191203214821.png" alt="-c"></p><ul><li><code>scala.collection.immutable</code> ：包中的集合类是不可变的，Scala会默认导入这个包，这意味着Scala默认使用不可变集合类，当你写下 Set 而没有加任何前缀，你会得到一个不可变的 Set，下图展示了这个包中所有的集合类</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20191204221225.png" alt="-c"></p><ul><li><code>scala.collection.mutable</code>：包中的集合类是可变的，如果你想要使用可变的集合类，通用的做法是导入<code>scala.collection.mutable</code>包即可，当你使用没有前缀的 Set 时仍然指的是一个不可变集合，当你使用 <code>mutable.Set</code>时指的是可变的集合类，下图展示了这个包中所有的集合类</li></ul><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20191203215029.png" alt="-c"></p><ul><li><code>scala.collection.generic</code>：包含了集合的构建块，集合类延迟了<code>collection.generic</code> 类中的部分操作实现</li></ul><h3 id="集合类的通用方法"><a href="#集合类的通用方法" class="headerlink" title="集合类的通用方法"></a>集合类的通用方法</h3><p>Scala 中的集合类有以下通用方法：</p><ul><li>集合创建：每一种集合都可以通过在集合类名后紧跟元素的方式进行创建</li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Traversable</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="type">Iterable</span>(<span class="string">&quot;x&quot;</span>, <span class="string">&quot;y&quot;</span>, <span class="string">&quot;z&quot;</span>)</span><br><span class="line"><span class="type">Map</span>(<span class="string">&quot;x&quot;</span> -&gt; <span class="number">24</span>, <span class="string">&quot;y&quot;</span> -&gt; <span class="number">25</span>, <span class="string">&quot;z&quot;</span> -&gt; <span class="number">26</span>)</span><br><span class="line"><span class="type">Set</span>(<span class="type">Color</span>.red, <span class="type">Color</span>.green, <span class="type">Color</span>.blue)</span><br><span class="line"><span class="type">SortedSet</span>(<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>)</span><br><span class="line"><span class="type">Buffer</span>(x, y, z)</span><br><span class="line"><span class="type">IndexedSeq</span>(<span class="number">1.0</span>, <span class="number">2.0</span>)</span><br><span class="line"><span class="type">LinearSeq</span>(a, b, c)</span><br><span class="line"><span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="type">HashMap</span>(<span class="string">&quot;x&quot;</span> -&gt; <span class="number">24</span>, <span class="string">&quot;y&quot;</span> -&gt; <span class="number">25</span>, <span class="string">&quot;z&quot;</span> -&gt; <span class="number">26</span>)</span><br></pre></td></tr></table></figure></div><ul><li>toString：所有集合类都可以用toString的方式进行打印；</li><li>返回类型一致原则：所有集合类的map方法都会返回相同类型的集合类，例如，在一个List上调用map会又生成一个List，在Set上调用会再生成一个Set，以此类推；</li><li>大多数类在集合树种都存在三种变体：root、mutable、immutable；</li></ul><h2 id="可遍历特质（Trait-Traversable）"><a href="#可遍历特质（Trait-Traversable）" class="headerlink" title="可遍历特质（Trait Traversable）"></a>可遍历特质（Trait Traversable）</h2><p>可遍历（Traversable）是容器（collection）类的最高级别特质，它唯一的抽象操作是<code>foreach</code>。<code>foreach</code> 是 <code>Traversable</code> 所有操作的基础，用于遍历容器中所有元素，并对每个元素进行指定的操作：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Elem 是容器中元素的类型，U是一个任意的返回值类型，对f的调用仅仅是容器遍历的副作用，实际上所有计算结果都被foreach抛弃（没有返回值）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foreach</span></span>[<span class="type">U</span>](f: <span class="type">Elem</span> =&gt; <span class="type">U</span>)</span><br></pre></td></tr></table></figure></div><p>要实现 Traversable 的容器类仅需要定义与之相关的方法，其他所有方法都可以从 Traversable 中继承，Traversable 定义了许多方法：</p><ol><li><strong>相加操作++（addition）</strong>表示把两个traversable对象附加在一起或者把一个迭代器的所有元素添加到traversable对象的尾部</li><li><strong>Map操作</strong>有map，flatMap和collect，它们可以通过对容器中的元素进行某些运算来生成一个新的容器</li><li><strong>转换器（Conversion）操作</strong>包括toArray，toList，toIterable，toSeq，toIndexedSeq，toStream，toSet，和toMap，它们可以按照某种特定的方法对一个Traversable 容器进行转换</li><li><strong>拷贝（Copying）操作</strong>有copyToBuffer和copyToArray。从字面意思就可以知道，它们分别用于把容器中的元素元素拷贝到一个缓冲区或者数组里</li><li><strong>Size info</strong>操作包括有isEmpty，nonEmpty，size和hasDefiniteSize</li><li><strong>元素检索（Element Retrieval）操作</strong>有head，last，headOption，lastOption和find。这些操作可以查找容器的第一个元素或者最后一个元素，或者第一个符合某种条件的元素。注意，尽管如此，但也不是所有的容器都明确定义了什么是“第一个”或”最后一个“。例如，通过哈希值储存元素的哈希集合（hashSet），每次运行哈希值都会发生改变。在这种情况下，程序每次运行都可能会导致哈希集合的”第一个“元素发生变化。如果一个容器总是以相同的规则排列元素，那这个容器是有序的。大多数容器都是有序的，但有些不是（例如哈希集合）– 排序会造成一些额外消耗。排序对于重复性测试和辅助调试是不可或缺的。这就是为什么Scala容器中的所有容器类型都把有序作为可选项。例如，带有序性的HashSet就是LinkedHashSet</li><li><strong>子容器检索（sub-collection Retrieval）操作</strong>有tail，init，slice，take，drop，takeWhilte，dropWhile，filter，filteNot和withFilter。它们都可以通过范围索引或一些论断的判断返回某些子容器</li><li><strong>拆分（Subdivision）操作</strong>有splitAt，span，partition和groupBy，它们用于把一个容器（collection）里的元素分割成多个子容器</li><li><strong>元素测试（Element test）</strong>包括有exists，forall和count，它们可以用一个给定论断来对容器中的元素进行判断</li><li><strong>折叠（Folds）操作</strong>有foldLeft，foldRight，/:，:\，reduceLeft和reduceRight，用于对连续性元素的二进制操作</li><li><strong>特殊折叠（Specific folds）</strong>包括sum, product, min, max。它们主要用于特定类型的容器（数值或比较）</li><li><strong>字符串（String）操作</strong>有mkString，addString和stringPrefix，可以将一个容器通过可选的方式转换为字符串</li><li><strong>视图（View）操作</strong>包含两个view方法的重载体。一个view对象可以当作是一个容器客观地展示</li></ol><p>Traversable对象的操作：</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20191203215045.png" alt="-c"></p><p>可以选择使用操作符记法，也可以选择点记法，这取决于个人喜好，但是没有参数的方法除外，这时必须使用点记法，为了一致性推荐使用点记法。</p><h2 id="可迭代特质（Trait-Iterable）"><a href="#可迭代特质（Trait-Iterable）" class="headerlink" title="可迭代特质（Trait Iterable）"></a>可迭代特质（Trait Iterable）</h2><p>可迭代是容器类的另一个特质，这个特质里所有方法的定义都基于一个抽象方法<code>iterator</code>，从<code>Traversable Trait</code>中继承来的foreach方法在这里也是利用 <code>iterator</code> 来实现的：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foreach</span></span>[<span class="type">U</span>](f: <span class="type">Elem</span> =&gt; <span class="type">U</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> it = iterator</span><br><span class="line">  <span class="keyword">while</span> (it.hasNext) f(it.next())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>Iterator 有两个方法返回迭代器：grouped和sliding，这些迭代器返回的不是单个元素，而是原容器元素的全部子序列，grouped方法返回元素的增量分块，sliding方法生成一个滑动元素的窗口：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> xs = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">xs: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">scala&gt; <span class="keyword">val</span> git = xs grouped <span class="number">3</span></span><br><span class="line">git: <span class="type">Iterator</span>[<span class="type">List</span>[<span class="type">Int</span>]] = non-empty iterator</span><br><span class="line">scala&gt; git.next()</span><br><span class="line">res3: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">scala&gt; git.next()</span><br><span class="line">res4: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">scala&gt; <span class="keyword">val</span> sit = xs sliding <span class="number">3</span></span><br><span class="line">sit: <span class="type">Iterator</span>[<span class="type">List</span>[<span class="type">Int</span>]] = non-empty iterator</span><br><span class="line">scala&gt; sit.next()</span><br><span class="line">res5: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">scala&gt; sit.next()</span><br><span class="line">res6: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">scala&gt; sit.next()</span><br><span class="line">res7: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure></div><p>Iterator 在 Traversable 的基础上添加了一些其他方法：</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20191203215057.png" alt="-c"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://docs.scala-lang.org/zh-cn/overviews/collections/introduction.html">Mutable和Immutable集合</a></p><p><a href="https://windor.gitbooks.io/beginners-guide-to-scala/content/chp5-the-option-type.html">类型 Option</a></p><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Scala 2.8 的集合框架有以下特点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;易用：使用 20~50 个方法的词汇量就足以解决大部分的集合问题；&lt;/li&gt;
&lt;li&gt;简洁：可以通过单独的一个词来执行一个或多个循环；&lt;/li&gt;
&lt;li&gt;安全：Scala 集合的静态类型和函数性质意味着在
      
    
    </summary>
    
      <category term="Scala" scheme="http://liketea.xyz/categories/Scala/"/>
    
    
      <category term="教程" scheme="http://liketea.xyz/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="Scala" scheme="http://liketea.xyz/tags/Scala/"/>
    
  </entry>
  
  <entry>
    <title>Scala 教程：Collections（二）—— Set</title>
    <link href="http://liketea.xyz/Scala/Scala/Scala%20%E6%95%99%E7%A8%8B%EF%BC%9ACollections%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%20Set/"/>
    <id>http://liketea.xyz/Scala/Scala/Scala 教程：Collections（二）—— Set/</id>
    <published>2020-08-04T08:00:00.000Z</published>
    <updated>2021-06-02T10:44:40.907Z</updated>
    
    <content type="html"><![CDATA[<p>Set 是不包含重复元素的可迭代对象，Scala 默认使用的是不可变集合，对集合的任何修改都会生成一个新的集合，如果你想使用可变集合，需要引用 scala.collection.mutable.Set 。</p><h2 id="Set-创建"><a href="#Set-创建" class="headerlink" title="Set 创建"></a>Set 创建</h2><p>集合的一般创建方式：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建空 Set</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> setImmut = <span class="type">Set</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 默认创建不可变集合</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> setImmut = <span class="type">Set</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">scala&gt; println(setImmut.getClass.getName)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建可变集合</span></span><br><span class="line">scala&gt; <span class="keyword">import</span> scala.collection.mutable</span><br><span class="line">scala&gt; <span class="keyword">val</span> setMut = mutable.<span class="type">Set</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">scala&gt; println(setMut.getClass.getName)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将可变集合转化为不可变集合</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> set = setMut.toSet</span><br><span class="line">scala&gt; println(set.getClass.getName)</span><br></pre></td></tr></table></figure></div><h2 id="Set-操作"><a href="#Set-操作" class="headerlink" title="Set 操作"></a>Set 操作</h2><h3 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h3><p>集合的任何操作都可以使用以下三个基本操作来表达：</p><ol><li><code>head</code>：返回集合第一个元素</li><li><code>tail</code>：返回一个集合，包含除了第一元素之外的其他元素</li><li><code>isEmpty</code>：在集合为空时返回 true</li></ol><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> site = <span class="type">Set</span>(<span class="string">&quot;Runoob&quot;</span>, <span class="string">&quot;Google&quot;</span>, <span class="string">&quot;Baidu&quot;</span>)</span><br><span class="line">scala&gt; <span class="keyword">val</span> nums: <span class="type">Set</span>[<span class="type">Int</span>] = <span class="type">Set</span>()</span><br><span class="line"></span><br><span class="line">scala&gt; println( <span class="string">&quot;第一网站是 : &quot;</span> + site.head)</span><br><span class="line">scala&gt; println( <span class="string">&quot;最后一个网站是 : &quot;</span> + site.tail)</span><br><span class="line">scala&gt; println( <span class="string">&quot;查看列表 site 是否为空 : &quot;</span> + site.isEmpty)</span><br><span class="line">scala&gt; println( <span class="string">&quot;查看 nums 是否为空 : &quot;</span> + nums.isEmpty)</span><br><span class="line"></span><br><span class="line">第一网站是 : <span class="type">Runoob</span></span><br><span class="line">最后一个网站是 : <span class="type">Set</span>(<span class="type">Google</span>, <span class="type">Baidu</span>)</span><br><span class="line">查看列表 site 是否为空 : <span class="literal">false</span></span><br><span class="line">查看 nums 是否为空 : <span class="literal">true</span></span><br></pre></td></tr></table></figure></div><h3 id="不可变-Set"><a href="#不可变-Set" class="headerlink" title="不可变 Set"></a>不可变 Set</h3><p>不可变 Set 的测、增、删、集合操作：</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20191203215331.png" alt="-c"></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> setA = <span class="type">Set</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">scala&gt; <span class="keyword">val</span> setB = <span class="type">Set</span>(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">scala&gt; <span class="keyword">val</span> setC = <span class="type">Set</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 测：判断是否包含某个元素</span></span><br><span class="line">scala&gt; println(setA.contains(<span class="number">3</span>))</span><br><span class="line">scala&gt; println(setA(<span class="number">3</span>))</span><br><span class="line"><span class="comment">// 测：判断是否是另一个集合的子集</span></span><br><span class="line">scala&gt; println(setA.subsetOf(setC))</span><br><span class="line"><span class="literal">true</span></span><br><span class="line"><span class="literal">true</span></span><br><span class="line"><span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 增：追加单个元素、多个元素、集合</span></span><br><span class="line">scala&gt; println(setA + <span class="number">4</span>)</span><br><span class="line">scala&gt; println(setA + (<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>))</span><br><span class="line">scala&gt; println(setA ++ <span class="type">Set</span>(<span class="number">3</span>,<span class="number">4</span>) )</span><br><span class="line"><span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="type">Set</span>(<span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 删：删除单个元素、多个元素、集合</span></span><br><span class="line">scala&gt; println(setA - <span class="number">3</span>)</span><br><span class="line">scala&gt; println(setA - (<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">scala&gt; println(setA -- setB)</span><br><span class="line"><span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="type">Set</span>(<span class="number">3</span>)</span><br><span class="line"><span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 删：清空集合</span></span><br><span class="line">scala&gt; println(setA.empty)</span><br><span class="line"><span class="type">Set</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查：返回集合中最小元素</span></span><br><span class="line">scala&gt; println(setA.min)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 二元操作</span></span><br><span class="line">scala&gt; println(setA &amp; setB)</span><br><span class="line">scala&gt; println(setA | setB)</span><br><span class="line">scala&gt; println(setA &amp;~ setB)</span><br><span class="line"><span class="type">Set</span>(<span class="number">3</span>)</span><br><span class="line"><span class="type">Set</span>(<span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></div><h3 id="可变-Set"><a href="#可变-Set" class="headerlink" title="可变 Set"></a>可变 Set</h3><p>可变 Set 支持不可变集合的所有操作，同时还支持对集合的原地修改操作：</p><p><img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/20191203215341.png" alt="-c"></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">import</span> scala.collection.mutable</span><br><span class="line">scala&gt; <span class="keyword">val</span> setA = mutable.<span class="type">Set</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">scala&gt; <span class="keyword">val</span> setB = mutable.<span class="type">Set</span>(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">scala&gt; <span class="keyword">val</span> setC = mutable.<span class="type">Set</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; setA += <span class="number">4</span></span><br><span class="line">scala&gt; println(setA)</span><br><span class="line"><span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">scala&gt; setA -= <span class="number">5</span></span><br><span class="line">scala&gt; println(setA)</span><br><span class="line"><span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; setA ++= setB</span><br><span class="line">scala&gt; println(setA)</span><br><span class="line"><span class="type">Set</span>(<span class="number">1</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">scala&gt; setA --= setB</span><br><span class="line">scala&gt; println(setA)</span><br><span class="line"><span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; setC.retain(x=&gt;x % <span class="number">2</span>==<span class="number">0</span>)</span><br><span class="line">scala&gt; println(setC)</span><br><span class="line"><span class="type">Set</span>(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; setB(<span class="number">999</span>) = <span class="literal">true</span></span><br><span class="line">scala&gt; println(setB)</span><br><span class="line"><span class="type">Set</span>(<span class="number">999</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure></div><p>对比 Set 和 mutable.Set：</p><ol><li>可变集合同样提供了 <code>+</code>、<code>++</code> 和 <code>-</code>、<code>--</code> 来添加或删除元素，但很少使用，因为这些操作都需要通过集合拷贝来实现，可变集合提供了更有效的更新方法 <code>+=</code>、<code>++=</code> 和 <code>-=</code>、<code>--=</code>，这些方法在集合中添加或删除元素，返回变化后的集合；</li><li>不可变集合同样提供了 <code>+=</code> 和 <code>-=</code> 操作，虽然效果相同，但它们在实现上是不同的，可变集合的<code>+=</code>是在可变集合上调用<code>+=</code>方法，它会改变s的内容，但不可变类型的<code>+=</code>却是赋值操作的简写，它是在集合上应用方法<code>+</code>，并把结果赋值给集合变量；这体现了一个重要的原则：<strong>我们通常能用一个非不可变集合的变量(var)来替换可变集合的常量(val)</strong>；</li><li>可变集合默认使用哈希表来存储集合元素，不可变集合则根据元素个数不同使用不同的方式来实现元素个数不超过4的集合可以使用单例对象来表达（较小的不可变集合往往会比可变集合更加高效），超过4个元素的不可变集合则使用trie树来实现；</li></ol><h3 id="可变-Set-和不可变-Set-相互转化"><a href="#可变-Set-和不可变-Set-相互转化" class="headerlink" title="可变 Set 和不可变 Set 相互转化"></a>可变 Set 和不可变 Set 相互转化</h3><p>可变 Set 和不可变 Set 可以通过 Seq 作为中间桥梁进行相互转化：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SCALA"><figure class="iseeu highlight /scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> set_im = <span class="type">Set</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">set_im: scala.collection.immutable.<span class="type">Set</span>[<span class="type">Int</span>] = <span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> set_mm = mutable.<span class="type">Set</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">set_mm: scala.collection.mutable.<span class="type">Set</span>[<span class="type">Int</span>] = <span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; mutable.<span class="type">Set</span>(set_im.toSeq:_*)</span><br><span class="line">res26: scala.collection.mutable.<span class="type">Set</span>[<span class="type">Int</span>] = <span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">Set</span>(set_mm.toSeq:_*)</span><br><span class="line">res27: scala.collection.immutable.<span class="type">Set</span>[<span class="type">Int</span>] = <span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure></div><h2 id="Set-选择"><a href="#Set-选择" class="headerlink" title="Set 选择"></a>Set 选择</h2><p>选择一个 Set 比选择一个 Seq 要简单得多，可以直接使用可变与不可变的 Set。SoredSet 是按内容排序存储；LinkedHashSet 是按插入顺序存储；ListSet 可以像使用 List 一样使用，按插入顺序反序存储。</p><div class="table-container"><table><thead><tr><th></th><th style="text-align:center">Immutable</th><th style="text-align:center">Mutable</th><th>Description</th></tr></thead><tbody><tr><td>BitSet</td><td style="text-align:center">✓</td><td style="text-align:center">✓</td><td>A set of “non-negative integers represented as variable-size arrays of bits packed into 64-bit words.” Used to save memory when you have a set of integers.</td></tr><tr><td>HashSet</td><td style="text-align:center">✓</td><td style="text-align:center">✓</td><td>The immutable version “implements sets using a hash trie”; the mutable version “implements sets using a hashtable.”</td></tr><tr><td>LinkedHashSet</td><td style="text-align:center"></td><td style="text-align:center">✓</td><td>A mutable set implemented using a hashtable. Returns elements in the order in which they were inserted.</td></tr><tr><td>ListSet</td><td style="text-align:center">✓</td><td style="text-align:center"></td><td>A set implemented using a list structure.</td></tr><tr><td>TreeSet</td><td style="text-align:center">✓</td><td style="text-align:center">✓</td><td>The immutable version “implements immutable sets using a tree.” The mutable version is a mutable SortedSet with “an immutable AVL Tree as underlying data structure.”</td></tr><tr><td>Set</td><td style="text-align:center">✓</td><td style="text-align:center">✓</td><td>Generic base traits, with both mutable and immutable implementations.</td></tr><tr><td>SortedSet</td><td style="text-align:center">✓</td><td style="text-align:center">✓</td><td>A base trait. (Creating a variable as a SortedSet returns a TreeSet.)</td></tr></tbody></table></div><p>集合和映射类型常用操作的性能特点：</p><div class="table-container"><table><thead><tr><th>是否可变类型</th><th>具体类型</th><th>lookup</th><th>add</th><th>remove</th><th>min</th></tr></thead><tbody><tr><td>immutable</td><td>HashSet/HashMap</td><td>eC</td><td>eC</td><td>eC</td><td>L</td></tr><tr><td>immutable</td><td>TreeSet/TreeMap</td><td>Log</td><td>Log</td><td>Log</td><td>Log</td></tr><tr><td>immutable</td><td>BitSet</td><td>C</td><td>L</td><td>L</td><td>eC1</td></tr><tr><td>immutable</td><td>ListMap</td><td>L</td><td>L</td><td>L</td><td>L</td></tr><tr><td>mutable</td><td>HashSet/HashMap</td><td>eC</td><td>eC</td><td>eC</td><td>L</td></tr><tr><td>mutable</td><td>WeakHashMap</td><td>eC</td><td>eC</td><td>eC</td><td>L</td></tr><tr><td>mutable</td><td>BitSet</td><td>C</td><td>aC</td><td>C</td><td>eC1</td></tr><tr><td>mutable</td><td>TreeSet</td><td>Log</td><td>Log</td><td>Log</td><td>Log</td></tr></tbody></table></div><p>操作说明：</p><div class="table-container"><table><thead><tr><th>操作</th><th>说明</th></tr></thead><tbody><tr><td>lookup</td><td>测试一个元素是否被包含在集合中，或者找出一个键对应的值</td></tr><tr><td>add</td><td>添加一个新的元素到一个集合中或者添加一个键值对到一个映射中。</td></tr><tr><td>remove</td><td>移除一个集合中的一个元素或者移除一个映射中一个键。</td></tr><tr><td>min</td><td>集合中的最小元素，或者映射中的最小键。</td></tr></tbody></table></div><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://www.runoob.com/scala/scala-sets.html">Scala Set(集合)</a></li><li><a href="https://docs.scala-lang.org/zh-cn/overviews/collections/sets.html">Scala 集合</a></li></ul><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Set 是不包含重复元素的可迭代对象，Scala 默认使用的是不可变集合，对集合的任何修改都会生成一个新的集合，如果你想使用可变集合，需要引用 scala.collection.mutable.Set 。&lt;/p&gt;
&lt;h2 id=&quot;Set-创建&quot;&gt;&lt;a href=&quot;#Set-
      
    
    </summary>
    
      <category term="Scala" scheme="http://liketea.xyz/categories/Scala/"/>
    
    
      <category term="教程" scheme="http://liketea.xyz/tags/%E6%95%99%E7%A8%8B/"/>
    
      <category term="Scala" scheme="http://liketea.xyz/tags/Scala/"/>
    
  </entry>
  
</feed>
