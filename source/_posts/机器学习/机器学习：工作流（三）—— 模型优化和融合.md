---
title: 机器学习：工作流（三）—— 模型优化和融合
date: 2018-10-23 20:23:53
tags: 
    - 机器学习
categories:
    - 机器学习
---

[sklearn.model_selection.GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)，用于自动搜索超参数的最优值。GridSearchCV从之前的grid_search模块移动到了model_selection模块。

## 网格搜索

使用思路：
1. 按照超参数的重要度（依赖于经验和理论）依次对参数进行调优，对于每个参数或每两个参数，调优的过程如下
2. 首先猜测待调优参数的大致范围，其余参数取初始估计值
3. 将该超参数名作为key（字符串），对应的取值范围作为value（列表）构造出param_grid字典，连通其他参数一起传入GridSearchCV构造网格搜索模型。交叉验证中最重要的是确定[评估指标metrics](http://scikit-learn.org/stable/modules/classes.html)和评估方法(传入k-fold 的indices)
4. 在使用GridSearchCV对象fit完整训练集时，会系统的遍历多种参数组合，通过交叉验证确定最佳的参数
5. 通过GridSearchCV对象的best_params_ 属性获取最佳参数，best_score_属性获取最佳性能得分

工作原理：
1. 构造原始模型，非调优参数取预估值
2. 构造调优参数字典，交叉验证性能指标和评估方法
3. 将原始模型，交叉验证参数连通其他参数连同其他参数一起传入GridSearchCV构造函数，构造网格搜索模型
4. 使用网格搜索模型fit完整训练集，开始执行网格搜索：
1. 每轮将待调优的参数的一个组合传入分类器
2. 对分类器按照所选的评估方法和评估指标进行交叉验证
3. 记录最佳参数结果，再用最佳参数在完全训练集上refit一个模型并返回该“最佳模型”（如果使用贪心算法分步选取参数的话，得到最佳参数比得到最佳模型更重要）
5. 通过训练好的网格搜索模型获取最佳参数或者直接通过它的predict方法进行预测

缺点：
1. 这个方法适合于小数据集，一旦数据的量级上去了，很难得出结果。此时通常采用一种贪心算法：拿当前对模型影响最大的参数调优，直到最优化；再拿下一个影响最大的参数调优，如此下去，直到所有的参数调整完毕。这个方法的缺点就是可能会调到局部最优而不是全局最优，但是省时间省力，巨大的优势面前，还是试一试吧，后续可以再拿bagging再优化。

## 参数解读

`class sklearn.model_selection.GridSearchCV(estimator, param_grid, scoring=None, fit_params=None, n_jobs=1, iid=True, refit=True, cv=None, verbose=0, pre_dispatch=‘2*n_jobs’, error_score=’raise’, return_train_score=True)`

1. **estimator**：所使用的分类器对象，如
`estimator = XGBClassifier( learning_rate =0.1, n_estimators=500, max_depth=5,min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,objective= 'binary:logistic', nthread=5, scale_pos_weight=1, seed=27)`，并且传入除需要确定最佳的参数之外的其他参数。每一个分类器都需要一个scoring参数，或者score方法。
2. **param_grid**：传入字典，其中当前调优参数名（字符串）作为字典的key，参数备选取值（列表）作为value
3. **scoring**：性能指标，有以下几种情形：
1. None，使用分类器默认的性能指标（如果有的话）
2. 单个值：可以是一个表示性能指标的[字符串](http://scikit-learn.org/stable/modules/model_evaluation.html)或者是一个可调用的返回性能指标的[函数](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring)；
3. 多个值：字符串列表或者是一个字典，名字作为key，可调用函数作为value
4. 自定义函数：每个计分器返回一个值，值越大说明性能越好（对于一些损失函数取相反数）
4. n_jobs：线程数，默认为1，取-1跟CPU核数一致。取代了较早版本中是nthred
5. pre_dispatch：指定总共分发的并行任务数。当n_jobs大于1时，数据将在每个运行点进行复制，这可能导致OOM，而设置pre_dispatch参数，则可以预先划分总共的job数量，使数据最多被复制pre_dispatch次
6. iid：默认True，则假设数据在folds间独立同分布，误差估计为所有样本之和，而非各个fold的平均。
7. **cv**：[交叉验证参数](http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)，有以下几种情形：
1. 默认为None，使用3-k交叉验证
2. 整数，指定fold的折数
3. 产生 trainset,valset indices（训练集-验证集索引列表）的可迭代对象或生成器
8. **refit**：默认为True，在网格搜索结束后，用最佳参数结果再次fit一遍全部数据集。
1. 重新训练的模型可以通过GridSearchCV实例的best_estimator_属性得到
2. 允许直接通过GridSearchCV实例的predict方法对新数据进行预测。
3. 同样`best_index_`, `best_score_` 和 `best_parameters_`这些属性只有在refit之后才能访问
9. verbose：日志冗长度，int：
1. 0：不输出训练过程
2：1：偶尔输出
3. `>1`：对每个子模型都输出
10. error_score :‘raise’ (default) or numeric,Value to assign to the score if an error occurs in estimator fitting. If set to ‘raise’, the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error.
11. `return_train_score`:缺省值为True，如果为False,`cv_results_`属性不会包含训练scores


## 常用属性
其中`best_*_`属性必须refit=True时才可用：

1. `cv_results_`:网格搜索结果，ndarray字典，可以被转化为DataFrame
2. `best_estimator_ `:最佳模型，当refit=True时，返回使用最佳参数在完整训练集上重新拟合的模型；
3. `best_score_`：最佳得分，`best_estimator_ `交叉验证的平均性能评估得分
4. `best_params_` :最佳参数， 在交叉验证中得到的最佳参数
5. `scorer_ `: function or a dict,网格搜索使用的评估桉树
6. `n_splits_ `:所用交叉验证的折数

## 常用方法
predict方法只有在refit=True时才可用：

1. `fit(X, y=None, groups=None, **fit_params)[source]`：重新拟合数据集。参见具体分类器的fit函数
1. `array-like`, 训练集`shape = [n_samples, n_features]`
2. y : array-like, 标签列，`shape = [n_samples] `
3. array-like, `shape = (n_samples,)`, 可选，用于划分训练集/验证集
2. `predict(X)`：调用包含了最佳参数的分类器对测试集X进行预测
3. `predict_log_proba(X)`：预测对数概率
4. `predict_proba(X)`：预测概率
5. `get_params(deep=True)`：获取该模型的参数
6. `set_params(**params)`：设置该模型的参数

## 实例

```python
>>> from sklearn import svm, datasets
>>> from sklearn.model_selection import GridSearchCV
>>> iris = datasets.load_iris()
>>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}
>>> svc = svm.SVC()
>>> clf = GridSearchCV(svc, parameters)
>>> clf.fit(iris.data, iris.target)
...
GridSearchCV(cv=None, error_score=...,
estimator=SVC(C=1.0, cache_size=..., class_weight=..., coef0=...,
decision_function_shape='ovr', degree=..., gamma=...,
kernel='rbf', max_iter=-1, probability=False,
random_state=None, shrinking=True, tol=...,
verbose=False),
fit_params=None, iid=..., n_jobs=1,
param_grid=..., pre_dispatch=..., refit=..., return_train_score=...,
scoring=..., verbose=...)
>>> sorted(clf.cv_results_.keys())
...
['mean_fit_time', 'mean_score_time', 'mean_test_score',...
'mean_train_score', 'param_C', 'param_kernel', 'params',...
'rank_test_score', 'split0_test_score',...
'split0_train_score', 'split1_test_score', 'split1_train_score',...
'split2_test_score', 'split2_train_score',...
'std_fit_time', 'std_score_time', 'std_test_score', 'std_train_score'...]
```